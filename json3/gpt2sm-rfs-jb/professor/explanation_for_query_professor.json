{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "professor"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "44",
            "description": "references to professors or academic professionals",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5509939254515083,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "44",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:28:31.021Z",
                "maxActApprox": 69.065,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    44,
                    97409,
                    68007,
                    73248,
                    6218,
                    12928,
                    78071,
                    10517,
                    36642,
                    57268,
                    86544,
                    24175,
                    38945,
                    46751,
                    16944,
                    64654,
                    54842,
                    80673,
                    89731,
                    4411,
                    91451,
                    13602,
                    30381,
                    37952,
                    61929
                ],
                "topkCosSimValues": [
                    1,
                    0.682,
                    0.6665,
                    0.6403,
                    0.6203,
                    0.5641,
                    0.5467,
                    0.5436,
                    0.5101,
                    0.5068,
                    0.4948,
                    0.4865,
                    0.4824,
                    0.4778,
                    0.466,
                    0.4496,
                    0.4487,
                    0.4411,
                    0.4342,
                    0.4323,
                    0.4296,
                    0.4259,
                    0.4254,
                    0.4248,
                    0.4224
                ],
                "neuron_alignment_indices": [
                    679,
                    631,
                    288
                ],
                "neuron_alignment_values": [
                    0.119,
                    0.105,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    631,
                    60,
                    462
                ],
                "correlated_neurons_pearson": [
                    0.012,
                    0.012,
                    0.011
                ],
                "correlated_neurons_l1": [
                    0.012,
                    0.011,
                    0.01
                ],
                "correlated_features_indices": [
                    143,
                    119,
                    44
                ],
                "correlated_features_pearson": [
                    0.003,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0,
                    0
                ],
                "neg_str": [
                    " ashore",
                    " cruc",
                    " routed",
                    " handc",
                    " leash",
                    " setback",
                    " cramped",
                    "boat",
                    " ranger",
                    " overboard"
                ],
                "neg_values": [
                    -0.724,
                    -0.695,
                    -0.693,
                    -0.692,
                    -0.686,
                    -0.673,
                    -0.658,
                    -0.649,
                    -0.642,
                    -0.637
                ],
                "pos_str": [
                    "essors",
                    "iles",
                    "iciency",
                    "icient",
                    "ession",
                    "essor",
                    "umo",
                    "ound",
                    "edes",
                    "illing"
                ],
                "pos_values": [
                    1.594,
                    1.219,
                    1.163,
                    1.116,
                    1.079,
                    1.079,
                    1.004,
                    0.952,
                    0.947,
                    0.934
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    18,
                    7,
                    3,
                    2,
                    5,
                    3,
                    1,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    3,
                    2,
                    1,
                    0,
                    1,
                    2,
                    0,
                    3,
                    1,
                    1,
                    2,
                    2,
                    1,
                    2,
                    3,
                    0,
                    2,
                    0,
                    3,
                    3,
                    4,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.814,
                    2.193,
                    3.572,
                    4.951,
                    6.329,
                    7.708,
                    9.087,
                    10.466,
                    11.845,
                    13.223,
                    14.602,
                    15.981,
                    17.36,
                    18.739,
                    20.117,
                    21.496,
                    22.875,
                    24.254,
                    25.633,
                    27.011,
                    28.39,
                    29.769,
                    31.148,
                    32.527,
                    33.906,
                    35.284,
                    36.663,
                    38.042,
                    39.421,
                    40.8,
                    42.178,
                    43.557,
                    44.936,
                    46.315,
                    47.694,
                    49.072,
                    50.451,
                    51.83,
                    53.209,
                    54.588,
                    55.966,
                    57.345,
                    58.724,
                    60.103,
                    61.482,
                    62.861,
                    64.239,
                    65.618,
                    66.997,
                    68.376
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    6,
                    14,
                    42,
                    75,
                    191,
                    371,
                    768,
                    1215,
                    1887,
                    2745,
                    3433,
                    4077,
                    4512,
                    4550,
                    4539,
                    3938,
                    3641,
                    3162,
                    2725,
                    2201,
                    1796,
                    1387,
                    996,
                    711,
                    448,
                    332,
                    191,
                    134,
                    71,
                    40,
                    20,
                    13,
                    4,
                    4,
                    4,
                    2,
                    1,
                    2,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.701,
                    -0.655,
                    -0.608,
                    -0.562,
                    -0.516,
                    -0.469,
                    -0.423,
                    -0.377,
                    -0.33,
                    -0.284,
                    -0.237,
                    -0.191,
                    -0.145,
                    -0.098,
                    -0.052,
                    -0.006,
                    0.041,
                    0.087,
                    0.134,
                    0.18,
                    0.226,
                    0.273,
                    0.319,
                    0.365,
                    0.412,
                    0.458,
                    0.504,
                    0.551,
                    0.597,
                    0.644,
                    0.69,
                    0.736,
                    0.783,
                    0.829,
                    0.875,
                    0.922,
                    0.968,
                    1.015,
                    1.061,
                    1.107,
                    1.154,
                    1.2,
                    1.246,
                    1.293,
                    1.339,
                    1.386,
                    1.432,
                    1.478,
                    1.525,
                    1.571
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "mentions of academic professionals, specifically professors",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to professors or academic professionals",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygew2cxbdb010exx12lsn1d",
                        "tokens": [
                            " to",
                            " this",
                            " idea",
                            " was",
                            " outlined",
                            " in",
                            " a",
                            " 2013",
                            " post",
                            ",",
                            " Challenges",
                            " of",
                            " Passive",
                            " Funding",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " shift",
                            " led",
                            " to",
                            " a",
                            " noticeable",
                            " improvement",
                            " in",
                            " our",
                            " ability",
                            " to",
                            " source",
                            " tangible",
                            " giving",
                            " opportunities",
                            ".",
                            "\n",
                            "\n",
                            "Examples",
                            " of",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "giving",
                            " to",
                            " learn",
                            "\u00e2\u0122",
                            "\u013f",
                            " dynamic",
                            "\n",
                            "\n",
                            "The",
                            " first",
                            " cause",
                            " we",
                            " chose",
                            " for",
                            " a",
                            " relatively",
                            " deep",
                            " investigation",
                            " \u2013",
                            " including",
                            " some",
                            " grants",
                            " \u2013",
                            " was",
                            " criminal",
                            " justice",
                            " reform",
                            " .",
                            " Of",
                            " the",
                            " causes",
                            " we",
                            " were",
                            " interested",
                            " in",
                            ",",
                            " it",
                            " seemed",
                            " to",
                            " offer",
                            " the",
                            " best",
                            " odds",
                            " of",
                            " quickly",
                            " finding",
                            " \u00e2\u0122",
                            "\u013e",
                            "sh",
                            "o",
                            "vel",
                            "-",
                            "ready",
                            "\u00e2\u0122",
                            "\u013f",
                            " giving",
                            " opportunities",
                            ",",
                            " based",
                            " on",
                            " the",
                            " comments",
                            " of",
                            " Steven",
                            " Tel",
                            "es",
                            " .",
                            " We",
                            " told",
                            " Prof",
                            ".",
                            " Tel",
                            "es",
                            " that",
                            " we",
                            " were",
                            " interested",
                            " in",
                            " making",
                            " some",
                            " initial",
                            " grants",
                            " in",
                            " this",
                            " cause",
                            ",",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "44",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 69.065,
                        "maxValueTokenIndex": 109,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            69.065,
                            8.569,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:34.412Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 69.065,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew2czbdbo10exhcif3be5",
                        "tokens": [
                            " to",
                            " this",
                            " idea",
                            " was",
                            " outlined",
                            " in",
                            " a",
                            " 2013",
                            " post",
                            ",",
                            " Challenges",
                            " of",
                            " Passive",
                            " Funding",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " shift",
                            " led",
                            " to",
                            " a",
                            " noticeable",
                            " improvement",
                            " in",
                            " our",
                            " ability",
                            " to",
                            " source",
                            " tangible",
                            " giving",
                            " opportunities",
                            ".",
                            "\n",
                            "\n",
                            "Examples",
                            " of",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "giving",
                            " to",
                            " learn",
                            "\u00e2\u0122",
                            "\u013f",
                            " dynamic",
                            "\n",
                            "\n",
                            "The",
                            " first",
                            " cause",
                            " we",
                            " chose",
                            " for",
                            " a",
                            " relatively",
                            " deep",
                            " investigation",
                            " \u2013",
                            " including",
                            " some",
                            " grants",
                            " \u2013",
                            " was",
                            " criminal",
                            " justice",
                            " reform",
                            " .",
                            " Of",
                            " the",
                            " causes",
                            " we",
                            " were",
                            " interested",
                            " in",
                            ",",
                            " it",
                            " seemed",
                            " to",
                            " offer",
                            " the",
                            " best",
                            " odds",
                            " of",
                            " quickly",
                            " finding",
                            " \u00e2\u0122",
                            "\u013e",
                            "sh",
                            "o",
                            "vel",
                            "-",
                            "ready",
                            "\u00e2\u0122",
                            "\u013f",
                            " giving",
                            " opportunities",
                            ",",
                            " based",
                            " on",
                            " the",
                            " comments",
                            " of",
                            " Steven",
                            " Tel",
                            "es",
                            " .",
                            " We",
                            " told",
                            " Prof",
                            ".",
                            " Tel",
                            "es",
                            " that",
                            " we",
                            " were",
                            " interested",
                            " in",
                            " making",
                            " some",
                            " initial",
                            " grants",
                            " in",
                            " this",
                            " cause",
                            ",",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "44",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 69.065,
                        "maxValueTokenIndex": 109,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            69.065,
                            8.569,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:34.412Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 55.252,
                        "binMax": 69.065,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew2cxbdb110exlmqmddh2",
                        "tokens": [
                            " to",
                            " state",
                            " schools",
                            ",",
                            " not",
                            " private",
                            " schools",
                            ".",
                            " Acad",
                            "emies",
                            " and",
                            " free",
                            " schools",
                            " can",
                            " also",
                            " choose",
                            " not",
                            " to",
                            " follow",
                            " it",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " an",
                            " interview",
                            " with",
                            " the",
                            " Times",
                            " Educational",
                            " Supplement",
                            " (",
                            "T",
                            "ES",
                            "),",
                            " Prof",
                            " Roberts",
                            ",",
                            " who",
                            " has",
                            " presented",
                            " a",
                            " number",
                            " of",
                            " BBC",
                            " programmes",
                            " including",
                            " The",
                            " Incredible",
                            " Human",
                            " Journey",
                            " and",
                            " Origins",
                            " of",
                            " Us",
                            ",",
                            " said",
                            ":",
                            " \u00e2\u0122",
                            "\u013e",
                            "There",
                            " should",
                            " be",
                            " regulation",
                            " that",
                            " prevents",
                            " all",
                            " schools",
                            ",",
                            " not",
                            " just",
                            " state",
                            " schools",
                            ",",
                            " from",
                            " teaching",
                            " creation",
                            "ism",
                            " because",
                            " it",
                            " is",
                            " indoctr",
                            "ination",
                            ",",
                            " it",
                            " is",
                            " planting",
                            " ideas",
                            " into",
                            " children",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " heads",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "We",
                            " should",
                            " be",
                            " teaching",
                            " children",
                            " to",
                            " be",
                            " much",
                            " more",
                            " open",
                            "-",
                            "minded",
                            ".",
                            " People",
                            " who",
                            " believe",
                            " in",
                            " creation",
                            "ism",
                            " say",
                            " that",
                            " by",
                            " teaching",
                            " evolution",
                            " you",
                            " are",
                            " indoctr",
                            "inating"
                        ],
                        "dataIndex": null,
                        "index": "44",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 65.873,
                        "maxValueTokenIndex": 35,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            65.873,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:34.412Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 69.065,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "64654",
            "description": "references to individuals holding academic titles or positions, particularly professors",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5421083296601978,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "64654",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:52:58.223Z",
                "maxActApprox": 56.254,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    64654,
                    46751,
                    97409,
                    93548,
                    35435,
                    42428,
                    64882,
                    74864,
                    17380,
                    43982,
                    25167,
                    53510,
                    38575,
                    29411,
                    7003,
                    86615,
                    3486,
                    27016,
                    44,
                    48115,
                    9418,
                    84880,
                    78206,
                    9804,
                    15503
                ],
                "topkCosSimValues": [
                    1,
                    0.7346,
                    0.7089,
                    0.5919,
                    0.5586,
                    0.544,
                    0.5384,
                    0.5211,
                    0.4974,
                    0.4959,
                    0.4917,
                    0.484,
                    0.4795,
                    0.4746,
                    0.4722,
                    0.4697,
                    0.4636,
                    0.4527,
                    0.4496,
                    0.4442,
                    0.4432,
                    0.4382,
                    0.4371,
                    0.4321,
                    0.4315
                ],
                "neuron_alignment_indices": [
                    288,
                    679,
                    302
                ],
                "neuron_alignment_values": [
                    0.137,
                    0.126,
                    0.107
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    414,
                    204,
                    302
                ],
                "correlated_neurons_pearson": [
                    0.02,
                    0.019,
                    0.019
                ],
                "correlated_neurons_l1": [
                    0.018,
                    0.019,
                    0.02
                ],
                "correlated_features_indices": [
                    64715,
                    64602,
                    64657
                ],
                "correlated_features_pearson": [
                    0.001,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0.001,
                    0
                ],
                "neg_str": [
                    " Bundy",
                    " leash",
                    " spont",
                    "opter",
                    "MSN",
                    "\u00e3\u0125\u00bc\u00e3\u0125\u00b3",
                    " strang",
                    " territ",
                    " Pradesh",
                    " gratification"
                ],
                "neg_values": [
                    -0.645,
                    -0.638,
                    -0.622,
                    -0.604,
                    -0.602,
                    -0.601,
                    -0.595,
                    -0.59,
                    -0.582,
                    -0.579
                ],
                "pos_str": [
                    " emer",
                    "essors",
                    " specializing",
                    "itatively",
                    "iate",
                    "essor",
                    " professor",
                    " PhD",
                    " doctoral",
                    "hips"
                ],
                "pos_values": [
                    1.309,
                    1.131,
                    1.058,
                    0.999,
                    0.955,
                    0.953,
                    0.923,
                    0.882,
                    0.869,
                    0.867
                ],
                "frac_nonzero": 0.00012,
                "freq_hist_data_bar_heights": [
                    46,
                    39,
                    29,
                    15,
                    9,
                    11,
                    10,
                    7,
                    10,
                    12,
                    2,
                    7,
                    6,
                    8,
                    7,
                    8,
                    1,
                    4,
                    8,
                    4,
                    5,
                    6,
                    3,
                    3,
                    2,
                    7,
                    3,
                    4,
                    3,
                    3,
                    4,
                    5,
                    4,
                    1,
                    3,
                    2,
                    6,
                    7,
                    1,
                    2,
                    2,
                    3,
                    8,
                    9,
                    12,
                    10,
                    9,
                    7,
                    4,
                    6
                ],
                "freq_hist_data_bar_values": [
                    0.582,
                    1.707,
                    2.832,
                    3.956,
                    5.081,
                    6.206,
                    7.33,
                    8.455,
                    9.58,
                    10.704,
                    11.829,
                    12.954,
                    14.078,
                    15.203,
                    16.328,
                    17.452,
                    18.577,
                    19.702,
                    20.826,
                    21.951,
                    23.076,
                    24.2,
                    25.325,
                    26.45,
                    27.574,
                    28.699,
                    29.824,
                    30.948,
                    32.073,
                    33.198,
                    34.322,
                    35.447,
                    36.572,
                    37.696,
                    38.821,
                    39.946,
                    41.07,
                    42.195,
                    43.32,
                    44.444,
                    45.569,
                    46.694,
                    47.818,
                    48.943,
                    50.068,
                    51.192,
                    52.317,
                    53.442,
                    54.566,
                    55.691
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    13,
                    18,
                    51,
                    98,
                    190,
                    365,
                    606,
                    891,
                    1409,
                    1983,
                    2599,
                    3130,
                    3805,
                    4271,
                    4493,
                    4398,
                    4114,
                    3780,
                    3333,
                    2672,
                    2125,
                    1616,
                    1235,
                    913,
                    660,
                    472,
                    325,
                    239,
                    143,
                    125,
                    76,
                    34,
                    16,
                    15,
                    11,
                    9,
                    8,
                    5,
                    1,
                    3,
                    0,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.625,
                    -0.586,
                    -0.547,
                    -0.508,
                    -0.469,
                    -0.43,
                    -0.391,
                    -0.352,
                    -0.313,
                    -0.274,
                    -0.234,
                    -0.195,
                    -0.156,
                    -0.117,
                    -0.078,
                    -0.039,
                    0,
                    0.039,
                    0.078,
                    0.117,
                    0.156,
                    0.195,
                    0.235,
                    0.274,
                    0.313,
                    0.352,
                    0.391,
                    0.43,
                    0.469,
                    0.508,
                    0.547,
                    0.586,
                    0.625,
                    0.664,
                    0.703,
                    0.743,
                    0.782,
                    0.821,
                    0.86,
                    0.899,
                    0.938,
                    0.977,
                    1.016,
                    1.055,
                    1.094,
                    1.133,
                    1.172,
                    1.212,
                    1.251,
                    1.29
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to academic positions, particularly the term \"professor\"",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to individuals holding academic titles or positions, particularly professors",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghwnihoc4c10ex5ossyetk",
                        "tokens": [
                            " because",
                            " the",
                            " plan",
                            " will",
                            " generate",
                            " enough",
                            " economic",
                            " growth",
                            " to",
                            " essentially",
                            " pay",
                            " for",
                            " itself",
                            ".",
                            " The",
                            " most",
                            " optimistic",
                            " projections",
                            " of",
                            " the",
                            " likely",
                            " economic",
                            " benefits",
                            " of",
                            " the",
                            " tax",
                            " cuts",
                            " are",
                            " driven",
                            " by",
                            " increased",
                            " trade",
                            " deficits",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "I",
                            " do",
                            " expect",
                            " a",
                            " major",
                            " trade",
                            " deficit",
                            ",",
                            " absolutely",
                            ",",
                            " as",
                            " part",
                            " of",
                            " this",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Laure",
                            "nce",
                            " J",
                            ".",
                            " Kot",
                            "lik",
                            "off",
                            ",",
                            " a",
                            " professor",
                            " of",
                            " economics",
                            " at",
                            " Boston",
                            " University",
                            " who",
                            " supports",
                            " the",
                            " proposed",
                            " tax",
                            " cuts",
                            " and",
                            " whose",
                            " analysis",
                            " of",
                            " the",
                            " economic",
                            " benefits",
                            " has",
                            " been",
                            " cited",
                            " by",
                            " the",
                            " White",
                            " House",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "If",
                            " this",
                            " tax",
                            " plan",
                            " works",
                            ",",
                            " it",
                            " works",
                            " because",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " becomes",
                            " more",
                            " open",
                            " to",
                            " trade",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "K",
                            "ot",
                            "lik",
                            "off",
                            " also",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "this",
                            " is"
                        ],
                        "dataIndex": null,
                        "index": "64654",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.254,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            56.254,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:53:01.142Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 56.253,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghwniioc4d10exz1bucadx",
                        "tokens": [
                            " Public",
                            " Safety",
                            " in",
                            " the",
                            " Interior",
                            " of",
                            " the",
                            " United",
                            " States",
                            ",",
                            " which",
                            " instructed",
                            " the",
                            " ICE",
                            " Director",
                            " to",
                            " make",
                            " this",
                            " report",
                            " public",
                            ".",
                            "\n",
                            "\n",
                            "L",
                            "ilia",
                            " Vel",
                            "\u00c3\u00a1s",
                            "quez",
                            ",",
                            " an",
                            " associate",
                            " professor",
                            " of",
                            " law",
                            " at",
                            " the",
                            " University",
                            " of",
                            " California",
                            " at",
                            " San",
                            " Diego",
                            ",",
                            " told",
                            " Univ",
                            "ision",
                            " that",
                            " the",
                            " federal",
                            " government",
                            " is",
                            " not",
                            " breaking",
                            " any",
                            " law",
                            " by",
                            " publishing",
                            " the",
                            " list",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "It",
                            " has",
                            " the",
                            " right",
                            " to",
                            " do",
                            " so",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " says",
                            " the",
                            " lawyer",
                            ",",
                            " who",
                            " has",
                            " worked",
                            " in",
                            " immigration",
                            " law",
                            " for",
                            " more",
                            " than",
                            " 25",
                            " years",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Looking",
                            " for",
                            " them",
                            " is",
                            " a",
                            " priority",
                            " especially",
                            " if",
                            " they",
                            " are",
                            " people",
                            " who",
                            " pose",
                            " a",
                            " threat",
                            " to",
                            " public",
                            " and",
                            " national",
                            " security",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " risks",
                            ",",
                            " she",
                            " adds",
                            ",",
                            " are",
                            " when",
                            " people",
                            " are",
                            " detained"
                        ],
                        "dataIndex": null,
                        "index": "64654",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.216,
                        "maxValueTokenIndex": 31,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            56.216,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:53:01.142Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 56.253,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghwniioc4e10exfrdu5a4m",
                        "tokens": [
                            " Medicine",
                            ".",
                            "\n",
                            "\n",
                            "Of",
                            " initial",
                            " hospital",
                            " admissions",
                            " for",
                            " firearms",
                            " injuries",
                            ",",
                            " 43",
                            " percent",
                            " were",
                            " in",
                            " the",
                            " South",
                            ".",
                            " The",
                            " West",
                            " and",
                            " Midwest",
                            " each",
                            " had",
                            " 20",
                            " percent",
                            " of",
                            " hospital",
                            "izations",
                            ",",
                            " while",
                            " the",
                            " Northeast",
                            " claimed",
                            " 16",
                            " percent",
                            ".",
                            " More",
                            " than",
                            " a",
                            " third",
                            " of",
                            " patients",
                            " treated",
                            " in",
                            " the",
                            " South",
                            " were",
                            " uninsured",
                            ".",
                            "\n",
                            "\n",
                            "Dr",
                            ".",
                            " Thomas",
                            " We",
                            "iser",
                            ",",
                            " an",
                            " associate",
                            " professor",
                            " of",
                            " surgery",
                            ",",
                            " and",
                            " Sar",
                            "abeth",
                            " Sp",
                            "itzer",
                            ",",
                            " a",
                            " medical",
                            " student",
                            ",",
                            " analyzed",
                            " in",
                            "patient",
                            " hospital",
                            " records",
                            " to",
                            " conclude",
                            " that",
                            " the",
                            " initial",
                            " hospital",
                            "ization",
                            " of",
                            " patients",
                            " wounded",
                            " by",
                            " guns",
                            " over",
                            " the",
                            " eight",
                            "-",
                            "year",
                            " period",
                            " cost",
                            " Americans",
                            " more",
                            " than",
                            " $",
                            "6",
                            ".",
                            "6",
                            " billion",
                            ".",
                            " The",
                            " researchers",
                            " used",
                            " a",
                            " sample",
                            " of",
                            " more",
                            " than",
                            " 250",
                            ",",
                            "000",
                            " patients",
                            " admitted",
                            " to",
                            " American",
                            " hospitals",
                            " with",
                            " gunshot",
                            " injuries"
                        ],
                        "dataIndex": null,
                        "index": "64654",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 55.598,
                        "maxValueTokenIndex": 61,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.443,
                            55.598,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:53:01.142Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 56.253,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "73248",
            "description": "terms related to academic and professional titles, particularly \"professor\" and its variations",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5385626875497522,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "73248",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:02:16.310Z",
                "maxActApprox": 42.505,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    73248,
                    78071,
                    6218,
                    44,
                    82084,
                    83641,
                    46751,
                    10517,
                    98235,
                    92240,
                    76490,
                    94665,
                    81565,
                    7692,
                    76233,
                    4282,
                    56217,
                    25684,
                    73889,
                    1825,
                    35820,
                    35193,
                    83200,
                    44695,
                    65418
                ],
                "topkCosSimValues": [
                    1,
                    0.7921,
                    0.7639,
                    0.6403,
                    0.4589,
                    0.4237,
                    0.422,
                    0.4121,
                    0.3954,
                    0.3942,
                    0.3938,
                    0.3914,
                    0.3823,
                    0.3762,
                    0.3693,
                    0.363,
                    0.3593,
                    0.3561,
                    0.352,
                    0.3519,
                    0.3518,
                    0.3505,
                    0.3504,
                    0.3478,
                    0.3467
                ],
                "neuron_alignment_indices": [
                    575,
                    288,
                    60
                ],
                "neuron_alignment_values": [
                    0.134,
                    0.117,
                    0.115
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    60,
                    631,
                    90
                ],
                "correlated_neurons_pearson": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_neurons_l1": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_features_indices": [
                    73188,
                    73248,
                    73223
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "MENTS",
                    " halfway",
                    "warm",
                    "MENT",
                    " Mali",
                    "doors",
                    "forth",
                    " shortened",
                    " Weir",
                    " Warriors"
                ],
                "neg_values": [
                    -0.837,
                    -0.738,
                    -0.713,
                    -0.674,
                    -0.656,
                    -0.651,
                    -0.65,
                    -0.635,
                    -0.631,
                    -0.609
                ],
                "pos_str": [
                    "essor",
                    "iles",
                    "iciency",
                    "ound",
                    "essors",
                    "iler",
                    "ession",
                    "icient",
                    "iling",
                    "ilers"
                ],
                "pos_values": [
                    1.483,
                    1.343,
                    1.315,
                    1.266,
                    1.262,
                    1.247,
                    1.218,
                    1.178,
                    1.176,
                    1.171
                ],
                "frac_nonzero": 4e-05,
                "freq_hist_data_bar_heights": [
                    18,
                    11,
                    6,
                    2,
                    4,
                    3,
                    1,
                    3,
                    1,
                    1,
                    0,
                    1,
                    0,
                    1,
                    1,
                    2,
                    2,
                    1,
                    3,
                    2,
                    7,
                    4,
                    3,
                    4,
                    2,
                    5,
                    3,
                    2,
                    0,
                    3,
                    3,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    3,
                    3,
                    3,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.456,
                    1.306,
                    2.155,
                    3.004,
                    3.854,
                    4.703,
                    5.553,
                    6.402,
                    7.252,
                    8.101,
                    8.951,
                    9.8,
                    10.65,
                    11.499,
                    12.349,
                    13.198,
                    14.048,
                    14.897,
                    15.746,
                    16.596,
                    17.445,
                    18.295,
                    19.144,
                    19.994,
                    20.843,
                    21.693,
                    22.542,
                    23.392,
                    24.241,
                    25.091,
                    25.94,
                    26.79,
                    27.639,
                    28.488,
                    29.338,
                    30.187,
                    31.037,
                    31.886,
                    32.736,
                    33.585,
                    34.435,
                    35.284,
                    36.134,
                    36.983,
                    37.833,
                    38.682,
                    39.532,
                    40.381,
                    41.23,
                    42.08
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    2,
                    5,
                    16,
                    34,
                    82,
                    193,
                    421,
                    838,
                    1452,
                    2355,
                    3209,
                    4187,
                    4815,
                    5149,
                    4891,
                    4532,
                    3936,
                    3166,
                    2494,
                    1962,
                    1476,
                    1161,
                    906,
                    725,
                    600,
                    449,
                    325,
                    284,
                    197,
                    137,
                    94,
                    60,
                    40,
                    18,
                    14,
                    9,
                    5,
                    2,
                    1,
                    2,
                    3,
                    2,
                    2,
                    2,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.814,
                    -0.768,
                    -0.721,
                    -0.675,
                    -0.628,
                    -0.582,
                    -0.536,
                    -0.489,
                    -0.443,
                    -0.396,
                    -0.35,
                    -0.304,
                    -0.257,
                    -0.211,
                    -0.164,
                    -0.118,
                    -0.072,
                    -0.025,
                    0.021,
                    0.068,
                    0.114,
                    0.16,
                    0.207,
                    0.253,
                    0.3,
                    0.346,
                    0.392,
                    0.439,
                    0.485,
                    0.532,
                    0.578,
                    0.624,
                    0.671,
                    0.717,
                    0.764,
                    0.81,
                    0.857,
                    0.903,
                    0.949,
                    0.996,
                    1.042,
                    1.089,
                    1.135,
                    1.181,
                    1.228,
                    1.274,
                    1.321,
                    1.367,
                    1.413,
                    1.46
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " occurrences of the word \"Prof\" and its variations, indicating references to professors or professional titles",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " instances of the term \"prof\" in various contexts, indicating a focus on professional titles or qualifications",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "terms related to academic and professional titles, particularly \"professor\" and its variations",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi8oifuuvh10extionc3n7",
                        "tokens": [
                            ",",
                            " but",
                            " you",
                            "'re",
                            " here",
                            ",",
                            " so",
                            " you",
                            " better",
                            " f",
                            "------",
                            " deal",
                            " with",
                            " it",
                            ",",
                            " girl",
                            ".\"",
                            "<|endoftext|>",
                            "Overview",
                            "\n",
                            "\n",
                            "A",
                            "VE",
                            "X",
                            "IR",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " A",
                            "VD",
                            "3",
                            "U",
                            "H",
                            "3",
                            "100",
                            "12",
                            "04",
                            "G",
                            "-",
                            "2",
                            "CI",
                            " is",
                            " a",
                            " Dual",
                            " channel",
                            " 512",
                            "M",
                            " x",
                            " 64",
                            "-",
                            "bit",
                            " 4",
                            "GB",
                            " single",
                            " side",
                            " (",
                            "40",
                            "96",
                            "MB",
                            ")",
                            " x",
                            "2",
                            " DDR",
                            "3",
                            "-",
                            "3",
                            "100",
                            "MHz",
                            " CL",
                            "12",
                            " S",
                            "DR",
                            "AM",
                            "(",
                            "S",
                            "ynchronous",
                            " DR",
                            "AM",
                            ")",
                            " memory",
                            " modules",
                            ",",
                            " based",
                            " on",
                            " eight",
                            " 512",
                            "M",
                            " x",
                            " 8",
                            "\u2013",
                            "bit",
                            " DDR",
                            "3",
                            " FB",
                            "GA",
                            " components",
                            " per",
                            " module",
                            ".",
                            " Each",
                            " module",
                            " kit",
                            " supports",
                            " Intel",
                            " X",
                            "MP",
                            " 1",
                            ".",
                            "3",
                            " (",
                            "Extreme",
                            " Memory",
                            " Prof",
                            "iles",
                            ").",
                            " Total",
                            " kit",
                            " capacity",
                            " is",
                            " 8",
                            "GB",
                            ".",
                            " It",
                            " supports",
                            " newest",
                            " generation",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "73248",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.505,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.505,
                            3.583,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:22.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 34.004,
                        "binMax": 42.505,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi8oiduuuv10exnvub6ol3",
                        "tokens": [
                            ",",
                            " but",
                            " you",
                            "'re",
                            " here",
                            ",",
                            " so",
                            " you",
                            " better",
                            " f",
                            "------",
                            " deal",
                            " with",
                            " it",
                            ",",
                            " girl",
                            ".\"",
                            "<|endoftext|>",
                            "Overview",
                            "\n",
                            "\n",
                            "A",
                            "VE",
                            "X",
                            "IR",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " A",
                            "VD",
                            "3",
                            "U",
                            "H",
                            "3",
                            "100",
                            "12",
                            "04",
                            "G",
                            "-",
                            "2",
                            "CI",
                            " is",
                            " a",
                            " Dual",
                            " channel",
                            " 512",
                            "M",
                            " x",
                            " 64",
                            "-",
                            "bit",
                            " 4",
                            "GB",
                            " single",
                            " side",
                            " (",
                            "40",
                            "96",
                            "MB",
                            ")",
                            " x",
                            "2",
                            " DDR",
                            "3",
                            "-",
                            "3",
                            "100",
                            "MHz",
                            " CL",
                            "12",
                            " S",
                            "DR",
                            "AM",
                            "(",
                            "S",
                            "ynchronous",
                            " DR",
                            "AM",
                            ")",
                            " memory",
                            " modules",
                            ",",
                            " based",
                            " on",
                            " eight",
                            " 512",
                            "M",
                            " x",
                            " 8",
                            "\u2013",
                            "bit",
                            " DDR",
                            "3",
                            " FB",
                            "GA",
                            " components",
                            " per",
                            " module",
                            ".",
                            " Each",
                            " module",
                            " kit",
                            " supports",
                            " Intel",
                            " X",
                            "MP",
                            " 1",
                            ".",
                            "3",
                            " (",
                            "Extreme",
                            " Memory",
                            " Prof",
                            "iles",
                            ").",
                            " Total",
                            " kit",
                            " capacity",
                            " is",
                            " 8",
                            "GB",
                            ".",
                            " It",
                            " supports",
                            " newest",
                            " generation",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "73248",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.505,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.505,
                            3.583,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:22.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 42.505,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi8oiduuuw10exivjqdc30",
                        "tokens": [
                            " Google",
                            " apps",
                            " with",
                            " its",
                            " 1",
                            ".",
                            "5",
                            "GHz",
                            " quad",
                            "-",
                            "core",
                            " processor",
                            ",",
                            " and",
                            " 5",
                            ".",
                            "1",
                            " surround",
                            " sound",
                            " lends",
                            " clarity",
                            " to",
                            " business",
                            " calls",
                            " and",
                            " video",
                            " game",
                            " sound",
                            " effects",
                            ".",
                            "\n",
                            "\n",
                            "C",
                            "NET",
                            " Editor",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Choice",
                            " Tablet",
                            "\n",
                            "\n",
                            "C",
                            "NET",
                            " called",
                            " the",
                            " ASUS",
                            " Google",
                            " Nexus",
                            " 7",
                            " \u00e2\u0122",
                            "\u013e",
                            "the",
                            " best",
                            " tablet",
                            " value",
                            " on",
                            " the",
                            " market",
                            "\u00e2\u0122",
                            "\u013f",
                            " because",
                            " of",
                            " its",
                            " HD",
                            " screen",
                            ",",
                            " battery",
                            " life",
                            ",",
                            " and",
                            " speedy",
                            " performance",
                            ".",
                            " The",
                            " latter",
                            " is",
                            " thanks",
                            " to",
                            " the",
                            " quad",
                            "-",
                            "core",
                            " processor",
                            ",",
                            " which",
                            " the",
                            " review",
                            " notes",
                            " helps",
                            " seamlessly",
                            " power",
                            " racing",
                            " games",
                            " and",
                            " create",
                            " \u00e2\u0122",
                            "\u013e",
                            "the",
                            " best",
                            "-",
                            "performing",
                            " small",
                            " tablet",
                            " for",
                            " gaming",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Create",
                            " Kid",
                            "-",
                            "Friend",
                            "ly",
                            " Prof",
                            "iles",
                            " with",
                            " Android",
                            " 4",
                            ".",
                            "3",
                            "\n",
                            "\n",
                            "You",
                            " can"
                        ],
                        "dataIndex": null,
                        "index": "73248",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.245,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.245,
                            2.185,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:22.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 42.505,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "64654",
            "description": "references to academic positions, particularly the term \"professor\"",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5316485445708989,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "64654",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:52:58.223Z",
                "maxActApprox": 56.254,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    64654,
                    46751,
                    97409,
                    93548,
                    35435,
                    42428,
                    64882,
                    74864,
                    17380,
                    43982,
                    25167,
                    53510,
                    38575,
                    29411,
                    7003,
                    86615,
                    3486,
                    27016,
                    44,
                    48115,
                    9418,
                    84880,
                    78206,
                    9804,
                    15503
                ],
                "topkCosSimValues": [
                    1,
                    0.7346,
                    0.7089,
                    0.5919,
                    0.5586,
                    0.544,
                    0.5384,
                    0.5211,
                    0.4974,
                    0.4959,
                    0.4917,
                    0.484,
                    0.4795,
                    0.4746,
                    0.4722,
                    0.4697,
                    0.4636,
                    0.4527,
                    0.4496,
                    0.4442,
                    0.4432,
                    0.4382,
                    0.4371,
                    0.4321,
                    0.4315
                ],
                "neuron_alignment_indices": [
                    288,
                    679,
                    302
                ],
                "neuron_alignment_values": [
                    0.137,
                    0.126,
                    0.107
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    414,
                    204,
                    302
                ],
                "correlated_neurons_pearson": [
                    0.02,
                    0.019,
                    0.019
                ],
                "correlated_neurons_l1": [
                    0.018,
                    0.019,
                    0.02
                ],
                "correlated_features_indices": [
                    64715,
                    64602,
                    64657
                ],
                "correlated_features_pearson": [
                    0.001,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0.001,
                    0
                ],
                "neg_str": [
                    " Bundy",
                    " leash",
                    " spont",
                    "opter",
                    "MSN",
                    "\u00e3\u0125\u00bc\u00e3\u0125\u00b3",
                    " strang",
                    " territ",
                    " Pradesh",
                    " gratification"
                ],
                "neg_values": [
                    -0.645,
                    -0.638,
                    -0.622,
                    -0.604,
                    -0.602,
                    -0.601,
                    -0.595,
                    -0.59,
                    -0.582,
                    -0.579
                ],
                "pos_str": [
                    " emer",
                    "essors",
                    " specializing",
                    "itatively",
                    "iate",
                    "essor",
                    " professor",
                    " PhD",
                    " doctoral",
                    "hips"
                ],
                "pos_values": [
                    1.309,
                    1.131,
                    1.058,
                    0.999,
                    0.955,
                    0.953,
                    0.923,
                    0.882,
                    0.869,
                    0.867
                ],
                "frac_nonzero": 0.00012,
                "freq_hist_data_bar_heights": [
                    46,
                    39,
                    29,
                    15,
                    9,
                    11,
                    10,
                    7,
                    10,
                    12,
                    2,
                    7,
                    6,
                    8,
                    7,
                    8,
                    1,
                    4,
                    8,
                    4,
                    5,
                    6,
                    3,
                    3,
                    2,
                    7,
                    3,
                    4,
                    3,
                    3,
                    4,
                    5,
                    4,
                    1,
                    3,
                    2,
                    6,
                    7,
                    1,
                    2,
                    2,
                    3,
                    8,
                    9,
                    12,
                    10,
                    9,
                    7,
                    4,
                    6
                ],
                "freq_hist_data_bar_values": [
                    0.582,
                    1.707,
                    2.832,
                    3.956,
                    5.081,
                    6.206,
                    7.33,
                    8.455,
                    9.58,
                    10.704,
                    11.829,
                    12.954,
                    14.078,
                    15.203,
                    16.328,
                    17.452,
                    18.577,
                    19.702,
                    20.826,
                    21.951,
                    23.076,
                    24.2,
                    25.325,
                    26.45,
                    27.574,
                    28.699,
                    29.824,
                    30.948,
                    32.073,
                    33.198,
                    34.322,
                    35.447,
                    36.572,
                    37.696,
                    38.821,
                    39.946,
                    41.07,
                    42.195,
                    43.32,
                    44.444,
                    45.569,
                    46.694,
                    47.818,
                    48.943,
                    50.068,
                    51.192,
                    52.317,
                    53.442,
                    54.566,
                    55.691
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    13,
                    18,
                    51,
                    98,
                    190,
                    365,
                    606,
                    891,
                    1409,
                    1983,
                    2599,
                    3130,
                    3805,
                    4271,
                    4493,
                    4398,
                    4114,
                    3780,
                    3333,
                    2672,
                    2125,
                    1616,
                    1235,
                    913,
                    660,
                    472,
                    325,
                    239,
                    143,
                    125,
                    76,
                    34,
                    16,
                    15,
                    11,
                    9,
                    8,
                    5,
                    1,
                    3,
                    0,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.625,
                    -0.586,
                    -0.547,
                    -0.508,
                    -0.469,
                    -0.43,
                    -0.391,
                    -0.352,
                    -0.313,
                    -0.274,
                    -0.234,
                    -0.195,
                    -0.156,
                    -0.117,
                    -0.078,
                    -0.039,
                    0,
                    0.039,
                    0.078,
                    0.117,
                    0.156,
                    0.195,
                    0.235,
                    0.274,
                    0.313,
                    0.352,
                    0.391,
                    0.43,
                    0.469,
                    0.508,
                    0.547,
                    0.586,
                    0.625,
                    0.664,
                    0.703,
                    0.743,
                    0.782,
                    0.821,
                    0.86,
                    0.899,
                    0.938,
                    0.977,
                    1.016,
                    1.055,
                    1.094,
                    1.133,
                    1.172,
                    1.212,
                    1.251,
                    1.29
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to academic positions, particularly the term \"professor\"",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to individuals holding academic titles or positions, particularly professors",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghwnihoc4c10ex5ossyetk",
                        "tokens": [
                            " because",
                            " the",
                            " plan",
                            " will",
                            " generate",
                            " enough",
                            " economic",
                            " growth",
                            " to",
                            " essentially",
                            " pay",
                            " for",
                            " itself",
                            ".",
                            " The",
                            " most",
                            " optimistic",
                            " projections",
                            " of",
                            " the",
                            " likely",
                            " economic",
                            " benefits",
                            " of",
                            " the",
                            " tax",
                            " cuts",
                            " are",
                            " driven",
                            " by",
                            " increased",
                            " trade",
                            " deficits",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "I",
                            " do",
                            " expect",
                            " a",
                            " major",
                            " trade",
                            " deficit",
                            ",",
                            " absolutely",
                            ",",
                            " as",
                            " part",
                            " of",
                            " this",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Laure",
                            "nce",
                            " J",
                            ".",
                            " Kot",
                            "lik",
                            "off",
                            ",",
                            " a",
                            " professor",
                            " of",
                            " economics",
                            " at",
                            " Boston",
                            " University",
                            " who",
                            " supports",
                            " the",
                            " proposed",
                            " tax",
                            " cuts",
                            " and",
                            " whose",
                            " analysis",
                            " of",
                            " the",
                            " economic",
                            " benefits",
                            " has",
                            " been",
                            " cited",
                            " by",
                            " the",
                            " White",
                            " House",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "If",
                            " this",
                            " tax",
                            " plan",
                            " works",
                            ",",
                            " it",
                            " works",
                            " because",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " becomes",
                            " more",
                            " open",
                            " to",
                            " trade",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "K",
                            "ot",
                            "lik",
                            "off",
                            " also",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "this",
                            " is"
                        ],
                        "dataIndex": null,
                        "index": "64654",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.254,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            56.254,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:53:01.142Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 56.253,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghwniioc4d10exz1bucadx",
                        "tokens": [
                            " Public",
                            " Safety",
                            " in",
                            " the",
                            " Interior",
                            " of",
                            " the",
                            " United",
                            " States",
                            ",",
                            " which",
                            " instructed",
                            " the",
                            " ICE",
                            " Director",
                            " to",
                            " make",
                            " this",
                            " report",
                            " public",
                            ".",
                            "\n",
                            "\n",
                            "L",
                            "ilia",
                            " Vel",
                            "\u00c3\u00a1s",
                            "quez",
                            ",",
                            " an",
                            " associate",
                            " professor",
                            " of",
                            " law",
                            " at",
                            " the",
                            " University",
                            " of",
                            " California",
                            " at",
                            " San",
                            " Diego",
                            ",",
                            " told",
                            " Univ",
                            "ision",
                            " that",
                            " the",
                            " federal",
                            " government",
                            " is",
                            " not",
                            " breaking",
                            " any",
                            " law",
                            " by",
                            " publishing",
                            " the",
                            " list",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "It",
                            " has",
                            " the",
                            " right",
                            " to",
                            " do",
                            " so",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " says",
                            " the",
                            " lawyer",
                            ",",
                            " who",
                            " has",
                            " worked",
                            " in",
                            " immigration",
                            " law",
                            " for",
                            " more",
                            " than",
                            " 25",
                            " years",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Looking",
                            " for",
                            " them",
                            " is",
                            " a",
                            " priority",
                            " especially",
                            " if",
                            " they",
                            " are",
                            " people",
                            " who",
                            " pose",
                            " a",
                            " threat",
                            " to",
                            " public",
                            " and",
                            " national",
                            " security",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " risks",
                            ",",
                            " she",
                            " adds",
                            ",",
                            " are",
                            " when",
                            " people",
                            " are",
                            " detained"
                        ],
                        "dataIndex": null,
                        "index": "64654",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.216,
                        "maxValueTokenIndex": 31,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            56.216,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:53:01.142Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 56.253,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghwniioc4e10exfrdu5a4m",
                        "tokens": [
                            " Medicine",
                            ".",
                            "\n",
                            "\n",
                            "Of",
                            " initial",
                            " hospital",
                            " admissions",
                            " for",
                            " firearms",
                            " injuries",
                            ",",
                            " 43",
                            " percent",
                            " were",
                            " in",
                            " the",
                            " South",
                            ".",
                            " The",
                            " West",
                            " and",
                            " Midwest",
                            " each",
                            " had",
                            " 20",
                            " percent",
                            " of",
                            " hospital",
                            "izations",
                            ",",
                            " while",
                            " the",
                            " Northeast",
                            " claimed",
                            " 16",
                            " percent",
                            ".",
                            " More",
                            " than",
                            " a",
                            " third",
                            " of",
                            " patients",
                            " treated",
                            " in",
                            " the",
                            " South",
                            " were",
                            " uninsured",
                            ".",
                            "\n",
                            "\n",
                            "Dr",
                            ".",
                            " Thomas",
                            " We",
                            "iser",
                            ",",
                            " an",
                            " associate",
                            " professor",
                            " of",
                            " surgery",
                            ",",
                            " and",
                            " Sar",
                            "abeth",
                            " Sp",
                            "itzer",
                            ",",
                            " a",
                            " medical",
                            " student",
                            ",",
                            " analyzed",
                            " in",
                            "patient",
                            " hospital",
                            " records",
                            " to",
                            " conclude",
                            " that",
                            " the",
                            " initial",
                            " hospital",
                            "ization",
                            " of",
                            " patients",
                            " wounded",
                            " by",
                            " guns",
                            " over",
                            " the",
                            " eight",
                            "-",
                            "year",
                            " period",
                            " cost",
                            " Americans",
                            " more",
                            " than",
                            " $",
                            "6",
                            ".",
                            "6",
                            " billion",
                            ".",
                            " The",
                            " researchers",
                            " used",
                            " a",
                            " sample",
                            " of",
                            " more",
                            " than",
                            " 250",
                            ",",
                            "000",
                            " patients",
                            " admitted",
                            " to",
                            " American",
                            " hospitals",
                            " with",
                            " gunshot",
                            " injuries"
                        ],
                        "dataIndex": null,
                        "index": "64654",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 55.598,
                        "maxValueTokenIndex": 61,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.443,
                            55.598,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:53:01.142Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 56.253,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "37264",
            "description": "references to professors or academic titles",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5280241088881567,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "37264",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:05:54.689Z",
                "maxActApprox": 66.666,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    37264,
                    17330,
                    39715,
                    11796,
                    48794,
                    39782,
                    30557,
                    24511,
                    25826,
                    30100,
                    38723,
                    39060,
                    15773,
                    36712,
                    11521,
                    38952,
                    19725,
                    21149,
                    28263,
                    40312,
                    36846,
                    4531,
                    18527,
                    47105,
                    36694
                ],
                "topkCosSimValues": [
                    1,
                    0.7674,
                    0.6723,
                    0.4632,
                    0.3805,
                    0.379,
                    0.3714,
                    0.3691,
                    0.3643,
                    0.362,
                    0.3583,
                    0.3525,
                    0.3511,
                    0.3486,
                    0.3483,
                    0.3478,
                    0.3463,
                    0.3455,
                    0.3412,
                    0.3408,
                    0.3407,
                    0.3398,
                    0.3392,
                    0.338,
                    0.3363
                ],
                "neuron_alignment_indices": [
                    288,
                    575,
                    90
                ],
                "neuron_alignment_values": [
                    0.125,
                    0.116,
                    0.114
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    90,
                    462,
                    60
                ],
                "correlated_neurons_pearson": [
                    0.01,
                    0.009,
                    0.009
                ],
                "correlated_neurons_l1": [
                    0.01,
                    0.009,
                    0.009
                ],
                "correlated_features_indices": [
                    37375,
                    37309,
                    37274
                ],
                "correlated_features_pearson": [
                    0.002,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0,
                    0
                ],
                "neg_str": [
                    "MENTS",
                    "doors",
                    " Nebula",
                    " halfway",
                    "MENT",
                    " Mali",
                    " Blazers",
                    "wolves",
                    "boat",
                    " PAL"
                ],
                "neg_values": [
                    -0.795,
                    -0.738,
                    -0.683,
                    -0.645,
                    -0.633,
                    -0.63,
                    -0.63,
                    -0.621,
                    -0.618,
                    -0.614
                ],
                "pos_str": [
                    "essor",
                    "iciency",
                    "ession",
                    "iles",
                    "essors",
                    "ound",
                    "icient",
                    "essed",
                    "iling",
                    "iled"
                ],
                "pos_values": [
                    1.703,
                    1.46,
                    1.395,
                    1.352,
                    1.336,
                    1.3,
                    1.262,
                    1.16,
                    1.145,
                    1.12
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    25,
                    19,
                    9,
                    6,
                    5,
                    3,
                    1,
                    3,
                    0,
                    2,
                    3,
                    4,
                    0,
                    0,
                    0,
                    2,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    2,
                    0,
                    0,
                    0,
                    1,
                    2,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    1,
                    0,
                    0,
                    2,
                    1,
                    2,
                    2,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.675,
                    2.009,
                    3.342,
                    4.675,
                    6.008,
                    7.341,
                    8.674,
                    10.007,
                    11.341,
                    12.674,
                    14.007,
                    15.34,
                    16.673,
                    18.006,
                    19.339,
                    20.672,
                    22.006,
                    23.339,
                    24.672,
                    26.005,
                    27.338,
                    28.671,
                    30.004,
                    31.338,
                    32.671,
                    34.004,
                    35.337,
                    36.67,
                    38.003,
                    39.336,
                    40.669,
                    42.003,
                    43.336,
                    44.669,
                    46.002,
                    47.335,
                    48.668,
                    50.001,
                    51.335,
                    52.668,
                    54.001,
                    55.334,
                    56.667,
                    58,
                    59.333,
                    60.666,
                    62,
                    63.333,
                    64.666,
                    65.999
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    1,
                    14,
                    28,
                    61,
                    167,
                    342,
                    733,
                    1313,
                    2223,
                    3322,
                    4307,
                    5326,
                    5424,
                    5288,
                    4612,
                    3911,
                    2999,
                    2399,
                    1821,
                    1361,
                    1084,
                    888,
                    683,
                    542,
                    406,
                    321,
                    243,
                    157,
                    103,
                    81,
                    34,
                    19,
                    16,
                    7,
                    6,
                    3,
                    2,
                    1,
                    0,
                    2,
                    2,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.77,
                    -0.72,
                    -0.67,
                    -0.621,
                    -0.571,
                    -0.521,
                    -0.471,
                    -0.421,
                    -0.371,
                    -0.321,
                    -0.271,
                    -0.221,
                    -0.171,
                    -0.121,
                    -0.071,
                    -0.021,
                    0.029,
                    0.079,
                    0.129,
                    0.179,
                    0.229,
                    0.279,
                    0.329,
                    0.379,
                    0.429,
                    0.479,
                    0.529,
                    0.579,
                    0.629,
                    0.679,
                    0.728,
                    0.778,
                    0.828,
                    0.878,
                    0.928,
                    0.978,
                    1.028,
                    1.078,
                    1.128,
                    1.178,
                    1.228,
                    1.278,
                    1.328,
                    1.378,
                    1.428,
                    1.478,
                    1.528,
                    1.578,
                    1.628,
                    1.678
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to professors or academic titles",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk6j3tc9zifi66672ytlyar",
                        "tokens": [
                            "\n",
                            "\n",
                            "The",
                            " alleged",
                            " attackers",
                            " will",
                            " make",
                            " their",
                            " first",
                            " appearance",
                            " in",
                            " court",
                            " Friday",
                            ",",
                            " when",
                            " they",
                            " also",
                            " face",
                            " charges",
                            " of",
                            " kidnapping",
                            " and",
                            " battery",
                            " for",
                            " the",
                            " assault",
                            ",",
                            " which",
                            " was",
                            " captured",
                            " on",
                            " cellphone",
                            " video",
                            " by",
                            " one",
                            " of",
                            " the",
                            " assailants",
                            " and",
                            " viewed",
                            " by",
                            " millions",
                            " on",
                            " social",
                            " media",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "This",
                            " should",
                            " never",
                            " have",
                            " happened",
                            ",\"",
                            " said",
                            " David",
                            " Boyd",
                            ",",
                            " the",
                            " victim",
                            "'s",
                            " brother",
                            "-",
                            "in",
                            "-",
                            "law",
                            " at",
                            " a",
                            " brief",
                            " news",
                            " conference",
                            " in",
                            " suburban",
                            " Chicago",
                            ".",
                            " He",
                            " said",
                            " the",
                            " victim",
                            " was",
                            " traumat",
                            "ized",
                            " but",
                            " doing",
                            " as",
                            " well",
                            " as",
                            " could",
                            " be",
                            " expected",
                            ".",
                            " Neal",
                            " St",
                            "rom",
                            ",",
                            " who",
                            " is",
                            " acting",
                            " as",
                            " a",
                            " family",
                            " spokesman",
                            ",",
                            " told",
                            " The",
                            " Associated",
                            " Press",
                            " that",
                            " the",
                            " victim",
                            " has",
                            " had",
                            " \"",
                            "prof",
                            "ound",
                            " emotional",
                            " and",
                            " physical",
                            " disabilities",
                            " throughout",
                            " his",
                            " life",
                            ".\"",
                            " He",
                            " did",
                            " not"
                        ],
                        "dataIndex": null,
                        "index": "37264",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 66.666,
                        "maxValueTokenIndex": 114,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            66.666,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:05:55.388Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 66.666,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6j3tc9zigi666ci5ahn65",
                        "tokens": [
                            " former",
                            " employer",
                            ".",
                            "\n",
                            "\n",
                            "Media",
                            " observers",
                            " have",
                            " harshly",
                            " criticized",
                            " CNN",
                            " over",
                            " Lew",
                            "andowski",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " hiring",
                            " pointing",
                            " to",
                            " his",
                            " non",
                            "-",
                            "dis",
                            "closure",
                            " and",
                            " likely",
                            " non",
                            "-",
                            "dis",
                            "par",
                            "agement",
                            " agreements",
                            " with",
                            " the",
                            " Trump",
                            " campaign",
                            " as",
                            " \u00e2\u0122",
                            "\u013e",
                            "prof",
                            "ound",
                            "ly",
                            " disturbing",
                            "\u00e2\u0122",
                            "\u013f",
                            " ethical",
                            " conflicts",
                            ".",
                            " Since",
                            " his",
                            " hiring",
                            ",",
                            " Lew",
                            "andowski",
                            " has",
                            " by",
                            " his",
                            " own",
                            " admission",
                            " continued",
                            " to",
                            " advise",
                            " the",
                            " Trump",
                            " campaign",
                            ",",
                            " even",
                            " pushing",
                            " a",
                            " camera",
                            " away",
                            " from",
                            " the",
                            " candidate",
                            " during",
                            " a",
                            " campaign",
                            " stop",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " his",
                            " on",
                            "-",
                            "air",
                            " appearances",
                            ",",
                            " Lew",
                            "andowski",
                            " has",
                            " acted",
                            " more",
                            " like",
                            " a",
                            " spokesman",
                            " for",
                            " the",
                            " campaign",
                            " than",
                            " as",
                            " an",
                            " independent",
                            " commentator",
                            ",",
                            " defending",
                            " all",
                            " of",
                            " Trump",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " actions",
                            " in",
                            " a",
                            " way",
                            " that",
                            ",",
                            " as",
                            " one",
                            " Washington",
                            " Post",
                            " reporter",
                            " noted",
                            ",",
                            " indicates"
                        ],
                        "dataIndex": null,
                        "index": "37264",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 62.942,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            62.942,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:05:55.388Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 66.666,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6j3tc9zihi666cky00e3l",
                        "tokens": [
                            "\n",
                            "It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " not",
                            " the",
                            " actual",
                            " 1973",
                            " war",
                            " that",
                            " the",
                            " Army",
                            " believes",
                            " parallels",
                            " the",
                            " modern",
                            "-",
                            "day",
                            " conflict",
                            " in",
                            " Ukraine",
                            " but",
                            " rather",
                            " the",
                            " Army",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " approach",
                            " afterward",
                            " in",
                            " digest",
                            "ing",
                            " its",
                            " lessons",
                            "\u2014",
                            "and",
                            " folding",
                            " them",
                            " into",
                            " its",
                            " own",
                            " war",
                            " plans",
                            ".",
                            " The",
                            " study",
                            " of",
                            " that",
                            " earlier",
                            " war",
                            " \u00e2\u0122",
                            "\u013e",
                            "serv",
                            "es",
                            " as",
                            " a",
                            " useful",
                            " model",
                            " for",
                            " analyzing",
                            " the",
                            " conflict",
                            " in",
                            " Ukraine",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " says",
                            " Colonel",
                            " Kelly",
                            " Ivan",
                            "off",
                            ",",
                            " a",
                            " field",
                            " artillery",
                            " officer",
                            " and",
                            " top",
                            " aide",
                            " to",
                            " McMaster",
                            ",",
                            " who",
                            " adds",
                            " that",
                            " the",
                            " detailed",
                            " undertaking",
                            " to",
                            " study",
                            " the",
                            " 1973",
                            " war",
                            " was",
                            " to",
                            " \u00e2\u0122",
                            "\u013e",
                            "prof",
                            "ound",
                            "ly",
                            " influence",
                            " the",
                            " development",
                            " of",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " Army",
                            " for",
                            " the",
                            " next",
                            " 15",
                            " years",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " Russia",
                            " New",
                            " Generation"
                        ],
                        "dataIndex": null,
                        "index": "37264",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.684,
                        "maxValueTokenIndex": 100,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.684,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:05:55.388Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 66.666,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "73248",
            "description": " occurrences of the word \"Prof\" and its variations, indicating references to professors or professional titles",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5220659090319827,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "73248",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:02:16.310Z",
                "maxActApprox": 42.505,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    73248,
                    78071,
                    6218,
                    44,
                    82084,
                    83641,
                    46751,
                    10517,
                    98235,
                    92240,
                    76490,
                    94665,
                    81565,
                    7692,
                    76233,
                    4282,
                    56217,
                    25684,
                    73889,
                    1825,
                    35820,
                    35193,
                    83200,
                    44695,
                    65418
                ],
                "topkCosSimValues": [
                    1,
                    0.7921,
                    0.7639,
                    0.6403,
                    0.4589,
                    0.4237,
                    0.422,
                    0.4121,
                    0.3954,
                    0.3942,
                    0.3938,
                    0.3914,
                    0.3823,
                    0.3762,
                    0.3693,
                    0.363,
                    0.3593,
                    0.3561,
                    0.352,
                    0.3519,
                    0.3518,
                    0.3505,
                    0.3504,
                    0.3478,
                    0.3467
                ],
                "neuron_alignment_indices": [
                    575,
                    288,
                    60
                ],
                "neuron_alignment_values": [
                    0.134,
                    0.117,
                    0.115
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    60,
                    631,
                    90
                ],
                "correlated_neurons_pearson": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_neurons_l1": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_features_indices": [
                    73188,
                    73248,
                    73223
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "MENTS",
                    " halfway",
                    "warm",
                    "MENT",
                    " Mali",
                    "doors",
                    "forth",
                    " shortened",
                    " Weir",
                    " Warriors"
                ],
                "neg_values": [
                    -0.837,
                    -0.738,
                    -0.713,
                    -0.674,
                    -0.656,
                    -0.651,
                    -0.65,
                    -0.635,
                    -0.631,
                    -0.609
                ],
                "pos_str": [
                    "essor",
                    "iles",
                    "iciency",
                    "ound",
                    "essors",
                    "iler",
                    "ession",
                    "icient",
                    "iling",
                    "ilers"
                ],
                "pos_values": [
                    1.483,
                    1.343,
                    1.315,
                    1.266,
                    1.262,
                    1.247,
                    1.218,
                    1.178,
                    1.176,
                    1.171
                ],
                "frac_nonzero": 4e-05,
                "freq_hist_data_bar_heights": [
                    18,
                    11,
                    6,
                    2,
                    4,
                    3,
                    1,
                    3,
                    1,
                    1,
                    0,
                    1,
                    0,
                    1,
                    1,
                    2,
                    2,
                    1,
                    3,
                    2,
                    7,
                    4,
                    3,
                    4,
                    2,
                    5,
                    3,
                    2,
                    0,
                    3,
                    3,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    3,
                    3,
                    3,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.456,
                    1.306,
                    2.155,
                    3.004,
                    3.854,
                    4.703,
                    5.553,
                    6.402,
                    7.252,
                    8.101,
                    8.951,
                    9.8,
                    10.65,
                    11.499,
                    12.349,
                    13.198,
                    14.048,
                    14.897,
                    15.746,
                    16.596,
                    17.445,
                    18.295,
                    19.144,
                    19.994,
                    20.843,
                    21.693,
                    22.542,
                    23.392,
                    24.241,
                    25.091,
                    25.94,
                    26.79,
                    27.639,
                    28.488,
                    29.338,
                    30.187,
                    31.037,
                    31.886,
                    32.736,
                    33.585,
                    34.435,
                    35.284,
                    36.134,
                    36.983,
                    37.833,
                    38.682,
                    39.532,
                    40.381,
                    41.23,
                    42.08
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    2,
                    5,
                    16,
                    34,
                    82,
                    193,
                    421,
                    838,
                    1452,
                    2355,
                    3209,
                    4187,
                    4815,
                    5149,
                    4891,
                    4532,
                    3936,
                    3166,
                    2494,
                    1962,
                    1476,
                    1161,
                    906,
                    725,
                    600,
                    449,
                    325,
                    284,
                    197,
                    137,
                    94,
                    60,
                    40,
                    18,
                    14,
                    9,
                    5,
                    2,
                    1,
                    2,
                    3,
                    2,
                    2,
                    2,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.814,
                    -0.768,
                    -0.721,
                    -0.675,
                    -0.628,
                    -0.582,
                    -0.536,
                    -0.489,
                    -0.443,
                    -0.396,
                    -0.35,
                    -0.304,
                    -0.257,
                    -0.211,
                    -0.164,
                    -0.118,
                    -0.072,
                    -0.025,
                    0.021,
                    0.068,
                    0.114,
                    0.16,
                    0.207,
                    0.253,
                    0.3,
                    0.346,
                    0.392,
                    0.439,
                    0.485,
                    0.532,
                    0.578,
                    0.624,
                    0.671,
                    0.717,
                    0.764,
                    0.81,
                    0.857,
                    0.903,
                    0.949,
                    0.996,
                    1.042,
                    1.089,
                    1.135,
                    1.181,
                    1.228,
                    1.274,
                    1.321,
                    1.367,
                    1.413,
                    1.46
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " occurrences of the word \"Prof\" and its variations, indicating references to professors or professional titles",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " instances of the term \"prof\" in various contexts, indicating a focus on professional titles or qualifications",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "terms related to academic and professional titles, particularly \"professor\" and its variations",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi8oifuuvh10extionc3n7",
                        "tokens": [
                            ",",
                            " but",
                            " you",
                            "'re",
                            " here",
                            ",",
                            " so",
                            " you",
                            " better",
                            " f",
                            "------",
                            " deal",
                            " with",
                            " it",
                            ",",
                            " girl",
                            ".\"",
                            "<|endoftext|>",
                            "Overview",
                            "\n",
                            "\n",
                            "A",
                            "VE",
                            "X",
                            "IR",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " A",
                            "VD",
                            "3",
                            "U",
                            "H",
                            "3",
                            "100",
                            "12",
                            "04",
                            "G",
                            "-",
                            "2",
                            "CI",
                            " is",
                            " a",
                            " Dual",
                            " channel",
                            " 512",
                            "M",
                            " x",
                            " 64",
                            "-",
                            "bit",
                            " 4",
                            "GB",
                            " single",
                            " side",
                            " (",
                            "40",
                            "96",
                            "MB",
                            ")",
                            " x",
                            "2",
                            " DDR",
                            "3",
                            "-",
                            "3",
                            "100",
                            "MHz",
                            " CL",
                            "12",
                            " S",
                            "DR",
                            "AM",
                            "(",
                            "S",
                            "ynchronous",
                            " DR",
                            "AM",
                            ")",
                            " memory",
                            " modules",
                            ",",
                            " based",
                            " on",
                            " eight",
                            " 512",
                            "M",
                            " x",
                            " 8",
                            "\u2013",
                            "bit",
                            " DDR",
                            "3",
                            " FB",
                            "GA",
                            " components",
                            " per",
                            " module",
                            ".",
                            " Each",
                            " module",
                            " kit",
                            " supports",
                            " Intel",
                            " X",
                            "MP",
                            " 1",
                            ".",
                            "3",
                            " (",
                            "Extreme",
                            " Memory",
                            " Prof",
                            "iles",
                            ").",
                            " Total",
                            " kit",
                            " capacity",
                            " is",
                            " 8",
                            "GB",
                            ".",
                            " It",
                            " supports",
                            " newest",
                            " generation",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "73248",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.505,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.505,
                            3.583,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:22.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 34.004,
                        "binMax": 42.505,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi8oiduuuv10exnvub6ol3",
                        "tokens": [
                            ",",
                            " but",
                            " you",
                            "'re",
                            " here",
                            ",",
                            " so",
                            " you",
                            " better",
                            " f",
                            "------",
                            " deal",
                            " with",
                            " it",
                            ",",
                            " girl",
                            ".\"",
                            "<|endoftext|>",
                            "Overview",
                            "\n",
                            "\n",
                            "A",
                            "VE",
                            "X",
                            "IR",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " A",
                            "VD",
                            "3",
                            "U",
                            "H",
                            "3",
                            "100",
                            "12",
                            "04",
                            "G",
                            "-",
                            "2",
                            "CI",
                            " is",
                            " a",
                            " Dual",
                            " channel",
                            " 512",
                            "M",
                            " x",
                            " 64",
                            "-",
                            "bit",
                            " 4",
                            "GB",
                            " single",
                            " side",
                            " (",
                            "40",
                            "96",
                            "MB",
                            ")",
                            " x",
                            "2",
                            " DDR",
                            "3",
                            "-",
                            "3",
                            "100",
                            "MHz",
                            " CL",
                            "12",
                            " S",
                            "DR",
                            "AM",
                            "(",
                            "S",
                            "ynchronous",
                            " DR",
                            "AM",
                            ")",
                            " memory",
                            " modules",
                            ",",
                            " based",
                            " on",
                            " eight",
                            " 512",
                            "M",
                            " x",
                            " 8",
                            "\u2013",
                            "bit",
                            " DDR",
                            "3",
                            " FB",
                            "GA",
                            " components",
                            " per",
                            " module",
                            ".",
                            " Each",
                            " module",
                            " kit",
                            " supports",
                            " Intel",
                            " X",
                            "MP",
                            " 1",
                            ".",
                            "3",
                            " (",
                            "Extreme",
                            " Memory",
                            " Prof",
                            "iles",
                            ").",
                            " Total",
                            " kit",
                            " capacity",
                            " is",
                            " 8",
                            "GB",
                            ".",
                            " It",
                            " supports",
                            " newest",
                            " generation",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "73248",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.505,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.505,
                            3.583,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:22.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 42.505,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi8oiduuuw10exivjqdc30",
                        "tokens": [
                            " Google",
                            " apps",
                            " with",
                            " its",
                            " 1",
                            ".",
                            "5",
                            "GHz",
                            " quad",
                            "-",
                            "core",
                            " processor",
                            ",",
                            " and",
                            " 5",
                            ".",
                            "1",
                            " surround",
                            " sound",
                            " lends",
                            " clarity",
                            " to",
                            " business",
                            " calls",
                            " and",
                            " video",
                            " game",
                            " sound",
                            " effects",
                            ".",
                            "\n",
                            "\n",
                            "C",
                            "NET",
                            " Editor",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Choice",
                            " Tablet",
                            "\n",
                            "\n",
                            "C",
                            "NET",
                            " called",
                            " the",
                            " ASUS",
                            " Google",
                            " Nexus",
                            " 7",
                            " \u00e2\u0122",
                            "\u013e",
                            "the",
                            " best",
                            " tablet",
                            " value",
                            " on",
                            " the",
                            " market",
                            "\u00e2\u0122",
                            "\u013f",
                            " because",
                            " of",
                            " its",
                            " HD",
                            " screen",
                            ",",
                            " battery",
                            " life",
                            ",",
                            " and",
                            " speedy",
                            " performance",
                            ".",
                            " The",
                            " latter",
                            " is",
                            " thanks",
                            " to",
                            " the",
                            " quad",
                            "-",
                            "core",
                            " processor",
                            ",",
                            " which",
                            " the",
                            " review",
                            " notes",
                            " helps",
                            " seamlessly",
                            " power",
                            " racing",
                            " games",
                            " and",
                            " create",
                            " \u00e2\u0122",
                            "\u013e",
                            "the",
                            " best",
                            "-",
                            "performing",
                            " small",
                            " tablet",
                            " for",
                            " gaming",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Create",
                            " Kid",
                            "-",
                            "Friend",
                            "ly",
                            " Prof",
                            "iles",
                            " with",
                            " Android",
                            " 4",
                            ".",
                            "3",
                            "\n",
                            "\n",
                            "You",
                            " can"
                        ],
                        "dataIndex": null,
                        "index": "73248",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.245,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.245,
                            2.185,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:22.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 42.505,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "73248",
            "description": " instances of the term \"prof\" in various contexts, indicating a focus on professional titles or qualifications",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5214760303497351,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "73248",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:02:16.310Z",
                "maxActApprox": 42.505,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    73248,
                    78071,
                    6218,
                    44,
                    82084,
                    83641,
                    46751,
                    10517,
                    98235,
                    92240,
                    76490,
                    94665,
                    81565,
                    7692,
                    76233,
                    4282,
                    56217,
                    25684,
                    73889,
                    1825,
                    35820,
                    35193,
                    83200,
                    44695,
                    65418
                ],
                "topkCosSimValues": [
                    1,
                    0.7921,
                    0.7639,
                    0.6403,
                    0.4589,
                    0.4237,
                    0.422,
                    0.4121,
                    0.3954,
                    0.3942,
                    0.3938,
                    0.3914,
                    0.3823,
                    0.3762,
                    0.3693,
                    0.363,
                    0.3593,
                    0.3561,
                    0.352,
                    0.3519,
                    0.3518,
                    0.3505,
                    0.3504,
                    0.3478,
                    0.3467
                ],
                "neuron_alignment_indices": [
                    575,
                    288,
                    60
                ],
                "neuron_alignment_values": [
                    0.134,
                    0.117,
                    0.115
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    60,
                    631,
                    90
                ],
                "correlated_neurons_pearson": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_neurons_l1": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_features_indices": [
                    73188,
                    73248,
                    73223
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "MENTS",
                    " halfway",
                    "warm",
                    "MENT",
                    " Mali",
                    "doors",
                    "forth",
                    " shortened",
                    " Weir",
                    " Warriors"
                ],
                "neg_values": [
                    -0.837,
                    -0.738,
                    -0.713,
                    -0.674,
                    -0.656,
                    -0.651,
                    -0.65,
                    -0.635,
                    -0.631,
                    -0.609
                ],
                "pos_str": [
                    "essor",
                    "iles",
                    "iciency",
                    "ound",
                    "essors",
                    "iler",
                    "ession",
                    "icient",
                    "iling",
                    "ilers"
                ],
                "pos_values": [
                    1.483,
                    1.343,
                    1.315,
                    1.266,
                    1.262,
                    1.247,
                    1.218,
                    1.178,
                    1.176,
                    1.171
                ],
                "frac_nonzero": 4e-05,
                "freq_hist_data_bar_heights": [
                    18,
                    11,
                    6,
                    2,
                    4,
                    3,
                    1,
                    3,
                    1,
                    1,
                    0,
                    1,
                    0,
                    1,
                    1,
                    2,
                    2,
                    1,
                    3,
                    2,
                    7,
                    4,
                    3,
                    4,
                    2,
                    5,
                    3,
                    2,
                    0,
                    3,
                    3,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    3,
                    3,
                    3,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.456,
                    1.306,
                    2.155,
                    3.004,
                    3.854,
                    4.703,
                    5.553,
                    6.402,
                    7.252,
                    8.101,
                    8.951,
                    9.8,
                    10.65,
                    11.499,
                    12.349,
                    13.198,
                    14.048,
                    14.897,
                    15.746,
                    16.596,
                    17.445,
                    18.295,
                    19.144,
                    19.994,
                    20.843,
                    21.693,
                    22.542,
                    23.392,
                    24.241,
                    25.091,
                    25.94,
                    26.79,
                    27.639,
                    28.488,
                    29.338,
                    30.187,
                    31.037,
                    31.886,
                    32.736,
                    33.585,
                    34.435,
                    35.284,
                    36.134,
                    36.983,
                    37.833,
                    38.682,
                    39.532,
                    40.381,
                    41.23,
                    42.08
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    2,
                    5,
                    16,
                    34,
                    82,
                    193,
                    421,
                    838,
                    1452,
                    2355,
                    3209,
                    4187,
                    4815,
                    5149,
                    4891,
                    4532,
                    3936,
                    3166,
                    2494,
                    1962,
                    1476,
                    1161,
                    906,
                    725,
                    600,
                    449,
                    325,
                    284,
                    197,
                    137,
                    94,
                    60,
                    40,
                    18,
                    14,
                    9,
                    5,
                    2,
                    1,
                    2,
                    3,
                    2,
                    2,
                    2,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.814,
                    -0.768,
                    -0.721,
                    -0.675,
                    -0.628,
                    -0.582,
                    -0.536,
                    -0.489,
                    -0.443,
                    -0.396,
                    -0.35,
                    -0.304,
                    -0.257,
                    -0.211,
                    -0.164,
                    -0.118,
                    -0.072,
                    -0.025,
                    0.021,
                    0.068,
                    0.114,
                    0.16,
                    0.207,
                    0.253,
                    0.3,
                    0.346,
                    0.392,
                    0.439,
                    0.485,
                    0.532,
                    0.578,
                    0.624,
                    0.671,
                    0.717,
                    0.764,
                    0.81,
                    0.857,
                    0.903,
                    0.949,
                    0.996,
                    1.042,
                    1.089,
                    1.135,
                    1.181,
                    1.228,
                    1.274,
                    1.321,
                    1.367,
                    1.413,
                    1.46
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " occurrences of the word \"Prof\" and its variations, indicating references to professors or professional titles",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " instances of the term \"prof\" in various contexts, indicating a focus on professional titles or qualifications",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "terms related to academic and professional titles, particularly \"professor\" and its variations",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi8oifuuvh10extionc3n7",
                        "tokens": [
                            ",",
                            " but",
                            " you",
                            "'re",
                            " here",
                            ",",
                            " so",
                            " you",
                            " better",
                            " f",
                            "------",
                            " deal",
                            " with",
                            " it",
                            ",",
                            " girl",
                            ".\"",
                            "<|endoftext|>",
                            "Overview",
                            "\n",
                            "\n",
                            "A",
                            "VE",
                            "X",
                            "IR",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " A",
                            "VD",
                            "3",
                            "U",
                            "H",
                            "3",
                            "100",
                            "12",
                            "04",
                            "G",
                            "-",
                            "2",
                            "CI",
                            " is",
                            " a",
                            " Dual",
                            " channel",
                            " 512",
                            "M",
                            " x",
                            " 64",
                            "-",
                            "bit",
                            " 4",
                            "GB",
                            " single",
                            " side",
                            " (",
                            "40",
                            "96",
                            "MB",
                            ")",
                            " x",
                            "2",
                            " DDR",
                            "3",
                            "-",
                            "3",
                            "100",
                            "MHz",
                            " CL",
                            "12",
                            " S",
                            "DR",
                            "AM",
                            "(",
                            "S",
                            "ynchronous",
                            " DR",
                            "AM",
                            ")",
                            " memory",
                            " modules",
                            ",",
                            " based",
                            " on",
                            " eight",
                            " 512",
                            "M",
                            " x",
                            " 8",
                            "\u2013",
                            "bit",
                            " DDR",
                            "3",
                            " FB",
                            "GA",
                            " components",
                            " per",
                            " module",
                            ".",
                            " Each",
                            " module",
                            " kit",
                            " supports",
                            " Intel",
                            " X",
                            "MP",
                            " 1",
                            ".",
                            "3",
                            " (",
                            "Extreme",
                            " Memory",
                            " Prof",
                            "iles",
                            ").",
                            " Total",
                            " kit",
                            " capacity",
                            " is",
                            " 8",
                            "GB",
                            ".",
                            " It",
                            " supports",
                            " newest",
                            " generation",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "73248",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.505,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.505,
                            3.583,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:22.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 34.004,
                        "binMax": 42.505,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi8oiduuuv10exnvub6ol3",
                        "tokens": [
                            ",",
                            " but",
                            " you",
                            "'re",
                            " here",
                            ",",
                            " so",
                            " you",
                            " better",
                            " f",
                            "------",
                            " deal",
                            " with",
                            " it",
                            ",",
                            " girl",
                            ".\"",
                            "<|endoftext|>",
                            "Overview",
                            "\n",
                            "\n",
                            "A",
                            "VE",
                            "X",
                            "IR",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " A",
                            "VD",
                            "3",
                            "U",
                            "H",
                            "3",
                            "100",
                            "12",
                            "04",
                            "G",
                            "-",
                            "2",
                            "CI",
                            " is",
                            " a",
                            " Dual",
                            " channel",
                            " 512",
                            "M",
                            " x",
                            " 64",
                            "-",
                            "bit",
                            " 4",
                            "GB",
                            " single",
                            " side",
                            " (",
                            "40",
                            "96",
                            "MB",
                            ")",
                            " x",
                            "2",
                            " DDR",
                            "3",
                            "-",
                            "3",
                            "100",
                            "MHz",
                            " CL",
                            "12",
                            " S",
                            "DR",
                            "AM",
                            "(",
                            "S",
                            "ynchronous",
                            " DR",
                            "AM",
                            ")",
                            " memory",
                            " modules",
                            ",",
                            " based",
                            " on",
                            " eight",
                            " 512",
                            "M",
                            " x",
                            " 8",
                            "\u2013",
                            "bit",
                            " DDR",
                            "3",
                            " FB",
                            "GA",
                            " components",
                            " per",
                            " module",
                            ".",
                            " Each",
                            " module",
                            " kit",
                            " supports",
                            " Intel",
                            " X",
                            "MP",
                            " 1",
                            ".",
                            "3",
                            " (",
                            "Extreme",
                            " Memory",
                            " Prof",
                            "iles",
                            ").",
                            " Total",
                            " kit",
                            " capacity",
                            " is",
                            " 8",
                            "GB",
                            ".",
                            " It",
                            " supports",
                            " newest",
                            " generation",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "73248",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.505,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.505,
                            3.583,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:22.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 42.505,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi8oiduuuw10exivjqdc30",
                        "tokens": [
                            " Google",
                            " apps",
                            " with",
                            " its",
                            " 1",
                            ".",
                            "5",
                            "GHz",
                            " quad",
                            "-",
                            "core",
                            " processor",
                            ",",
                            " and",
                            " 5",
                            ".",
                            "1",
                            " surround",
                            " sound",
                            " lends",
                            " clarity",
                            " to",
                            " business",
                            " calls",
                            " and",
                            " video",
                            " game",
                            " sound",
                            " effects",
                            ".",
                            "\n",
                            "\n",
                            "C",
                            "NET",
                            " Editor",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Choice",
                            " Tablet",
                            "\n",
                            "\n",
                            "C",
                            "NET",
                            " called",
                            " the",
                            " ASUS",
                            " Google",
                            " Nexus",
                            " 7",
                            " \u00e2\u0122",
                            "\u013e",
                            "the",
                            " best",
                            " tablet",
                            " value",
                            " on",
                            " the",
                            " market",
                            "\u00e2\u0122",
                            "\u013f",
                            " because",
                            " of",
                            " its",
                            " HD",
                            " screen",
                            ",",
                            " battery",
                            " life",
                            ",",
                            " and",
                            " speedy",
                            " performance",
                            ".",
                            " The",
                            " latter",
                            " is",
                            " thanks",
                            " to",
                            " the",
                            " quad",
                            "-",
                            "core",
                            " processor",
                            ",",
                            " which",
                            " the",
                            " review",
                            " notes",
                            " helps",
                            " seamlessly",
                            " power",
                            " racing",
                            " games",
                            " and",
                            " create",
                            " \u00e2\u0122",
                            "\u013e",
                            "the",
                            " best",
                            "-",
                            "performing",
                            " small",
                            " tablet",
                            " for",
                            " gaming",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Create",
                            " Kid",
                            "-",
                            "Friend",
                            "ly",
                            " Prof",
                            "iles",
                            " with",
                            " Android",
                            " 4",
                            ".",
                            "3",
                            "\n",
                            "\n",
                            "You",
                            " can"
                        ],
                        "dataIndex": null,
                        "index": "73248",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.245,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.245,
                            2.185,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:22.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 42.505,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "46751",
            "description": "references to professors and their roles in academia",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5182025145413,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "46751",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:32:23.357Z",
                "maxActApprox": 30.995,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    46751,
                    64654,
                    97409,
                    35435,
                    42428,
                    48115,
                    84880,
                    19951,
                    93548,
                    15503,
                    44,
                    78642,
                    46770,
                    36352,
                    77827,
                    78206,
                    53510,
                    12698,
                    89161,
                    52515,
                    64882,
                    27016,
                    73248,
                    36233,
                    29411
                ],
                "topkCosSimValues": [
                    1,
                    0.7346,
                    0.6608,
                    0.6388,
                    0.5611,
                    0.5439,
                    0.5238,
                    0.5138,
                    0.5048,
                    0.4814,
                    0.4778,
                    0.4745,
                    0.4665,
                    0.4651,
                    0.4633,
                    0.4489,
                    0.4471,
                    0.4457,
                    0.4377,
                    0.4341,
                    0.4332,
                    0.4247,
                    0.422,
                    0.4213,
                    0.4182
                ],
                "neuron_alignment_indices": [
                    679,
                    288,
                    167
                ],
                "neuron_alignment_values": [
                    0.158,
                    0.123,
                    0.115
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    679,
                    111,
                    235
                ],
                "correlated_neurons_pearson": [
                    0.015,
                    0.015,
                    0.015
                ],
                "correlated_neurons_l1": [
                    0.017,
                    0.014,
                    0.016
                ],
                "correlated_features_indices": [
                    46770,
                    46718,
                    46666
                ],
                "correlated_features_pearson": [
                    0.003,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0.001,
                    0
                ],
                "neg_str": [
                    " territ",
                    " launchers",
                    " Krypt",
                    "axy",
                    " recovery",
                    " Pradesh",
                    " Recovery",
                    " Siberia",
                    " launcher",
                    " Territories"
                ],
                "neg_values": [
                    -0.854,
                    -0.742,
                    -0.708,
                    -0.657,
                    -0.653,
                    -0.645,
                    -0.642,
                    -0.639,
                    -0.635,
                    -0.627
                ],
                "pos_str": [
                    "essors",
                    "hips",
                    "ials",
                    "iate",
                    "essor",
                    "hip",
                    "ulas",
                    "iles",
                    "ially",
                    " professors"
                ],
                "pos_values": [
                    1.395,
                    1.016,
                    1.009,
                    0.986,
                    0.962,
                    0.888,
                    0.864,
                    0.801,
                    0.797,
                    0.794
                ],
                "frac_nonzero": 0.00011,
                "freq_hist_data_bar_heights": [
                    46,
                    35,
                    28,
                    16,
                    24,
                    7,
                    10,
                    6,
                    9,
                    8,
                    6,
                    8,
                    5,
                    7,
                    8,
                    3,
                    3,
                    4,
                    3,
                    0,
                    1,
                    2,
                    6,
                    8,
                    0,
                    2,
                    2,
                    4,
                    2,
                    2,
                    1,
                    4,
                    7,
                    10,
                    7,
                    1,
                    8,
                    5,
                    4,
                    7,
                    5,
                    3,
                    2,
                    3,
                    7,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.332,
                    0.951,
                    1.571,
                    2.19,
                    2.81,
                    3.429,
                    4.048,
                    4.668,
                    5.287,
                    5.907,
                    6.526,
                    7.146,
                    7.765,
                    8.385,
                    9.004,
                    9.624,
                    10.243,
                    10.862,
                    11.482,
                    12.101,
                    12.721,
                    13.34,
                    13.96,
                    14.579,
                    15.199,
                    15.818,
                    16.438,
                    17.057,
                    17.676,
                    18.296,
                    18.915,
                    19.535,
                    20.154,
                    20.774,
                    21.393,
                    22.013,
                    22.632,
                    23.252,
                    23.871,
                    24.49,
                    25.11,
                    25.729,
                    26.349,
                    26.968,
                    27.588,
                    28.207,
                    28.827,
                    29.446,
                    30.065,
                    30.685
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    1,
                    6,
                    9,
                    22,
                    64,
                    134,
                    246,
                    407,
                    750,
                    1228,
                    1969,
                    2802,
                    3672,
                    4489,
                    5086,
                    5239,
                    5167,
                    4577,
                    3678,
                    3016,
                    2250,
                    1715,
                    1252,
                    882,
                    580,
                    367,
                    267,
                    170,
                    74,
                    57,
                    30,
                    25,
                    7,
                    10,
                    0,
                    2,
                    0,
                    2,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.832,
                    -0.787,
                    -0.742,
                    -0.697,
                    -0.652,
                    -0.607,
                    -0.562,
                    -0.517,
                    -0.472,
                    -0.427,
                    -0.382,
                    -0.337,
                    -0.292,
                    -0.247,
                    -0.202,
                    -0.157,
                    -0.112,
                    -0.067,
                    -0.022,
                    0.023,
                    0.068,
                    0.113,
                    0.158,
                    0.203,
                    0.248,
                    0.293,
                    0.338,
                    0.383,
                    0.428,
                    0.473,
                    0.518,
                    0.563,
                    0.608,
                    0.653,
                    0.698,
                    0.742,
                    0.787,
                    0.832,
                    0.877,
                    0.922,
                    0.967,
                    1.012,
                    1.057,
                    1.102,
                    1.147,
                    1.192,
                    1.237,
                    1.282,
                    1.327,
                    1.372
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to professors and their roles in academia",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " references to professors or their roles in academia",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygh6f9happu10exny4niu7s",
                        "tokens": [
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " received",
                            " death",
                            " threats",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Ped",
                            "h",
                            "az",
                            "ur",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "But",
                            " no",
                            " one",
                            " at",
                            " the",
                            " university",
                            " has",
                            " offered",
                            " to",
                            " protect",
                            " me",
                            " or",
                            " my",
                            " students",
                            ".",
                            " That",
                            " is",
                            " why",
                            " I",
                            " went",
                            " to",
                            " the",
                            " police",
                            " last",
                            " Monday",
                            " to",
                            " request",
                            " protection",
                            " for",
                            " my",
                            " class",
                            " \u2014",
                            " titled",
                            " \u00e2\u0122",
                            "\u013a",
                            "Su",
                            "icide",
                            " Terror",
                            "\u00e2\u0122",
                            "\u013b",
                            " \u2014",
                            " which",
                            " is",
                            " in",
                            " a",
                            " basement",
                            ",",
                            " so",
                            " in",
                            " an",
                            " emergency",
                            " situation",
                            ",",
                            " it",
                            " would",
                            " be",
                            " very",
                            " hard",
                            " to",
                            " evacuate",
                            " 95",
                            " students",
                            ".",
                            " I",
                            " couldn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " take",
                            " the",
                            " chance",
                            " that",
                            " because",
                            " of",
                            " my",
                            " name",
                            ",",
                            " someone",
                            " would",
                            " try",
                            " to",
                            " do",
                            " away",
                            " with",
                            " a",
                            " \u00e2\u0122",
                            "\u013a",
                            "Z",
                            "ion",
                            "ist",
                            " professor",
                            ".",
                            "\u00e2\u0122",
                            "\u013b",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " first",
                            " course",
                            " of",
                            " action",
                            " Ped",
                            "h",
                            "az",
                            "ur",
                            " took",
                            " was",
                            " to"
                        ],
                        "dataIndex": null,
                        "index": "46751",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 30.995,
                        "maxValueTokenIndex": 107,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            30.995,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:32:37.418Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 24.796,
                        "binMax": 30.995,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh6f9eapp810exijseqnbs",
                        "tokens": [
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " received",
                            " death",
                            " threats",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Ped",
                            "h",
                            "az",
                            "ur",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "But",
                            " no",
                            " one",
                            " at",
                            " the",
                            " university",
                            " has",
                            " offered",
                            " to",
                            " protect",
                            " me",
                            " or",
                            " my",
                            " students",
                            ".",
                            " That",
                            " is",
                            " why",
                            " I",
                            " went",
                            " to",
                            " the",
                            " police",
                            " last",
                            " Monday",
                            " to",
                            " request",
                            " protection",
                            " for",
                            " my",
                            " class",
                            " \u2014",
                            " titled",
                            " \u00e2\u0122",
                            "\u013a",
                            "Su",
                            "icide",
                            " Terror",
                            "\u00e2\u0122",
                            "\u013b",
                            " \u2014",
                            " which",
                            " is",
                            " in",
                            " a",
                            " basement",
                            ",",
                            " so",
                            " in",
                            " an",
                            " emergency",
                            " situation",
                            ",",
                            " it",
                            " would",
                            " be",
                            " very",
                            " hard",
                            " to",
                            " evacuate",
                            " 95",
                            " students",
                            ".",
                            " I",
                            " couldn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " take",
                            " the",
                            " chance",
                            " that",
                            " because",
                            " of",
                            " my",
                            " name",
                            ",",
                            " someone",
                            " would",
                            " try",
                            " to",
                            " do",
                            " away",
                            " with",
                            " a",
                            " \u00e2\u0122",
                            "\u013a",
                            "Z",
                            "ion",
                            "ist",
                            " professor",
                            ".",
                            "\u00e2\u0122",
                            "\u013b",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " first",
                            " course",
                            " of",
                            " action",
                            " Ped",
                            "h",
                            "az",
                            "ur",
                            " took",
                            " was",
                            " to"
                        ],
                        "dataIndex": null,
                        "index": "46751",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 30.995,
                        "maxValueTokenIndex": 107,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            30.995,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:32:37.418Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 30.995,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh6f9fapp910ex2xttekrg",
                        "tokens": [
                            " view",
                            " up",
                            " to",
                            " six",
                            " devices",
                            " on",
                            " the",
                            " network",
                            " in",
                            " the",
                            " free",
                            " license",
                            " version",
                            ",",
                            " but",
                            " the",
                            " full",
                            " version",
                            ",",
                            " which",
                            " scans",
                            " the",
                            " network",
                            " and",
                            " displays",
                            " all",
                            " connected",
                            " devices",
                            ",",
                            " is",
                            " not",
                            " free",
                            ".",
                            "\n",
                            "\n",
                            "What",
                            " if",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " on",
                            " a",
                            " budget",
                            " or",
                            " your",
                            " local",
                            " network",
                            " has",
                            " more",
                            " than",
                            " five",
                            " additional",
                            " devices",
                            " connected",
                            "?",
                            " Try",
                            " i",
                            "Net",
                            " instead",
                            ".",
                            " This",
                            " inexpensive",
                            " utility",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " free",
                            " but",
                            " scans",
                            " your",
                            " entire",
                            " network",
                            " and",
                            " displays",
                            " all",
                            " connected",
                            " devices",
                            ",",
                            " including",
                            " Bon",
                            "j",
                            "our",
                            " connections",
                            ",",
                            " and",
                            " it",
                            " has",
                            " a",
                            " graphic",
                            " interface",
                            ".",
                            "\n",
                            "\n",
                            "Well",
                            " done",
                            ",",
                            " fast",
                            ",",
                            " easy",
                            ",",
                            " cheaper",
                            ".",
                            "<|endoftext|>",
                            "University",
                            " professors",
                            " in",
                            " New",
                            " Brunswick",
                            " are",
                            " asking",
                            " St",
                            ".",
                            " Thomas",
                            " University",
                            " to",
                            " withdraw",
                            " its",
                            " offer",
                            " to",
                            " host",
                            " C",
                            "TV",
                            "'s",
                            " leaders",
                            "'"
                        ],
                        "dataIndex": null,
                        "index": "46751",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.867,
                        "maxValueTokenIndex": 106,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.867,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:32:37.418Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 30.995,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "17375",
            "description": "mentions of academic positions, particularly the title \"professor\"",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5173237323761023,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "17375",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:07:00.697Z",
                "maxActApprox": 50.455,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    17375,
                    23486,
                    15579,
                    19680,
                    23827,
                    23000,
                    11785,
                    9709,
                    16661,
                    7511,
                    15794,
                    8895,
                    11745,
                    2349,
                    17218,
                    19718,
                    1720,
                    8698,
                    9504,
                    18093,
                    48,
                    16447,
                    20005,
                    21154,
                    2701
                ],
                "topkCosSimValues": [
                    1,
                    0.5407,
                    0.5345,
                    0.5098,
                    0.5082,
                    0.505,
                    0.504,
                    0.4992,
                    0.4901,
                    0.4802,
                    0.4584,
                    0.4361,
                    0.4358,
                    0.4279,
                    0.4209,
                    0.4142,
                    0.4044,
                    0.4025,
                    0.4024,
                    0.3968,
                    0.3964,
                    0.3947,
                    0.3939,
                    0.3911,
                    0.3874
                ],
                "neuron_alignment_indices": [
                    679,
                    288,
                    447
                ],
                "neuron_alignment_values": [
                    0.132,
                    0.112,
                    0.112
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    235,
                    414,
                    145
                ],
                "correlated_neurons_pearson": [
                    0.024,
                    0.024,
                    0.023
                ],
                "correlated_neurons_l1": [
                    0.025,
                    0.021,
                    0.023
                ],
                "correlated_features_indices": [
                    17402,
                    17382,
                    17386
                ],
                "correlated_features_pearson": [
                    0.066,
                    0.002,
                    0.002
                ],
                "correlated_features_l1": [
                    0.066,
                    0.003,
                    0.003
                ],
                "neg_str": [
                    " Bundy",
                    " territ",
                    " Pradesh",
                    "opter",
                    " deployment",
                    " spont",
                    " leash",
                    "\u00e3\u0125\u00bc\u00e3\u0125\u00b3",
                    " launchers",
                    "tera"
                ],
                "neg_values": [
                    -0.661,
                    -0.656,
                    -0.652,
                    -0.633,
                    -0.63,
                    -0.618,
                    -0.616,
                    -0.61,
                    -0.598,
                    -0.595
                ],
                "pos_str": [
                    "essors",
                    " emer",
                    "iate",
                    "essor",
                    "itatively",
                    "ials",
                    "hips",
                    "sonian",
                    " specializing",
                    "onym"
                ],
                "pos_values": [
                    1.28,
                    1.13,
                    0.986,
                    0.973,
                    0.965,
                    0.937,
                    0.932,
                    0.856,
                    0.848,
                    0.842
                ],
                "frac_nonzero": 0.0003500000000000001,
                "freq_hist_data_bar_heights": [
                    241,
                    170,
                    107,
                    67,
                    52,
                    46,
                    36,
                    27,
                    21,
                    13,
                    9,
                    7,
                    3,
                    1,
                    3,
                    2,
                    2,
                    5,
                    2,
                    3,
                    4,
                    0,
                    3,
                    5,
                    9,
                    3,
                    6,
                    5,
                    6,
                    4,
                    10,
                    10,
                    9,
                    8,
                    12,
                    10,
                    14,
                    9,
                    17,
                    16,
                    9,
                    12,
                    5,
                    8,
                    20,
                    18,
                    17,
                    8,
                    16,
                    9
                ],
                "freq_hist_data_bar_values": [
                    0.518,
                    1.526,
                    2.535,
                    3.544,
                    4.553,
                    5.562,
                    6.571,
                    7.579,
                    8.588,
                    9.597,
                    10.606,
                    11.615,
                    12.624,
                    13.632,
                    14.641,
                    15.65,
                    16.659,
                    17.668,
                    18.677,
                    19.686,
                    20.694,
                    21.703,
                    22.712,
                    23.721,
                    24.73,
                    25.739,
                    26.747,
                    27.756,
                    28.765,
                    29.774,
                    30.783,
                    31.792,
                    32.801,
                    33.809,
                    34.818,
                    35.827,
                    36.836,
                    37.845,
                    38.854,
                    39.862,
                    40.871,
                    41.88,
                    42.889,
                    43.898,
                    44.907,
                    45.915,
                    46.924,
                    47.933,
                    48.942,
                    49.951
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    5,
                    14,
                    36,
                    67,
                    145,
                    245,
                    463,
                    637,
                    1077,
                    1631,
                    2245,
                    2891,
                    3610,
                    4050,
                    4456,
                    4550,
                    4462,
                    4035,
                    3456,
                    2911,
                    2304,
                    1826,
                    1373,
                    1105,
                    798,
                    569,
                    451,
                    265,
                    200,
                    140,
                    73,
                    75,
                    23,
                    18,
                    17,
                    5,
                    9,
                    7,
                    1,
                    0,
                    3,
                    2,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.642,
                    -0.603,
                    -0.564,
                    -0.525,
                    -0.486,
                    -0.448,
                    -0.409,
                    -0.37,
                    -0.331,
                    -0.292,
                    -0.254,
                    -0.215,
                    -0.176,
                    -0.137,
                    -0.098,
                    -0.059,
                    -0.021,
                    0.018,
                    0.057,
                    0.096,
                    0.135,
                    0.174,
                    0.212,
                    0.251,
                    0.29,
                    0.329,
                    0.368,
                    0.406,
                    0.445,
                    0.484,
                    0.523,
                    0.562,
                    0.601,
                    0.639,
                    0.678,
                    0.717,
                    0.756,
                    0.795,
                    0.834,
                    0.872,
                    0.911,
                    0.95,
                    0.989,
                    1.028,
                    1.066,
                    1.105,
                    1.144,
                    1.183,
                    1.222,
                    1.261
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "mentions of academic positions, particularly the title \"professor\"",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmszkogijui666oyvsthuo",
                        "tokens": [
                            "idget",
                            " Fre",
                            "ist",
                            "hler",
                            ",",
                            " an",
                            " associate",
                            " professor",
                            " at",
                            " UCLA",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " L",
                            "us",
                            "kin",
                            " School",
                            " of",
                            " Public",
                            " Affairs",
                            ",",
                            " had",
                            " examined",
                            " the",
                            " effect",
                            " of",
                            " liquor",
                            " stores",
                            " on",
                            " neighborhoods",
                            " and",
                            " thought",
                            " a",
                            " similar",
                            " approach",
                            " could",
                            " be",
                            " taken",
                            " to",
                            " dispensaries",
                            ".",
                            " In",
                            " late",
                            " 2011",
                            ",",
                            " Fre",
                            "ist",
                            "hler",
                            " was",
                            " approved",
                            " by",
                            " the",
                            " National",
                            " Institute",
                            " on",
                            " Drug",
                            " Abuse",
                            " for",
                            " five",
                            " years",
                            "\u00e2\u0122",
                            "\u013b",
                            " worth",
                            " of",
                            " research",
                            " into",
                            " the",
                            " impact",
                            " of",
                            " dispensaries",
                            " on",
                            " their",
                            " communities",
                            ".",
                            "\n",
                            "\n",
                            "Her",
                            " students",
                            " are",
                            " visiting",
                            " dispensaries",
                            " and",
                            " conducting",
                            " operational",
                            " surveys",
                            ",",
                            " which",
                            " ask",
                            " about",
                            " the",
                            " condition",
                            " of",
                            " the",
                            " dispensary",
                            ",",
                            " the",
                            " patients",
                            " that",
                            " enter",
                            ",",
                            " and",
                            " the",
                            " types",
                            " of",
                            " products",
                            " the",
                            " stores",
                            " sell",
                            ".",
                            " At",
                            " the",
                            " project",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " halfway",
                            " point",
                            ",",
                            " about",
                            " 10",
                            " students",
                            " have",
                            " worked",
                            " with",
                            " Fre",
                            "ist",
                            "hler"
                        ],
                        "dataIndex": null,
                        "index": "17375",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.455,
                        "maxValueTokenIndex": 7,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.455,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:07.351Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.455,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmszkogijvi666h59vub6d",
                        "tokens": [
                            " that",
                            " the",
                            " design",
                            " \u00e2\u0122",
                            "\u013e",
                            "does",
                            " not",
                            " reduce",
                            " existing",
                            " stockp",
                            "iles",
                            " of",
                            " spent",
                            " nuclear",
                            " fuel",
                            "\u00e2\u0122",
                            "\u013f",
                            " or",
                            " use",
                            " them",
                            " as",
                            " its",
                            " fuel",
                            " source",
                            ".",
                            " The",
                            " promise",
                            " of",
                            " recycling",
                            " nuclear",
                            " waste",
                            ",",
                            " which",
                            " poses",
                            " tricky",
                            " storage",
                            " and",
                            " proliferation",
                            " challenges",
                            ",",
                            " was",
                            " a",
                            " key",
                            " initial",
                            " attraction",
                            " of",
                            " the",
                            " company",
                            " and",
                            " captured",
                            " considerable",
                            " attention",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "In",
                            " early",
                            " 2016",
                            ",",
                            " we",
                            " realized",
                            " there",
                            " was",
                            " a",
                            " problem",
                            " with",
                            " our",
                            " initial",
                            " analysis",
                            " and",
                            " started",
                            " working",
                            " to",
                            " correct",
                            " the",
                            " error",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " co",
                            "founder",
                            " Leslie",
                            " Dew",
                            "an",
                            " said",
                            " in",
                            " an",
                            " e",
                            "-",
                            "mail",
                            " response",
                            " to",
                            " an",
                            " inquiry",
                            " from",
                            " MIT",
                            " Technology",
                            " Review",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " dramatic",
                            " revisions",
                            " followed",
                            " an",
                            " analysis",
                            " in",
                            " late",
                            " 2015",
                            " by",
                            " K",
                            "ord",
                            " Smith",
                            ",",
                            " a",
                            " professor",
                            " of",
                            " nuclear",
                            " science",
                            " and",
                            " engineering",
                            " at",
                            " MIT",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "17375",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.262,
                        "maxValueTokenIndex": 118,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.262,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:07.351Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.455,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmszkogijwi6661xv9nu5l",
                        "tokens": [
                            " two",
                            " years",
                            " there",
                            " have",
                            " been",
                            " hundreds",
                            " of",
                            " data",
                            " breaches",
                            " involving",
                            " customer",
                            " information",
                            ",",
                            " some",
                            " very",
                            " serious",
                            " like",
                            " the",
                            " Target",
                            " breach",
                            " in",
                            " 2013",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Holt",
                            ",",
                            " associate",
                            " professor",
                            " of",
                            " criminal",
                            " justice",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " happening",
                            " so",
                            " often",
                            " that",
                            " average",
                            " consumers",
                            " are",
                            " just",
                            " getting",
                            " into",
                            " this",
                            " mindset",
                            " of",
                            ",",
                            " \u00e2\u0122",
                            "\u013a",
                            "Well",
                            ",",
                            " my",
                            " bank",
                            " will",
                            " just",
                            " re",
                            "-",
                            "issue",
                            " the",
                            " card",
                            ",",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " not",
                            " a",
                            " problem",
                            ".",
                            "\u00e2\u0122",
                            "\u013b",
                            " But",
                            " this",
                            " is",
                            " more",
                            " than",
                            " a",
                            " hassle",
                            " or",
                            " inconvenience",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " real",
                            " economic",
                            " phenomenon",
                            " that",
                            " has",
                            " real",
                            " economic",
                            " impact",
                            " and",
                            " consequences",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "H",
                            "olt",
                            " and",
                            " fellow",
                            " researchers",
                            " analyzed",
                            " online",
                            " forums",
                            " in",
                            " English",
                            " and",
                            " Russian",
                            " where",
                            " criminals",
                            " sold",
                            " stolen",
                            " financial",
                            " and",
                            " personal"
                        ],
                        "dataIndex": null,
                        "index": "17375",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.058,
                        "maxValueTokenIndex": 29,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.058,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.302,
                            1.268,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:07.351Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.455,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "48794",
            "description": "references to academic titles and professions, specifically those related to professors",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5127978187320669,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "48794",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:26:10.852Z",
                "maxActApprox": 49.595,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    48794,
                    15773,
                    8330,
                    41472,
                    38872,
                    31459,
                    5198,
                    30967,
                    39715,
                    13657,
                    47724,
                    8748,
                    42517,
                    36846,
                    33946,
                    34564,
                    8162,
                    29334,
                    35512,
                    35244,
                    34160,
                    5131,
                    46531,
                    12493,
                    30790
                ],
                "topkCosSimValues": [
                    1,
                    0.7476,
                    0.5951,
                    0.5587,
                    0.5217,
                    0.5194,
                    0.5056,
                    0.4906,
                    0.4834,
                    0.4802,
                    0.4772,
                    0.4687,
                    0.4667,
                    0.4559,
                    0.4535,
                    0.4461,
                    0.4434,
                    0.4418,
                    0.4377,
                    0.4374,
                    0.434,
                    0.4332,
                    0.4291,
                    0.4268,
                    0.4026
                ],
                "neuron_alignment_indices": [
                    679,
                    288,
                    102
                ],
                "neuron_alignment_values": [
                    0.145,
                    0.115,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    414,
                    145,
                    235
                ],
                "correlated_neurons_pearson": [
                    0.021,
                    0.019,
                    0.019
                ],
                "correlated_neurons_l1": [
                    0.019,
                    0.019,
                    0.02
                ],
                "correlated_features_indices": [
                    48807,
                    48894,
                    48828
                ],
                "correlated_features_pearson": [
                    0.005,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.005,
                    0.001,
                    0
                ],
                "neg_str": [
                    " Pradesh",
                    " Bundy",
                    " territ",
                    "opter",
                    " launchers",
                    "tera",
                    "\u00e3\u0125\u00bc\u00e3\u0125\u00b3",
                    " leash",
                    " Passage",
                    " Clan"
                ],
                "neg_values": [
                    -0.674,
                    -0.667,
                    -0.661,
                    -0.647,
                    -0.63,
                    -0.628,
                    -0.627,
                    -0.618,
                    -0.616,
                    -0.59
                ],
                "pos_str": [
                    " emer",
                    "essors",
                    "itatively",
                    "iate",
                    "essor",
                    "ials",
                    "hips",
                    " specializing",
                    " professor",
                    " professors"
                ],
                "pos_values": [
                    1.255,
                    1.246,
                    1.015,
                    0.995,
                    0.972,
                    0.954,
                    0.942,
                    0.93,
                    0.886,
                    0.873
                ],
                "frac_nonzero": 0.00014,
                "freq_hist_data_bar_heights": [
                    58,
                    43,
                    24,
                    18,
                    12,
                    10,
                    8,
                    4,
                    1,
                    9,
                    3,
                    2,
                    6,
                    3,
                    1,
                    7,
                    2,
                    3,
                    6,
                    5,
                    3,
                    5,
                    7,
                    7,
                    3,
                    6,
                    11,
                    6,
                    8,
                    11,
                    3,
                    7,
                    7,
                    6,
                    3,
                    10,
                    4,
                    4,
                    10,
                    3,
                    10,
                    8,
                    8,
                    9,
                    10,
                    14,
                    5,
                    8,
                    11,
                    7
                ],
                "freq_hist_data_bar_values": [
                    0.499,
                    1.491,
                    2.483,
                    3.475,
                    4.467,
                    5.458,
                    6.45,
                    7.442,
                    8.434,
                    9.426,
                    10.418,
                    11.409,
                    12.401,
                    13.393,
                    14.385,
                    15.377,
                    16.369,
                    17.36,
                    18.352,
                    19.344,
                    20.336,
                    21.328,
                    22.32,
                    23.311,
                    24.303,
                    25.295,
                    26.287,
                    27.279,
                    28.271,
                    29.262,
                    30.254,
                    31.246,
                    32.238,
                    33.23,
                    34.222,
                    35.213,
                    36.205,
                    37.197,
                    38.189,
                    39.181,
                    40.173,
                    41.164,
                    42.156,
                    43.148,
                    44.14,
                    45.132,
                    46.124,
                    47.115,
                    48.107,
                    49.099
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    5,
                    11,
                    25,
                    41,
                    110,
                    180,
                    384,
                    576,
                    830,
                    1287,
                    1936,
                    2579,
                    3292,
                    3848,
                    4327,
                    4673,
                    4534,
                    4250,
                    3734,
                    3231,
                    2697,
                    1945,
                    1587,
                    1156,
                    893,
                    648,
                    459,
                    322,
                    259,
                    152,
                    96,
                    82,
                    34,
                    22,
                    14,
                    8,
                    8,
                    7,
                    1,
                    2,
                    2,
                    2,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.655,
                    -0.616,
                    -0.578,
                    -0.539,
                    -0.5,
                    -0.462,
                    -0.423,
                    -0.385,
                    -0.346,
                    -0.308,
                    -0.269,
                    -0.23,
                    -0.192,
                    -0.153,
                    -0.115,
                    -0.076,
                    -0.037,
                    0.001,
                    0.04,
                    0.078,
                    0.117,
                    0.155,
                    0.194,
                    0.233,
                    0.271,
                    0.31,
                    0.348,
                    0.387,
                    0.426,
                    0.464,
                    0.503,
                    0.541,
                    0.58,
                    0.618,
                    0.657,
                    0.696,
                    0.734,
                    0.773,
                    0.811,
                    0.85,
                    0.889,
                    0.927,
                    0.966,
                    1.004,
                    1.043,
                    1.082,
                    1.12,
                    1.159,
                    1.197,
                    1.236
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to academic titles and professions, specifically those related to professors",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk798j8kmb9i666nxfvyag9",
                        "tokens": [
                            "head",
                            " Wednesday",
                            " night",
                            " in",
                            " the",
                            " first",
                            " of",
                            " three",
                            " presidential",
                            " debates",
                            "\u2014",
                            "if",
                            " that",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " what",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " willing",
                            " to",
                            " call",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "These",
                            " are",
                            " more",
                            " accurately",
                            " called",
                            " joint",
                            " television",
                            " appearances",
                            " where",
                            " they",
                            " have",
                            " journalists",
                            " asking",
                            " the",
                            " questions",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " \u00e2\u0122",
                            "\u013e",
                            "J",
                            ".",
                            " Michael",
                            " Hogan",
                            ",",
                            " Ph",
                            ".",
                            "D",
                            ".,",
                            " Director",
                            " of",
                            " the",
                            " Center",
                            " for",
                            " Democratic",
                            " Del",
                            "iber",
                            "ation",
                            " and",
                            " a",
                            " professor",
                            " at",
                            " Pennsylvania",
                            " State",
                            " University",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "A",
                            " real",
                            " debate",
                            " would",
                            " be",
                            " more",
                            " unpredictable",
                            ".",
                            " They",
                            " couldn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " rely",
                            " on",
                            " the",
                            " sound",
                            " bites",
                            " they",
                            " use",
                            " to",
                            " answer",
                            " reporters",
                            "\u00e2\u0122",
                            "\u013b",
                            " questions",
                            " or",
                            " that",
                            " they",
                            " pull",
                            " right",
                            " out",
                            " of",
                            " their",
                            " campaign",
                            " stump",
                            " speeches",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Either",
                            " way",
                            ",",
                            " the",
                            " presidential",
                            " candidates"
                        ],
                        "dataIndex": null,
                        "index": "48794",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.595,
                        "maxValueTokenIndex": 71,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.595,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:26:14.883Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.595,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk798j9kmbai6662ohudjsk",
                        "tokens": [
                            " really",
                            " an",
                            " incentive",
                            " to",
                            " do",
                            " it",
                            " well",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Lib",
                            "by",
                            " Hem",
                            "ph",
                            "ill",
                            ",",
                            " a",
                            " professor",
                            " of",
                            " information",
                            " studies",
                            " at",
                            " the",
                            " University",
                            " of",
                            " Michigan",
                            " in",
                            " Ann",
                            " Arbor",
                            ".",
                            "\n",
                            "\n",
                            "T",
                            "ees",
                            "pring",
                            " is",
                            " a",
                            " San",
                            " Francisco",
                            "-",
                            "based",
                            " company",
                            " that",
                            " has",
                            " raised",
                            " millions",
                            " of",
                            " dollars",
                            " from",
                            " Silicon",
                            " Valley",
                            " sources",
                            " such",
                            " as",
                            " start",
                            "-",
                            "up",
                            " incub",
                            "ator",
                            " Y",
                            " Com",
                            "bin",
                            "ator",
                            " and",
                            " venture",
                            " capital",
                            " firms",
                            " including",
                            " Andre",
                            "essen",
                            " Horowitz",
                            " and",
                            " Kh",
                            "os",
                            "la",
                            " Ventures",
                            ".",
                            "\n",
                            "\n",
                            "Its",
                            " business",
                            " model",
                            " is",
                            " to",
                            " act",
                            " as",
                            " an",
                            " intermediary",
                            ":",
                            " Customers",
                            " upload",
                            " designs",
                            " for",
                            " custom",
                            " T",
                            "-",
                            "shirts",
                            " and",
                            " other",
                            " logo",
                            " items",
                            ".",
                            " They",
                            " then",
                            " sell",
                            " the",
                            " items",
                            " either",
                            " on",
                            " the",
                            " Te",
                            "es",
                            "pring",
                            " site",
                            " or",
                            " on",
                            " their",
                            " own",
                            " sites",
                            ".",
                            " Te",
                            "es",
                            "pring",
                            " takes",
                            " a",
                            " cut"
                        ],
                        "dataIndex": null,
                        "index": "48794",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.884,
                        "maxValueTokenIndex": 18,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.884,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:26:14.883Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.595,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk798jbkmbti666osjk03w2",
                        "tokens": [
                            " really",
                            " an",
                            " incentive",
                            " to",
                            " do",
                            " it",
                            " well",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Lib",
                            "by",
                            " Hem",
                            "ph",
                            "ill",
                            ",",
                            " a",
                            " professor",
                            " of",
                            " information",
                            " studies",
                            " at",
                            " the",
                            " University",
                            " of",
                            " Michigan",
                            " in",
                            " Ann",
                            " Arbor",
                            ".",
                            "\n",
                            "\n",
                            "T",
                            "ees",
                            "pring",
                            " is",
                            " a",
                            " San",
                            " Francisco",
                            "-",
                            "based",
                            " company",
                            " that",
                            " has",
                            " raised",
                            " millions",
                            " of",
                            " dollars",
                            " from",
                            " Silicon",
                            " Valley",
                            " sources",
                            " such",
                            " as",
                            " start",
                            "-",
                            "up",
                            " incub",
                            "ator",
                            " Y",
                            " Com",
                            "bin",
                            "ator",
                            " and",
                            " venture",
                            " capital",
                            " firms",
                            " including",
                            " Andre",
                            "essen",
                            " Horowitz",
                            " and",
                            " Kh",
                            "os",
                            "la",
                            " Ventures",
                            ".",
                            "\n",
                            "\n",
                            "Its",
                            " business",
                            " model",
                            " is",
                            " to",
                            " act",
                            " as",
                            " an",
                            " intermediary",
                            ":",
                            " Customers",
                            " upload",
                            " designs",
                            " for",
                            " custom",
                            " T",
                            "-",
                            "shirts",
                            " and",
                            " other",
                            " logo",
                            " items",
                            ".",
                            " They",
                            " then",
                            " sell",
                            " the",
                            " items",
                            " either",
                            " on",
                            " the",
                            " Te",
                            "es",
                            "pring",
                            " site",
                            " or",
                            " on",
                            " their",
                            " own",
                            " sites",
                            ".",
                            " Te",
                            "es",
                            "pring",
                            " takes",
                            " a",
                            " cut"
                        ],
                        "dataIndex": null,
                        "index": "48794",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.884,
                        "maxValueTokenIndex": 18,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.884,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:26:14.883Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 39.676,
                        "binMax": 49.595,
                        "binContains": 3e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "46751",
            "description": " references to professors or their roles in academia",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5101803541183508,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "46751",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:32:23.357Z",
                "maxActApprox": 30.995,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    46751,
                    64654,
                    97409,
                    35435,
                    42428,
                    48115,
                    84880,
                    19951,
                    93548,
                    15503,
                    44,
                    78642,
                    46770,
                    36352,
                    77827,
                    78206,
                    53510,
                    12698,
                    89161,
                    52515,
                    64882,
                    27016,
                    73248,
                    36233,
                    29411
                ],
                "topkCosSimValues": [
                    1,
                    0.7346,
                    0.6608,
                    0.6388,
                    0.5611,
                    0.5439,
                    0.5238,
                    0.5138,
                    0.5048,
                    0.4814,
                    0.4778,
                    0.4745,
                    0.4665,
                    0.4651,
                    0.4633,
                    0.4489,
                    0.4471,
                    0.4457,
                    0.4377,
                    0.4341,
                    0.4332,
                    0.4247,
                    0.422,
                    0.4213,
                    0.4182
                ],
                "neuron_alignment_indices": [
                    679,
                    288,
                    167
                ],
                "neuron_alignment_values": [
                    0.158,
                    0.123,
                    0.115
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    679,
                    111,
                    235
                ],
                "correlated_neurons_pearson": [
                    0.015,
                    0.015,
                    0.015
                ],
                "correlated_neurons_l1": [
                    0.017,
                    0.014,
                    0.016
                ],
                "correlated_features_indices": [
                    46770,
                    46718,
                    46666
                ],
                "correlated_features_pearson": [
                    0.003,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0.001,
                    0
                ],
                "neg_str": [
                    " territ",
                    " launchers",
                    " Krypt",
                    "axy",
                    " recovery",
                    " Pradesh",
                    " Recovery",
                    " Siberia",
                    " launcher",
                    " Territories"
                ],
                "neg_values": [
                    -0.854,
                    -0.742,
                    -0.708,
                    -0.657,
                    -0.653,
                    -0.645,
                    -0.642,
                    -0.639,
                    -0.635,
                    -0.627
                ],
                "pos_str": [
                    "essors",
                    "hips",
                    "ials",
                    "iate",
                    "essor",
                    "hip",
                    "ulas",
                    "iles",
                    "ially",
                    " professors"
                ],
                "pos_values": [
                    1.395,
                    1.016,
                    1.009,
                    0.986,
                    0.962,
                    0.888,
                    0.864,
                    0.801,
                    0.797,
                    0.794
                ],
                "frac_nonzero": 0.00011,
                "freq_hist_data_bar_heights": [
                    46,
                    35,
                    28,
                    16,
                    24,
                    7,
                    10,
                    6,
                    9,
                    8,
                    6,
                    8,
                    5,
                    7,
                    8,
                    3,
                    3,
                    4,
                    3,
                    0,
                    1,
                    2,
                    6,
                    8,
                    0,
                    2,
                    2,
                    4,
                    2,
                    2,
                    1,
                    4,
                    7,
                    10,
                    7,
                    1,
                    8,
                    5,
                    4,
                    7,
                    5,
                    3,
                    2,
                    3,
                    7,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.332,
                    0.951,
                    1.571,
                    2.19,
                    2.81,
                    3.429,
                    4.048,
                    4.668,
                    5.287,
                    5.907,
                    6.526,
                    7.146,
                    7.765,
                    8.385,
                    9.004,
                    9.624,
                    10.243,
                    10.862,
                    11.482,
                    12.101,
                    12.721,
                    13.34,
                    13.96,
                    14.579,
                    15.199,
                    15.818,
                    16.438,
                    17.057,
                    17.676,
                    18.296,
                    18.915,
                    19.535,
                    20.154,
                    20.774,
                    21.393,
                    22.013,
                    22.632,
                    23.252,
                    23.871,
                    24.49,
                    25.11,
                    25.729,
                    26.349,
                    26.968,
                    27.588,
                    28.207,
                    28.827,
                    29.446,
                    30.065,
                    30.685
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    1,
                    6,
                    9,
                    22,
                    64,
                    134,
                    246,
                    407,
                    750,
                    1228,
                    1969,
                    2802,
                    3672,
                    4489,
                    5086,
                    5239,
                    5167,
                    4577,
                    3678,
                    3016,
                    2250,
                    1715,
                    1252,
                    882,
                    580,
                    367,
                    267,
                    170,
                    74,
                    57,
                    30,
                    25,
                    7,
                    10,
                    0,
                    2,
                    0,
                    2,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.832,
                    -0.787,
                    -0.742,
                    -0.697,
                    -0.652,
                    -0.607,
                    -0.562,
                    -0.517,
                    -0.472,
                    -0.427,
                    -0.382,
                    -0.337,
                    -0.292,
                    -0.247,
                    -0.202,
                    -0.157,
                    -0.112,
                    -0.067,
                    -0.022,
                    0.023,
                    0.068,
                    0.113,
                    0.158,
                    0.203,
                    0.248,
                    0.293,
                    0.338,
                    0.383,
                    0.428,
                    0.473,
                    0.518,
                    0.563,
                    0.608,
                    0.653,
                    0.698,
                    0.742,
                    0.787,
                    0.832,
                    0.877,
                    0.922,
                    0.967,
                    1.012,
                    1.057,
                    1.102,
                    1.147,
                    1.192,
                    1.237,
                    1.282,
                    1.327,
                    1.372
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to professors and their roles in academia",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " references to professors or their roles in academia",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygh6f9happu10exny4niu7s",
                        "tokens": [
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " received",
                            " death",
                            " threats",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Ped",
                            "h",
                            "az",
                            "ur",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "But",
                            " no",
                            " one",
                            " at",
                            " the",
                            " university",
                            " has",
                            " offered",
                            " to",
                            " protect",
                            " me",
                            " or",
                            " my",
                            " students",
                            ".",
                            " That",
                            " is",
                            " why",
                            " I",
                            " went",
                            " to",
                            " the",
                            " police",
                            " last",
                            " Monday",
                            " to",
                            " request",
                            " protection",
                            " for",
                            " my",
                            " class",
                            " \u2014",
                            " titled",
                            " \u00e2\u0122",
                            "\u013a",
                            "Su",
                            "icide",
                            " Terror",
                            "\u00e2\u0122",
                            "\u013b",
                            " \u2014",
                            " which",
                            " is",
                            " in",
                            " a",
                            " basement",
                            ",",
                            " so",
                            " in",
                            " an",
                            " emergency",
                            " situation",
                            ",",
                            " it",
                            " would",
                            " be",
                            " very",
                            " hard",
                            " to",
                            " evacuate",
                            " 95",
                            " students",
                            ".",
                            " I",
                            " couldn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " take",
                            " the",
                            " chance",
                            " that",
                            " because",
                            " of",
                            " my",
                            " name",
                            ",",
                            " someone",
                            " would",
                            " try",
                            " to",
                            " do",
                            " away",
                            " with",
                            " a",
                            " \u00e2\u0122",
                            "\u013a",
                            "Z",
                            "ion",
                            "ist",
                            " professor",
                            ".",
                            "\u00e2\u0122",
                            "\u013b",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " first",
                            " course",
                            " of",
                            " action",
                            " Ped",
                            "h",
                            "az",
                            "ur",
                            " took",
                            " was",
                            " to"
                        ],
                        "dataIndex": null,
                        "index": "46751",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 30.995,
                        "maxValueTokenIndex": 107,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            30.995,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:32:37.418Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 24.796,
                        "binMax": 30.995,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh6f9eapp810exijseqnbs",
                        "tokens": [
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " received",
                            " death",
                            " threats",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Ped",
                            "h",
                            "az",
                            "ur",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "But",
                            " no",
                            " one",
                            " at",
                            " the",
                            " university",
                            " has",
                            " offered",
                            " to",
                            " protect",
                            " me",
                            " or",
                            " my",
                            " students",
                            ".",
                            " That",
                            " is",
                            " why",
                            " I",
                            " went",
                            " to",
                            " the",
                            " police",
                            " last",
                            " Monday",
                            " to",
                            " request",
                            " protection",
                            " for",
                            " my",
                            " class",
                            " \u2014",
                            " titled",
                            " \u00e2\u0122",
                            "\u013a",
                            "Su",
                            "icide",
                            " Terror",
                            "\u00e2\u0122",
                            "\u013b",
                            " \u2014",
                            " which",
                            " is",
                            " in",
                            " a",
                            " basement",
                            ",",
                            " so",
                            " in",
                            " an",
                            " emergency",
                            " situation",
                            ",",
                            " it",
                            " would",
                            " be",
                            " very",
                            " hard",
                            " to",
                            " evacuate",
                            " 95",
                            " students",
                            ".",
                            " I",
                            " couldn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " take",
                            " the",
                            " chance",
                            " that",
                            " because",
                            " of",
                            " my",
                            " name",
                            ",",
                            " someone",
                            " would",
                            " try",
                            " to",
                            " do",
                            " away",
                            " with",
                            " a",
                            " \u00e2\u0122",
                            "\u013a",
                            "Z",
                            "ion",
                            "ist",
                            " professor",
                            ".",
                            "\u00e2\u0122",
                            "\u013b",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " first",
                            " course",
                            " of",
                            " action",
                            " Ped",
                            "h",
                            "az",
                            "ur",
                            " took",
                            " was",
                            " to"
                        ],
                        "dataIndex": null,
                        "index": "46751",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 30.995,
                        "maxValueTokenIndex": 107,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            30.995,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:32:37.418Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 30.995,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh6f9fapp910ex2xttekrg",
                        "tokens": [
                            " view",
                            " up",
                            " to",
                            " six",
                            " devices",
                            " on",
                            " the",
                            " network",
                            " in",
                            " the",
                            " free",
                            " license",
                            " version",
                            ",",
                            " but",
                            " the",
                            " full",
                            " version",
                            ",",
                            " which",
                            " scans",
                            " the",
                            " network",
                            " and",
                            " displays",
                            " all",
                            " connected",
                            " devices",
                            ",",
                            " is",
                            " not",
                            " free",
                            ".",
                            "\n",
                            "\n",
                            "What",
                            " if",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " on",
                            " a",
                            " budget",
                            " or",
                            " your",
                            " local",
                            " network",
                            " has",
                            " more",
                            " than",
                            " five",
                            " additional",
                            " devices",
                            " connected",
                            "?",
                            " Try",
                            " i",
                            "Net",
                            " instead",
                            ".",
                            " This",
                            " inexpensive",
                            " utility",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " free",
                            " but",
                            " scans",
                            " your",
                            " entire",
                            " network",
                            " and",
                            " displays",
                            " all",
                            " connected",
                            " devices",
                            ",",
                            " including",
                            " Bon",
                            "j",
                            "our",
                            " connections",
                            ",",
                            " and",
                            " it",
                            " has",
                            " a",
                            " graphic",
                            " interface",
                            ".",
                            "\n",
                            "\n",
                            "Well",
                            " done",
                            ",",
                            " fast",
                            ",",
                            " easy",
                            ",",
                            " cheaper",
                            ".",
                            "<|endoftext|>",
                            "University",
                            " professors",
                            " in",
                            " New",
                            " Brunswick",
                            " are",
                            " asking",
                            " St",
                            ".",
                            " Thomas",
                            " University",
                            " to",
                            " withdraw",
                            " its",
                            " offer",
                            " to",
                            " host",
                            " C",
                            "TV",
                            "'s",
                            " leaders",
                            "'"
                        ],
                        "dataIndex": null,
                        "index": "46751",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.867,
                        "maxValueTokenIndex": 106,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.867,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:32:37.418Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 30.995,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "21059",
            "description": "scientific and academic titles, such as 'scientist', 'researcher', and 'professor', especially with corresponding fields of study",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5209186387609633,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "21059",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:11:45.415Z",
                "maxActApprox": 30.149,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    21059,
                    15052,
                    17678,
                    3055,
                    17402,
                    12016,
                    9502,
                    19014,
                    12774,
                    7818,
                    21417,
                    12028,
                    16490,
                    253,
                    16699,
                    8553,
                    3578,
                    9444,
                    12258,
                    16749,
                    14029,
                    4153,
                    7648,
                    20873,
                    12214
                ],
                "topkCosSimValues": [
                    1,
                    0.6284,
                    0.5645,
                    0.5493,
                    0.5484,
                    0.5377,
                    0.5003,
                    0.4969,
                    0.4895,
                    0.4593,
                    0.4485,
                    0.4359,
                    0.4334,
                    0.4312,
                    0.4288,
                    0.4238,
                    0.4204,
                    0.4185,
                    0.4124,
                    0.3983,
                    0.3936,
                    0.3918,
                    0.3899,
                    0.3892,
                    0.3708
                ],
                "neuron_alignment_indices": [
                    414,
                    233,
                    684
                ],
                "neuron_alignment_values": [
                    0.114,
                    0.089,
                    0.086
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    204,
                    414,
                    104
                ],
                "correlated_neurons_pearson": [
                    0.039,
                    0.036,
                    0.032
                ],
                "correlated_neurons_l1": [
                    0.039,
                    0.03,
                    0.031
                ],
                "correlated_features_indices": [
                    21015,
                    21089,
                    20992
                ],
                "correlated_features_pearson": [
                    0.016,
                    0.009,
                    0.009
                ],
                "correlated_features_l1": [
                    0.017,
                    0.009,
                    0.009
                ],
                "neg_str": [
                    " needles",
                    "ombies",
                    " idiots",
                    "rums",
                    "Players",
                    "Ts",
                    "Reward",
                    "humans",
                    " hordes",
                    "SPONSORED"
                ],
                "neg_values": [
                    -0.786,
                    -0.75,
                    -0.737,
                    -0.734,
                    -0.712,
                    -0.672,
                    -0.664,
                    -0.66,
                    -0.65,
                    -0.65
                ],
                "pos_str": [
                    " specializing",
                    "hunter",
                    " adjunct",
                    "alyst",
                    " assistant",
                    " extraord",
                    " affiliated",
                    "abase",
                    " emer",
                    " adviser"
                ],
                "pos_values": [
                    1.065,
                    0.853,
                    0.827,
                    0.809,
                    0.807,
                    0.785,
                    0.766,
                    0.761,
                    0.749,
                    0.748
                ],
                "frac_nonzero": 0.0009,
                "freq_hist_data_bar_heights": [
                    317,
                    308,
                    233,
                    205,
                    184,
                    176,
                    123,
                    105,
                    87,
                    98,
                    82,
                    69,
                    76,
                    50,
                    48,
                    49,
                    44,
                    49,
                    44,
                    42,
                    27,
                    36,
                    23,
                    20,
                    20,
                    22,
                    24,
                    23,
                    17,
                    18,
                    19,
                    21,
                    16,
                    17,
                    11,
                    13,
                    24,
                    16,
                    13,
                    9,
                    11,
                    10,
                    11,
                    12,
                    4,
                    2,
                    2,
                    4,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.302,
                    0.905,
                    1.508,
                    2.111,
                    2.714,
                    3.317,
                    3.92,
                    4.523,
                    5.126,
                    5.729,
                    6.332,
                    6.934,
                    7.537,
                    8.14,
                    8.743,
                    9.346,
                    9.949,
                    10.552,
                    11.155,
                    11.758,
                    12.361,
                    12.964,
                    13.567,
                    14.17,
                    14.773,
                    15.376,
                    15.979,
                    16.582,
                    17.185,
                    17.788,
                    18.391,
                    18.994,
                    19.597,
                    20.2,
                    20.803,
                    21.406,
                    22.009,
                    22.612,
                    23.215,
                    23.818,
                    24.421,
                    25.024,
                    25.627,
                    26.23,
                    26.833,
                    27.436,
                    28.039,
                    28.642,
                    29.245,
                    29.848
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    3,
                    0,
                    8,
                    8,
                    23,
                    46,
                    91,
                    164,
                    230,
                    398,
                    600,
                    767,
                    1095,
                    1435,
                    1842,
                    2410,
                    2936,
                    3476,
                    4077,
                    4295,
                    4418,
                    4308,
                    3954,
                    3291,
                    2921,
                    2200,
                    1507,
                    1171,
                    802,
                    566,
                    425,
                    247,
                    210,
                    107,
                    77,
                    58,
                    33,
                    26,
                    9,
                    7,
                    8,
                    1,
                    3,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.767,
                    -0.73,
                    -0.693,
                    -0.656,
                    -0.619,
                    -0.582,
                    -0.545,
                    -0.508,
                    -0.471,
                    -0.434,
                    -0.397,
                    -0.36,
                    -0.323,
                    -0.286,
                    -0.249,
                    -0.212,
                    -0.175,
                    -0.138,
                    -0.101,
                    -0.064,
                    -0.027,
                    0.01,
                    0.047,
                    0.084,
                    0.121,
                    0.158,
                    0.195,
                    0.232,
                    0.269,
                    0.306,
                    0.343,
                    0.38,
                    0.417,
                    0.454,
                    0.491,
                    0.528,
                    0.565,
                    0.602,
                    0.639,
                    0.676,
                    0.713,
                    0.75,
                    0.787,
                    0.824,
                    0.861,
                    0.898,
                    0.935,
                    0.972,
                    1.009,
                    1.046
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "scientific and academic titles, such as 'scientist', 'researcher', and 'professor', especially with corresponding fields of study",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmz1mrk0nli666hooh36n6",
                        "tokens": [
                            ",",
                            " this",
                            " study",
                            " underscores",
                            " the",
                            " purpose",
                            " of",
                            " agricultural",
                            " research",
                            " funding",
                            ",",
                            " especially",
                            " in",
                            " developing",
                            " countries",
                            ",\"",
                            " says",
                            " Andrew",
                            " Bal",
                            "m",
                            "ford",
                            ",",
                            " a",
                            " conservation",
                            " scientist",
                            " at",
                            " the",
                            " University",
                            " of",
                            " Cambridge",
                            ",",
                            " UK",
                            ".",
                            " Unless",
                            " the",
                            " world",
                            " sees",
                            " a",
                            " second",
                            " green",
                            " revolution",
                            ",",
                            " some",
                            " 1",
                            ".",
                            "5",
                            " billion",
                            " to",
                            " 2",
                            " billion",
                            " additional",
                            " hectares",
                            " will",
                            " need",
                            " to",
                            " be",
                            " put",
                            " into",
                            " production",
                            " by",
                            " 2050",
                            " to",
                            " feed",
                            " a",
                            " growing",
                            " population",
                            ",",
                            " according",
                            " to",
                            " an",
                            " ongoing",
                            " analysis",
                            " by",
                            " David",
                            " Til",
                            "man",
                            ",",
                            " an",
                            " ec",
                            "ologist",
                            " at",
                            " the",
                            " University",
                            " of",
                            " Minnesota",
                            " in",
                            " St",
                            " Paul",
                            ".",
                            " Fortunately",
                            ",",
                            " there",
                            " is",
                            " plenty",
                            " of",
                            " cleared",
                            " land",
                            " that",
                            " is",
                            " under",
                            "performing",
                            " and",
                            " massive",
                            " potential",
                            " for",
                            " boosting",
                            " yields",
                            " in",
                            " developing",
                            " countries",
                            ",",
                            " Til",
                            "man",
                            " says",
                            ".",
                            " \"",
                            "If",
                            " we",
                            " want",
                            " to",
                            " save",
                            " the",
                            " Earth",
                            ",",
                            " we",
                            " have",
                            " to"
                        ],
                        "dataIndex": null,
                        "index": "21059",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 30.149,
                        "maxValueTokenIndex": 79,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            22.077,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.387,
                            30.149,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:11:49.971Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 30.149,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmz1mrk0nmi66667zf36bs",
                        "tokens": [
                            "shift",
                            " work",
                            " can",
                            " increase",
                            " the",
                            " risk",
                            " of",
                            " developing",
                            " Type",
                            " 2",
                            " diabetes",
                            ".",
                            " The",
                            " backward",
                            " schedule",
                            " can",
                            " mess",
                            " with",
                            " the",
                            " body",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " ability",
                            " to",
                            " use",
                            " insulin",
                            " properly",
                            " to",
                            " break",
                            " down",
                            " sugars",
                            " in",
                            " the",
                            " blood",
                            ",",
                            " according",
                            " to",
                            " Dr",
                            ".",
                            " Frank",
                            " Hu",
                            ",",
                            " a",
                            " professor",
                            " of",
                            " nutrition",
                            " and",
                            " epidem",
                            "iology",
                            " at",
                            " Harvard",
                            " School",
                            " of",
                            " Public",
                            " Health",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " a",
                            " study",
                            " involving",
                            " nearly",
                            " 177",
                            ",",
                            "000",
                            " middle",
                            "-",
                            "aged",
                            " women",
                            " enrolled",
                            " in",
                            " two",
                            " Nurs",
                            "es",
                            "\u00e2\u0122",
                            "\u013b",
                            " Health",
                            " Studies",
                            ",",
                            " women",
                            " who",
                            " worked",
                            " rotating",
                            " night",
                            " shifts",
                            " for",
                            " 1",
                            " to",
                            " 2",
                            " years",
                            " increased",
                            " their",
                            " risk",
                            " of",
                            " developing",
                            " diabetes",
                            " by",
                            " 5",
                            "%",
                            " over",
                            " a",
                            " 20",
                            "-",
                            "year",
                            " follow",
                            "-",
                            "up",
                            " period",
                            ",",
                            " compared",
                            " with",
                            " women",
                            " who",
                            " didn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " get",
                            " assigned",
                            " these",
                            " shifts",
                            ".",
                            " Women",
                            " who",
                            " kept"
                        ],
                        "dataIndex": null,
                        "index": "21059",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.493,
                        "maxValueTokenIndex": 44,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.493,
                            0,
                            0,
                            0,
                            0,
                            5.697,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:11:49.971Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 30.149,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmz1mrk0nni666n9rakryb",
                        "tokens": [
                            " the",
                            " risk",
                            " of",
                            " unwanted",
                            " side",
                            " effects",
                            ",\"",
                            " said",
                            " Dr",
                            ".",
                            " Mun",
                            "itta",
                            " M",
                            "uth",
                            "ana",
                            ",",
                            " a",
                            " researcher",
                            " at",
                            " the",
                            " University",
                            " of",
                            " Sheffield",
                            ",",
                            " in",
                            " a",
                            " press",
                            " release",
                            ".",
                            " \"",
                            "The",
                            " beauty",
                            " of",
                            " using",
                            " the",
                            " MRI",
                            " scanner",
                            " to",
                            " administer",
                            " the",
                            " therapy",
                            " is",
                            " that",
                            " you",
                            " can",
                            " also",
                            " use",
                            " it",
                            " for",
                            " its",
                            " original",
                            " purpose",
                            " providing",
                            " a",
                            " real",
                            "-",
                            "time",
                            " image",
                            "-",
                            "guide",
                            " to",
                            " ensure",
                            " the",
                            " treatment",
                            " has",
                            " gone",
                            " where",
                            " it",
                            " is",
                            " needed",
                            ".\"",
                            "\n",
                            "\n",
                            "The",
                            " researchers",
                            " injected",
                            " immune",
                            " cells",
                            " carrying",
                            " SP",
                            "IO",
                            "s",
                            " and",
                            " the",
                            " cancer",
                            " killing",
                            " on",
                            "co",
                            "ly",
                            "tic",
                            " virus",
                            " into",
                            " mice",
                            " with",
                            " cancer",
                            ",",
                            " and",
                            " directed",
                            " to",
                            " primary",
                            " and",
                            " secondary",
                            " tumors",
                            " in",
                            " their",
                            " bodies",
                            " using",
                            " an",
                            " MRI",
                            " scanner",
                            ".",
                            " The",
                            " method",
                            " result",
                            " in",
                            " an",
                            " 800",
                            " percent",
                            " increase",
                            " in",
                            " the",
                            " therapy",
                            "'s",
                            " effectiveness",
                            ".",
                            "\n",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "21059",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.491,
                        "maxValueTokenIndex": 17,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.491,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:11:49.971Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 30.149,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "24986",
            "description": "words related to academic titles, particularly references to professors and their positions",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5039607286453283,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "24986",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:43:41.991Z",
                "maxActApprox": 48.344,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    24986,
                    28221,
                    27049,
                    31907,
                    46508,
                    12325,
                    39950,
                    6717,
                    16083,
                    21308,
                    18038,
                    21413,
                    18722,
                    12687,
                    12146,
                    4207,
                    17750,
                    14435,
                    29520,
                    3226,
                    14569,
                    19453,
                    15171,
                    35837,
                    34581
                ],
                "topkCosSimValues": [
                    1,
                    0.2915,
                    0.2913,
                    0.2913,
                    0.2898,
                    0.2892,
                    0.2886,
                    0.2853,
                    0.2796,
                    0.2755,
                    0.2742,
                    0.2717,
                    0.2691,
                    0.2675,
                    0.2648,
                    0.2636,
                    0.263,
                    0.2615,
                    0.2607,
                    0.259,
                    0.2574,
                    0.2564,
                    0.2546,
                    0.2542,
                    0.2538
                ],
                "neuron_alignment_indices": [
                    763,
                    354,
                    356
                ],
                "neuron_alignment_values": [
                    0.117,
                    0.114,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    326,
                    763,
                    659
                ],
                "correlated_neurons_pearson": [
                    0.007,
                    0.006,
                    0.006
                ],
                "correlated_neurons_l1": [
                    0.006,
                    0.006,
                    0.006
                ],
                "correlated_features_indices": [
                    24993,
                    24991,
                    25024
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.006,
                    0.003,
                    0.002
                ],
                "neg_str": [
                    "CVE",
                    " marrow",
                    "ibaba",
                    " princ",
                    " exha",
                    " gobl",
                    " silence",
                    "atch",
                    " unprepared",
                    " appropriation"
                ],
                "neg_values": [
                    -0.739,
                    -0.718,
                    -0.704,
                    -0.668,
                    -0.655,
                    -0.654,
                    -0.652,
                    -0.636,
                    -0.626,
                    -0.621
                ],
                "pos_str": [
                    "idget",
                    "uously",
                    "own",
                    "robe",
                    "uous",
                    "oad",
                    "oggle",
                    "te",
                    "tic",
                    "yll"
                ],
                "pos_values": [
                    1.075,
                    0.917,
                    0.915,
                    0.874,
                    0.843,
                    0.826,
                    0.816,
                    0.804,
                    0.801,
                    0.785
                ],
                "frac_nonzero": 8.999999999999999e-05,
                "freq_hist_data_bar_heights": [
                    113,
                    54,
                    49,
                    16,
                    14,
                    6,
                    6,
                    7,
                    5,
                    1,
                    2,
                    1,
                    2,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.484,
                    1.451,
                    2.418,
                    3.385,
                    4.352,
                    5.319,
                    6.286,
                    7.252,
                    8.219,
                    9.186,
                    10.153,
                    11.12,
                    12.087,
                    13.054,
                    14.021,
                    14.987,
                    15.954,
                    16.921,
                    17.888,
                    18.855,
                    19.822,
                    20.789,
                    21.756,
                    22.722,
                    23.689,
                    24.656,
                    25.623,
                    26.59,
                    27.557,
                    28.524,
                    29.49,
                    30.457,
                    31.424,
                    32.391,
                    33.358,
                    34.325,
                    35.292,
                    36.259,
                    37.225,
                    38.192,
                    39.159,
                    40.126,
                    41.093,
                    42.06,
                    43.027,
                    43.993,
                    44.96,
                    45.927,
                    46.894,
                    47.861
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    1,
                    4,
                    6,
                    11,
                    25,
                    53,
                    68,
                    166,
                    289,
                    535,
                    803,
                    1166,
                    1555,
                    2044,
                    2598,
                    3169,
                    3790,
                    4201,
                    4062,
                    4154,
                    3884,
                    3455,
                    3065,
                    2581,
                    2074,
                    1686,
                    1323,
                    958,
                    769,
                    547,
                    378,
                    297,
                    204,
                    100,
                    82,
                    57,
                    33,
                    18,
                    11,
                    13,
                    9,
                    4,
                    2,
                    1,
                    2,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.721,
                    -0.685,
                    -0.649,
                    -0.612,
                    -0.576,
                    -0.54,
                    -0.503,
                    -0.467,
                    -0.431,
                    -0.395,
                    -0.358,
                    -0.322,
                    -0.286,
                    -0.249,
                    -0.213,
                    -0.177,
                    -0.141,
                    -0.104,
                    -0.068,
                    -0.032,
                    0.005,
                    0.041,
                    0.077,
                    0.113,
                    0.15,
                    0.186,
                    0.222,
                    0.259,
                    0.295,
                    0.331,
                    0.367,
                    0.404,
                    0.44,
                    0.476,
                    0.513,
                    0.549,
                    0.585,
                    0.621,
                    0.658,
                    0.694,
                    0.73,
                    0.767,
                    0.803,
                    0.839,
                    0.875,
                    0.912,
                    0.948,
                    0.984,
                    1.021,
                    1.057
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "words related to academic titles, particularly references to professors and their positions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk5qn65yo4ti6661zy02m08",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "Ped",
                            "erson",
                            " told",
                            " me",
                            " that",
                            " FBI",
                            " agent",
                            " Mark",
                            " Col",
                            "burn",
                            " told",
                            " him",
                            ",",
                            " quote",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "The",
                            " Johnson",
                            " County",
                            " Prosecutor",
                            " won",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " do",
                            " anything",
                            " until",
                            " the",
                            " Grand",
                            " Jury",
                            " conven",
                            "es",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " Well",
                            ",",
                            " the",
                            " next",
                            " day",
                            " was",
                            " Sunday",
                            ",",
                            " when",
                            " Dr",
                            ".",
                            " George",
                            " T",
                            "iller",
                            " was",
                            " killed",
                            ",",
                            " allegedly",
                            " by",
                            " Scott",
                            " Ro",
                            "eder",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " called",
                            " the",
                            " Kansas",
                            " City",
                            " FBI",
                            " and",
                            " reached",
                            " Col",
                            "burn",
                            ",",
                            " who",
                            " referred",
                            " me",
                            " to",
                            " FBI",
                            " spokesperson",
                            " Br",
                            "idget",
                            " Patton",
                            ".",
                            " I",
                            " asked",
                            " her",
                            " why",
                            " Scott",
                            " Ro",
                            "eder",
                            " had",
                            " not",
                            " been",
                            " arrested",
                            " when",
                            " he",
                            " vandal",
                            "ized",
                            " the",
                            " Kansas",
                            " City",
                            " clinic",
                            " the",
                            " day",
                            " before",
                            ".",
                            "\n",
                            "\n",
                            "BR",
                            "ID",
                            "GET",
                            " PAT",
                            "TON",
                            ":",
                            " [",
                            "ina",
                            "ud",
                            "ible",
                            "]",
                            " was",
                            " notified",
                            " about",
                            " vandalism",
                            " that",
                            " occurred"
                        ],
                        "dataIndex": null,
                        "index": "24986",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.344,
                        "maxValueTokenIndex": 82,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.344,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.861,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:43:47.724Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 48.344,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5qn67yo5fi666jmzss1j0",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "Ped",
                            "erson",
                            " told",
                            " me",
                            " that",
                            " FBI",
                            " agent",
                            " Mark",
                            " Col",
                            "burn",
                            " told",
                            " him",
                            ",",
                            " quote",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "The",
                            " Johnson",
                            " County",
                            " Prosecutor",
                            " won",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " do",
                            " anything",
                            " until",
                            " the",
                            " Grand",
                            " Jury",
                            " conven",
                            "es",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " Well",
                            ",",
                            " the",
                            " next",
                            " day",
                            " was",
                            " Sunday",
                            ",",
                            " when",
                            " Dr",
                            ".",
                            " George",
                            " T",
                            "iller",
                            " was",
                            " killed",
                            ",",
                            " allegedly",
                            " by",
                            " Scott",
                            " Ro",
                            "eder",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " called",
                            " the",
                            " Kansas",
                            " City",
                            " FBI",
                            " and",
                            " reached",
                            " Col",
                            "burn",
                            ",",
                            " who",
                            " referred",
                            " me",
                            " to",
                            " FBI",
                            " spokesperson",
                            " Br",
                            "idget",
                            " Patton",
                            ".",
                            " I",
                            " asked",
                            " her",
                            " why",
                            " Scott",
                            " Ro",
                            "eder",
                            " had",
                            " not",
                            " been",
                            " arrested",
                            " when",
                            " he",
                            " vandal",
                            "ized",
                            " the",
                            " Kansas",
                            " City",
                            " clinic",
                            " the",
                            " day",
                            " before",
                            ".",
                            "\n",
                            "\n",
                            "BR",
                            "ID",
                            "GET",
                            " PAT",
                            "TON",
                            ":",
                            " [",
                            "ina",
                            "ud",
                            "ible",
                            "]",
                            " was",
                            " notified",
                            " about",
                            " vandalism",
                            " that",
                            " occurred"
                        ],
                        "dataIndex": null,
                        "index": "24986",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.344,
                        "maxValueTokenIndex": 82,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.344,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.861,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:43:47.724Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 38.675,
                        "binMax": 48.344,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5qn65yo4ui666rb2lrh5y",
                        "tokens": [
                            "\n",
                            "\n",
                            "AMY",
                            " GOODMAN",
                            ":",
                            " And",
                            " were",
                            " you",
                            " notified",
                            " more",
                            " than",
                            " once",
                            " in",
                            " two",
                            " different",
                            " incidents",
                            "?",
                            "\n",
                            "\n",
                            "BR",
                            "ID",
                            "GET",
                            " PAT",
                            "TON",
                            ":",
                            " Honestly",
                            ",",
                            " Amy",
                            ",",
                            " I",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " have",
                            " the",
                            " answer",
                            " to",
                            " that",
                            ".",
                            "\n",
                            "\n",
                            "AMY",
                            " GOODMAN",
                            ":",
                            " That",
                            " was",
                            " Br",
                            "idget",
                            " Patton",
                            ",",
                            " FBI",
                            " spokesperson",
                            " in",
                            " Kansas",
                            " City",
                            " about",
                            " why",
                            " the",
                            " FBI",
                            " did",
                            " not",
                            " respond",
                            " to",
                            " the",
                            " two",
                            " reports",
                            " of",
                            " vandalism",
                            " at",
                            " a",
                            " women",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " health",
                            " clinic",
                            " in",
                            " Kansas",
                            " City",
                            " last",
                            " week",
                            ".",
                            " The",
                            " man",
                            " who",
                            " vandal",
                            "ized",
                            " that",
                            " clinic",
                            ",",
                            " Scott",
                            " Ro",
                            "eder",
                            ",",
                            " has",
                            " now",
                            " been",
                            " charged",
                            " with",
                            " the",
                            " murder",
                            " of",
                            " Dr",
                            ".",
                            " T",
                            "iller",
                            ".",
                            "\n",
                            "\n",
                            "Scott",
                            " Ro",
                            "eder",
                            " has",
                            " a",
                            " history",
                            " of",
                            " involvement",
                            " in",
                            " anti",
                            "-",
                            "abortion",
                            " activism",
                            " and",
                            " has",
                            " ties",
                            " to"
                        ],
                        "dataIndex": null,
                        "index": "24986",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.17,
                        "maxValueTokenIndex": 48,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.853,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.17,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:43:47.724Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 48.344,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "44",
            "description": "mentions of academic professionals, specifically professors",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5009816587556406,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "44",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:28:31.021Z",
                "maxActApprox": 69.065,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    44,
                    97409,
                    68007,
                    73248,
                    6218,
                    12928,
                    78071,
                    10517,
                    36642,
                    57268,
                    86544,
                    24175,
                    38945,
                    46751,
                    16944,
                    64654,
                    54842,
                    80673,
                    89731,
                    4411,
                    91451,
                    13602,
                    30381,
                    37952,
                    61929
                ],
                "topkCosSimValues": [
                    1,
                    0.682,
                    0.6665,
                    0.6403,
                    0.6203,
                    0.5641,
                    0.5467,
                    0.5436,
                    0.5101,
                    0.5068,
                    0.4948,
                    0.4865,
                    0.4824,
                    0.4778,
                    0.466,
                    0.4496,
                    0.4487,
                    0.4411,
                    0.4342,
                    0.4323,
                    0.4296,
                    0.4259,
                    0.4254,
                    0.4248,
                    0.4224
                ],
                "neuron_alignment_indices": [
                    679,
                    631,
                    288
                ],
                "neuron_alignment_values": [
                    0.119,
                    0.105,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    631,
                    60,
                    462
                ],
                "correlated_neurons_pearson": [
                    0.012,
                    0.012,
                    0.011
                ],
                "correlated_neurons_l1": [
                    0.012,
                    0.011,
                    0.01
                ],
                "correlated_features_indices": [
                    143,
                    119,
                    44
                ],
                "correlated_features_pearson": [
                    0.003,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0,
                    0
                ],
                "neg_str": [
                    " ashore",
                    " cruc",
                    " routed",
                    " handc",
                    " leash",
                    " setback",
                    " cramped",
                    "boat",
                    " ranger",
                    " overboard"
                ],
                "neg_values": [
                    -0.724,
                    -0.695,
                    -0.693,
                    -0.692,
                    -0.686,
                    -0.673,
                    -0.658,
                    -0.649,
                    -0.642,
                    -0.637
                ],
                "pos_str": [
                    "essors",
                    "iles",
                    "iciency",
                    "icient",
                    "ession",
                    "essor",
                    "umo",
                    "ound",
                    "edes",
                    "illing"
                ],
                "pos_values": [
                    1.594,
                    1.219,
                    1.163,
                    1.116,
                    1.079,
                    1.079,
                    1.004,
                    0.952,
                    0.947,
                    0.934
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    18,
                    7,
                    3,
                    2,
                    5,
                    3,
                    1,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    3,
                    2,
                    1,
                    0,
                    1,
                    2,
                    0,
                    3,
                    1,
                    1,
                    2,
                    2,
                    1,
                    2,
                    3,
                    0,
                    2,
                    0,
                    3,
                    3,
                    4,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.814,
                    2.193,
                    3.572,
                    4.951,
                    6.329,
                    7.708,
                    9.087,
                    10.466,
                    11.845,
                    13.223,
                    14.602,
                    15.981,
                    17.36,
                    18.739,
                    20.117,
                    21.496,
                    22.875,
                    24.254,
                    25.633,
                    27.011,
                    28.39,
                    29.769,
                    31.148,
                    32.527,
                    33.906,
                    35.284,
                    36.663,
                    38.042,
                    39.421,
                    40.8,
                    42.178,
                    43.557,
                    44.936,
                    46.315,
                    47.694,
                    49.072,
                    50.451,
                    51.83,
                    53.209,
                    54.588,
                    55.966,
                    57.345,
                    58.724,
                    60.103,
                    61.482,
                    62.861,
                    64.239,
                    65.618,
                    66.997,
                    68.376
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    6,
                    14,
                    42,
                    75,
                    191,
                    371,
                    768,
                    1215,
                    1887,
                    2745,
                    3433,
                    4077,
                    4512,
                    4550,
                    4539,
                    3938,
                    3641,
                    3162,
                    2725,
                    2201,
                    1796,
                    1387,
                    996,
                    711,
                    448,
                    332,
                    191,
                    134,
                    71,
                    40,
                    20,
                    13,
                    4,
                    4,
                    4,
                    2,
                    1,
                    2,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.701,
                    -0.655,
                    -0.608,
                    -0.562,
                    -0.516,
                    -0.469,
                    -0.423,
                    -0.377,
                    -0.33,
                    -0.284,
                    -0.237,
                    -0.191,
                    -0.145,
                    -0.098,
                    -0.052,
                    -0.006,
                    0.041,
                    0.087,
                    0.134,
                    0.18,
                    0.226,
                    0.273,
                    0.319,
                    0.365,
                    0.412,
                    0.458,
                    0.504,
                    0.551,
                    0.597,
                    0.644,
                    0.69,
                    0.736,
                    0.783,
                    0.829,
                    0.875,
                    0.922,
                    0.968,
                    1.015,
                    1.061,
                    1.107,
                    1.154,
                    1.2,
                    1.246,
                    1.293,
                    1.339,
                    1.386,
                    1.432,
                    1.478,
                    1.525,
                    1.571
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "mentions of academic professionals, specifically professors",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to professors or academic professionals",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygew2cxbdb010exx12lsn1d",
                        "tokens": [
                            " to",
                            " this",
                            " idea",
                            " was",
                            " outlined",
                            " in",
                            " a",
                            " 2013",
                            " post",
                            ",",
                            " Challenges",
                            " of",
                            " Passive",
                            " Funding",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " shift",
                            " led",
                            " to",
                            " a",
                            " noticeable",
                            " improvement",
                            " in",
                            " our",
                            " ability",
                            " to",
                            " source",
                            " tangible",
                            " giving",
                            " opportunities",
                            ".",
                            "\n",
                            "\n",
                            "Examples",
                            " of",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "giving",
                            " to",
                            " learn",
                            "\u00e2\u0122",
                            "\u013f",
                            " dynamic",
                            "\n",
                            "\n",
                            "The",
                            " first",
                            " cause",
                            " we",
                            " chose",
                            " for",
                            " a",
                            " relatively",
                            " deep",
                            " investigation",
                            " \u2013",
                            " including",
                            " some",
                            " grants",
                            " \u2013",
                            " was",
                            " criminal",
                            " justice",
                            " reform",
                            " .",
                            " Of",
                            " the",
                            " causes",
                            " we",
                            " were",
                            " interested",
                            " in",
                            ",",
                            " it",
                            " seemed",
                            " to",
                            " offer",
                            " the",
                            " best",
                            " odds",
                            " of",
                            " quickly",
                            " finding",
                            " \u00e2\u0122",
                            "\u013e",
                            "sh",
                            "o",
                            "vel",
                            "-",
                            "ready",
                            "\u00e2\u0122",
                            "\u013f",
                            " giving",
                            " opportunities",
                            ",",
                            " based",
                            " on",
                            " the",
                            " comments",
                            " of",
                            " Steven",
                            " Tel",
                            "es",
                            " .",
                            " We",
                            " told",
                            " Prof",
                            ".",
                            " Tel",
                            "es",
                            " that",
                            " we",
                            " were",
                            " interested",
                            " in",
                            " making",
                            " some",
                            " initial",
                            " grants",
                            " in",
                            " this",
                            " cause",
                            ",",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "44",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 69.065,
                        "maxValueTokenIndex": 109,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            69.065,
                            8.569,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:34.412Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 69.065,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew2czbdbo10exhcif3be5",
                        "tokens": [
                            " to",
                            " this",
                            " idea",
                            " was",
                            " outlined",
                            " in",
                            " a",
                            " 2013",
                            " post",
                            ",",
                            " Challenges",
                            " of",
                            " Passive",
                            " Funding",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " shift",
                            " led",
                            " to",
                            " a",
                            " noticeable",
                            " improvement",
                            " in",
                            " our",
                            " ability",
                            " to",
                            " source",
                            " tangible",
                            " giving",
                            " opportunities",
                            ".",
                            "\n",
                            "\n",
                            "Examples",
                            " of",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "giving",
                            " to",
                            " learn",
                            "\u00e2\u0122",
                            "\u013f",
                            " dynamic",
                            "\n",
                            "\n",
                            "The",
                            " first",
                            " cause",
                            " we",
                            " chose",
                            " for",
                            " a",
                            " relatively",
                            " deep",
                            " investigation",
                            " \u2013",
                            " including",
                            " some",
                            " grants",
                            " \u2013",
                            " was",
                            " criminal",
                            " justice",
                            " reform",
                            " .",
                            " Of",
                            " the",
                            " causes",
                            " we",
                            " were",
                            " interested",
                            " in",
                            ",",
                            " it",
                            " seemed",
                            " to",
                            " offer",
                            " the",
                            " best",
                            " odds",
                            " of",
                            " quickly",
                            " finding",
                            " \u00e2\u0122",
                            "\u013e",
                            "sh",
                            "o",
                            "vel",
                            "-",
                            "ready",
                            "\u00e2\u0122",
                            "\u013f",
                            " giving",
                            " opportunities",
                            ",",
                            " based",
                            " on",
                            " the",
                            " comments",
                            " of",
                            " Steven",
                            " Tel",
                            "es",
                            " .",
                            " We",
                            " told",
                            " Prof",
                            ".",
                            " Tel",
                            "es",
                            " that",
                            " we",
                            " were",
                            " interested",
                            " in",
                            " making",
                            " some",
                            " initial",
                            " grants",
                            " in",
                            " this",
                            " cause",
                            ",",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "44",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 69.065,
                        "maxValueTokenIndex": 109,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            69.065,
                            8.569,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:34.412Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 55.252,
                        "binMax": 69.065,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew2cxbdb110exlmqmddh2",
                        "tokens": [
                            " to",
                            " state",
                            " schools",
                            ",",
                            " not",
                            " private",
                            " schools",
                            ".",
                            " Acad",
                            "emies",
                            " and",
                            " free",
                            " schools",
                            " can",
                            " also",
                            " choose",
                            " not",
                            " to",
                            " follow",
                            " it",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " an",
                            " interview",
                            " with",
                            " the",
                            " Times",
                            " Educational",
                            " Supplement",
                            " (",
                            "T",
                            "ES",
                            "),",
                            " Prof",
                            " Roberts",
                            ",",
                            " who",
                            " has",
                            " presented",
                            " a",
                            " number",
                            " of",
                            " BBC",
                            " programmes",
                            " including",
                            " The",
                            " Incredible",
                            " Human",
                            " Journey",
                            " and",
                            " Origins",
                            " of",
                            " Us",
                            ",",
                            " said",
                            ":",
                            " \u00e2\u0122",
                            "\u013e",
                            "There",
                            " should",
                            " be",
                            " regulation",
                            " that",
                            " prevents",
                            " all",
                            " schools",
                            ",",
                            " not",
                            " just",
                            " state",
                            " schools",
                            ",",
                            " from",
                            " teaching",
                            " creation",
                            "ism",
                            " because",
                            " it",
                            " is",
                            " indoctr",
                            "ination",
                            ",",
                            " it",
                            " is",
                            " planting",
                            " ideas",
                            " into",
                            " children",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " heads",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "We",
                            " should",
                            " be",
                            " teaching",
                            " children",
                            " to",
                            " be",
                            " much",
                            " more",
                            " open",
                            "-",
                            "minded",
                            ".",
                            " People",
                            " who",
                            " believe",
                            " in",
                            " creation",
                            "ism",
                            " say",
                            " that",
                            " by",
                            " teaching",
                            " evolution",
                            " you",
                            " are",
                            " indoctr",
                            "inating"
                        ],
                        "dataIndex": null,
                        "index": "44",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 65.873,
                        "maxValueTokenIndex": 35,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            65.873,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:34.412Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 69.065,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "1720",
            "description": "names or titles of academic professionals",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4999791085707619,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "1720",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:46:44.976Z",
                "maxActApprox": 48.094,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    1720,
                    13995,
                    1868,
                    3241,
                    9172,
                    18677,
                    22575,
                    16132,
                    7843,
                    15174,
                    18848,
                    23902,
                    5446,
                    17375,
                    6153,
                    5941,
                    23693,
                    23957,
                    7991,
                    21778,
                    16800,
                    3258,
                    20506,
                    23000,
                    6989
                ],
                "topkCosSimValues": [
                    1,
                    0.6258,
                    0.5995,
                    0.5856,
                    0.5793,
                    0.5309,
                    0.4861,
                    0.4668,
                    0.4621,
                    0.4495,
                    0.4295,
                    0.4247,
                    0.4045,
                    0.4044,
                    0.3858,
                    0.3759,
                    0.3738,
                    0.3604,
                    0.3517,
                    0.3485,
                    0.3479,
                    0.3473,
                    0.3467,
                    0.3412,
                    0.3344
                ],
                "neuron_alignment_indices": [
                    510,
                    430,
                    408
                ],
                "neuron_alignment_values": [
                    0.108,
                    0.099,
                    0.086
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    430,
                    631,
                    204
                ],
                "correlated_neurons_pearson": [
                    0.027,
                    0.026,
                    0.026
                ],
                "correlated_neurons_l1": [
                    0.028,
                    0.026,
                    0.026
                ],
                "correlated_features_indices": [
                    1762,
                    1684,
                    1675
                ],
                "correlated_features_pearson": [
                    0.005,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.005,
                    0,
                    0.001
                ],
                "neg_str": [
                    "OPA",
                    " routed",
                    " destro",
                    "tumblr",
                    " scrimmage",
                    " actionGroup",
                    " ranch",
                    "LET",
                    " pony",
                    " handc"
                ],
                "neg_values": [
                    -0.78,
                    -0.764,
                    -0.699,
                    -0.68,
                    -0.674,
                    -0.673,
                    -0.672,
                    -0.668,
                    -0.663,
                    -0.655
                ],
                "pos_str": [
                    "essors",
                    " Richard",
                    " Ian",
                    " Nigel",
                    " Andrew",
                    " Stephen",
                    " Jonathan",
                    " Geoffrey",
                    " Hawking",
                    " Allan"
                ],
                "pos_values": [
                    1.089,
                    0.952,
                    0.916,
                    0.892,
                    0.891,
                    0.887,
                    0.884,
                    0.882,
                    0.879,
                    0.878
                ],
                "frac_nonzero": 0.00032,
                "freq_hist_data_bar_heights": [
                    207,
                    125,
                    114,
                    61,
                    72,
                    53,
                    46,
                    34,
                    42,
                    28,
                    19,
                    19,
                    23,
                    16,
                    13,
                    8,
                    8,
                    17,
                    7,
                    14,
                    12,
                    4,
                    4,
                    3,
                    8,
                    4,
                    7,
                    3,
                    5,
                    4,
                    3,
                    2,
                    1,
                    1,
                    1,
                    1,
                    2,
                    4,
                    1,
                    2,
                    0,
                    1,
                    2,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.485,
                    1.446,
                    2.408,
                    3.37,
                    4.332,
                    5.294,
                    6.256,
                    7.217,
                    8.179,
                    9.141,
                    10.103,
                    11.065,
                    12.026,
                    12.988,
                    13.95,
                    14.912,
                    15.874,
                    16.835,
                    17.797,
                    18.759,
                    19.721,
                    20.683,
                    21.645,
                    22.606,
                    23.568,
                    24.53,
                    25.492,
                    26.454,
                    27.415,
                    28.377,
                    29.339,
                    30.301,
                    31.263,
                    32.224,
                    33.186,
                    34.148,
                    35.11,
                    36.072,
                    37.034,
                    37.995,
                    38.957,
                    39.919,
                    40.881,
                    41.843,
                    42.804,
                    43.766,
                    44.728,
                    45.69,
                    46.652,
                    47.613
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    0,
                    5,
                    8,
                    6,
                    22,
                    38,
                    83,
                    147,
                    252,
                    508,
                    725,
                    1118,
                    1617,
                    2219,
                    2727,
                    3228,
                    3546,
                    3789,
                    3980,
                    3761,
                    3436,
                    3040,
                    2815,
                    2396,
                    2113,
                    1700,
                    1468,
                    1182,
                    998,
                    788,
                    625,
                    490,
                    385,
                    277,
                    214,
                    156,
                    118,
                    90,
                    72,
                    35,
                    25,
                    23,
                    13,
                    14,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.761,
                    -0.724,
                    -0.687,
                    -0.649,
                    -0.612,
                    -0.575,
                    -0.537,
                    -0.5,
                    -0.462,
                    -0.425,
                    -0.388,
                    -0.35,
                    -0.313,
                    -0.276,
                    -0.238,
                    -0.201,
                    -0.163,
                    -0.126,
                    -0.089,
                    -0.051,
                    -0.014,
                    0.023,
                    0.061,
                    0.098,
                    0.136,
                    0.173,
                    0.21,
                    0.248,
                    0.285,
                    0.322,
                    0.36,
                    0.397,
                    0.434,
                    0.472,
                    0.509,
                    0.547,
                    0.584,
                    0.621,
                    0.659,
                    0.696,
                    0.734,
                    0.771,
                    0.808,
                    0.846,
                    0.883,
                    0.92,
                    0.958,
                    0.995,
                    1.032,
                    1.07
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "names or titles of academic professionals",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdm2vbr1msni666ymw7z17u",
                        "tokens": [
                            " had",
                            " eroded",
                            " in",
                            " a",
                            " large",
                            " glacier",
                            " that",
                            " fed",
                            " a",
                            " number",
                            " of",
                            " small",
                            " lakes",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " gl",
                            "acial",
                            " lakes",
                            " used",
                            " to",
                            " feed",
                            " two",
                            " river",
                            " systems",
                            " -",
                            " the",
                            " Slim",
                            "s",
                            " River",
                            " and",
                            " the",
                            " K",
                            "ask",
                            "aw",
                            "ul",
                            "sh",
                            " River",
                            " -",
                            " but",
                            " when",
                            " water",
                            " from",
                            " one",
                            " lake",
                            " poured",
                            " through",
                            " the",
                            " channel",
                            " into",
                            " another",
                            ",",
                            " it",
                            " cut",
                            " the",
                            " Slim",
                            "s",
                            " off",
                            " from",
                            " its",
                            " water",
                            " source",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " event",
                            " is",
                            " known",
                            " as",
                            " river",
                            " piracy",
                            " or",
                            " stream",
                            " capture",
                            ",",
                            " and",
                            " can",
                            " take",
                            " thousands",
                            " of",
                            " years",
                            ".",
                            " But",
                            " the",
                            " researchers",
                            " documented",
                            " the",
                            " piracy",
                            " of",
                            " the",
                            " Slim",
                            "s",
                            " River",
                            " in",
                            " just",
                            " one",
                            " spring",
                            ".",
                            "\n",
                            "\n",
                            "Prof",
                            " Sh",
                            "ugar",
                            " said",
                            " his",
                            " colleague",
                            ",",
                            " John",
                            " Cl",
                            "ague",
                            ",",
                            " at",
                            " Simon",
                            " Fraser",
                            " University",
                            " in",
                            " British",
                            " Columbia",
                            ",",
                            " had",
                            " predicted",
                            " this",
                            " event",
                            " just",
                            " a"
                        ],
                        "dataIndex": null,
                        "index": "1720",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.094,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.094,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:46:48.801Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 48.094,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdm2vbt1mt9i6666je3axni",
                        "tokens": [
                            " had",
                            " eroded",
                            " in",
                            " a",
                            " large",
                            " glacier",
                            " that",
                            " fed",
                            " a",
                            " number",
                            " of",
                            " small",
                            " lakes",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " gl",
                            "acial",
                            " lakes",
                            " used",
                            " to",
                            " feed",
                            " two",
                            " river",
                            " systems",
                            " -",
                            " the",
                            " Slim",
                            "s",
                            " River",
                            " and",
                            " the",
                            " K",
                            "ask",
                            "aw",
                            "ul",
                            "sh",
                            " River",
                            " -",
                            " but",
                            " when",
                            " water",
                            " from",
                            " one",
                            " lake",
                            " poured",
                            " through",
                            " the",
                            " channel",
                            " into",
                            " another",
                            ",",
                            " it",
                            " cut",
                            " the",
                            " Slim",
                            "s",
                            " off",
                            " from",
                            " its",
                            " water",
                            " source",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " event",
                            " is",
                            " known",
                            " as",
                            " river",
                            " piracy",
                            " or",
                            " stream",
                            " capture",
                            ",",
                            " and",
                            " can",
                            " take",
                            " thousands",
                            " of",
                            " years",
                            ".",
                            " But",
                            " the",
                            " researchers",
                            " documented",
                            " the",
                            " piracy",
                            " of",
                            " the",
                            " Slim",
                            "s",
                            " River",
                            " in",
                            " just",
                            " one",
                            " spring",
                            ".",
                            "\n",
                            "\n",
                            "Prof",
                            " Sh",
                            "ugar",
                            " said",
                            " his",
                            " colleague",
                            ",",
                            " John",
                            " Cl",
                            "ague",
                            ",",
                            " at",
                            " Simon",
                            " Fraser",
                            " University",
                            " in",
                            " British",
                            " Columbia",
                            ",",
                            " had",
                            " predicted",
                            " this",
                            " event",
                            " just",
                            " a"
                        ],
                        "dataIndex": null,
                        "index": "1720",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.094,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.094,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:46:48.801Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 38.476,
                        "binMax": 48.094,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdm2vbr1msoi666rgjq17td",
                        "tokens": [
                            " dead",
                            ",",
                            " because",
                            " these",
                            " procedures",
                            " for",
                            " forfeiture",
                            " during",
                            " the",
                            " trial",
                            " will",
                            " kill",
                            " the",
                            " company",
                            "\u00e2\u0122",
                            "\u013f",
                            "<|endoftext|>",
                            "According",
                            " to",
                            " a",
                            " duo",
                            " of",
                            " Australian",
                            " scientists",
                            ",",
                            " Aboriginal",
                            " society",
                            " has",
                            " preserved",
                            " memories",
                            " of",
                            " Australia",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " coastline",
                            " dating",
                            " back",
                            " to",
                            " 11",
                            ",",
                            "000",
                            " \u2013",
                            " 5",
                            ",",
                            "300",
                            " BC",
                            ".",
                            "\n",
                            "\n",
                            "Prof",
                            ".",
                            " Patrick",
                            " N",
                            "unn",
                            " of",
                            " the",
                            " University",
                            " of",
                            " the",
                            " Sunshine",
                            " Coast",
                            " and",
                            " Dr",
                            " Nick",
                            " Reid",
                            " of",
                            " the",
                            " University",
                            " of",
                            " New",
                            " England",
                            " analyzed",
                            " Aboriginal",
                            " stories",
                            " from",
                            " 21",
                            " places",
                            " around",
                            " Australia",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " coastline",
                            ",",
                            " each",
                            " describing",
                            " a",
                            " time",
                            " when",
                            " sea",
                            " levels",
                            " were",
                            " significantly",
                            " lower",
                            " than",
                            " today",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "The",
                            " present",
                            " sea",
                            " levels",
                            " in",
                            " Australia",
                            " were",
                            " reached",
                            " 7",
                            ",",
                            "000",
                            " years",
                            " ago",
                            " and",
                            " as",
                            " such",
                            " any",
                            " stories",
                            " about",
                            " the",
                            " coastline",
                            " stretching",
                            " much",
                            " further",
                            " out"
                        ],
                        "dataIndex": null,
                        "index": "1720",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.367,
                        "maxValueTokenIndex": 50,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.367,
                            10.379,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.735,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:46:48.801Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 48.094,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "34160",
            "description": "references to academic or research titles indicating seniority or expertise",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.49877545230242415,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "34160",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:00:11.124Z",
                "maxActApprox": 47.104,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    34160,
                    38755,
                    17307,
                    48794,
                    8706,
                    20569,
                    37534,
                    45492,
                    40658,
                    46058,
                    38872,
                    34564,
                    8299,
                    8330,
                    792,
                    37293,
                    15987,
                    15773,
                    44045,
                    6623,
                    7983,
                    24107,
                    8673,
                    40197,
                    1223
                ],
                "topkCosSimValues": [
                    1,
                    0.5055,
                    0.4667,
                    0.434,
                    0.3904,
                    0.3841,
                    0.3763,
                    0.3648,
                    0.3501,
                    0.3476,
                    0.3392,
                    0.3332,
                    0.3324,
                    0.3291,
                    0.3269,
                    0.3226,
                    0.3148,
                    0.3111,
                    0.3015,
                    0.3003,
                    0.2987,
                    0.2979,
                    0.2947,
                    0.2943,
                    0.2931
                ],
                "neuron_alignment_indices": [
                    519,
                    407,
                    109
                ],
                "neuron_alignment_values": [
                    0.125,
                    0.114,
                    0.111
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    21,
                    407,
                    519
                ],
                "correlated_neurons_pearson": [
                    0.011,
                    0.01,
                    0.009
                ],
                "correlated_neurons_l1": [
                    0.01,
                    0.01,
                    0.008
                ],
                "correlated_features_indices": [
                    34101,
                    34105,
                    34087
                ],
                "correlated_features_pearson": [
                    0.001,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0.001,
                    0
                ],
                "neg_str": [
                    " skelet",
                    " curfew",
                    " destro",
                    " compulsion",
                    " annexed",
                    " DRAG",
                    " ultras",
                    " disag",
                    " dehyd",
                    " stairs"
                ],
                "neg_values": [
                    -0.68,
                    -0.671,
                    -0.665,
                    -0.663,
                    -0.631,
                    -0.631,
                    -0.631,
                    -0.613,
                    -0.612,
                    -0.601
                ],
                "pos_str": [
                    "hips",
                    " laureate",
                    "iola",
                    "\u0124\u00ac",
                    "graduate",
                    "inguished",
                    "ference",
                    "holder",
                    "ervative",
                    " Lowell"
                ],
                "pos_values": [
                    1.04,
                    0.832,
                    0.763,
                    0.76,
                    0.754,
                    0.752,
                    0.748,
                    0.746,
                    0.735,
                    0.727
                ],
                "frac_nonzero": 4e-05,
                "freq_hist_data_bar_heights": [
                    34,
                    23,
                    15,
                    13,
                    4,
                    6,
                    4,
                    2,
                    2,
                    3,
                    1,
                    0,
                    1,
                    1,
                    2,
                    1,
                    0,
                    0,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    4,
                    2,
                    3,
                    1,
                    4,
                    0,
                    1,
                    2,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.476,
                    1.418,
                    2.36,
                    3.302,
                    4.244,
                    5.186,
                    6.128,
                    7.07,
                    8.012,
                    8.954,
                    9.896,
                    10.838,
                    11.78,
                    12.722,
                    13.664,
                    14.606,
                    15.548,
                    16.49,
                    17.432,
                    18.374,
                    19.316,
                    20.258,
                    21.2,
                    22.141,
                    23.083,
                    24.025,
                    24.967,
                    25.909,
                    26.851,
                    27.793,
                    28.735,
                    29.677,
                    30.619,
                    31.561,
                    32.503,
                    33.445,
                    34.387,
                    35.329,
                    36.271,
                    37.213,
                    38.155,
                    39.097,
                    40.039,
                    40.981,
                    41.923,
                    42.865,
                    43.807,
                    44.749,
                    45.691,
                    46.633
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    5,
                    4,
                    11,
                    31,
                    59,
                    106,
                    184,
                    291,
                    458,
                    759,
                    1056,
                    1418,
                    2055,
                    2452,
                    2925,
                    3459,
                    3685,
                    3982,
                    3906,
                    3778,
                    3541,
                    3262,
                    2713,
                    2377,
                    1955,
                    1531,
                    1181,
                    897,
                    668,
                    471,
                    335,
                    220,
                    158,
                    112,
                    84,
                    50,
                    29,
                    15,
                    15,
                    6,
                    7,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.662,
                    -0.628,
                    -0.594,
                    -0.559,
                    -0.525,
                    -0.491,
                    -0.456,
                    -0.422,
                    -0.387,
                    -0.353,
                    -0.319,
                    -0.284,
                    -0.25,
                    -0.215,
                    -0.181,
                    -0.147,
                    -0.112,
                    -0.078,
                    -0.043,
                    -0.009,
                    0.025,
                    0.06,
                    0.094,
                    0.128,
                    0.163,
                    0.197,
                    0.232,
                    0.266,
                    0.3,
                    0.335,
                    0.369,
                    0.404,
                    0.438,
                    0.472,
                    0.507,
                    0.541,
                    0.575,
                    0.61,
                    0.644,
                    0.679,
                    0.713,
                    0.747,
                    0.782,
                    0.816,
                    0.851,
                    0.885,
                    0.919,
                    0.954,
                    0.988,
                    1.023
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to academic or research titles indicating seniority or expertise",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk6bwoz74oki666gxm054jb",
                        "tokens": [
                            "\u013f",
                            " between",
                            " Moscow",
                            " and",
                            " Beijing",
                            ",",
                            " he",
                            " sees",
                            " little",
                            " to",
                            " suggest",
                            " \u00e2\u0122",
                            "\u013e",
                            "a",
                            " new",
                            " threshold",
                            " of",
                            " collaboration",
                            " between",
                            " socialist",
                            " brothers",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Adam",
                            " Mount",
                            ",",
                            " a",
                            " senior",
                            " fellow",
                            " at",
                            " the",
                            " liberal",
                            " Center",
                            " for",
                            " American",
                            " Progress",
                            ",",
                            " is",
                            " more",
                            " concerned",
                            " by",
                            " Tuesday",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " coordinated",
                            " message",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "I",
                            " think",
                            " we",
                            " need",
                            " to",
                            " be",
                            " aware",
                            " of",
                            " the",
                            " possibility",
                            " that",
                            " China",
                            " and",
                            " Russia",
                            " could",
                            " take",
                            " a",
                            " step",
                            " back",
                            " from",
                            " containing",
                            " the",
                            " regime",
                            " and",
                            " move",
                            " towards",
                            " increased",
                            " diplomatic",
                            " recognition",
                            ",",
                            " which",
                            " could",
                            " someday",
                            " lead",
                            " to",
                            " their",
                            " recognition",
                            " of",
                            " North",
                            " Korea",
                            " as",
                            " a",
                            " nuclear",
                            " state",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Mount",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "That",
                            " would",
                            " be",
                            " in",
                            " keeping",
                            " with",
                            " Russia",
                            "'s",
                            " mod",
                            "us",
                            " oper",
                            "andi",
                            ",",
                            " which",
                            " is",
                            " to",
                            " support",
                            " rogue"
                        ],
                        "dataIndex": null,
                        "index": "34160",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 47.104,
                        "maxValueTokenIndex": 31,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            47.104,
                            2.529,
                            0.075,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:00:19.556Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 47.104,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6bwoz74oli666g42vaxdq",
                        "tokens": [
                            " and",
                            " director",
                            " of",
                            " Health",
                            " Policy",
                            " at",
                            " the",
                            " Manhattan",
                            " Institute",
                            ";",
                            " Av",
                            "ik",
                            " Roy",
                            ",",
                            " a",
                            " senior",
                            " fellow",
                            " at",
                            " the",
                            " Manhattan",
                            " Institute",
                            " and",
                            " editor",
                            " of",
                            " The",
                            " Ap",
                            "othe",
                            "c",
                            "ary",
                            ",",
                            " a",
                            " Forbes",
                            " health",
                            " care",
                            " blog",
                            ";",
                            " and",
                            " Y",
                            "ev",
                            "gen",
                            "iy",
                            " Fey",
                            "man",
                            ",",
                            " fellow",
                            " and",
                            " deputy",
                            " director",
                            " of",
                            " Health",
                            " Policy",
                            " at",
                            " the",
                            " Manhattan",
                            " Institute",
                            ".",
                            "\n",
                            "\n",
                            "METHOD",
                            "OLOGY",
                            "\n",
                            "\n",
                            "In",
                            " order",
                            " to",
                            " adequately",
                            " assess",
                            " the",
                            " information",
                            " required",
                            " to",
                            " develop",
                            " the",
                            " Obamacare",
                            " Impact",
                            " Map",
                            ",",
                            " we",
                            " used",
                            " three",
                            " separate",
                            " approaches",
                            " for",
                            " the",
                            " three",
                            " separate",
                            " sets",
                            " of",
                            " data",
                            " presented",
                            " in",
                            " the",
                            " map",
                            ".",
                            "\n",
                            "\n",
                            "Rate",
                            " Changes",
                            "\n",
                            "\n",
                            "In",
                            " order",
                            " to",
                            " document",
                            " rate",
                            " changes",
                            ",",
                            " we",
                            " first",
                            " gathered",
                            " pre",
                            "-",
                            "ACA",
                            " insurance",
                            " rates",
                            " using",
                            " the",
                            " federal",
                            " government",
                            "'s",
                            " find",
                            "er",
                            ".",
                            "health",
                            "care",
                            ".",
                            "gov"
                        ],
                        "dataIndex": null,
                        "index": "34160",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.884,
                        "maxValueTokenIndex": 16,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.884,
                            2.372,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            32.332,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:00:19.556Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 47.104,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6bwp174p3i6669ffuh79w",
                        "tokens": [
                            " and",
                            " director",
                            " of",
                            " Health",
                            " Policy",
                            " at",
                            " the",
                            " Manhattan",
                            " Institute",
                            ";",
                            " Av",
                            "ik",
                            " Roy",
                            ",",
                            " a",
                            " senior",
                            " fellow",
                            " at",
                            " the",
                            " Manhattan",
                            " Institute",
                            " and",
                            " editor",
                            " of",
                            " The",
                            " Ap",
                            "othe",
                            "c",
                            "ary",
                            ",",
                            " a",
                            " Forbes",
                            " health",
                            " care",
                            " blog",
                            ";",
                            " and",
                            " Y",
                            "ev",
                            "gen",
                            "iy",
                            " Fey",
                            "man",
                            ",",
                            " fellow",
                            " and",
                            " deputy",
                            " director",
                            " of",
                            " Health",
                            " Policy",
                            " at",
                            " the",
                            " Manhattan",
                            " Institute",
                            ".",
                            "\n",
                            "\n",
                            "METHOD",
                            "OLOGY",
                            "\n",
                            "\n",
                            "In",
                            " order",
                            " to",
                            " adequately",
                            " assess",
                            " the",
                            " information",
                            " required",
                            " to",
                            " develop",
                            " the",
                            " Obamacare",
                            " Impact",
                            " Map",
                            ",",
                            " we",
                            " used",
                            " three",
                            " separate",
                            " approaches",
                            " for",
                            " the",
                            " three",
                            " separate",
                            " sets",
                            " of",
                            " data",
                            " presented",
                            " in",
                            " the",
                            " map",
                            ".",
                            "\n",
                            "\n",
                            "Rate",
                            " Changes",
                            "\n",
                            "\n",
                            "In",
                            " order",
                            " to",
                            " document",
                            " rate",
                            " changes",
                            ",",
                            " we",
                            " first",
                            " gathered",
                            " pre",
                            "-",
                            "ACA",
                            " insurance",
                            " rates",
                            " using",
                            " the",
                            " federal",
                            " government",
                            "'s",
                            " find",
                            "er",
                            ".",
                            "health",
                            "care",
                            ".",
                            "gov"
                        ],
                        "dataIndex": null,
                        "index": "34160",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.884,
                        "maxValueTokenIndex": 16,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.884,
                            2.372,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            32.332,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:00:19.556Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 47.104,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "48115",
            "description": "references to faculty and their roles within academic institutions",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.49201469051969293,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "48115",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:35:05.088Z",
                "maxActApprox": 58.979,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    48115,
                    83675,
                    46751,
                    58808,
                    25398,
                    84880,
                    77827,
                    92973,
                    81118,
                    35435,
                    9870,
                    64654,
                    18421,
                    82102,
                    93548,
                    48216,
                    42428,
                    15503,
                    19860,
                    16769,
                    48017,
                    23829,
                    78206,
                    23900,
                    25065
                ],
                "topkCosSimValues": [
                    1,
                    0.596,
                    0.5439,
                    0.5203,
                    0.5012,
                    0.4976,
                    0.4692,
                    0.4625,
                    0.4552,
                    0.4461,
                    0.4442,
                    0.4442,
                    0.4421,
                    0.43,
                    0.4296,
                    0.4292,
                    0.4204,
                    0.4162,
                    0.4141,
                    0.4118,
                    0.408,
                    0.4076,
                    0.4065,
                    0.4062,
                    0.397
                ],
                "neuron_alignment_indices": [
                    288,
                    71,
                    285
                ],
                "neuron_alignment_values": [
                    0.167,
                    0.127,
                    0.117
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    325,
                    285,
                    11
                ],
                "correlated_neurons_pearson": [
                    0.011,
                    0.011,
                    0.01
                ],
                "correlated_neurons_l1": [
                    0.011,
                    0.01,
                    0.01
                ],
                "correlated_features_indices": [
                    48216,
                    48126,
                    48115
                ],
                "correlated_features_pearson": [
                    0.008,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.008,
                    0,
                    0
                ],
                "neg_str": [
                    "nings",
                    " launchers",
                    "lar",
                    "tar",
                    "6666",
                    " launcher",
                    " GPS",
                    " geop",
                    "ICO",
                    "icted"
                ],
                "neg_values": [
                    -0.719,
                    -0.693,
                    -0.662,
                    -0.641,
                    -0.639,
                    -0.62,
                    -0.611,
                    -0.608,
                    -0.602,
                    -0.595
                ],
                "pos_str": [
                    " members",
                    " faculty",
                    " member",
                    "members",
                    " senate",
                    "member",
                    "ulty",
                    "llor",
                    "ority",
                    " Members"
                ],
                "pos_values": [
                    0.994,
                    0.978,
                    0.965,
                    0.943,
                    0.929,
                    0.91,
                    0.907,
                    0.893,
                    0.847,
                    0.839
                ],
                "frac_nonzero": 6e-05,
                "freq_hist_data_bar_heights": [
                    54,
                    15,
                    17,
                    8,
                    10,
                    10,
                    6,
                    6,
                    2,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    2,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    1,
                    0,
                    1,
                    1,
                    1,
                    2,
                    2,
                    3,
                    1,
                    3,
                    6,
                    1,
                    5,
                    6,
                    3,
                    5,
                    3,
                    1,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.594,
                    1.774,
                    2.953,
                    4.133,
                    5.312,
                    6.492,
                    7.671,
                    8.851,
                    10.03,
                    11.21,
                    12.389,
                    13.568,
                    14.748,
                    15.927,
                    17.107,
                    18.286,
                    19.466,
                    20.645,
                    21.825,
                    23.004,
                    24.184,
                    25.363,
                    26.543,
                    27.722,
                    28.902,
                    30.081,
                    31.261,
                    32.44,
                    33.62,
                    34.799,
                    35.979,
                    37.158,
                    38.338,
                    39.517,
                    40.697,
                    41.876,
                    43.056,
                    44.235,
                    45.415,
                    46.594,
                    47.774,
                    48.953,
                    50.133,
                    51.312,
                    52.492,
                    53.671,
                    54.851,
                    56.03,
                    57.21,
                    58.389
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    1,
                    3,
                    6,
                    23,
                    19,
                    30,
                    85,
                    126,
                    207,
                    341,
                    545,
                    776,
                    1269,
                    1727,
                    2099,
                    2759,
                    3365,
                    3977,
                    4349,
                    4378,
                    4216,
                    3819,
                    3403,
                    3006,
                    2370,
                    1884,
                    1499,
                    1125,
                    843,
                    600,
                    417,
                    297,
                    227,
                    167,
                    105,
                    65,
                    41,
                    25,
                    23,
                    9,
                    9,
                    5,
                    5,
                    0,
                    2,
                    0,
                    3,
                    2,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.702,
                    -0.668,
                    -0.634,
                    -0.6,
                    -0.565,
                    -0.531,
                    -0.497,
                    -0.462,
                    -0.428,
                    -0.394,
                    -0.36,
                    -0.325,
                    -0.291,
                    -0.257,
                    -0.223,
                    -0.188,
                    -0.154,
                    -0.12,
                    -0.085,
                    -0.051,
                    -0.017,
                    0.017,
                    0.052,
                    0.086,
                    0.12,
                    0.154,
                    0.189,
                    0.223,
                    0.257,
                    0.292,
                    0.326,
                    0.36,
                    0.394,
                    0.429,
                    0.463,
                    0.497,
                    0.531,
                    0.566,
                    0.6,
                    0.634,
                    0.668,
                    0.703,
                    0.737,
                    0.771,
                    0.806,
                    0.84,
                    0.874,
                    0.908,
                    0.943,
                    0.977
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " terms related to university faculty and their roles",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to faculty and their roles within academic institutions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygh9ma1brd610exbylduhbw",
                        "tokens": [
                            " law",
                            " school",
                            " dean",
                            ",",
                            " as",
                            " well",
                            " as",
                            " the",
                            " Title",
                            " IX",
                            " investigator",
                            " who",
                            " investigated",
                            " Robinson",
                            " and",
                            " Title",
                            " IX",
                            " coordinator",
                            ":",
                            "\n",
                            "\n",
                            "Howard",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " finding",
                            " is",
                            " at",
                            " odds",
                            " with",
                            " the",
                            " plain",
                            " language",
                            " of",
                            " several",
                            " written",
                            " university",
                            " policies",
                            " and",
                            " could",
                            " chill",
                            " professors",
                            "\u00e2\u0122",
                            "\u013b",
                            " teaching",
                            " of",
                            " basic",
                            " legal",
                            " principles",
                            ".",
                            " As",
                            " a",
                            " result",
                            ",",
                            " it",
                            " puts",
                            " at",
                            " risk",
                            " both",
                            " faculty",
                            " rights",
                            " and",
                            " the",
                            " su",
                            "fficiency",
                            " of",
                            " law",
                            " students",
                            "\u00e2\u0122",
                            "\u013b",
                            " education",
                            ".",
                            "\n",
                            "\n",
                            "Though",
                            " Howard",
                            " is",
                            " private",
                            ",",
                            " it",
                            " has",
                            " two",
                            " written",
                            " policies",
                            " that",
                            " on",
                            " their",
                            " face",
                            " apply",
                            " to",
                            " Robinson",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " classroom",
                            " conduct",
                            ".",
                            " One",
                            " seems",
                            " explicitly",
                            " designed",
                            " to",
                            " encompass",
                            " controversial",
                            " legal",
                            " subjects",
                            ",",
                            " from",
                            " the",
                            " Faculty",
                            " Handbook",
                            ",",
                            " last",
                            " updated",
                            " 24",
                            " years",
                            " ago",
                            ":",
                            "\n",
                            "\n",
                            "Fac",
                            "ulty",
                            " members",
                            " are",
                            " entitled",
                            " to",
                            " freedom"
                        ],
                        "dataIndex": null,
                        "index": "48115",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 58.979,
                        "maxValueTokenIndex": 59,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.477,
                            0,
                            0,
                            3.329,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            58.979,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.756,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.295,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:35:06.481Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 47.183,
                        "binMax": 58.979,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh9m9zbrcj10ex73kw14bq",
                        "tokens": [
                            " law",
                            " school",
                            " dean",
                            ",",
                            " as",
                            " well",
                            " as",
                            " the",
                            " Title",
                            " IX",
                            " investigator",
                            " who",
                            " investigated",
                            " Robinson",
                            " and",
                            " Title",
                            " IX",
                            " coordinator",
                            ":",
                            "\n",
                            "\n",
                            "Howard",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " finding",
                            " is",
                            " at",
                            " odds",
                            " with",
                            " the",
                            " plain",
                            " language",
                            " of",
                            " several",
                            " written",
                            " university",
                            " policies",
                            " and",
                            " could",
                            " chill",
                            " professors",
                            "\u00e2\u0122",
                            "\u013b",
                            " teaching",
                            " of",
                            " basic",
                            " legal",
                            " principles",
                            ".",
                            " As",
                            " a",
                            " result",
                            ",",
                            " it",
                            " puts",
                            " at",
                            " risk",
                            " both",
                            " faculty",
                            " rights",
                            " and",
                            " the",
                            " su",
                            "fficiency",
                            " of",
                            " law",
                            " students",
                            "\u00e2\u0122",
                            "\u013b",
                            " education",
                            ".",
                            "\n",
                            "\n",
                            "Though",
                            " Howard",
                            " is",
                            " private",
                            ",",
                            " it",
                            " has",
                            " two",
                            " written",
                            " policies",
                            " that",
                            " on",
                            " their",
                            " face",
                            " apply",
                            " to",
                            " Robinson",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " classroom",
                            " conduct",
                            ".",
                            " One",
                            " seems",
                            " explicitly",
                            " designed",
                            " to",
                            " encompass",
                            " controversial",
                            " legal",
                            " subjects",
                            ",",
                            " from",
                            " the",
                            " Faculty",
                            " Handbook",
                            ",",
                            " last",
                            " updated",
                            " 24",
                            " years",
                            " ago",
                            ":",
                            "\n",
                            "\n",
                            "Fac",
                            "ulty",
                            " members",
                            " are",
                            " entitled",
                            " to",
                            " freedom"
                        ],
                        "dataIndex": null,
                        "index": "48115",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 58.979,
                        "maxValueTokenIndex": 59,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.477,
                            0,
                            0,
                            3.329,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            58.979,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.756,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.295,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:35:06.481Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 58.979,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh9m9zbrck10exg6gdxi4p",
                        "tokens": [
                            "\u013f",
                            "\n",
                            "\n",
                            "In",
                            " a",
                            " campus",
                            "wide",
                            " email",
                            ",",
                            " Christ",
                            " said",
                            " the",
                            " intent",
                            " of",
                            " the",
                            " new",
                            " task",
                            " force",
                            " is",
                            " to",
                            " address",
                            " the",
                            " controversy",
                            " that",
                            " free",
                            " speech",
                            " issues",
                            " have",
                            " caused",
                            " on",
                            " campus",
                            ",",
                            " as",
                            " well",
                            " as",
                            " to",
                            " examine",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "complex",
                            " set",
                            " of",
                            " issues",
                            " and",
                            " propose",
                            " solutions",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " The",
                            " commission",
                            " will",
                            " be",
                            " comprised",
                            " of",
                            " students",
                            ",",
                            " staff",
                            ",",
                            " faculty",
                            " and",
                            " administrators",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " commission",
                            " is",
                            " still",
                            " in",
                            " the",
                            " very",
                            " early",
                            " stages",
                            " of",
                            " development",
                            ",",
                            " according",
                            " to",
                            " campus",
                            " spokesperson",
                            " Dan",
                            " Mog",
                            "ul",
                            "of",
                            ",",
                            " and",
                            " more",
                            " information",
                            " will",
                            " be",
                            " released",
                            " in",
                            " the",
                            " coming",
                            " weeks",
                            ".",
                            " Mog",
                            "ul",
                            "of",
                            " added",
                            " that",
                            " the",
                            " chancellor",
                            " is",
                            " still",
                            " final",
                            "izing",
                            " the",
                            " commission",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " objectives",
                            " and",
                            " exact",
                            " membership",
                            " makeup",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "The",
                            " team",
                            " must"
                        ],
                        "dataIndex": null,
                        "index": "48115",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.75,
                        "maxValueTokenIndex": 60,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.078,
                            0,
                            56.75,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:35:06.481Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 58.979,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "13453",
            "description": "terms related to individuals who hold academic or esteemed titles, especially in the context of emeritus professors",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4895367622375524,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "13453",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:44:53.207Z",
                "maxActApprox": 54.545,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    13453,
                    15529,
                    92810,
                    45460,
                    39299,
                    32597,
                    42708,
                    51269,
                    30223,
                    26645,
                    53212,
                    54624,
                    88231,
                    55246,
                    23783,
                    71249,
                    14199,
                    55835,
                    43345,
                    23724,
                    17556,
                    18463,
                    57060,
                    29590,
                    88297
                ],
                "topkCosSimValues": [
                    1,
                    0.5694,
                    0.5437,
                    0.4536,
                    0.3869,
                    0.3838,
                    0.3658,
                    0.3596,
                    0.3559,
                    0.3544,
                    0.3536,
                    0.3428,
                    0.3409,
                    0.3381,
                    0.33,
                    0.3296,
                    0.3237,
                    0.3212,
                    0.3175,
                    0.3154,
                    0.3147,
                    0.3145,
                    0.3106,
                    0.3103,
                    0.3098
                ],
                "neuron_alignment_indices": [
                    642,
                    288,
                    749
                ],
                "neuron_alignment_values": [
                    0.133,
                    0.116,
                    0.11
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    555,
                    746,
                    749
                ],
                "correlated_neurons_pearson": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_l1": [
                    0.005,
                    0.004,
                    0.005
                ],
                "correlated_features_indices": [
                    13558,
                    13559,
                    13453
                ],
                "correlated_features_pearson": [
                    0.001,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0,
                    0
                ],
                "neg_str": [
                    "\u00e8\u00a6\u013c\u00e9\u0128\u0134",
                    "avorite",
                    "76561",
                    " shack",
                    " mileage",
                    "isSpecialOrderable",
                    " absorb",
                    " captcha",
                    "20439",
                    " bip"
                ],
                "neg_values": [
                    -0.803,
                    -0.788,
                    -0.769,
                    -0.698,
                    -0.697,
                    -0.687,
                    -0.671,
                    -0.642,
                    -0.634,
                    -0.631
                ],
                "pos_str": [
                    "gencies",
                    "gent",
                    "gence",
                    "itus",
                    "gency",
                    "mberg",
                    "usalem",
                    "ging",
                    "iat",
                    "inary"
                ],
                "pos_values": [
                    1.236,
                    1.235,
                    1.226,
                    1.126,
                    1.05,
                    0.957,
                    0.92,
                    0.914,
                    0.895,
                    0.89
                ],
                "frac_nonzero": 2e-05,
                "freq_hist_data_bar_heights": [
                    16,
                    10,
                    7,
                    5,
                    1,
                    0,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.606,
                    1.696,
                    2.786,
                    3.875,
                    4.965,
                    6.055,
                    7.144,
                    8.234,
                    9.324,
                    10.413,
                    11.503,
                    12.593,
                    13.682,
                    14.772,
                    15.862,
                    16.951,
                    18.041,
                    19.131,
                    20.22,
                    21.31,
                    22.4,
                    23.489,
                    24.579,
                    25.669,
                    26.758,
                    27.848,
                    28.938,
                    30.027,
                    31.117,
                    32.207,
                    33.296,
                    34.386,
                    35.476,
                    36.565,
                    37.655,
                    38.745,
                    39.834,
                    40.924,
                    42.014,
                    43.103,
                    44.193,
                    45.283,
                    46.372,
                    47.462,
                    48.552,
                    49.641,
                    50.731,
                    51.821,
                    52.91,
                    54
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    0,
                    3,
                    2,
                    8,
                    17,
                    38,
                    74,
                    129,
                    291,
                    443,
                    795,
                    1247,
                    1757,
                    2445,
                    3079,
                    3825,
                    4187,
                    4416,
                    4660,
                    4427,
                    3935,
                    3552,
                    2776,
                    2213,
                    1677,
                    1294,
                    877,
                    613,
                    443,
                    337,
                    210,
                    182,
                    100,
                    80,
                    40,
                    35,
                    15,
                    7,
                    4,
                    8,
                    5,
                    2,
                    1,
                    0,
                    1,
                    0,
                    1,
                    0,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.783,
                    -0.742,
                    -0.701,
                    -0.661,
                    -0.62,
                    -0.579,
                    -0.538,
                    -0.497,
                    -0.457,
                    -0.416,
                    -0.375,
                    -0.334,
                    -0.294,
                    -0.253,
                    -0.212,
                    -0.171,
                    -0.13,
                    -0.09,
                    -0.049,
                    -0.008,
                    0.033,
                    0.073,
                    0.114,
                    0.155,
                    0.196,
                    0.237,
                    0.277,
                    0.318,
                    0.359,
                    0.4,
                    0.441,
                    0.481,
                    0.522,
                    0.563,
                    0.604,
                    0.644,
                    0.685,
                    0.726,
                    0.767,
                    0.808,
                    0.848,
                    0.889,
                    0.93,
                    0.971,
                    1.011,
                    1.052,
                    1.093,
                    1.134,
                    1.175,
                    1.215
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to individuals who hold academic or esteemed titles, especially in the context of emeritus professors",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to emergent figures in various contexts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfh2y8lhv510exgvixah8g",
                        "tokens": [
                            " institute",
                            " itself",
                            ",",
                            " where",
                            " I",
                            " once",
                            " worked",
                            " as",
                            " director",
                            " of",
                            " education",
                            ",",
                            " was",
                            " founded",
                            " to",
                            " advocate",
                            " for",
                            " these",
                            " youth",
                            " in",
                            " 1979",
                            " by",
                            " the",
                            " late",
                            " Damien",
                            " Martin",
                            " and",
                            " Emer",
                            "y",
                            " H",
                            "et",
                            "rick",
                            ".",
                            "\n",
                            "\n",
                            "New",
                            " York",
                            "'s",
                            " S",
                            "AGE",
                            " --",
                            " for",
                            " Services",
                            " and",
                            " Advoc",
                            "acy",
                            " for",
                            " GL",
                            "BT",
                            " Eld",
                            "ers",
                            " --",
                            " was",
                            " the",
                            " first",
                            " U",
                            ".",
                            "S",
                            ".",
                            " group",
                            " for",
                            " older",
                            " gays",
                            " and",
                            " lesbians",
                            " in",
                            " 1978",
                            ".",
                            "\n",
                            "\n",
                            "Gay",
                            " journalists",
                            " founded",
                            " the",
                            " Gay",
                            " and",
                            " Lesbian",
                            " Alliance",
                            " Against",
                            " Def",
                            "amation",
                            " in",
                            " 1985",
                            " to",
                            " fight",
                            " anti",
                            "-",
                            "gay",
                            " defamation",
                            " in",
                            " the",
                            " media",
                            ",",
                            " especially",
                            " at",
                            " the",
                            " New",
                            " York",
                            " Post",
                            ".",
                            " Originally",
                            " a",
                            " fierce",
                            " watchdog",
                            ",",
                            " it",
                            " has",
                            " gone",
                            " on",
                            " to",
                            " become",
                            " a",
                            " largely",
                            " West",
                            " Coast",
                            " operation",
                            " famous",
                            " for",
                            " big",
                            " annual",
                            " dinners",
                            " honoring",
                            " positive",
                            " LGBT",
                            " portray",
                            "als",
                            " in"
                        ],
                        "dataIndex": null,
                        "index": "13453",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 54.545,
                        "maxValueTokenIndex": 27,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            54.545,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:55.449Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 43.636,
                        "binMax": 54.545,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfh2y6lhuk10ex2jp1h1z5",
                        "tokens": [
                            " institute",
                            " itself",
                            ",",
                            " where",
                            " I",
                            " once",
                            " worked",
                            " as",
                            " director",
                            " of",
                            " education",
                            ",",
                            " was",
                            " founded",
                            " to",
                            " advocate",
                            " for",
                            " these",
                            " youth",
                            " in",
                            " 1979",
                            " by",
                            " the",
                            " late",
                            " Damien",
                            " Martin",
                            " and",
                            " Emer",
                            "y",
                            " H",
                            "et",
                            "rick",
                            ".",
                            "\n",
                            "\n",
                            "New",
                            " York",
                            "'s",
                            " S",
                            "AGE",
                            " --",
                            " for",
                            " Services",
                            " and",
                            " Advoc",
                            "acy",
                            " for",
                            " GL",
                            "BT",
                            " Eld",
                            "ers",
                            " --",
                            " was",
                            " the",
                            " first",
                            " U",
                            ".",
                            "S",
                            ".",
                            " group",
                            " for",
                            " older",
                            " gays",
                            " and",
                            " lesbians",
                            " in",
                            " 1978",
                            ".",
                            "\n",
                            "\n",
                            "Gay",
                            " journalists",
                            " founded",
                            " the",
                            " Gay",
                            " and",
                            " Lesbian",
                            " Alliance",
                            " Against",
                            " Def",
                            "amation",
                            " in",
                            " 1985",
                            " to",
                            " fight",
                            " anti",
                            "-",
                            "gay",
                            " defamation",
                            " in",
                            " the",
                            " media",
                            ",",
                            " especially",
                            " at",
                            " the",
                            " New",
                            " York",
                            " Post",
                            ".",
                            " Originally",
                            " a",
                            " fierce",
                            " watchdog",
                            ",",
                            " it",
                            " has",
                            " gone",
                            " on",
                            " to",
                            " become",
                            " a",
                            " largely",
                            " West",
                            " Coast",
                            " operation",
                            " famous",
                            " for",
                            " big",
                            " annual",
                            " dinners",
                            " honoring",
                            " positive",
                            " LGBT",
                            " portray",
                            "als",
                            " in"
                        ],
                        "dataIndex": null,
                        "index": "13453",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 54.545,
                        "maxValueTokenIndex": 27,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            54.545,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:55.449Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 54.545,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfh2y6lhul10exlgg1xljb",
                        "tokens": [
                            " album",
                            " Let",
                            " It",
                            " Be",
                            " in",
                            " the",
                            " Apple",
                            " Studio",
                            ",",
                            " with",
                            " equipment",
                            " borrowed",
                            " from",
                            " E",
                            "MI",
                            ";",
                            " during",
                            " takes",
                            " they",
                            " had",
                            " to",
                            " shut",
                            " down",
                            " the",
                            " building",
                            "'s",
                            " central",
                            " heating",
                            ",",
                            " also",
                            " located",
                            " in",
                            " the",
                            " basement",
                            ",",
                            " because",
                            " the",
                            " lack",
                            " of",
                            " sound",
                            "proof",
                            "ing",
                            " allowed",
                            " the",
                            " heating",
                            " system",
                            " to",
                            " be",
                            " heard",
                            " in",
                            " the",
                            " studio",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " redesign",
                            " and",
                            " rebuilding",
                            " of",
                            " the",
                            " basement",
                            " to",
                            " accommodate",
                            " proper",
                            " recording",
                            " facilities",
                            " was",
                            " overseen",
                            " by",
                            " former",
                            " E",
                            "MI",
                            " engineer",
                            " Geoff",
                            " Emer",
                            "ick",
                            ",",
                            " and",
                            " took",
                            " eighteen",
                            " months",
                            " at",
                            " an",
                            " estimated",
                            " cost",
                            " of",
                            " $",
                            "1",
                            ".",
                            "5",
                            " million",
                            ".",
                            " Beatles",
                            "'",
                            " technical",
                            " engineer",
                            " Claude",
                            " Harper",
                            " aided",
                            " on",
                            " the",
                            " project",
                            ",",
                            " as",
                            " well",
                            ".[",
                            "51",
                            "]",
                            " The",
                            " studio",
                            " reopened",
                            " on",
                            " 30",
                            " September",
                            " 1971",
                            " and",
                            " now",
                            " included",
                            " its",
                            " own",
                            " natural",
                            " echo",
                            " chamber",
                            ",",
                            " a",
                            " wide"
                        ],
                        "dataIndex": null,
                        "index": "13453",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 47.5,
                        "maxValueTokenIndex": 75,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            47.5,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:55.449Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 54.545,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "23827",
            "description": "references to faculty and staff within educational contexts",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4888338744640386,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "23827",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:15:23.675Z",
                "maxActApprox": 59.99,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    23827,
                    21563,
                    17375,
                    16447,
                    9709,
                    19680,
                    10923,
                    15579,
                    7511,
                    2114,
                    19718,
                    16661,
                    11785,
                    18939,
                    16628,
                    19083,
                    11699,
                    8895,
                    17218,
                    20621,
                    13036,
                    48,
                    15582,
                    18435,
                    19269
                ],
                "topkCosSimValues": [
                    1,
                    0.5404,
                    0.5082,
                    0.5079,
                    0.4952,
                    0.4843,
                    0.4681,
                    0.4603,
                    0.445,
                    0.4373,
                    0.4321,
                    0.4062,
                    0.3982,
                    0.3904,
                    0.3794,
                    0.3713,
                    0.3698,
                    0.3583,
                    0.3573,
                    0.3554,
                    0.3503,
                    0.3448,
                    0.3424,
                    0.336,
                    0.3347
                ],
                "neuron_alignment_indices": [
                    288,
                    71,
                    285
                ],
                "neuron_alignment_values": [
                    0.141,
                    0.122,
                    0.11
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    325,
                    288,
                    285
                ],
                "correlated_neurons_pearson": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_neurons_l1": [
                    0.013,
                    0.013,
                    0.011
                ],
                "correlated_features_indices": [
                    23836,
                    23830,
                    23935
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.002,
                    0.001
                ],
                "correlated_features_l1": [
                    0.005,
                    0.002,
                    0.002
                ],
                "neg_str": [
                    " launchers",
                    "tar",
                    " launcher",
                    "nings",
                    "6666",
                    "lar",
                    " Zimbabwe",
                    " GPS",
                    " HERO",
                    " Rossi"
                ],
                "neg_values": [
                    -0.684,
                    -0.665,
                    -0.662,
                    -0.652,
                    -0.638,
                    -0.613,
                    -0.607,
                    -0.604,
                    -0.6,
                    -0.599
                ],
                "pos_str": [
                    " faculty",
                    " members",
                    "ulty",
                    " member",
                    "members",
                    "llor",
                    "member",
                    " senate",
                    " unions",
                    " Members"
                ],
                "pos_values": [
                    1.01,
                    0.989,
                    0.977,
                    0.967,
                    0.955,
                    0.943,
                    0.911,
                    0.903,
                    0.834,
                    0.807
                ],
                "frac_nonzero": 0.00018,
                "freq_hist_data_bar_heights": [
                    197,
                    118,
                    49,
                    39,
                    28,
                    15,
                    14,
                    16,
                    11,
                    14,
                    8,
                    2,
                    4,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    1,
                    1,
                    3,
                    1,
                    1,
                    3,
                    2,
                    1,
                    4,
                    3,
                    11,
                    0,
                    5,
                    4,
                    6,
                    3,
                    0,
                    1,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.6,
                    1.8,
                    3,
                    4.2,
                    5.4,
                    6.599,
                    7.799,
                    8.999,
                    10.199,
                    11.399,
                    12.598,
                    13.798,
                    14.998,
                    16.198,
                    17.398,
                    18.597,
                    19.797,
                    20.997,
                    22.197,
                    23.397,
                    24.596,
                    25.796,
                    26.996,
                    28.196,
                    29.396,
                    30.595,
                    31.795,
                    32.995,
                    34.195,
                    35.395,
                    36.594,
                    37.794,
                    38.994,
                    40.194,
                    41.394,
                    42.593,
                    43.793,
                    44.993,
                    46.193,
                    47.393,
                    48.592,
                    49.792,
                    50.992,
                    52.192,
                    53.392,
                    54.591,
                    55.791,
                    56.991,
                    58.191,
                    59.391
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    1,
                    10,
                    13,
                    28,
                    44,
                    87,
                    130,
                    238,
                    363,
                    590,
                    804,
                    1201,
                    1668,
                    2097,
                    2648,
                    3198,
                    3825,
                    4242,
                    4203,
                    4168,
                    3740,
                    3433,
                    2957,
                    2393,
                    1963,
                    1572,
                    1229,
                    965,
                    675,
                    509,
                    377,
                    256,
                    175,
                    156,
                    96,
                    73,
                    37,
                    26,
                    21,
                    16,
                    10,
                    4,
                    2,
                    2,
                    0,
                    1,
                    1,
                    3,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.667,
                    -0.633,
                    -0.599,
                    -0.565,
                    -0.531,
                    -0.497,
                    -0.464,
                    -0.43,
                    -0.396,
                    -0.362,
                    -0.328,
                    -0.294,
                    -0.26,
                    -0.226,
                    -0.192,
                    -0.159,
                    -0.125,
                    -0.091,
                    -0.057,
                    -0.023,
                    0.011,
                    0.045,
                    0.079,
                    0.112,
                    0.146,
                    0.18,
                    0.214,
                    0.248,
                    0.282,
                    0.316,
                    0.35,
                    0.384,
                    0.417,
                    0.451,
                    0.485,
                    0.519,
                    0.553,
                    0.587,
                    0.621,
                    0.655,
                    0.688,
                    0.722,
                    0.756,
                    0.79,
                    0.824,
                    0.858,
                    0.892,
                    0.926,
                    0.959,
                    0.993
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to faculty and staff within educational contexts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdn3nmdmncri666zffq0b47",
                        "tokens": [
                            " May",
                            " 31",
                            ",",
                            " 2015",
                            " 23",
                            ":",
                            "58",
                            " IST",
                            "<|endoftext|>",
                            "Chance",
                            "llor",
                            " Carol",
                            " Christ",
                            " announced",
                            " a",
                            " new",
                            " commission",
                            " on",
                            " Thursday",
                            " to",
                            " assess",
                            " ways",
                            " to",
                            " better",
                            " handle",
                            " campus",
                            " free",
                            " speech",
                            " situations",
                            " like",
                            " the",
                            " canceled",
                            " \u00e2\u0122",
                            "\u013e",
                            "Free",
                            " Speech",
                            " Week",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "In",
                            " a",
                            " campus",
                            "wide",
                            " email",
                            ",",
                            " Christ",
                            " said",
                            " the",
                            " intent",
                            " of",
                            " the",
                            " new",
                            " task",
                            " force",
                            " is",
                            " to",
                            " address",
                            " the",
                            " controversy",
                            " that",
                            " free",
                            " speech",
                            " issues",
                            " have",
                            " caused",
                            " on",
                            " campus",
                            ",",
                            " as",
                            " well",
                            " as",
                            " to",
                            " examine",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "complex",
                            " set",
                            " of",
                            " issues",
                            " and",
                            " propose",
                            " solutions",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " The",
                            " commission",
                            " will",
                            " be",
                            " comprised",
                            " of",
                            " students",
                            ",",
                            " staff",
                            ",",
                            " faculty",
                            " and",
                            " administrators",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " commission",
                            " is",
                            " still",
                            " in",
                            " the",
                            " very",
                            " early",
                            " stages",
                            " of",
                            " development",
                            ",",
                            " according",
                            " to",
                            " campus",
                            " spokesperson",
                            " Dan",
                            " Mog",
                            "ul",
                            "of",
                            ",",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "23827",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.99,
                        "maxValueTokenIndex": 99,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.589,
                            0,
                            59.99,
                            0.427,
                            3.981,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:15:25.099Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 59.991,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn3nmdmncsi666hdklq0vz",
                        "tokens": [
                            "The",
                            " faculty",
                            " will",
                            " expel",
                            " the",
                            " criminals",
                            " and",
                            " per",
                            "sec",
                            "ute",
                            " [",
                            " ]",
                            " them",
                            " if",
                            " found",
                            ".\"",
                            " The",
                            " Philadelphia",
                            " Record",
                            ":",
                            " \"",
                            "P",
                            "ainted",
                            " Harvard",
                            " Red",
                            " \u2014",
                            " Dis",
                            "gr",
                            "ace",
                            "ful",
                            " Ant",
                            "ics",
                            " of",
                            " Rum",
                            "-",
                            "C",
                            "raz",
                            "ed",
                            " Students",
                            ".",
                            " \u2014",
                            " Cambridge",
                            " is",
                            " Hor",
                            "ri",
                            "\u00c2\u0143",
                            "f",
                            "ied",
                            ".",
                            " \u2014",
                            " The",
                            " Faculty",
                            " Bent",
                            " on",
                            " V",
                            "enge",
                            "\u00c2\u0143",
                            "ance",
                            " ...",
                            " Last",
                            " night",
                            " the",
                            " whole",
                            " college",
                            " celebrated",
                            " a",
                            " wild",
                            " org",
                            "ie",
                            " [",
                            "sic",
                            "]",
                            " ...",
                            " There",
                            " were",
                            " supp",
                            "ers",
                            ",",
                            " bon",
                            "fires",
                            ",",
                            " fish",
                            "-",
                            "h",
                            "orns",
                            " and",
                            " a",
                            " general",
                            " pand",
                            "emo",
                            "\u00c2\u0143",
                            "ni",
                            "\u00c2\u0143",
                            "um",
                            ";",
                            " but",
                            ",",
                            " save",
                            " the",
                            " insane",
                            " acts",
                            " of",
                            " two",
                            " of",
                            " the",
                            " students",
                            ",",
                            " who",
                            ",",
                            " overcome",
                            " with",
                            " enthusi",
                            "\u00c2\u0143",
                            "asm",
                            ",",
                            " deliber",
                            "\u00c2\u0143",
                            "ately",
                            " threw",
                            " their",
                            " dress",
                            " coats",
                            " into",
                            " the",
                            " bon",
                            "fire",
                            " while"
                        ],
                        "dataIndex": null,
                        "index": "23827",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.863,
                        "maxValueTokenIndex": 1,
                        "minValue": 0,
                        "values": [
                            0,
                            59.863,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.254,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:15:25.099Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 59.991,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn3nmdmncti666k3kwyxu0",
                        "tokens": [
                            " because",
                            " they",
                            " have",
                            " more",
                            " exposure",
                            " to",
                            " the",
                            " realities",
                            " of",
                            " the",
                            " job",
                            " market",
                            " via",
                            " co",
                            "-",
                            "ops",
                            " and",
                            " connections",
                            " outside",
                            " of",
                            " school",
                            ".",
                            "\n",
                            "\n",
                            "Overall",
                            ",",
                            " students",
                            " have",
                            " high",
                            " expectations",
                            " that",
                            " their",
                            " university",
                            " degrees",
                            " will",
                            " amount",
                            " to",
                            " a",
                            " job",
                            " fairly",
                            " soon",
                            " after",
                            " graduation",
                            " \u2014",
                            " expectations",
                            " that",
                            " may",
                            " not",
                            " j",
                            "ibe",
                            " with",
                            " the",
                            " job",
                            " market",
                            ".",
                            "\n",
                            "\n",
                            "When",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " in",
                            " school",
                            ",",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " sort",
                            " of",
                            " in",
                            " a",
                            " bubble",
                            ".",
                            " You",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " really",
                            " know",
                            " what",
                            " the",
                            " real",
                            " world",
                            " is",
                            " like",
                            "\n",
                            "\n",
                            "Ar",
                            "ts",
                            " &",
                            " Social",
                            " Sciences",
                            " students",
                            ",",
                            " a",
                            " faculty",
                            " with",
                            " some",
                            " of",
                            " the",
                            " toughest",
                            " prospects",
                            " out",
                            " in",
                            " the",
                            " current",
                            " workforce",
                            ",",
                            " made",
                            " up",
                            " 47",
                            ".",
                            "2",
                            "%",
                            " of",
                            " her",
                            " study",
                            " sample",
                            ".",
                            "\n",
                            "\n",
                            "To",
                            " the",
                            " statement"
                        ],
                        "dataIndex": null,
                        "index": "23827",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.655,
                        "maxValueTokenIndex": 98,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.655,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:15:25.099Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 59.991,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "77717",
            "description": " titles and formal titles of academic professionals",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4812699390593118,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "77717",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:07:08.929Z",
                "maxActApprox": 25.395,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    77717,
                    25167,
                    48599,
                    34933,
                    3377,
                    1717,
                    64654,
                    93548,
                    39403,
                    76130,
                    45460,
                    57970,
                    17380,
                    3486,
                    7703,
                    43982,
                    36626,
                    13243,
                    17349,
                    31884,
                    26685,
                    51079,
                    95648,
                    42283,
                    89816
                ],
                "topkCosSimValues": [
                    1,
                    0.7235,
                    0.5208,
                    0.4114,
                    0.3858,
                    0.3837,
                    0.3825,
                    0.3689,
                    0.3514,
                    0.3484,
                    0.3471,
                    0.3456,
                    0.3429,
                    0.3416,
                    0.3215,
                    0.3208,
                    0.318,
                    0.3168,
                    0.3161,
                    0.3135,
                    0.3118,
                    0.3114,
                    0.3085,
                    0.3079,
                    0.3066
                ],
                "neuron_alignment_indices": [
                    288,
                    625,
                    327
                ],
                "neuron_alignment_values": [
                    0.132,
                    0.107,
                    0.094
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    485,
                    539,
                    207
                ],
                "correlated_neurons_pearson": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_features_indices": [
                    77717,
                    77684,
                    77763
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "MSN",
                    "ramid",
                    " cooker",
                    " frenzy",
                    "ocr",
                    " specificity",
                    " idiots",
                    "wana",
                    "zees",
                    "stro"
                ],
                "neg_values": [
                    -0.751,
                    -0.727,
                    -0.709,
                    -0.657,
                    -0.625,
                    -0.623,
                    -0.614,
                    -0.614,
                    -0.608,
                    -0.605
                ],
                "pos_str": [
                    "inguished",
                    "Newsletter",
                    "itus",
                    "pex",
                    "ername",
                    "utive",
                    "essor",
                    "fitting",
                    "DAQ",
                    " dean"
                ],
                "pos_values": [
                    0.86,
                    0.787,
                    0.775,
                    0.77,
                    0.741,
                    0.73,
                    0.684,
                    0.677,
                    0.671,
                    0.667
                ],
                "frac_nonzero": 4e-05,
                "freq_hist_data_bar_heights": [
                    77,
                    24,
                    5,
                    8,
                    6,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.255,
                    0.762,
                    1.27,
                    1.778,
                    2.286,
                    2.794,
                    3.302,
                    3.81,
                    4.318,
                    4.825,
                    5.333,
                    5.841,
                    6.349,
                    6.857,
                    7.365,
                    7.873,
                    8.381,
                    8.889,
                    9.396,
                    9.904,
                    10.412,
                    10.92,
                    11.428,
                    11.936,
                    12.444,
                    12.952,
                    13.459,
                    13.967,
                    14.475,
                    14.983,
                    15.491,
                    15.999,
                    16.507,
                    17.015,
                    17.522,
                    18.03,
                    18.538,
                    19.046,
                    19.554,
                    20.062,
                    20.57,
                    21.078,
                    21.585,
                    22.093,
                    22.601,
                    23.109,
                    23.617,
                    24.125,
                    24.633,
                    25.141
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    1,
                    1,
                    2,
                    7,
                    13,
                    10,
                    24,
                    67,
                    138,
                    190,
                    352,
                    438,
                    698,
                    994,
                    1268,
                    1639,
                    2061,
                    2475,
                    2944,
                    3333,
                    3579,
                    3747,
                    3831,
                    3853,
                    3553,
                    3100,
                    2670,
                    2247,
                    1830,
                    1523,
                    1093,
                    806,
                    579,
                    390,
                    284,
                    191,
                    118,
                    74,
                    45,
                    33,
                    25,
                    15,
                    4,
                    4,
                    1,
                    1,
                    3,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.735,
                    -0.702,
                    -0.67,
                    -0.638,
                    -0.606,
                    -0.574,
                    -0.541,
                    -0.509,
                    -0.477,
                    -0.445,
                    -0.413,
                    -0.38,
                    -0.348,
                    -0.316,
                    -0.284,
                    -0.251,
                    -0.219,
                    -0.187,
                    -0.155,
                    -0.123,
                    -0.09,
                    -0.058,
                    -0.026,
                    0.006,
                    0.038,
                    0.071,
                    0.103,
                    0.135,
                    0.167,
                    0.199,
                    0.232,
                    0.264,
                    0.296,
                    0.328,
                    0.361,
                    0.393,
                    0.425,
                    0.457,
                    0.489,
                    0.522,
                    0.554,
                    0.586,
                    0.618,
                    0.65,
                    0.683,
                    0.715,
                    0.747,
                    0.779,
                    0.811,
                    0.844
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " titles and formal titles of academic professionals",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "suffixes or endings that suggest professional titles or academic status",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygiex14y90g10exxa4fy1m0",
                        "tokens": [
                            " Journey",
                            " of",
                            " Ni",
                            "els",
                            " K",
                            "lim",
                            " to",
                            " the",
                            " World",
                            " Underground",
                            " must",
                            " be",
                            " considered",
                            " the",
                            " first",
                            " presentation",
                            " of",
                            " the",
                            " idea",
                            " of",
                            " the",
                            " hollow",
                            " earth",
                            ".",
                            "\n",
                            "\n",
                            "Peter",
                            " F",
                            "itting",
                            " is",
                            " professor",
                            " emer",
                            "itus",
                            " of",
                            " French",
                            " and",
                            " Cinema",
                            " Studies",
                            " at",
                            " the",
                            " University",
                            " of",
                            " Toronto",
                            ".",
                            " His",
                            " work",
                            " has",
                            " focused",
                            " primarily",
                            " on",
                            " utopian",
                            " fiction",
                            " and",
                            " on",
                            " 20",
                            "th",
                            " century",
                            " science",
                            " fiction",
                            ".",
                            " In",
                            " 2004",
                            " he",
                            " published",
                            ":",
                            " Sub",
                            "ter",
                            "ranean",
                            " Worlds",
                            ":",
                            " A",
                            " Critical",
                            " Anth",
                            "ology",
                            ",",
                            " (",
                            "W",
                            "esley",
                            "an",
                            " UP",
                            ").",
                            "\n",
                            "\n",
                            "For",
                            " more",
                            " information",
                            " on",
                            " these",
                            " topics",
                            " and",
                            " samples",
                            " of",
                            " his",
                            " work",
                            " see",
                            ":",
                            " The",
                            " Society",
                            " for",
                            " U",
                            "top",
                            "ian",
                            " Studies",
                            " and",
                            " Science",
                            " Fiction",
                            " Studies",
                            ".",
                            "\n",
                            "\n",
                            "Links",
                            " to",
                            " Works",
                            "<|endoftext|>",
                            "Me",
                            "gan",
                            " Gle",
                            "ason",
                            ",",
                            " from",
                            " St",
                            ",",
                            " Louis",
                            ",",
                            " Mo",
                            ".,",
                            " felt"
                        ],
                        "dataIndex": null,
                        "index": "77717",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.395,
                        "maxValueTokenIndex": 32,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.375,
                            25.395,
                            2.075,
                            0,
                            0,
                            0,
                            0.268,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:07:13.306Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 25.395,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiex15y90l10exkl28cizg",
                        "tokens": [
                            " Journey",
                            " of",
                            " Ni",
                            "els",
                            " K",
                            "lim",
                            " to",
                            " the",
                            " World",
                            " Underground",
                            " must",
                            " be",
                            " considered",
                            " the",
                            " first",
                            " presentation",
                            " of",
                            " the",
                            " idea",
                            " of",
                            " the",
                            " hollow",
                            " earth",
                            ".",
                            "\n",
                            "\n",
                            "Peter",
                            " F",
                            "itting",
                            " is",
                            " professor",
                            " emer",
                            "itus",
                            " of",
                            " French",
                            " and",
                            " Cinema",
                            " Studies",
                            " at",
                            " the",
                            " University",
                            " of",
                            " Toronto",
                            ".",
                            " His",
                            " work",
                            " has",
                            " focused",
                            " primarily",
                            " on",
                            " utopian",
                            " fiction",
                            " and",
                            " on",
                            " 20",
                            "th",
                            " century",
                            " science",
                            " fiction",
                            ".",
                            " In",
                            " 2004",
                            " he",
                            " published",
                            ":",
                            " Sub",
                            "ter",
                            "ranean",
                            " Worlds",
                            ":",
                            " A",
                            " Critical",
                            " Anth",
                            "ology",
                            ",",
                            " (",
                            "W",
                            "esley",
                            "an",
                            " UP",
                            ").",
                            "\n",
                            "\n",
                            "For",
                            " more",
                            " information",
                            " on",
                            " these",
                            " topics",
                            " and",
                            " samples",
                            " of",
                            " his",
                            " work",
                            " see",
                            ":",
                            " The",
                            " Society",
                            " for",
                            " U",
                            "top",
                            "ian",
                            " Studies",
                            " and",
                            " Science",
                            " Fiction",
                            " Studies",
                            ".",
                            "\n",
                            "\n",
                            "Links",
                            " to",
                            " Works",
                            "<|endoftext|>",
                            "Me",
                            "gan",
                            " Gle",
                            "ason",
                            ",",
                            " from",
                            " St",
                            ",",
                            " Louis",
                            ",",
                            " Mo",
                            ".,",
                            " felt"
                        ],
                        "dataIndex": null,
                        "index": "77717",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.395,
                        "maxValueTokenIndex": 32,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.375,
                            25.395,
                            2.075,
                            0,
                            0,
                            0,
                            0.268,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:07:13.306Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 25.395,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiex15y90q10exma5f32n2",
                        "tokens": [
                            " Journey",
                            " of",
                            " Ni",
                            "els",
                            " K",
                            "lim",
                            " to",
                            " the",
                            " World",
                            " Underground",
                            " must",
                            " be",
                            " considered",
                            " the",
                            " first",
                            " presentation",
                            " of",
                            " the",
                            " idea",
                            " of",
                            " the",
                            " hollow",
                            " earth",
                            ".",
                            "\n",
                            "\n",
                            "Peter",
                            " F",
                            "itting",
                            " is",
                            " professor",
                            " emer",
                            "itus",
                            " of",
                            " French",
                            " and",
                            " Cinema",
                            " Studies",
                            " at",
                            " the",
                            " University",
                            " of",
                            " Toronto",
                            ".",
                            " His",
                            " work",
                            " has",
                            " focused",
                            " primarily",
                            " on",
                            " utopian",
                            " fiction",
                            " and",
                            " on",
                            " 20",
                            "th",
                            " century",
                            " science",
                            " fiction",
                            ".",
                            " In",
                            " 2004",
                            " he",
                            " published",
                            ":",
                            " Sub",
                            "ter",
                            "ranean",
                            " Worlds",
                            ":",
                            " A",
                            " Critical",
                            " Anth",
                            "ology",
                            ",",
                            " (",
                            "W",
                            "esley",
                            "an",
                            " UP",
                            ").",
                            "\n",
                            "\n",
                            "For",
                            " more",
                            " information",
                            " on",
                            " these",
                            " topics",
                            " and",
                            " samples",
                            " of",
                            " his",
                            " work",
                            " see",
                            ":",
                            " The",
                            " Society",
                            " for",
                            " U",
                            "top",
                            "ian",
                            " Studies",
                            " and",
                            " Science",
                            " Fiction",
                            " Studies",
                            ".",
                            "\n",
                            "\n",
                            "Links",
                            " to",
                            " Works",
                            "<|endoftext|>",
                            "Me",
                            "gan",
                            " Gle",
                            "ason",
                            ",",
                            " from",
                            " St",
                            ",",
                            " Louis",
                            ",",
                            " Mo",
                            ".,",
                            " felt"
                        ],
                        "dataIndex": null,
                        "index": "77717",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.395,
                        "maxValueTokenIndex": 32,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.375,
                            25.395,
                            2.075,
                            0,
                            0,
                            0,
                            0.268,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:07:13.306Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 25.395,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}