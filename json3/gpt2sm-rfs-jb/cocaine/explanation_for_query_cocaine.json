{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "cocaine"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "15050",
            "description": "references to cocaine",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.7156510566369018,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "15050",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:46:40.099Z",
                "maxActApprox": 59.167,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    15050,
                    59250,
                    46659,
                    96213,
                    35384,
                    20001,
                    53894,
                    61758,
                    97812,
                    54916,
                    89659,
                    59995,
                    63306,
                    89795,
                    43230,
                    51089,
                    56061,
                    27167,
                    13573,
                    22878,
                    10082,
                    77583,
                    13452,
                    81902,
                    59394
                ],
                "topkCosSimValues": [
                    1,
                    0.567,
                    0.4435,
                    0.4428,
                    0.4062,
                    0.4002,
                    0.3993,
                    0.3906,
                    0.3899,
                    0.3875,
                    0.3873,
                    0.3867,
                    0.3848,
                    0.38,
                    0.3789,
                    0.3775,
                    0.3761,
                    0.3754,
                    0.3736,
                    0.3703,
                    0.3694,
                    0.3664,
                    0.3635,
                    0.3619,
                    0.3614
                ],
                "neuron_alignment_indices": [
                    288,
                    549,
                    545
                ],
                "neuron_alignment_values": [
                    0.127,
                    0.114,
                    0.108
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    746,
                    67,
                    545
                ],
                "correlated_neurons_pearson": [
                    0.004,
                    0.004,
                    0.003
                ],
                "correlated_neurons_l1": [
                    0.003,
                    0.004,
                    0.003
                ],
                "correlated_features_indices": [
                    15014,
                    15057,
                    15077
                ],
                "correlated_features_pearson": [
                    0.002,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0,
                    0
                ],
                "neg_str": [
                    " Barcl",
                    " GOODMAN",
                    "\u012a\u0134",
                    "\u00e9\u0139\u013a",
                    "CLASS",
                    " Wembley",
                    " Turk",
                    " Prompt",
                    "\u00e3\u0124\u00b6",
                    "DragonMagazine"
                ],
                "neg_values": [
                    -0.826,
                    -0.719,
                    -0.682,
                    -0.651,
                    -0.649,
                    -0.634,
                    -0.61,
                    -0.602,
                    -0.601,
                    -0.597
                ],
                "pos_str": [
                    " coc",
                    "ulture",
                    "anus",
                    "leans",
                    "reated",
                    "roach",
                    "ombs",
                    "overed",
                    "ategor",
                    "ached"
                ],
                "pos_values": [
                    1.031,
                    0.994,
                    0.951,
                    0.939,
                    0.886,
                    0.886,
                    0.858,
                    0.852,
                    0.851,
                    0.845
                ],
                "frac_nonzero": 1e-05,
                "freq_hist_data_bar_heights": [
                    17,
                    3,
                    1,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.612,
                    1.795,
                    2.978,
                    4.161,
                    5.344,
                    6.527,
                    7.709,
                    8.892,
                    10.075,
                    11.258,
                    12.441,
                    13.624,
                    14.807,
                    15.99,
                    17.173,
                    18.356,
                    19.539,
                    20.722,
                    21.905,
                    23.088,
                    24.27,
                    25.453,
                    26.636,
                    27.819,
                    29.002,
                    30.185,
                    31.368,
                    32.551,
                    33.734,
                    34.917,
                    36.1,
                    37.283,
                    38.466,
                    39.648,
                    40.831,
                    42.014,
                    43.197,
                    44.38,
                    45.563,
                    46.746,
                    47.929,
                    49.112,
                    50.295,
                    51.478,
                    52.661,
                    53.844,
                    55.027,
                    56.209,
                    57.392,
                    58.575
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    1,
                    2,
                    2,
                    14,
                    19,
                    39,
                    77,
                    146,
                    279,
                    474,
                    706,
                    1033,
                    1548,
                    2120,
                    2744,
                    3392,
                    3971,
                    4313,
                    4430,
                    4395,
                    3999,
                    3619,
                    2957,
                    2377,
                    1861,
                    1462,
                    1075,
                    830,
                    616,
                    495,
                    336,
                    262,
                    207,
                    154,
                    106,
                    67,
                    45,
                    33,
                    13,
                    15,
                    9,
                    3,
                    3,
                    2,
                    2,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.808,
                    -0.77,
                    -0.733,
                    -0.696,
                    -0.659,
                    -0.622,
                    -0.585,
                    -0.548,
                    -0.51,
                    -0.473,
                    -0.436,
                    -0.399,
                    -0.362,
                    -0.325,
                    -0.288,
                    -0.25,
                    -0.213,
                    -0.176,
                    -0.139,
                    -0.102,
                    -0.065,
                    -0.027,
                    0.01,
                    0.047,
                    0.084,
                    0.121,
                    0.158,
                    0.195,
                    0.233,
                    0.27,
                    0.307,
                    0.344,
                    0.381,
                    0.418,
                    0.456,
                    0.493,
                    0.53,
                    0.567,
                    0.604,
                    0.641,
                    0.678,
                    0.716,
                    0.753,
                    0.79,
                    0.827,
                    0.864,
                    0.901,
                    0.938,
                    0.976,
                    1.013
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "words related to cocaine or its derivatives",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to cocaine",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfji3cmpco10exk98lwyr5",
                        "tokens": [
                            "Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " statement",
                            " calling",
                            " President",
                            " Trump",
                            " \u00e2\u0122",
                            "\u013e",
                            "ment",
                            "ally",
                            " der",
                            "anged",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " promising",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "highest",
                            "-",
                            "level",
                            " of",
                            " the",
                            " hard",
                            "line",
                            " counter",
                            "measures",
                            "\u00e2\u0122",
                            "\u013f",
                            " shows",
                            " that",
                            " he",
                            " has",
                            " taken",
                            " ownership",
                            " of",
                            " this",
                            " showdown",
                            " and",
                            " that",
                            " he",
                            " alone",
                            "\u2014",
                            "as",
                            " the",
                            " leader",
                            " of",
                            " North",
                            " Korea",
                            "\u2014",
                            "will",
                            " defend",
                            " the",
                            " country",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " survival",
                            ",",
                            " as",
                            " well",
                            " as",
                            " its",
                            " dignity",
                            ".",
                            " Kim",
                            " also",
                            " has",
                            " a",
                            " bias",
                            " for",
                            " action",
                            " and",
                            " he",
                            " wants",
                            " to",
                            " win",
                            ",",
                            " as",
                            " the",
                            " Kim",
                            " family",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " former",
                            " sushi",
                            " chef",
                            " recalled",
                            ",",
                            " and",
                            " as",
                            " Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " recent",
                            " behavior",
                            " has",
                            " shown",
                            ".",
                            " Not",
                            " only",
                            " has",
                            " Kim",
                            " Jong",
                            "-",
                            "un",
                            " grown",
                            " up",
                            " in",
                            " a",
                            " coc",
                            "oon",
                            " of",
                            " indul",
                            "gence",
                            " and",
                            " privilege",
                            ",",
                            " he",
                            " has",
                            " inherited",
                            " advanced"
                        ],
                        "dataIndex": null,
                        "index": "15050",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.167,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.167,
                            7.314,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:48.361Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 59.167,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfji3cmpcs10exyu8nva2a",
                        "tokens": [
                            "Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " statement",
                            " calling",
                            " President",
                            " Trump",
                            " \u00e2\u0122",
                            "\u013e",
                            "ment",
                            "ally",
                            " der",
                            "anged",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " promising",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "highest",
                            "-",
                            "level",
                            " of",
                            " the",
                            " hard",
                            "line",
                            " counter",
                            "measures",
                            "\u00e2\u0122",
                            "\u013f",
                            " shows",
                            " that",
                            " he",
                            " has",
                            " taken",
                            " ownership",
                            " of",
                            " this",
                            " showdown",
                            " and",
                            " that",
                            " he",
                            " alone",
                            "\u2014",
                            "as",
                            " the",
                            " leader",
                            " of",
                            " North",
                            " Korea",
                            "\u2014",
                            "will",
                            " defend",
                            " the",
                            " country",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " survival",
                            ",",
                            " as",
                            " well",
                            " as",
                            " its",
                            " dignity",
                            ".",
                            " Kim",
                            " also",
                            " has",
                            " a",
                            " bias",
                            " for",
                            " action",
                            " and",
                            " he",
                            " wants",
                            " to",
                            " win",
                            ",",
                            " as",
                            " the",
                            " Kim",
                            " family",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " former",
                            " sushi",
                            " chef",
                            " recalled",
                            ",",
                            " and",
                            " as",
                            " Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " recent",
                            " behavior",
                            " has",
                            " shown",
                            ".",
                            " Not",
                            " only",
                            " has",
                            " Kim",
                            " Jong",
                            "-",
                            "un",
                            " grown",
                            " up",
                            " in",
                            " a",
                            " coc",
                            "oon",
                            " of",
                            " indul",
                            "gence",
                            " and",
                            " privilege",
                            ",",
                            " he",
                            " has",
                            " inherited",
                            " advanced"
                        ],
                        "dataIndex": null,
                        "index": "15050",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.167,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.167,
                            7.314,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:48.361Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 59.167,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfji3empda10exp8io8tig",
                        "tokens": [
                            "Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " statement",
                            " calling",
                            " President",
                            " Trump",
                            " \u00e2\u0122",
                            "\u013e",
                            "ment",
                            "ally",
                            " der",
                            "anged",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " promising",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "highest",
                            "-",
                            "level",
                            " of",
                            " the",
                            " hard",
                            "line",
                            " counter",
                            "measures",
                            "\u00e2\u0122",
                            "\u013f",
                            " shows",
                            " that",
                            " he",
                            " has",
                            " taken",
                            " ownership",
                            " of",
                            " this",
                            " showdown",
                            " and",
                            " that",
                            " he",
                            " alone",
                            "\u2014",
                            "as",
                            " the",
                            " leader",
                            " of",
                            " North",
                            " Korea",
                            "\u2014",
                            "will",
                            " defend",
                            " the",
                            " country",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " survival",
                            ",",
                            " as",
                            " well",
                            " as",
                            " its",
                            " dignity",
                            ".",
                            " Kim",
                            " also",
                            " has",
                            " a",
                            " bias",
                            " for",
                            " action",
                            " and",
                            " he",
                            " wants",
                            " to",
                            " win",
                            ",",
                            " as",
                            " the",
                            " Kim",
                            " family",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " former",
                            " sushi",
                            " chef",
                            " recalled",
                            ",",
                            " and",
                            " as",
                            " Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " recent",
                            " behavior",
                            " has",
                            " shown",
                            ".",
                            " Not",
                            " only",
                            " has",
                            " Kim",
                            " Jong",
                            "-",
                            "un",
                            " grown",
                            " up",
                            " in",
                            " a",
                            " coc",
                            "oon",
                            " of",
                            " indul",
                            "gence",
                            " and",
                            " privilege",
                            ",",
                            " he",
                            " has",
                            " inherited",
                            " advanced"
                        ],
                        "dataIndex": null,
                        "index": "15050",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.167,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.167,
                            7.314,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:48.361Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 47.333,
                        "binMax": 59.167,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "30639",
            "description": "references to cocaine and related substances",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.7033574404333497,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "30639",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:53:54.144Z",
                "maxActApprox": 60.762,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    30639,
                    32046,
                    36761,
                    47759,
                    47962,
                    22479,
                    13385,
                    37288,
                    27285,
                    1849,
                    6388,
                    4478,
                    46260,
                    32573,
                    26614,
                    9844,
                    37692,
                    5364,
                    2522,
                    45361,
                    29808,
                    25100,
                    23753,
                    12971,
                    14632
                ],
                "topkCosSimValues": [
                    1,
                    0.7064,
                    0.6306,
                    0.6096,
                    0.5965,
                    0.5213,
                    0.5164,
                    0.5096,
                    0.4945,
                    0.4846,
                    0.4759,
                    0.4606,
                    0.4447,
                    0.4392,
                    0.4384,
                    0.4383,
                    0.4367,
                    0.4308,
                    0.427,
                    0.4269,
                    0.4255,
                    0.4244,
                    0.424,
                    0.4194,
                    0.4147
                ],
                "neuron_alignment_indices": [
                    481,
                    288,
                    447
                ],
                "neuron_alignment_values": [
                    0.164,
                    0.134,
                    0.123
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.006,
                    0.006
                ],
                "correlated_neurons_indices": [
                    698,
                    461,
                    384
                ],
                "correlated_neurons_pearson": [
                    0.012,
                    0.011,
                    0.01
                ],
                "correlated_neurons_l1": [
                    0.012,
                    0.01,
                    0.009
                ],
                "correlated_features_indices": [
                    30707,
                    30636,
                    30682
                ],
                "correlated_features_pearson": [
                    0.006,
                    0.002,
                    0.001
                ],
                "correlated_features_l1": [
                    0.006,
                    0.002,
                    0.001
                ],
                "neg_str": [
                    "laus",
                    "hof",
                    "\u012a\u0134",
                    "DEM",
                    "Reviewer",
                    "soType",
                    "Madison",
                    "aer",
                    " Koen",
                    " Brach"
                ],
                "neg_values": [
                    -0.775,
                    -0.768,
                    -0.73,
                    -0.718,
                    -0.691,
                    -0.69,
                    -0.688,
                    -0.685,
                    -0.683,
                    -0.677
                ],
                "pos_str": [
                    " cocaine",
                    " residue",
                    " addict",
                    " addicts",
                    " addiction",
                    " overdose",
                    " overdoses",
                    " poisoning",
                    " methamphetamine",
                    " cartels"
                ],
                "pos_values": [
                    1.239,
                    1.076,
                    1.065,
                    1.053,
                    1.047,
                    1.035,
                    1.023,
                    0.967,
                    0.967,
                    0.948
                ],
                "frac_nonzero": 8.999999999999999e-05,
                "freq_hist_data_bar_heights": [
                    95,
                    44,
                    28,
                    18,
                    13,
                    6,
                    7,
                    8,
                    3,
                    5,
                    2,
                    6,
                    3,
                    4,
                    3,
                    1,
                    0,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    2,
                    1,
                    0,
                    0,
                    5,
                    5,
                    8,
                    6,
                    0,
                    2,
                    3,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.647,
                    1.861,
                    3.076,
                    4.29,
                    5.504,
                    6.719,
                    7.933,
                    9.148,
                    10.362,
                    11.577,
                    12.791,
                    14.006,
                    15.22,
                    16.434,
                    17.649,
                    18.863,
                    20.078,
                    21.292,
                    22.507,
                    23.721,
                    24.936,
                    26.15,
                    27.364,
                    28.579,
                    29.793,
                    31.008,
                    32.222,
                    33.437,
                    34.651,
                    35.866,
                    37.08,
                    38.294,
                    39.509,
                    40.723,
                    41.938,
                    43.152,
                    44.367,
                    45.581,
                    46.796,
                    48.01,
                    49.224,
                    50.439,
                    51.653,
                    52.868,
                    54.082,
                    55.297,
                    56.511,
                    57.726,
                    58.94,
                    60.154
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    2,
                    16,
                    13,
                    39,
                    52,
                    129,
                    201,
                    318,
                    471,
                    774,
                    1102,
                    1573,
                    2101,
                    2587,
                    3252,
                    3735,
                    4001,
                    4241,
                    4310,
                    4008,
                    3676,
                    3172,
                    2595,
                    2145,
                    1675,
                    1169,
                    873,
                    622,
                    446,
                    281,
                    213,
                    148,
                    102,
                    66,
                    47,
                    26,
                    25,
                    10,
                    12,
                    7,
                    7,
                    4,
                    2,
                    2,
                    4,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.755,
                    -0.715,
                    -0.674,
                    -0.634,
                    -0.594,
                    -0.553,
                    -0.513,
                    -0.473,
                    -0.433,
                    -0.392,
                    -0.352,
                    -0.312,
                    -0.272,
                    -0.231,
                    -0.191,
                    -0.151,
                    -0.11,
                    -0.07,
                    -0.03,
                    0.01,
                    0.051,
                    0.091,
                    0.131,
                    0.172,
                    0.212,
                    0.252,
                    0.292,
                    0.333,
                    0.373,
                    0.413,
                    0.453,
                    0.494,
                    0.534,
                    0.574,
                    0.615,
                    0.655,
                    0.695,
                    0.735,
                    0.776,
                    0.816,
                    0.856,
                    0.897,
                    0.937,
                    0.977,
                    1.017,
                    1.058,
                    1.098,
                    1.138,
                    1.178,
                    1.219
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to cocaine and related substances",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk63su13vk0i666y89f2cvr",
                        "tokens": [
                            ",",
                            " said",
                            " senior",
                            " author",
                            " Don",
                            " Cooper",
                            ",",
                            " assistant",
                            " professor",
                            " of",
                            " psychiatry",
                            " at",
                            " the",
                            " University",
                            " of",
                            " Texas",
                            " South",
                            "western",
                            " Medical",
                            " Center",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " idea",
                            ",",
                            " that",
                            " an",
                            " individual",
                            " nerve",
                            " cell",
                            " can",
                            " hold",
                            " a",
                            " trace",
                            " memory",
                            ",",
                            " is",
                            " also",
                            " related",
                            " to",
                            " drug",
                            " addiction",
                            ",",
                            " the",
                            " study",
                            " found",
                            ".",
                            " By",
                            " giving",
                            " cocaine",
                            " to",
                            " mice",
                            " in",
                            " the",
                            " laboratory",
                            ",",
                            " the",
                            " researchers",
                            " explained",
                            " why",
                            " the",
                            " drug",
                            " imp",
                            "airs",
                            " short",
                            " term",
                            " memory",
                            ":",
                            " Coc",
                            "aine",
                            " causes",
                            " a",
                            " buildup",
                            " of",
                            " dopamine",
                            ",",
                            " a",
                            " brain",
                            " chemical",
                            " that",
                            " decreases",
                            " the",
                            " individual",
                            " nerve",
                            " cells",
                            "'",
                            " ability",
                            " to",
                            " hold",
                            " moment",
                            "-",
                            "to",
                            "-",
                            "mom",
                            "ent",
                            " information",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " study",
                            " is",
                            " an",
                            " important",
                            " contribution",
                            " to",
                            " the",
                            " field",
                            " of",
                            " working",
                            " memory",
                            " because",
                            " it",
                            " shows",
                            " the",
                            " molecular",
                            " mechanisms",
                            " involved",
                            " in",
                            " the",
                            " process",
                            ",",
                            " said",
                            " Michael",
                            " Kuh",
                            "ar"
                        ],
                        "dataIndex": null,
                        "index": "30639",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 60.762,
                        "maxValueTokenIndex": 50,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.155,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            60.762,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.201,
                            20.7,
                            0,
                            0,
                            0,
                            0,
                            8.172,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:54:01.192Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 60.762,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk63su13vk1i666whq7bvot",
                        "tokens": [
                            " dollars",
                            " worth",
                            " of",
                            " cocaine",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " ATF",
                            " agent",
                            " explains",
                            " that",
                            " he",
                            " needs",
                            " a",
                            " robbery",
                            " crew",
                            " to",
                            " help",
                            " him",
                            " overtake",
                            " armed",
                            " guards",
                            " in",
                            " the",
                            " house",
                            " and",
                            " steal",
                            " the",
                            " cocaine",
                            ".",
                            " Once",
                            " the",
                            " crew",
                            " meets",
                            " to",
                            " prepare",
                            " for",
                            " the",
                            " armed",
                            " robbery",
                            ",",
                            " federal",
                            " authorities",
                            " bust",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "Several",
                            " of",
                            " the",
                            " bust",
                            "s",
                            " have",
                            " lead",
                            " to",
                            " the",
                            " deaths",
                            " of",
                            " suspects",
                            " who",
                            " shot",
                            " at",
                            " or",
                            " tried",
                            " to",
                            " run",
                            " down",
                            " agents",
                            " in",
                            " an",
                            " attempt",
                            " to",
                            " flee",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            "form",
                            "ants",
                            " are",
                            " paid",
                            " by",
                            " the",
                            " ATF",
                            " to",
                            " pressure",
                            " people",
                            " to",
                            " join",
                            " the",
                            " fake",
                            " robberies",
                            ".",
                            " Individuals",
                            " may",
                            " be",
                            " targeted",
                            " simply",
                            " because",
                            " the",
                            " informants",
                            " know",
                            " them",
                            " through",
                            " work",
                            " or",
                            " a",
                            " personal",
                            " connection",
                            ",",
                            " just",
                            " like",
                            " a",
                            " r",
                            "affle",
                            " ticket",
                            " sale",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " preparation",
                            " for",
                            " the",
                            " fake"
                        ],
                        "dataIndex": null,
                        "index": "30639",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 60.716,
                        "maxValueTokenIndex": 3,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            60.716,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            51.546,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:54:01.192Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 60.762,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk63su43vkmi6660ns383u1",
                        "tokens": [
                            " dollars",
                            " worth",
                            " of",
                            " cocaine",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " ATF",
                            " agent",
                            " explains",
                            " that",
                            " he",
                            " needs",
                            " a",
                            " robbery",
                            " crew",
                            " to",
                            " help",
                            " him",
                            " overtake",
                            " armed",
                            " guards",
                            " in",
                            " the",
                            " house",
                            " and",
                            " steal",
                            " the",
                            " cocaine",
                            ".",
                            " Once",
                            " the",
                            " crew",
                            " meets",
                            " to",
                            " prepare",
                            " for",
                            " the",
                            " armed",
                            " robbery",
                            ",",
                            " federal",
                            " authorities",
                            " bust",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "Several",
                            " of",
                            " the",
                            " bust",
                            "s",
                            " have",
                            " lead",
                            " to",
                            " the",
                            " deaths",
                            " of",
                            " suspects",
                            " who",
                            " shot",
                            " at",
                            " or",
                            " tried",
                            " to",
                            " run",
                            " down",
                            " agents",
                            " in",
                            " an",
                            " attempt",
                            " to",
                            " flee",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            "form",
                            "ants",
                            " are",
                            " paid",
                            " by",
                            " the",
                            " ATF",
                            " to",
                            " pressure",
                            " people",
                            " to",
                            " join",
                            " the",
                            " fake",
                            " robberies",
                            ".",
                            " Individuals",
                            " may",
                            " be",
                            " targeted",
                            " simply",
                            " because",
                            " the",
                            " informants",
                            " know",
                            " them",
                            " through",
                            " work",
                            " or",
                            " a",
                            " personal",
                            " connection",
                            ",",
                            " just",
                            " like",
                            " a",
                            " r",
                            "affle",
                            " ticket",
                            " sale",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " preparation",
                            " for",
                            " the",
                            " fake"
                        ],
                        "dataIndex": null,
                        "index": "30639",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 60.716,
                        "maxValueTokenIndex": 3,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            60.716,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            51.546,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:54:01.192Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 48.609,
                        "binMax": 60.762,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "51089",
            "description": "references to cocaine and its associated terminology",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6741300627070703,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "51089",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:38:14.891Z",
                "maxActApprox": 56.244,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    51089,
                    66264,
                    93834,
                    95121,
                    83933,
                    13775,
                    22346,
                    19646,
                    93178,
                    36800,
                    39003,
                    15729,
                    3570,
                    60483,
                    6468,
                    59250,
                    59791,
                    55695,
                    15939,
                    5551,
                    40091,
                    81344,
                    90520,
                    62292,
                    16740
                ],
                "topkCosSimValues": [
                    1,
                    0.6526,
                    0.5893,
                    0.5828,
                    0.572,
                    0.5636,
                    0.5472,
                    0.5471,
                    0.5395,
                    0.5342,
                    0.5319,
                    0.5126,
                    0.5039,
                    0.4956,
                    0.4949,
                    0.4874,
                    0.4798,
                    0.4723,
                    0.4587,
                    0.4467,
                    0.4452,
                    0.4434,
                    0.4431,
                    0.4395,
                    0.4364
                ],
                "neuron_alignment_indices": [
                    288,
                    481,
                    384
                ],
                "neuron_alignment_values": [
                    0.146,
                    0.146,
                    0.115
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.007,
                    0.005
                ],
                "correlated_neurons_indices": [
                    698,
                    461,
                    384
                ],
                "correlated_neurons_pearson": [
                    0.009,
                    0.008,
                    0.008
                ],
                "correlated_neurons_l1": [
                    0.009,
                    0.008,
                    0.007
                ],
                "correlated_features_indices": [
                    51116,
                    50975,
                    51089
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.002,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0.002,
                    0
                ],
                "neg_str": [
                    "hof",
                    "\u012a\u0134",
                    "lying",
                    "laus",
                    "edIn",
                    "DEM",
                    "aer",
                    "Madison",
                    " Canterbury",
                    "\u0143\u0136"
                ],
                "neg_values": [
                    -0.817,
                    -0.766,
                    -0.737,
                    -0.724,
                    -0.721,
                    -0.71,
                    -0.709,
                    -0.695,
                    -0.695,
                    -0.686
                ],
                "pos_str": [
                    " cocaine",
                    " addict",
                    " addicts",
                    " residue",
                    " addiction",
                    " overdose",
                    " cartels",
                    " overdoses",
                    " traffickers",
                    " sulf"
                ],
                "pos_values": [
                    1.148,
                    1.01,
                    1.007,
                    1.005,
                    0.97,
                    0.948,
                    0.924,
                    0.903,
                    0.902,
                    0.876
                ],
                "frac_nonzero": 2e-05,
                "freq_hist_data_bar_heights": [
                    15,
                    6,
                    3,
                    1,
                    1,
                    1,
                    5,
                    1,
                    1,
                    4,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    2,
                    3,
                    0,
                    3,
                    1,
                    1,
                    1,
                    5,
                    2,
                    1,
                    2,
                    1,
                    2,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.604,
                    1.728,
                    2.852,
                    3.976,
                    5.101,
                    6.225,
                    7.349,
                    8.473,
                    9.597,
                    10.721,
                    11.845,
                    12.969,
                    14.093,
                    15.217,
                    16.341,
                    17.465,
                    18.589,
                    19.713,
                    20.837,
                    21.961,
                    23.085,
                    24.209,
                    25.333,
                    26.457,
                    27.581,
                    28.705,
                    29.829,
                    30.953,
                    32.077,
                    33.201,
                    34.325,
                    35.449,
                    36.573,
                    37.697,
                    38.821,
                    39.945,
                    41.069,
                    42.193,
                    43.317,
                    44.441,
                    45.565,
                    46.69,
                    47.814,
                    48.938,
                    50.062,
                    51.186,
                    52.31,
                    53.434,
                    54.558,
                    55.682
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    5,
                    12,
                    11,
                    22,
                    53,
                    100,
                    169,
                    248,
                    410,
                    563,
                    914,
                    1331,
                    1677,
                    2248,
                    2822,
                    3379,
                    3888,
                    4077,
                    4284,
                    4224,
                    4146,
                    3596,
                    2993,
                    2474,
                    1870,
                    1454,
                    1027,
                    719,
                    505,
                    340,
                    224,
                    171,
                    108,
                    53,
                    42,
                    32,
                    24,
                    10,
                    7,
                    7,
                    6,
                    3,
                    2,
                    1,
                    3,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.797,
                    -0.758,
                    -0.718,
                    -0.679,
                    -0.64,
                    -0.601,
                    -0.561,
                    -0.522,
                    -0.483,
                    -0.443,
                    -0.404,
                    -0.365,
                    -0.325,
                    -0.286,
                    -0.247,
                    -0.208,
                    -0.168,
                    -0.129,
                    -0.09,
                    -0.05,
                    -0.011,
                    0.028,
                    0.068,
                    0.107,
                    0.146,
                    0.185,
                    0.225,
                    0.264,
                    0.303,
                    0.343,
                    0.382,
                    0.421,
                    0.46,
                    0.5,
                    0.539,
                    0.578,
                    0.618,
                    0.657,
                    0.696,
                    0.736,
                    0.775,
                    0.814,
                    0.853,
                    0.893,
                    0.932,
                    0.971,
                    1.011,
                    1.05,
                    1.089,
                    1.129
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to cocaine and its associated terminology",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghdsshe0c510explmcpwjg",
                        "tokens": [
                            " an",
                            " individual",
                            " nerve",
                            " cell",
                            " can",
                            " hold",
                            " a",
                            " trace",
                            " memory",
                            ",",
                            " is",
                            " also",
                            " related",
                            " to",
                            " drug",
                            " addiction",
                            ",",
                            " the",
                            " study",
                            " found",
                            ".",
                            " By",
                            " giving",
                            " cocaine",
                            " to",
                            " mice",
                            " in",
                            " the",
                            " laboratory",
                            ",",
                            " the",
                            " researchers",
                            " explained",
                            " why",
                            " the",
                            " drug",
                            " imp",
                            "airs",
                            " short",
                            " term",
                            " memory",
                            ":",
                            " Coc",
                            "aine",
                            " causes",
                            " a",
                            " buildup",
                            " of",
                            " dopamine",
                            ",",
                            " a",
                            " brain",
                            " chemical",
                            " that",
                            " decreases",
                            " the",
                            " individual",
                            " nerve",
                            " cells",
                            "'",
                            " ability",
                            " to",
                            " hold",
                            " moment",
                            "-",
                            "to",
                            "-",
                            "mom",
                            "ent",
                            " information",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " study",
                            " is",
                            " an",
                            " important",
                            " contribution",
                            " to",
                            " the",
                            " field",
                            " of",
                            " working",
                            " memory",
                            " because",
                            " it",
                            " shows",
                            " the",
                            " molecular",
                            " mechanisms",
                            " involved",
                            " in",
                            " the",
                            " process",
                            ",",
                            " said",
                            " Michael",
                            " Kuh",
                            "ar",
                            ",",
                            " professor",
                            " of",
                            " neuro",
                            "ph",
                            "armac",
                            "ology",
                            " at",
                            " Em",
                            "ory",
                            " University",
                            ",",
                            " who",
                            " was",
                            " not",
                            " involved",
                            " with",
                            " the",
                            " research",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " distant",
                            " but",
                            " possible",
                            " implication"
                        ],
                        "dataIndex": null,
                        "index": "51089",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.244,
                        "maxValueTokenIndex": 23,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            56.244,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.564,
                            18.952,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:21.523Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 11.249,
                        "binMax": 22.497,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghdssee0ba10ex8wgvf3u2",
                        "tokens": [
                            " an",
                            " individual",
                            " nerve",
                            " cell",
                            " can",
                            " hold",
                            " a",
                            " trace",
                            " memory",
                            ",",
                            " is",
                            " also",
                            " related",
                            " to",
                            " drug",
                            " addiction",
                            ",",
                            " the",
                            " study",
                            " found",
                            ".",
                            " By",
                            " giving",
                            " cocaine",
                            " to",
                            " mice",
                            " in",
                            " the",
                            " laboratory",
                            ",",
                            " the",
                            " researchers",
                            " explained",
                            " why",
                            " the",
                            " drug",
                            " imp",
                            "airs",
                            " short",
                            " term",
                            " memory",
                            ":",
                            " Coc",
                            "aine",
                            " causes",
                            " a",
                            " buildup",
                            " of",
                            " dopamine",
                            ",",
                            " a",
                            " brain",
                            " chemical",
                            " that",
                            " decreases",
                            " the",
                            " individual",
                            " nerve",
                            " cells",
                            "'",
                            " ability",
                            " to",
                            " hold",
                            " moment",
                            "-",
                            "to",
                            "-",
                            "mom",
                            "ent",
                            " information",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " study",
                            " is",
                            " an",
                            " important",
                            " contribution",
                            " to",
                            " the",
                            " field",
                            " of",
                            " working",
                            " memory",
                            " because",
                            " it",
                            " shows",
                            " the",
                            " molecular",
                            " mechanisms",
                            " involved",
                            " in",
                            " the",
                            " process",
                            ",",
                            " said",
                            " Michael",
                            " Kuh",
                            "ar",
                            ",",
                            " professor",
                            " of",
                            " neuro",
                            "ph",
                            "armac",
                            "ology",
                            " at",
                            " Em",
                            "ory",
                            " University",
                            ",",
                            " who",
                            " was",
                            " not",
                            " involved",
                            " with",
                            " the",
                            " research",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " distant",
                            " but",
                            " possible",
                            " implication"
                        ],
                        "dataIndex": null,
                        "index": "51089",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.244,
                        "maxValueTokenIndex": 23,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            56.244,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.564,
                            18.952,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:21.523Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 56.244,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghdsshe0c610ex60x7xi4b",
                        "tokens": [
                            " an",
                            " individual",
                            " nerve",
                            " cell",
                            " can",
                            " hold",
                            " a",
                            " trace",
                            " memory",
                            ",",
                            " is",
                            " also",
                            " related",
                            " to",
                            " drug",
                            " addiction",
                            ",",
                            " the",
                            " study",
                            " found",
                            ".",
                            " By",
                            " giving",
                            " cocaine",
                            " to",
                            " mice",
                            " in",
                            " the",
                            " laboratory",
                            ",",
                            " the",
                            " researchers",
                            " explained",
                            " why",
                            " the",
                            " drug",
                            " imp",
                            "airs",
                            " short",
                            " term",
                            " memory",
                            ":",
                            " Coc",
                            "aine",
                            " causes",
                            " a",
                            " buildup",
                            " of",
                            " dopamine",
                            ",",
                            " a",
                            " brain",
                            " chemical",
                            " that",
                            " decreases",
                            " the",
                            " individual",
                            " nerve",
                            " cells",
                            "'",
                            " ability",
                            " to",
                            " hold",
                            " moment",
                            "-",
                            "to",
                            "-",
                            "mom",
                            "ent",
                            " information",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " study",
                            " is",
                            " an",
                            " important",
                            " contribution",
                            " to",
                            " the",
                            " field",
                            " of",
                            " working",
                            " memory",
                            " because",
                            " it",
                            " shows",
                            " the",
                            " molecular",
                            " mechanisms",
                            " involved",
                            " in",
                            " the",
                            " process",
                            ",",
                            " said",
                            " Michael",
                            " Kuh",
                            "ar",
                            ",",
                            " professor",
                            " of",
                            " neuro",
                            "ph",
                            "armac",
                            "ology",
                            " at",
                            " Em",
                            "ory",
                            " University",
                            ",",
                            " who",
                            " was",
                            " not",
                            " involved",
                            " with",
                            " the",
                            " research",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " distant",
                            " but",
                            " possible",
                            " implication"
                        ],
                        "dataIndex": null,
                        "index": "51089",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.244,
                        "maxValueTokenIndex": 23,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            56.244,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.564,
                            18.952,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:21.523Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 11.249,
                        "binMax": 22.497,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "15050",
            "description": "words related to cocaine or its derivatives",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6442955116297765,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "15050",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:46:40.099Z",
                "maxActApprox": 59.167,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    15050,
                    59250,
                    46659,
                    96213,
                    35384,
                    20001,
                    53894,
                    61758,
                    97812,
                    54916,
                    89659,
                    59995,
                    63306,
                    89795,
                    43230,
                    51089,
                    56061,
                    27167,
                    13573,
                    22878,
                    10082,
                    77583,
                    13452,
                    81902,
                    59394
                ],
                "topkCosSimValues": [
                    1,
                    0.567,
                    0.4435,
                    0.4428,
                    0.4062,
                    0.4002,
                    0.3993,
                    0.3906,
                    0.3899,
                    0.3875,
                    0.3873,
                    0.3867,
                    0.3848,
                    0.38,
                    0.3789,
                    0.3775,
                    0.3761,
                    0.3754,
                    0.3736,
                    0.3703,
                    0.3694,
                    0.3664,
                    0.3635,
                    0.3619,
                    0.3614
                ],
                "neuron_alignment_indices": [
                    288,
                    549,
                    545
                ],
                "neuron_alignment_values": [
                    0.127,
                    0.114,
                    0.108
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    746,
                    67,
                    545
                ],
                "correlated_neurons_pearson": [
                    0.004,
                    0.004,
                    0.003
                ],
                "correlated_neurons_l1": [
                    0.003,
                    0.004,
                    0.003
                ],
                "correlated_features_indices": [
                    15014,
                    15057,
                    15077
                ],
                "correlated_features_pearson": [
                    0.002,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0,
                    0
                ],
                "neg_str": [
                    " Barcl",
                    " GOODMAN",
                    "\u012a\u0134",
                    "\u00e9\u0139\u013a",
                    "CLASS",
                    " Wembley",
                    " Turk",
                    " Prompt",
                    "\u00e3\u0124\u00b6",
                    "DragonMagazine"
                ],
                "neg_values": [
                    -0.826,
                    -0.719,
                    -0.682,
                    -0.651,
                    -0.649,
                    -0.634,
                    -0.61,
                    -0.602,
                    -0.601,
                    -0.597
                ],
                "pos_str": [
                    " coc",
                    "ulture",
                    "anus",
                    "leans",
                    "reated",
                    "roach",
                    "ombs",
                    "overed",
                    "ategor",
                    "ached"
                ],
                "pos_values": [
                    1.031,
                    0.994,
                    0.951,
                    0.939,
                    0.886,
                    0.886,
                    0.858,
                    0.852,
                    0.851,
                    0.845
                ],
                "frac_nonzero": 1e-05,
                "freq_hist_data_bar_heights": [
                    17,
                    3,
                    1,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.612,
                    1.795,
                    2.978,
                    4.161,
                    5.344,
                    6.527,
                    7.709,
                    8.892,
                    10.075,
                    11.258,
                    12.441,
                    13.624,
                    14.807,
                    15.99,
                    17.173,
                    18.356,
                    19.539,
                    20.722,
                    21.905,
                    23.088,
                    24.27,
                    25.453,
                    26.636,
                    27.819,
                    29.002,
                    30.185,
                    31.368,
                    32.551,
                    33.734,
                    34.917,
                    36.1,
                    37.283,
                    38.466,
                    39.648,
                    40.831,
                    42.014,
                    43.197,
                    44.38,
                    45.563,
                    46.746,
                    47.929,
                    49.112,
                    50.295,
                    51.478,
                    52.661,
                    53.844,
                    55.027,
                    56.209,
                    57.392,
                    58.575
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    1,
                    2,
                    2,
                    14,
                    19,
                    39,
                    77,
                    146,
                    279,
                    474,
                    706,
                    1033,
                    1548,
                    2120,
                    2744,
                    3392,
                    3971,
                    4313,
                    4430,
                    4395,
                    3999,
                    3619,
                    2957,
                    2377,
                    1861,
                    1462,
                    1075,
                    830,
                    616,
                    495,
                    336,
                    262,
                    207,
                    154,
                    106,
                    67,
                    45,
                    33,
                    13,
                    15,
                    9,
                    3,
                    3,
                    2,
                    2,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.808,
                    -0.77,
                    -0.733,
                    -0.696,
                    -0.659,
                    -0.622,
                    -0.585,
                    -0.548,
                    -0.51,
                    -0.473,
                    -0.436,
                    -0.399,
                    -0.362,
                    -0.325,
                    -0.288,
                    -0.25,
                    -0.213,
                    -0.176,
                    -0.139,
                    -0.102,
                    -0.065,
                    -0.027,
                    0.01,
                    0.047,
                    0.084,
                    0.121,
                    0.158,
                    0.195,
                    0.233,
                    0.27,
                    0.307,
                    0.344,
                    0.381,
                    0.418,
                    0.456,
                    0.493,
                    0.53,
                    0.567,
                    0.604,
                    0.641,
                    0.678,
                    0.716,
                    0.753,
                    0.79,
                    0.827,
                    0.864,
                    0.901,
                    0.938,
                    0.976,
                    1.013
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "words related to cocaine or its derivatives",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to cocaine",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfji3cmpco10exk98lwyr5",
                        "tokens": [
                            "Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " statement",
                            " calling",
                            " President",
                            " Trump",
                            " \u00e2\u0122",
                            "\u013e",
                            "ment",
                            "ally",
                            " der",
                            "anged",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " promising",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "highest",
                            "-",
                            "level",
                            " of",
                            " the",
                            " hard",
                            "line",
                            " counter",
                            "measures",
                            "\u00e2\u0122",
                            "\u013f",
                            " shows",
                            " that",
                            " he",
                            " has",
                            " taken",
                            " ownership",
                            " of",
                            " this",
                            " showdown",
                            " and",
                            " that",
                            " he",
                            " alone",
                            "\u2014",
                            "as",
                            " the",
                            " leader",
                            " of",
                            " North",
                            " Korea",
                            "\u2014",
                            "will",
                            " defend",
                            " the",
                            " country",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " survival",
                            ",",
                            " as",
                            " well",
                            " as",
                            " its",
                            " dignity",
                            ".",
                            " Kim",
                            " also",
                            " has",
                            " a",
                            " bias",
                            " for",
                            " action",
                            " and",
                            " he",
                            " wants",
                            " to",
                            " win",
                            ",",
                            " as",
                            " the",
                            " Kim",
                            " family",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " former",
                            " sushi",
                            " chef",
                            " recalled",
                            ",",
                            " and",
                            " as",
                            " Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " recent",
                            " behavior",
                            " has",
                            " shown",
                            ".",
                            " Not",
                            " only",
                            " has",
                            " Kim",
                            " Jong",
                            "-",
                            "un",
                            " grown",
                            " up",
                            " in",
                            " a",
                            " coc",
                            "oon",
                            " of",
                            " indul",
                            "gence",
                            " and",
                            " privilege",
                            ",",
                            " he",
                            " has",
                            " inherited",
                            " advanced"
                        ],
                        "dataIndex": null,
                        "index": "15050",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.167,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.167,
                            7.314,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:48.361Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 59.167,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfji3cmpcs10exyu8nva2a",
                        "tokens": [
                            "Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " statement",
                            " calling",
                            " President",
                            " Trump",
                            " \u00e2\u0122",
                            "\u013e",
                            "ment",
                            "ally",
                            " der",
                            "anged",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " promising",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "highest",
                            "-",
                            "level",
                            " of",
                            " the",
                            " hard",
                            "line",
                            " counter",
                            "measures",
                            "\u00e2\u0122",
                            "\u013f",
                            " shows",
                            " that",
                            " he",
                            " has",
                            " taken",
                            " ownership",
                            " of",
                            " this",
                            " showdown",
                            " and",
                            " that",
                            " he",
                            " alone",
                            "\u2014",
                            "as",
                            " the",
                            " leader",
                            " of",
                            " North",
                            " Korea",
                            "\u2014",
                            "will",
                            " defend",
                            " the",
                            " country",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " survival",
                            ",",
                            " as",
                            " well",
                            " as",
                            " its",
                            " dignity",
                            ".",
                            " Kim",
                            " also",
                            " has",
                            " a",
                            " bias",
                            " for",
                            " action",
                            " and",
                            " he",
                            " wants",
                            " to",
                            " win",
                            ",",
                            " as",
                            " the",
                            " Kim",
                            " family",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " former",
                            " sushi",
                            " chef",
                            " recalled",
                            ",",
                            " and",
                            " as",
                            " Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " recent",
                            " behavior",
                            " has",
                            " shown",
                            ".",
                            " Not",
                            " only",
                            " has",
                            " Kim",
                            " Jong",
                            "-",
                            "un",
                            " grown",
                            " up",
                            " in",
                            " a",
                            " coc",
                            "oon",
                            " of",
                            " indul",
                            "gence",
                            " and",
                            " privilege",
                            ",",
                            " he",
                            " has",
                            " inherited",
                            " advanced"
                        ],
                        "dataIndex": null,
                        "index": "15050",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.167,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.167,
                            7.314,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:48.361Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 59.167,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfji3empda10exp8io8tig",
                        "tokens": [
                            "Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " statement",
                            " calling",
                            " President",
                            " Trump",
                            " \u00e2\u0122",
                            "\u013e",
                            "ment",
                            "ally",
                            " der",
                            "anged",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " promising",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "highest",
                            "-",
                            "level",
                            " of",
                            " the",
                            " hard",
                            "line",
                            " counter",
                            "measures",
                            "\u00e2\u0122",
                            "\u013f",
                            " shows",
                            " that",
                            " he",
                            " has",
                            " taken",
                            " ownership",
                            " of",
                            " this",
                            " showdown",
                            " and",
                            " that",
                            " he",
                            " alone",
                            "\u2014",
                            "as",
                            " the",
                            " leader",
                            " of",
                            " North",
                            " Korea",
                            "\u2014",
                            "will",
                            " defend",
                            " the",
                            " country",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " survival",
                            ",",
                            " as",
                            " well",
                            " as",
                            " its",
                            " dignity",
                            ".",
                            " Kim",
                            " also",
                            " has",
                            " a",
                            " bias",
                            " for",
                            " action",
                            " and",
                            " he",
                            " wants",
                            " to",
                            " win",
                            ",",
                            " as",
                            " the",
                            " Kim",
                            " family",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " former",
                            " sushi",
                            " chef",
                            " recalled",
                            ",",
                            " and",
                            " as",
                            " Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " recent",
                            " behavior",
                            " has",
                            " shown",
                            ".",
                            " Not",
                            " only",
                            " has",
                            " Kim",
                            " Jong",
                            "-",
                            "un",
                            " grown",
                            " up",
                            " in",
                            " a",
                            " coc",
                            "oon",
                            " of",
                            " indul",
                            "gence",
                            " and",
                            " privilege",
                            ",",
                            " he",
                            " has",
                            " inherited",
                            " advanced"
                        ],
                        "dataIndex": null,
                        "index": "15050",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.167,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.167,
                            7.314,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:48.361Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 47.333,
                        "binMax": 59.167,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "59250",
            "description": "terms related to cocaine and its derivatives",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6252770237542111,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "59250",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:47:08.017Z",
                "maxActApprox": 64.474,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    59250,
                    15050,
                    84380,
                    31918,
                    60483,
                    89795,
                    46659,
                    51089,
                    58452,
                    96213,
                    13452,
                    34458,
                    5450,
                    66556,
                    37235,
                    20001,
                    56111,
                    86735,
                    64848,
                    47627,
                    13573,
                    46553,
                    68040,
                    5639,
                    38252
                ],
                "topkCosSimValues": [
                    1,
                    0.567,
                    0.5229,
                    0.5199,
                    0.509,
                    0.5043,
                    0.4949,
                    0.4874,
                    0.4476,
                    0.4393,
                    0.4369,
                    0.4324,
                    0.4318,
                    0.4268,
                    0.4234,
                    0.4189,
                    0.4133,
                    0.408,
                    0.4079,
                    0.4076,
                    0.3975,
                    0.3959,
                    0.3933,
                    0.3928,
                    0.3873
                ],
                "neuron_alignment_indices": [
                    288,
                    67,
                    746
                ],
                "neuron_alignment_values": [
                    0.149,
                    0.12,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    67,
                    746,
                    637
                ],
                "correlated_neurons_pearson": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_features_indices": [
                    59375,
                    59250,
                    59316
                ],
                "correlated_features_pearson": [
                    0.014,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.014,
                    0,
                    0
                ],
                "neg_str": [
                    "\u00e8\u00a3\u0127",
                    "journal",
                    "Reviewer",
                    "\u00e9\u0139\u013a",
                    " vest",
                    " publication",
                    " Bundes",
                    " modesty",
                    " detector",
                    "\u012a\u0134"
                ],
                "neg_values": [
                    -0.799,
                    -0.657,
                    -0.657,
                    -0.657,
                    -0.649,
                    -0.648,
                    -0.638,
                    -0.633,
                    -0.617,
                    -0.615
                ],
                "pos_str": [
                    "aine",
                    "aleb",
                    "urrencies",
                    "anut",
                    "ursor",
                    "keyes",
                    "urrency",
                    "keye",
                    "ilage",
                    "leans"
                ],
                "pos_values": [
                    1.191,
                    1.009,
                    0.995,
                    0.989,
                    0.978,
                    0.973,
                    0.97,
                    0.959,
                    0.927,
                    0.91
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    54,
                    16,
                    6,
                    3,
                    3,
                    4,
                    4,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    1,
                    0,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.647,
                    1.936,
                    3.226,
                    4.515,
                    5.805,
                    7.094,
                    8.383,
                    9.673,
                    10.962,
                    12.252,
                    13.541,
                    14.831,
                    16.12,
                    17.41,
                    18.699,
                    19.988,
                    21.278,
                    22.567,
                    23.857,
                    25.146,
                    26.436,
                    27.725,
                    29.015,
                    30.304,
                    31.593,
                    32.883,
                    34.172,
                    35.462,
                    36.751,
                    38.041,
                    39.33,
                    40.62,
                    41.909,
                    43.198,
                    44.488,
                    45.777,
                    47.067,
                    48.356,
                    49.646,
                    50.935,
                    52.225,
                    53.514,
                    54.803,
                    56.093,
                    57.382,
                    58.672,
                    59.961,
                    61.251,
                    62.54,
                    63.83
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    5,
                    8,
                    15,
                    25,
                    59,
                    100,
                    222,
                    375,
                    576,
                    1060,
                    1573,
                    2291,
                    2971,
                    3809,
                    4307,
                    4762,
                    4776,
                    4349,
                    3909,
                    3283,
                    2705,
                    2093,
                    1631,
                    1253,
                    934,
                    760,
                    586,
                    442,
                    346,
                    277,
                    229,
                    139,
                    119,
                    73,
                    57,
                    54,
                    32,
                    17,
                    18,
                    7,
                    1,
                    5,
                    2,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.779,
                    -0.739,
                    -0.7,
                    -0.66,
                    -0.62,
                    -0.58,
                    -0.54,
                    -0.501,
                    -0.461,
                    -0.421,
                    -0.381,
                    -0.341,
                    -0.302,
                    -0.262,
                    -0.222,
                    -0.182,
                    -0.142,
                    -0.103,
                    -0.063,
                    -0.023,
                    0.017,
                    0.057,
                    0.096,
                    0.136,
                    0.176,
                    0.216,
                    0.256,
                    0.295,
                    0.335,
                    0.375,
                    0.415,
                    0.455,
                    0.494,
                    0.534,
                    0.574,
                    0.614,
                    0.654,
                    0.693,
                    0.733,
                    0.773,
                    0.813,
                    0.852,
                    0.892,
                    0.932,
                    0.972,
                    1.012,
                    1.051,
                    1.091,
                    1.131,
                    1.171
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to cocaine and addictive substances",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "terms related to cocaine and its derivatives",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghp3ihk70o10exv2s33yiy",
                        "tokens": [
                            " separate",
                            " canvas",
                            " contexts",
                            " for",
                            " each",
                            " view",
                            " that",
                            " then",
                            " get",
                            " compos",
                            "ited",
                            " back",
                            " together",
                            " at",
                            " the",
                            " final",
                            " step",
                            " in",
                            " rendering",
                            " using",
                            " draw",
                            "Image",
                            ".",
                            " This",
                            " style",
                            " is",
                            " akin",
                            " to",
                            " the",
                            " way",
                            " Core",
                            " Animation",
                            " works",
                            " in",
                            " Apple",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Coc",
                            "oa",
                            " framework",
                            ",",
                            " and",
                            " in",
                            " fact",
                            ",",
                            " GPU",
                            " accelerated",
                            " 3",
                            "D",
                            " transitions",
                            " are",
                            " possible",
                            " in",
                            " Blossom",
                            " as",
                            " well",
                            ".",
                            "\n",
                            "\n",
                            "Obviously",
                            ",",
                            " when",
                            " not",
                            " rendering",
                            " to",
                            " HTML",
                            " and",
                            " CSS",
                            ",",
                            " you",
                            " have",
                            " to",
                            " manage",
                            " everything",
                            " yourself",
                            ",",
                            " from",
                            " hit",
                            " testing",
                            " of",
                            " views",
                            ",",
                            " to",
                            " all",
                            " the",
                            " nuances",
                            " of",
                            " text",
                            " handling",
                            " including",
                            " all",
                            " the",
                            " platform",
                            " native",
                            " keyboard",
                            " shortcuts",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " the",
                            " first",
                            " time",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " an",
                            " attempt",
                            " to",
                            " create",
                            " an",
                            " entirely",
                            " canvas",
                            " based",
                            " view",
                            " pipeline",
                            ",",
                            " but",
                            " it",
                            " certainly"
                        ],
                        "dataIndex": null,
                        "index": "59250",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 64.474,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            64.474,
                            6.467,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:47:08.667Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 64.474,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghp3ijk71510ex8f724g7w",
                        "tokens": [
                            " separate",
                            " canvas",
                            " contexts",
                            " for",
                            " each",
                            " view",
                            " that",
                            " then",
                            " get",
                            " compos",
                            "ited",
                            " back",
                            " together",
                            " at",
                            " the",
                            " final",
                            " step",
                            " in",
                            " rendering",
                            " using",
                            " draw",
                            "Image",
                            ".",
                            " This",
                            " style",
                            " is",
                            " akin",
                            " to",
                            " the",
                            " way",
                            " Core",
                            " Animation",
                            " works",
                            " in",
                            " Apple",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Coc",
                            "oa",
                            " framework",
                            ",",
                            " and",
                            " in",
                            " fact",
                            ",",
                            " GPU",
                            " accelerated",
                            " 3",
                            "D",
                            " transitions",
                            " are",
                            " possible",
                            " in",
                            " Blossom",
                            " as",
                            " well",
                            ".",
                            "\n",
                            "\n",
                            "Obviously",
                            ",",
                            " when",
                            " not",
                            " rendering",
                            " to",
                            " HTML",
                            " and",
                            " CSS",
                            ",",
                            " you",
                            " have",
                            " to",
                            " manage",
                            " everything",
                            " yourself",
                            ",",
                            " from",
                            " hit",
                            " testing",
                            " of",
                            " views",
                            ",",
                            " to",
                            " all",
                            " the",
                            " nuances",
                            " of",
                            " text",
                            " handling",
                            " including",
                            " all",
                            " the",
                            " platform",
                            " native",
                            " keyboard",
                            " shortcuts",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " the",
                            " first",
                            " time",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " an",
                            " attempt",
                            " to",
                            " create",
                            " an",
                            " entirely",
                            " canvas",
                            " based",
                            " view",
                            " pipeline",
                            ",",
                            " but",
                            " it",
                            " certainly"
                        ],
                        "dataIndex": null,
                        "index": "59250",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 64.474,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            64.474,
                            6.467,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:47:08.667Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 64.474,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghp3ijk71910exzf65qpsr",
                        "tokens": [
                            " separate",
                            " canvas",
                            " contexts",
                            " for",
                            " each",
                            " view",
                            " that",
                            " then",
                            " get",
                            " compos",
                            "ited",
                            " back",
                            " together",
                            " at",
                            " the",
                            " final",
                            " step",
                            " in",
                            " rendering",
                            " using",
                            " draw",
                            "Image",
                            ".",
                            " This",
                            " style",
                            " is",
                            " akin",
                            " to",
                            " the",
                            " way",
                            " Core",
                            " Animation",
                            " works",
                            " in",
                            " Apple",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Coc",
                            "oa",
                            " framework",
                            ",",
                            " and",
                            " in",
                            " fact",
                            ",",
                            " GPU",
                            " accelerated",
                            " 3",
                            "D",
                            " transitions",
                            " are",
                            " possible",
                            " in",
                            " Blossom",
                            " as",
                            " well",
                            ".",
                            "\n",
                            "\n",
                            "Obviously",
                            ",",
                            " when",
                            " not",
                            " rendering",
                            " to",
                            " HTML",
                            " and",
                            " CSS",
                            ",",
                            " you",
                            " have",
                            " to",
                            " manage",
                            " everything",
                            " yourself",
                            ",",
                            " from",
                            " hit",
                            " testing",
                            " of",
                            " views",
                            ",",
                            " to",
                            " all",
                            " the",
                            " nuances",
                            " of",
                            " text",
                            " handling",
                            " including",
                            " all",
                            " the",
                            " platform",
                            " native",
                            " keyboard",
                            " shortcuts",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " the",
                            " first",
                            " time",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " an",
                            " attempt",
                            " to",
                            " create",
                            " an",
                            " entirely",
                            " canvas",
                            " based",
                            " view",
                            " pipeline",
                            ",",
                            " but",
                            " it",
                            " certainly"
                        ],
                        "dataIndex": null,
                        "index": "59250",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 64.474,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            64.474,
                            6.467,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:47:08.667Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 51.579,
                        "binMax": 64.474,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "4478",
            "description": "words related to cocaine and other drugs",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6193098610433897,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "4478",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:05:55.715Z",
                "maxActApprox": 68.054,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    4478,
                    48085,
                    34627,
                    17266,
                    30639,
                    10368,
                    3869,
                    18722,
                    5080,
                    27650,
                    45150,
                    33396,
                    30496,
                    40950,
                    28078,
                    17880,
                    12080,
                    14729,
                    4495,
                    46327,
                    2029,
                    33972,
                    24319,
                    1026,
                    27687
                ],
                "topkCosSimValues": [
                    1,
                    0.5211,
                    0.4989,
                    0.4739,
                    0.4606,
                    0.4555,
                    0.4486,
                    0.433,
                    0.4296,
                    0.4278,
                    0.4227,
                    0.42,
                    0.4178,
                    0.4175,
                    0.4136,
                    0.4114,
                    0.4058,
                    0.3993,
                    0.3977,
                    0.3973,
                    0.3943,
                    0.3927,
                    0.3876,
                    0.3849,
                    0.381
                ],
                "neuron_alignment_indices": [
                    288,
                    746,
                    67
                ],
                "neuron_alignment_values": [
                    0.135,
                    0.116,
                    0.113
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    67,
                    746,
                    396
                ],
                "correlated_neurons_pearson": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_features_indices": [
                    4483,
                    4383,
                    4412
                ],
                "correlated_features_pearson": [
                    0.003,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0,
                    0
                ],
                "neg_str": [
                    "\u00e9\u0139\u013a",
                    " Barcl",
                    "\u00e8\u00a3\u0127",
                    " Fraz",
                    "\u012a\u0134",
                    "naires",
                    "\u00e3\u0125\u0126",
                    " GOODMAN",
                    "CLASS",
                    "Reviewer"
                ],
                "neg_values": [
                    -0.687,
                    -0.669,
                    -0.662,
                    -0.656,
                    -0.635,
                    -0.63,
                    -0.624,
                    -0.622,
                    -0.618,
                    -0.609
                ],
                "pos_str": [
                    "aine",
                    "leans",
                    "aleb",
                    "ilage",
                    "ulture",
                    "urrency",
                    "reated",
                    "ombs",
                    "urrencies",
                    "rary"
                ],
                "pos_values": [
                    1.07,
                    1.032,
                    0.995,
                    0.993,
                    0.983,
                    0.968,
                    0.956,
                    0.928,
                    0.926,
                    0.918
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    31,
                    17,
                    13,
                    7,
                    9,
                    4,
                    2,
                    1,
                    0,
                    2,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.7,
                    2.061,
                    3.422,
                    4.782,
                    6.143,
                    7.504,
                    8.864,
                    10.225,
                    11.586,
                    12.946,
                    14.307,
                    15.668,
                    17.028,
                    18.389,
                    19.75,
                    21.11,
                    22.471,
                    23.832,
                    25.192,
                    26.553,
                    27.914,
                    29.274,
                    30.635,
                    31.996,
                    33.356,
                    34.717,
                    36.078,
                    37.438,
                    38.799,
                    40.16,
                    41.52,
                    42.881,
                    44.242,
                    45.602,
                    46.963,
                    48.324,
                    49.684,
                    51.045,
                    52.406,
                    53.766,
                    55.127,
                    56.488,
                    57.848,
                    59.209,
                    60.57,
                    61.93,
                    63.291,
                    64.652,
                    66.012,
                    67.373
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    5,
                    4,
                    14,
                    20,
                    55,
                    99,
                    169,
                    269,
                    430,
                    695,
                    1104,
                    1554,
                    2075,
                    2682,
                    3277,
                    3774,
                    4260,
                    4365,
                    4135,
                    3902,
                    3345,
                    2815,
                    2342,
                    1933,
                    1517,
                    1171,
                    876,
                    721,
                    591,
                    438,
                    361,
                    289,
                    217,
                    199,
                    160,
                    115,
                    79,
                    49,
                    37,
                    29,
                    23,
                    29,
                    15,
                    2,
                    5,
                    1,
                    4,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.669,
                    -0.634,
                    -0.599,
                    -0.564,
                    -0.529,
                    -0.494,
                    -0.459,
                    -0.423,
                    -0.388,
                    -0.353,
                    -0.318,
                    -0.283,
                    -0.248,
                    -0.213,
                    -0.177,
                    -0.142,
                    -0.107,
                    -0.072,
                    -0.037,
                    -0.002,
                    0.033,
                    0.069,
                    0.104,
                    0.139,
                    0.174,
                    0.209,
                    0.244,
                    0.279,
                    0.315,
                    0.35,
                    0.385,
                    0.42,
                    0.455,
                    0.49,
                    0.525,
                    0.561,
                    0.596,
                    0.631,
                    0.666,
                    0.701,
                    0.736,
                    0.771,
                    0.807,
                    0.842,
                    0.877,
                    0.912,
                    0.947,
                    0.982,
                    1.017,
                    1.053
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "words related to cocaine and other drugs",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4e4m4frqzi666r9tcxo6k",
                        "tokens": [
                            " of",
                            " 10",
                            "%",
                            " on",
                            " l",
                            "imes",
                            ",",
                            " bananas",
                            ",",
                            " mango",
                            "es",
                            ",",
                            " coc",
                            "on",
                            "uts",
                            ",",
                            " and",
                            " essentially",
                            " every",
                            " other",
                            " fruit",
                            " that",
                            " was",
                            " being",
                            " imported",
                            " to",
                            " the",
                            " US",
                            " at",
                            " the",
                            " time",
                            ".",
                            " Fruit",
                            " was",
                            " a",
                            " major",
                            " import",
                            " item",
                            ",",
                            " and",
                            " as",
                            " such",
                            ",",
                            " its",
                            " tariffs",
                            " constituted",
                            " a",
                            " considerable",
                            " portion",
                            " of",
                            " the",
                            " federal",
                            " budget",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " the",
                            " 18",
                            "72",
                            " revision",
                            ",",
                            " a",
                            " comma",
                            " was",
                            ",",
                            " for",
                            " some",
                            " inexplicable",
                            " reason",
                            ",",
                            " inserted",
                            " between",
                            " the",
                            " words",
                            " \u00e2\u0122",
                            "\u013e",
                            "fruit",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " \u00e2\u0122",
                            "\u013e",
                            "pl",
                            "ants",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " giving",
                            " fruit",
                            " imp",
                            "orters",
                            " the",
                            " means",
                            " of",
                            " evasion",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " been",
                            " looking",
                            " for",
                            ":",
                            "\n",
                            "\n",
                            "The",
                            " comma",
                            ",",
                            " intended",
                            " to",
                            " read",
                            " \u00e2\u0122",
                            "\u013e",
                            "fruit",
                            "-",
                            "pl",
                            "ants",
                            "\u00e2\u0122",
                            "\u013f",
                            " (",
                            "with",
                            " a",
                            " hyp",
                            "hen",
                            ",",
                            " not"
                        ],
                        "dataIndex": null,
                        "index": "4478",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 68.054,
                        "maxValueTokenIndex": 12,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            68.054,
                            6.279,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:06:03.910Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 68.053,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4e4m6frrki666ki7dzyqw",
                        "tokens": [
                            " of",
                            " 10",
                            "%",
                            " on",
                            " l",
                            "imes",
                            ",",
                            " bananas",
                            ",",
                            " mango",
                            "es",
                            ",",
                            " coc",
                            "on",
                            "uts",
                            ",",
                            " and",
                            " essentially",
                            " every",
                            " other",
                            " fruit",
                            " that",
                            " was",
                            " being",
                            " imported",
                            " to",
                            " the",
                            " US",
                            " at",
                            " the",
                            " time",
                            ".",
                            " Fruit",
                            " was",
                            " a",
                            " major",
                            " import",
                            " item",
                            ",",
                            " and",
                            " as",
                            " such",
                            ",",
                            " its",
                            " tariffs",
                            " constituted",
                            " a",
                            " considerable",
                            " portion",
                            " of",
                            " the",
                            " federal",
                            " budget",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " the",
                            " 18",
                            "72",
                            " revision",
                            ",",
                            " a",
                            " comma",
                            " was",
                            ",",
                            " for",
                            " some",
                            " inexplicable",
                            " reason",
                            ",",
                            " inserted",
                            " between",
                            " the",
                            " words",
                            " \u00e2\u0122",
                            "\u013e",
                            "fruit",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " \u00e2\u0122",
                            "\u013e",
                            "pl",
                            "ants",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " giving",
                            " fruit",
                            " imp",
                            "orters",
                            " the",
                            " means",
                            " of",
                            " evasion",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " been",
                            " looking",
                            " for",
                            ":",
                            "\n",
                            "\n",
                            "The",
                            " comma",
                            ",",
                            " intended",
                            " to",
                            " read",
                            " \u00e2\u0122",
                            "\u013e",
                            "fruit",
                            "-",
                            "pl",
                            "ants",
                            "\u00e2\u0122",
                            "\u013f",
                            " (",
                            "with",
                            " a",
                            " hyp",
                            "hen",
                            ",",
                            " not"
                        ],
                        "dataIndex": null,
                        "index": "4478",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 68.054,
                        "maxValueTokenIndex": 12,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            68.054,
                            6.279,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:06:03.910Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 54.443,
                        "binMax": 68.053,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4e4m4frr0i66662my2swp",
                        "tokens": [
                            " with",
                            " you",
                            ",",
                            " it",
                            "'s",
                            " fun",
                            " to",
                            " go",
                            " into",
                            " bar",
                            " bathrooms",
                            " with",
                            " another",
                            " person",
                            ",",
                            " and",
                            " wasting",
                            " money",
                            " feels",
                            " good",
                            ".",
                            " Coc",
                            "aine",
                            " activates",
                            " the",
                            " same",
                            " pleasure",
                            " centers",
                            " in",
                            " your",
                            " brain",
                            " as",
                            " breaking",
                            " champagne",
                            " glasses",
                            " or",
                            " taking",
                            " an",
                            " Uber",
                            ".",
                            " Te",
                            "ens",
                            " who",
                            " want",
                            " to",
                            " use",
                            " drugs",
                            " should",
                            " stick",
                            " with",
                            " pot",
                            " and",
                            " low",
                            "-",
                            "grade",
                            " psychedel",
                            "ics",
                            ",",
                            " drugs",
                            " that",
                            " coincide",
                            " with",
                            " their",
                            " unique",
                            " ability",
                            " to",
                            " identify",
                            " hypoc",
                            "rites",
                            " and",
                            " see",
                            " the",
                            " world",
                            " as",
                            " it",
                            " really",
                            " is",
                            ".",
                            " If",
                            " teens",
                            " want",
                            " to",
                            " feel",
                            " wired",
                            ",",
                            " they",
                            " should",
                            " use",
                            " energy",
                            " drinks",
                            " or",
                            " Ad",
                            "der",
                            "all",
                            ",",
                            " two",
                            " fairly",
                            " affordable",
                            " substances",
                            " that",
                            " they",
                            " already",
                            " have",
                            " easy",
                            " access",
                            " to",
                            ".",
                            " There",
                            "'s",
                            " a",
                            " time",
                            " and",
                            " a",
                            " place",
                            " for",
                            " cocaine",
                            ",",
                            " and",
                            " that",
                            " time",
                            " is",
                            " almost",
                            " never",
                            "\u2014",
                            "except",
                            " maybe",
                            " just"
                        ],
                        "dataIndex": null,
                        "index": "4478",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 55.244,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            55.244,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:06:03.910Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 68.053,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "7195",
            "description": "mentions of drugs, particularly cocaine",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6182110493842082,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "7195",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:53:54.469Z",
                "maxActApprox": 42.266,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    7195,
                    11791,
                    3975,
                    14575,
                    24546,
                    2976,
                    13735,
                    15094,
                    5746,
                    4905,
                    5189,
                    4562,
                    17717,
                    8878,
                    19655,
                    12331,
                    13404,
                    973,
                    13930,
                    18220,
                    17323,
                    11867,
                    23084,
                    6393,
                    17399
                ],
                "topkCosSimValues": [
                    1,
                    0.4575,
                    0.4478,
                    0.402,
                    0.3996,
                    0.3987,
                    0.3714,
                    0.3645,
                    0.3639,
                    0.3529,
                    0.3514,
                    0.3446,
                    0.3415,
                    0.3388,
                    0.3376,
                    0.3333,
                    0.3311,
                    0.3233,
                    0.321,
                    0.32,
                    0.3191,
                    0.3177,
                    0.3146,
                    0.3141,
                    0.3124
                ],
                "neuron_alignment_indices": [
                    746,
                    67,
                    99
                ],
                "neuron_alignment_values": [
                    0.119,
                    0.112,
                    0.104
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    67,
                    326,
                    343
                ],
                "correlated_neurons_pearson": [
                    0.017,
                    0.015,
                    0.015
                ],
                "correlated_neurons_l1": [
                    0.018,
                    0.013,
                    0.014
                ],
                "correlated_features_indices": [
                    7178,
                    7224,
                    7183
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.002,
                    0.002
                ],
                "correlated_features_l1": [
                    0.006,
                    0.003,
                    0.002
                ],
                "neg_str": [
                    "holes",
                    " \u00e3\u0124\u00b5\u00e3\u0125\u00bc\u00e3\u0125\u0128\u00e3\u0124\u00a3\u00e3\u0125\u00af\u00e3\u0125\u00b3",
                    "\u012a\u0134",
                    " Supplemental",
                    " Duchess",
                    "\u00e3\u0122\u0132",
                    "hole",
                    " Shutterstock",
                    " Burgess",
                    " roar"
                ],
                "neg_values": [
                    -0.691,
                    -0.688,
                    -0.685,
                    -0.64,
                    -0.597,
                    -0.594,
                    -0.587,
                    -0.581,
                    -0.572,
                    -0.559
                ],
                "pos_str": [
                    "keyes",
                    "keye",
                    "kefeller",
                    "kered",
                    "hester",
                    "ombs",
                    "ody",
                    "aine",
                    "het",
                    "ursor"
                ],
                "pos_values": [
                    1.091,
                    1.085,
                    1.078,
                    1.037,
                    1.015,
                    0.968,
                    0.963,
                    0.956,
                    0.95,
                    0.895
                ],
                "frac_nonzero": 0.00022,
                "freq_hist_data_bar_heights": [
                    150,
                    123,
                    88,
                    74,
                    44,
                    48,
                    32,
                    22,
                    15,
                    18,
                    16,
                    13,
                    10,
                    7,
                    4,
                    5,
                    3,
                    3,
                    3,
                    0,
                    0,
                    1,
                    0,
                    0,
                    2,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.424,
                    1.269,
                    2.115,
                    2.96,
                    3.805,
                    4.651,
                    5.496,
                    6.341,
                    7.186,
                    8.032,
                    8.877,
                    9.722,
                    10.568,
                    11.413,
                    12.258,
                    13.103,
                    13.949,
                    14.794,
                    15.639,
                    16.485,
                    17.33,
                    18.175,
                    19.02,
                    19.866,
                    20.711,
                    21.556,
                    22.402,
                    23.247,
                    24.092,
                    24.937,
                    25.783,
                    26.628,
                    27.473,
                    28.319,
                    29.164,
                    30.009,
                    30.855,
                    31.7,
                    32.545,
                    33.39,
                    34.236,
                    35.081,
                    35.926,
                    36.772,
                    37.617,
                    38.462,
                    39.307,
                    40.153,
                    40.998,
                    41.843
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    1,
                    3,
                    6,
                    17,
                    52,
                    74,
                    133,
                    236,
                    384,
                    630,
                    946,
                    1515,
                    1961,
                    2737,
                    3316,
                    3917,
                    4350,
                    4565,
                    4324,
                    4225,
                    3610,
                    2957,
                    2457,
                    1964,
                    1479,
                    1080,
                    831,
                    624,
                    468,
                    353,
                    254,
                    214,
                    145,
                    124,
                    77,
                    69,
                    43,
                    32,
                    26,
                    14,
                    12,
                    9,
                    10,
                    1,
                    0,
                    4,
                    1,
                    1,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.673,
                    -0.638,
                    -0.602,
                    -0.566,
                    -0.531,
                    -0.495,
                    -0.46,
                    -0.424,
                    -0.388,
                    -0.353,
                    -0.317,
                    -0.281,
                    -0.246,
                    -0.21,
                    -0.174,
                    -0.139,
                    -0.103,
                    -0.068,
                    -0.032,
                    0.004,
                    0.039,
                    0.075,
                    0.111,
                    0.146,
                    0.182,
                    0.218,
                    0.253,
                    0.289,
                    0.325,
                    0.36,
                    0.396,
                    0.431,
                    0.467,
                    0.503,
                    0.538,
                    0.574,
                    0.61,
                    0.645,
                    0.681,
                    0.717,
                    0.752,
                    0.788,
                    0.823,
                    0.859,
                    0.895,
                    0.93,
                    0.966,
                    1.002,
                    1.037,
                    1.073
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "mentions of drugs, particularly cocaine",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmc1h06u2ji666f25rqgxi",
                        "tokens": [
                            " with",
                            " you",
                            ",",
                            " it",
                            "'s",
                            " fun",
                            " to",
                            " go",
                            " into",
                            " bar",
                            " bathrooms",
                            " with",
                            " another",
                            " person",
                            ",",
                            " and",
                            " wasting",
                            " money",
                            " feels",
                            " good",
                            ".",
                            " Coc",
                            "aine",
                            " activates",
                            " the",
                            " same",
                            " pleasure",
                            " centers",
                            " in",
                            " your",
                            " brain",
                            " as",
                            " breaking",
                            " champagne",
                            " glasses",
                            " or",
                            " taking",
                            " an",
                            " Uber",
                            ".",
                            " Te",
                            "ens",
                            " who",
                            " want",
                            " to",
                            " use",
                            " drugs",
                            " should",
                            " stick",
                            " with",
                            " pot",
                            " and",
                            " low",
                            "-",
                            "grade",
                            " psychedel",
                            "ics",
                            ",",
                            " drugs",
                            " that",
                            " coincide",
                            " with",
                            " their",
                            " unique",
                            " ability",
                            " to",
                            " identify",
                            " hypoc",
                            "rites",
                            " and",
                            " see",
                            " the",
                            " world",
                            " as",
                            " it",
                            " really",
                            " is",
                            ".",
                            " If",
                            " teens",
                            " want",
                            " to",
                            " feel",
                            " wired",
                            ",",
                            " they",
                            " should",
                            " use",
                            " energy",
                            " drinks",
                            " or",
                            " Ad",
                            "der",
                            "all",
                            ",",
                            " two",
                            " fairly",
                            " affordable",
                            " substances",
                            " that",
                            " they",
                            " already",
                            " have",
                            " easy",
                            " access",
                            " to",
                            ".",
                            " There",
                            "'s",
                            " a",
                            " time",
                            " and",
                            " a",
                            " place",
                            " for",
                            " cocaine",
                            ",",
                            " and",
                            " that",
                            " time",
                            " is",
                            " almost",
                            " never",
                            "\u2014",
                            "except",
                            " maybe",
                            " just"
                        ],
                        "dataIndex": null,
                        "index": "7195",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.266,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.266,
                            0.327,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.434,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:53:56.694Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 42.266,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmc1h26u33i666wo34gk3w",
                        "tokens": [
                            " with",
                            " you",
                            ",",
                            " it",
                            "'s",
                            " fun",
                            " to",
                            " go",
                            " into",
                            " bar",
                            " bathrooms",
                            " with",
                            " another",
                            " person",
                            ",",
                            " and",
                            " wasting",
                            " money",
                            " feels",
                            " good",
                            ".",
                            " Coc",
                            "aine",
                            " activates",
                            " the",
                            " same",
                            " pleasure",
                            " centers",
                            " in",
                            " your",
                            " brain",
                            " as",
                            " breaking",
                            " champagne",
                            " glasses",
                            " or",
                            " taking",
                            " an",
                            " Uber",
                            ".",
                            " Te",
                            "ens",
                            " who",
                            " want",
                            " to",
                            " use",
                            " drugs",
                            " should",
                            " stick",
                            " with",
                            " pot",
                            " and",
                            " low",
                            "-",
                            "grade",
                            " psychedel",
                            "ics",
                            ",",
                            " drugs",
                            " that",
                            " coincide",
                            " with",
                            " their",
                            " unique",
                            " ability",
                            " to",
                            " identify",
                            " hypoc",
                            "rites",
                            " and",
                            " see",
                            " the",
                            " world",
                            " as",
                            " it",
                            " really",
                            " is",
                            ".",
                            " If",
                            " teens",
                            " want",
                            " to",
                            " feel",
                            " wired",
                            ",",
                            " they",
                            " should",
                            " use",
                            " energy",
                            " drinks",
                            " or",
                            " Ad",
                            "der",
                            "all",
                            ",",
                            " two",
                            " fairly",
                            " affordable",
                            " substances",
                            " that",
                            " they",
                            " already",
                            " have",
                            " easy",
                            " access",
                            " to",
                            ".",
                            " There",
                            "'s",
                            " a",
                            " time",
                            " and",
                            " a",
                            " place",
                            " for",
                            " cocaine",
                            ",",
                            " and",
                            " that",
                            " time",
                            " is",
                            " almost",
                            " never",
                            "\u2014",
                            "except",
                            " maybe",
                            " just"
                        ],
                        "dataIndex": null,
                        "index": "7195",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.266,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.266,
                            0.327,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.434,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:53:56.694Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 33.813,
                        "binMax": 42.266,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmc1h06u2ki666yc8ef96p",
                        "tokens": [
                            "amine",
                            ",",
                            " proc",
                            "aine",
                            ",",
                            " trim",
                            "eth",
                            "op",
                            "rim",
                            ",",
                            " chlor",
                            "oqu",
                            "ine",
                            ",",
                            " and",
                            " qu",
                            "in",
                            "ine",
                            ".",
                            " In",
                            " short",
                            ",",
                            " a",
                            " drug",
                            " cocktail",
                            " far",
                            " more",
                            " potent",
                            " than",
                            " the",
                            " original",
                            " name",
                            " brand",
                            " version",
                            ".",
                            "\n",
                            "\n",
                            "Indeed",
                            ",",
                            " reports",
                            " suggest",
                            " that",
                            " Syrian",
                            " insurgent",
                            " groups",
                            " ingest",
                            " a",
                            " far",
                            " ranging",
                            " and",
                            " prod",
                            "igious",
                            " amount",
                            " of",
                            " potent",
                            " drugs",
                            " including",
                            " \u00e2\u0122",
                            "\u013e",
                            "Balt",
                            "con",
                            "\u00e2\u0122",
                            "\u013f",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "Af",
                            "oun",
                            "\u00e2\u0122",
                            "\u013f",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            "Z",
                            "ol",
                            "m",
                            "\u00e2\u0122",
                            "\u013f",
                            ",",
                            " Op",
                            "ium",
                            ",",
                            " Hero",
                            "in",
                            ",",
                            " Coc",
                            "aine",
                            ",",
                            " and",
                            " Hash",
                            "ish",
                            ".",
                            "\n",
                            "\n",
                            "According",
                            " to",
                            " Frank",
                            " Lamb",
                            " in",
                            " Counter",
                            "P",
                            "unch",
                            ":",
                            " \u00e2\u0122",
                            "\u013e",
                            "J",
                            "ihad",
                            "ists",
                            " high",
                            " on",
                            " drugs",
                            " apparently",
                            " feel",
                            " invincible",
                            " and",
                            " hostile",
                            " and",
                            " do",
                            " not",
                            " fear",
                            " death",
                            ".",
                            " Many",
                            " are",
                            " indeed",
                            " ferocious",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "7195",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.513,
                        "maxValueTokenIndex": 85,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            5.555,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.513,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:53:56.694Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 42.266,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "59250",
            "description": "terms related to cocaine and addictive substances",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6025893451326695,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "59250",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:47:08.017Z",
                "maxActApprox": 64.474,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    59250,
                    15050,
                    84380,
                    31918,
                    60483,
                    89795,
                    46659,
                    51089,
                    58452,
                    96213,
                    13452,
                    34458,
                    5450,
                    66556,
                    37235,
                    20001,
                    56111,
                    86735,
                    64848,
                    47627,
                    13573,
                    46553,
                    68040,
                    5639,
                    38252
                ],
                "topkCosSimValues": [
                    1,
                    0.567,
                    0.5229,
                    0.5199,
                    0.509,
                    0.5043,
                    0.4949,
                    0.4874,
                    0.4476,
                    0.4393,
                    0.4369,
                    0.4324,
                    0.4318,
                    0.4268,
                    0.4234,
                    0.4189,
                    0.4133,
                    0.408,
                    0.4079,
                    0.4076,
                    0.3975,
                    0.3959,
                    0.3933,
                    0.3928,
                    0.3873
                ],
                "neuron_alignment_indices": [
                    288,
                    67,
                    746
                ],
                "neuron_alignment_values": [
                    0.149,
                    0.12,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    67,
                    746,
                    637
                ],
                "correlated_neurons_pearson": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_features_indices": [
                    59375,
                    59250,
                    59316
                ],
                "correlated_features_pearson": [
                    0.014,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.014,
                    0,
                    0
                ],
                "neg_str": [
                    "\u00e8\u00a3\u0127",
                    "journal",
                    "Reviewer",
                    "\u00e9\u0139\u013a",
                    " vest",
                    " publication",
                    " Bundes",
                    " modesty",
                    " detector",
                    "\u012a\u0134"
                ],
                "neg_values": [
                    -0.799,
                    -0.657,
                    -0.657,
                    -0.657,
                    -0.649,
                    -0.648,
                    -0.638,
                    -0.633,
                    -0.617,
                    -0.615
                ],
                "pos_str": [
                    "aine",
                    "aleb",
                    "urrencies",
                    "anut",
                    "ursor",
                    "keyes",
                    "urrency",
                    "keye",
                    "ilage",
                    "leans"
                ],
                "pos_values": [
                    1.191,
                    1.009,
                    0.995,
                    0.989,
                    0.978,
                    0.973,
                    0.97,
                    0.959,
                    0.927,
                    0.91
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    54,
                    16,
                    6,
                    3,
                    3,
                    4,
                    4,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    1,
                    0,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.647,
                    1.936,
                    3.226,
                    4.515,
                    5.805,
                    7.094,
                    8.383,
                    9.673,
                    10.962,
                    12.252,
                    13.541,
                    14.831,
                    16.12,
                    17.41,
                    18.699,
                    19.988,
                    21.278,
                    22.567,
                    23.857,
                    25.146,
                    26.436,
                    27.725,
                    29.015,
                    30.304,
                    31.593,
                    32.883,
                    34.172,
                    35.462,
                    36.751,
                    38.041,
                    39.33,
                    40.62,
                    41.909,
                    43.198,
                    44.488,
                    45.777,
                    47.067,
                    48.356,
                    49.646,
                    50.935,
                    52.225,
                    53.514,
                    54.803,
                    56.093,
                    57.382,
                    58.672,
                    59.961,
                    61.251,
                    62.54,
                    63.83
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    5,
                    8,
                    15,
                    25,
                    59,
                    100,
                    222,
                    375,
                    576,
                    1060,
                    1573,
                    2291,
                    2971,
                    3809,
                    4307,
                    4762,
                    4776,
                    4349,
                    3909,
                    3283,
                    2705,
                    2093,
                    1631,
                    1253,
                    934,
                    760,
                    586,
                    442,
                    346,
                    277,
                    229,
                    139,
                    119,
                    73,
                    57,
                    54,
                    32,
                    17,
                    18,
                    7,
                    1,
                    5,
                    2,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.779,
                    -0.739,
                    -0.7,
                    -0.66,
                    -0.62,
                    -0.58,
                    -0.54,
                    -0.501,
                    -0.461,
                    -0.421,
                    -0.381,
                    -0.341,
                    -0.302,
                    -0.262,
                    -0.222,
                    -0.182,
                    -0.142,
                    -0.103,
                    -0.063,
                    -0.023,
                    0.017,
                    0.057,
                    0.096,
                    0.136,
                    0.176,
                    0.216,
                    0.256,
                    0.295,
                    0.335,
                    0.375,
                    0.415,
                    0.455,
                    0.494,
                    0.534,
                    0.574,
                    0.614,
                    0.654,
                    0.693,
                    0.733,
                    0.773,
                    0.813,
                    0.852,
                    0.892,
                    0.932,
                    0.972,
                    1.012,
                    1.051,
                    1.091,
                    1.131,
                    1.171
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to cocaine and addictive substances",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "terms related to cocaine and its derivatives",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghp3ihk70o10exv2s33yiy",
                        "tokens": [
                            " separate",
                            " canvas",
                            " contexts",
                            " for",
                            " each",
                            " view",
                            " that",
                            " then",
                            " get",
                            " compos",
                            "ited",
                            " back",
                            " together",
                            " at",
                            " the",
                            " final",
                            " step",
                            " in",
                            " rendering",
                            " using",
                            " draw",
                            "Image",
                            ".",
                            " This",
                            " style",
                            " is",
                            " akin",
                            " to",
                            " the",
                            " way",
                            " Core",
                            " Animation",
                            " works",
                            " in",
                            " Apple",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Coc",
                            "oa",
                            " framework",
                            ",",
                            " and",
                            " in",
                            " fact",
                            ",",
                            " GPU",
                            " accelerated",
                            " 3",
                            "D",
                            " transitions",
                            " are",
                            " possible",
                            " in",
                            " Blossom",
                            " as",
                            " well",
                            ".",
                            "\n",
                            "\n",
                            "Obviously",
                            ",",
                            " when",
                            " not",
                            " rendering",
                            " to",
                            " HTML",
                            " and",
                            " CSS",
                            ",",
                            " you",
                            " have",
                            " to",
                            " manage",
                            " everything",
                            " yourself",
                            ",",
                            " from",
                            " hit",
                            " testing",
                            " of",
                            " views",
                            ",",
                            " to",
                            " all",
                            " the",
                            " nuances",
                            " of",
                            " text",
                            " handling",
                            " including",
                            " all",
                            " the",
                            " platform",
                            " native",
                            " keyboard",
                            " shortcuts",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " the",
                            " first",
                            " time",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " an",
                            " attempt",
                            " to",
                            " create",
                            " an",
                            " entirely",
                            " canvas",
                            " based",
                            " view",
                            " pipeline",
                            ",",
                            " but",
                            " it",
                            " certainly"
                        ],
                        "dataIndex": null,
                        "index": "59250",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 64.474,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            64.474,
                            6.467,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:47:08.667Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 64.474,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghp3ijk71510ex8f724g7w",
                        "tokens": [
                            " separate",
                            " canvas",
                            " contexts",
                            " for",
                            " each",
                            " view",
                            " that",
                            " then",
                            " get",
                            " compos",
                            "ited",
                            " back",
                            " together",
                            " at",
                            " the",
                            " final",
                            " step",
                            " in",
                            " rendering",
                            " using",
                            " draw",
                            "Image",
                            ".",
                            " This",
                            " style",
                            " is",
                            " akin",
                            " to",
                            " the",
                            " way",
                            " Core",
                            " Animation",
                            " works",
                            " in",
                            " Apple",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Coc",
                            "oa",
                            " framework",
                            ",",
                            " and",
                            " in",
                            " fact",
                            ",",
                            " GPU",
                            " accelerated",
                            " 3",
                            "D",
                            " transitions",
                            " are",
                            " possible",
                            " in",
                            " Blossom",
                            " as",
                            " well",
                            ".",
                            "\n",
                            "\n",
                            "Obviously",
                            ",",
                            " when",
                            " not",
                            " rendering",
                            " to",
                            " HTML",
                            " and",
                            " CSS",
                            ",",
                            " you",
                            " have",
                            " to",
                            " manage",
                            " everything",
                            " yourself",
                            ",",
                            " from",
                            " hit",
                            " testing",
                            " of",
                            " views",
                            ",",
                            " to",
                            " all",
                            " the",
                            " nuances",
                            " of",
                            " text",
                            " handling",
                            " including",
                            " all",
                            " the",
                            " platform",
                            " native",
                            " keyboard",
                            " shortcuts",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " the",
                            " first",
                            " time",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " an",
                            " attempt",
                            " to",
                            " create",
                            " an",
                            " entirely",
                            " canvas",
                            " based",
                            " view",
                            " pipeline",
                            ",",
                            " but",
                            " it",
                            " certainly"
                        ],
                        "dataIndex": null,
                        "index": "59250",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 64.474,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            64.474,
                            6.467,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:47:08.667Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 64.474,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghp3ijk71910exzf65qpsr",
                        "tokens": [
                            " separate",
                            " canvas",
                            " contexts",
                            " for",
                            " each",
                            " view",
                            " that",
                            " then",
                            " get",
                            " compos",
                            "ited",
                            " back",
                            " together",
                            " at",
                            " the",
                            " final",
                            " step",
                            " in",
                            " rendering",
                            " using",
                            " draw",
                            "Image",
                            ".",
                            " This",
                            " style",
                            " is",
                            " akin",
                            " to",
                            " the",
                            " way",
                            " Core",
                            " Animation",
                            " works",
                            " in",
                            " Apple",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Coc",
                            "oa",
                            " framework",
                            ",",
                            " and",
                            " in",
                            " fact",
                            ",",
                            " GPU",
                            " accelerated",
                            " 3",
                            "D",
                            " transitions",
                            " are",
                            " possible",
                            " in",
                            " Blossom",
                            " as",
                            " well",
                            ".",
                            "\n",
                            "\n",
                            "Obviously",
                            ",",
                            " when",
                            " not",
                            " rendering",
                            " to",
                            " HTML",
                            " and",
                            " CSS",
                            ",",
                            " you",
                            " have",
                            " to",
                            " manage",
                            " everything",
                            " yourself",
                            ",",
                            " from",
                            " hit",
                            " testing",
                            " of",
                            " views",
                            ",",
                            " to",
                            " all",
                            " the",
                            " nuances",
                            " of",
                            " text",
                            " handling",
                            " including",
                            " all",
                            " the",
                            " platform",
                            " native",
                            " keyboard",
                            " shortcuts",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " the",
                            " first",
                            " time",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " an",
                            " attempt",
                            " to",
                            " create",
                            " an",
                            " entirely",
                            " canvas",
                            " based",
                            " view",
                            " pipeline",
                            ",",
                            " but",
                            " it",
                            " certainly"
                        ],
                        "dataIndex": null,
                        "index": "59250",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 64.474,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            64.474,
                            6.467,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:47:08.667Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 51.579,
                        "binMax": 64.474,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "10491",
            "description": "mentions of illegal drugs, particularly cocaine",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5846000735580923,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "10491",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:58:04.713Z",
                "maxActApprox": 50.507,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    10491,
                    13178,
                    18400,
                    471,
                    17907,
                    23285,
                    9704,
                    10346,
                    190,
                    18076,
                    5953,
                    14086,
                    8640,
                    11055,
                    833,
                    6461,
                    5714,
                    21688,
                    9433,
                    14380,
                    7906,
                    4709,
                    11906,
                    599,
                    22564
                ],
                "topkCosSimValues": [
                    1,
                    0.6492,
                    0.5822,
                    0.5709,
                    0.5369,
                    0.4759,
                    0.4598,
                    0.4567,
                    0.4544,
                    0.4498,
                    0.4383,
                    0.4306,
                    0.4271,
                    0.4263,
                    0.4202,
                    0.4061,
                    0.4019,
                    0.397,
                    0.3792,
                    0.3782,
                    0.3776,
                    0.3756,
                    0.3742,
                    0.3738,
                    0.3717
                ],
                "neuron_alignment_indices": [
                    481,
                    447,
                    288
                ],
                "neuron_alignment_values": [
                    0.162,
                    0.109,
                    0.107
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    461,
                    35,
                    288
                ],
                "correlated_neurons_pearson": [
                    0.025,
                    0.025,
                    0.024
                ],
                "correlated_neurons_l1": [
                    0.023,
                    0.023,
                    0.027
                ],
                "correlated_features_indices": [
                    10428,
                    10486,
                    10382
                ],
                "correlated_features_pearson": [
                    0.013,
                    0.013,
                    0.005
                ],
                "correlated_features_l1": [
                    0.014,
                    0.014,
                    0.006
                ],
                "neg_str": [
                    "soType",
                    "Reviewer",
                    " Eag",
                    " Canterbury",
                    "Struct",
                    "arching",
                    "tnc",
                    "semble",
                    "Pont",
                    "earth"
                ],
                "neg_values": [
                    -0.727,
                    -0.727,
                    -0.716,
                    -0.69,
                    -0.688,
                    -0.687,
                    -0.687,
                    -0.682,
                    -0.68,
                    -0.68
                ],
                "pos_str": [
                    " cocaine",
                    " methamphetamine",
                    " overdose",
                    " addiction",
                    " addict",
                    " overdoses",
                    " addicts",
                    " drugs",
                    " intoxication",
                    " heroin"
                ],
                "pos_values": [
                    1.423,
                    1.22,
                    1.219,
                    1.21,
                    1.208,
                    1.201,
                    1.177,
                    1.174,
                    1.162,
                    1.094
                ],
                "frac_nonzero": 0.00062,
                "freq_hist_data_bar_heights": [
                    491,
                    318,
                    227,
                    191,
                    128,
                    102,
                    79,
                    69,
                    52,
                    39,
                    42,
                    31,
                    15,
                    22,
                    11,
                    9,
                    12,
                    5,
                    7,
                    8,
                    6,
                    5,
                    6,
                    3,
                    7,
                    8,
                    5,
                    9,
                    3,
                    2,
                    5,
                    2,
                    0,
                    1,
                    1,
                    1,
                    0,
                    3,
                    4,
                    1,
                    4,
                    3,
                    3,
                    4,
                    4,
                    2,
                    0,
                    2,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.506,
                    1.516,
                    2.526,
                    3.537,
                    4.547,
                    5.557,
                    6.567,
                    7.577,
                    8.587,
                    9.597,
                    10.607,
                    11.618,
                    12.628,
                    13.638,
                    14.648,
                    15.658,
                    16.668,
                    17.678,
                    18.688,
                    19.699,
                    20.709,
                    21.719,
                    22.729,
                    23.739,
                    24.749,
                    25.759,
                    26.769,
                    27.78,
                    28.79,
                    29.8,
                    30.81,
                    31.82,
                    32.83,
                    33.84,
                    34.85,
                    35.86,
                    36.871,
                    37.881,
                    38.891,
                    39.901,
                    40.911,
                    41.921,
                    42.931,
                    43.941,
                    44.952,
                    45.962,
                    46.972,
                    47.982,
                    48.992,
                    50.002
                ],
                "logits_hist_data_bar_heights": [
                    7,
                    16,
                    25,
                    53,
                    100,
                    165,
                    292,
                    423,
                    719,
                    1081,
                    1570,
                    2325,
                    2875,
                    3534,
                    4086,
                    4449,
                    4659,
                    4550,
                    4142,
                    3556,
                    2946,
                    2368,
                    1751,
                    1359,
                    1009,
                    657,
                    442,
                    316,
                    233,
                    171,
                    90,
                    77,
                    51,
                    40,
                    31,
                    25,
                    14,
                    10,
                    12,
                    12,
                    3,
                    3,
                    1,
                    1,
                    3,
                    4,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.705,
                    -0.662,
                    -0.619,
                    -0.576,
                    -0.533,
                    -0.49,
                    -0.447,
                    -0.404,
                    -0.361,
                    -0.318,
                    -0.275,
                    -0.232,
                    -0.189,
                    -0.146,
                    -0.103,
                    -0.06,
                    -0.017,
                    0.026,
                    0.069,
                    0.112,
                    0.155,
                    0.198,
                    0.241,
                    0.284,
                    0.327,
                    0.37,
                    0.413,
                    0.456,
                    0.499,
                    0.542,
                    0.585,
                    0.627,
                    0.67,
                    0.713,
                    0.756,
                    0.799,
                    0.842,
                    0.885,
                    0.928,
                    0.971,
                    1.014,
                    1.057,
                    1.1,
                    1.143,
                    1.186,
                    1.229,
                    1.272,
                    1.315,
                    1.358,
                    1.401
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "mentions of illegal drugs, particularly cocaine",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmhj5v9yw7i666gkdx00ig",
                        "tokens": [
                            " Kw",
                            "iat",
                            "kowski",
                            ",",
                            " was",
                            " fired",
                            " after",
                            " being",
                            " found",
                            " un",
                            "responsive",
                            " in",
                            " a",
                            " men",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " locker",
                            " room",
                            " with",
                            " sy",
                            "ring",
                            "es",
                            " and",
                            " needles",
                            ";",
                            " tests",
                            " found",
                            " cocaine",
                            " and",
                            " marijuana",
                            " in",
                            " his",
                            " system",
                            ",",
                            " said",
                            " the",
                            " official",
                            ",",
                            " Monica",
                            " Bowman",
                            ",",
                            " chief",
                            " executive",
                            " of",
                            " Arizona",
                            " Heart",
                            " Hospital",
                            ".",
                            " Mr",
                            ".",
                            " Kw",
                            "iat",
                            "kowski",
                            ",",
                            " 33",
                            ",",
                            " is",
                            " accused",
                            " of",
                            " stealing",
                            " an",
                            "esthetic",
                            " drugs",
                            " from",
                            " Ex",
                            "eter",
                            " Hospital",
                            " in",
                            " New",
                            " Hampshire",
                            " and",
                            " contamin",
                            "ating",
                            " sy",
                            "ring",
                            "es",
                            ".",
                            " His",
                            " strain",
                            " of",
                            " hepatitis",
                            " C",
                            " has",
                            " been",
                            " diagnosed",
                            " in",
                            " 30",
                            " patients",
                            ",",
                            " and",
                            " testing",
                            " has",
                            " been",
                            " recommended",
                            " for",
                            " about",
                            " 4",
                            ",",
                            "700",
                            " people",
                            " in",
                            " New",
                            " Hampshire",
                            " alone",
                            ".",
                            " Officials",
                            " are",
                            " still",
                            " determining",
                            " who",
                            " should",
                            " be",
                            " tested",
                            " elsewhere",
                            ".",
                            " They",
                            " have",
                            " confirmed",
                            " that",
                            " Mr",
                            ".",
                            " Kw",
                            "iat",
                            "kowski",
                            " also",
                            " worked"
                        ],
                        "dataIndex": null,
                        "index": "10491",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.507,
                        "maxValueTokenIndex": 28,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.507,
                            8.233,
                            18.399,
                            6.012,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.437,
                            0.75,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:58:12.908Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.507,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmhj5x9ywri666eu4veuxv",
                        "tokens": [
                            " Kw",
                            "iat",
                            "kowski",
                            ",",
                            " was",
                            " fired",
                            " after",
                            " being",
                            " found",
                            " un",
                            "responsive",
                            " in",
                            " a",
                            " men",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " locker",
                            " room",
                            " with",
                            " sy",
                            "ring",
                            "es",
                            " and",
                            " needles",
                            ";",
                            " tests",
                            " found",
                            " cocaine",
                            " and",
                            " marijuana",
                            " in",
                            " his",
                            " system",
                            ",",
                            " said",
                            " the",
                            " official",
                            ",",
                            " Monica",
                            " Bowman",
                            ",",
                            " chief",
                            " executive",
                            " of",
                            " Arizona",
                            " Heart",
                            " Hospital",
                            ".",
                            " Mr",
                            ".",
                            " Kw",
                            "iat",
                            "kowski",
                            ",",
                            " 33",
                            ",",
                            " is",
                            " accused",
                            " of",
                            " stealing",
                            " an",
                            "esthetic",
                            " drugs",
                            " from",
                            " Ex",
                            "eter",
                            " Hospital",
                            " in",
                            " New",
                            " Hampshire",
                            " and",
                            " contamin",
                            "ating",
                            " sy",
                            "ring",
                            "es",
                            ".",
                            " His",
                            " strain",
                            " of",
                            " hepatitis",
                            " C",
                            " has",
                            " been",
                            " diagnosed",
                            " in",
                            " 30",
                            " patients",
                            ",",
                            " and",
                            " testing",
                            " has",
                            " been",
                            " recommended",
                            " for",
                            " about",
                            " 4",
                            ",",
                            "700",
                            " people",
                            " in",
                            " New",
                            " Hampshire",
                            " alone",
                            ".",
                            " Officials",
                            " are",
                            " still",
                            " determining",
                            " who",
                            " should",
                            " be",
                            " tested",
                            " elsewhere",
                            ".",
                            " They",
                            " have",
                            " confirmed",
                            " that",
                            " Mr",
                            ".",
                            " Kw",
                            "iat",
                            "kowski",
                            " also",
                            " worked"
                        ],
                        "dataIndex": null,
                        "index": "10491",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.507,
                        "maxValueTokenIndex": 28,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.507,
                            8.233,
                            18.399,
                            6.012,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.437,
                            0.75,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:58:12.908Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 40.406,
                        "binMax": 50.507,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmhj5v9yw8i6669ryi3ta0",
                        "tokens": [
                            " dollars",
                            " worth",
                            " of",
                            " cocaine",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " ATF",
                            " agent",
                            " explains",
                            " that",
                            " he",
                            " needs",
                            " a",
                            " robbery",
                            " crew",
                            " to",
                            " help",
                            " him",
                            " overtake",
                            " armed",
                            " guards",
                            " in",
                            " the",
                            " house",
                            " and",
                            " steal",
                            " the",
                            " cocaine",
                            ".",
                            " Once",
                            " the",
                            " crew",
                            " meets",
                            " to",
                            " prepare",
                            " for",
                            " the",
                            " armed",
                            " robbery",
                            ",",
                            " federal",
                            " authorities",
                            " bust",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "Several",
                            " of",
                            " the",
                            " bust",
                            "s",
                            " have",
                            " lead",
                            " to",
                            " the",
                            " deaths",
                            " of",
                            " suspects",
                            " who",
                            " shot",
                            " at",
                            " or",
                            " tried",
                            " to",
                            " run",
                            " down",
                            " agents",
                            " in",
                            " an",
                            " attempt",
                            " to",
                            " flee",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            "form",
                            "ants",
                            " are",
                            " paid",
                            " by",
                            " the",
                            " ATF",
                            " to",
                            " pressure",
                            " people",
                            " to",
                            " join",
                            " the",
                            " fake",
                            " robberies",
                            ".",
                            " Individuals",
                            " may",
                            " be",
                            " targeted",
                            " simply",
                            " because",
                            " the",
                            " informants",
                            " know",
                            " them",
                            " through",
                            " work",
                            " or",
                            " a",
                            " personal",
                            " connection",
                            ",",
                            " just",
                            " like",
                            " a",
                            " r",
                            "affle",
                            " ticket",
                            " sale",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " preparation",
                            " for",
                            " the",
                            " fake"
                        ],
                        "dataIndex": null,
                        "index": "10491",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.329,
                        "maxValueTokenIndex": 3,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            48.329,
                            2.09,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            38.422,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:58:12.908Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.507,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "74706",
            "description": " references to crack cocaine",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5538025067389761,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "74706",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:03:53.021Z",
                "maxActApprox": 57.362,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    74706,
                    11446,
                    39006,
                    9625,
                    4773,
                    54142,
                    3058,
                    73523,
                    56218,
                    87455,
                    96973,
                    54621,
                    21788,
                    66724,
                    86509,
                    26663,
                    89055,
                    85177,
                    72215,
                    26103,
                    78835,
                    26830,
                    68391,
                    35753,
                    58556
                ],
                "topkCosSimValues": [
                    1,
                    0.7501,
                    0.7019,
                    0.4432,
                    0.4201,
                    0.403,
                    0.3962,
                    0.3899,
                    0.3856,
                    0.3854,
                    0.3781,
                    0.376,
                    0.374,
                    0.3725,
                    0.3681,
                    0.3617,
                    0.3602,
                    0.3557,
                    0.3506,
                    0.3491,
                    0.3483,
                    0.3468,
                    0.3459,
                    0.344,
                    0.3382
                ],
                "neuron_alignment_indices": [
                    35,
                    156,
                    211
                ],
                "neuron_alignment_values": [
                    0.116,
                    0.106,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    211,
                    35,
                    156
                ],
                "correlated_neurons_pearson": [
                    0.015,
                    0.014,
                    0.013
                ],
                "correlated_neurons_l1": [
                    0.011,
                    0.013,
                    0.012
                ],
                "correlated_features_indices": [
                    74724,
                    74706,
                    74652
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "ikk",
                    "istic",
                    " obser",
                    " Leth",
                    " traged",
                    "omorphic",
                    "velength",
                    "folk",
                    "isted",
                    " nomine"
                ],
                "neg_values": [
                    -0.778,
                    -0.735,
                    -0.731,
                    -0.71,
                    -0.709,
                    -0.706,
                    -0.7,
                    -0.679,
                    -0.679,
                    -0.678
                ],
                "pos_str": [
                    "Berry",
                    "pots",
                    "pot",
                    "lings",
                    "ible",
                    " cocaine",
                    "ling",
                    "buster",
                    "downs",
                    "down"
                ],
                "pos_values": [
                    1.149,
                    1.132,
                    1.053,
                    1.031,
                    1.022,
                    0.989,
                    0.969,
                    0.952,
                    0.924,
                    0.913
                ],
                "frac_nonzero": 4e-05,
                "freq_hist_data_bar_heights": [
                    16,
                    5,
                    5,
                    5,
                    3,
                    5,
                    2,
                    3,
                    0,
                    5,
                    0,
                    2,
                    4,
                    4,
                    1,
                    2,
                    5,
                    5,
                    0,
                    1,
                    7,
                    1,
                    1,
                    2,
                    0,
                    1,
                    1,
                    2,
                    1,
                    2,
                    2,
                    0,
                    2,
                    0,
                    0,
                    0,
                    2,
                    1,
                    1,
                    4,
                    5,
                    4,
                    0,
                    3,
                    3,
                    0,
                    1,
                    1,
                    0,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.605,
                    1.752,
                    2.899,
                    4.045,
                    5.192,
                    6.338,
                    7.485,
                    8.632,
                    9.778,
                    10.925,
                    12.071,
                    13.218,
                    14.365,
                    15.511,
                    16.658,
                    17.804,
                    18.951,
                    20.098,
                    21.244,
                    22.391,
                    23.537,
                    24.684,
                    25.831,
                    26.977,
                    28.124,
                    29.27,
                    30.417,
                    31.564,
                    32.71,
                    33.857,
                    35.003,
                    36.15,
                    37.297,
                    38.443,
                    39.59,
                    40.737,
                    41.883,
                    43.03,
                    44.176,
                    45.323,
                    46.47,
                    47.616,
                    48.763,
                    49.909,
                    51.056,
                    52.203,
                    53.349,
                    54.496,
                    55.642,
                    56.789
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    5,
                    7,
                    3,
                    7,
                    8,
                    28,
                    46,
                    101,
                    165,
                    326,
                    466,
                    825,
                    1272,
                    1854,
                    2521,
                    3263,
                    4222,
                    4823,
                    5063,
                    5162,
                    4669,
                    3893,
                    3146,
                    2426,
                    1627,
                    1262,
                    903,
                    634,
                    470,
                    325,
                    217,
                    149,
                    121,
                    80,
                    65,
                    28,
                    28,
                    9,
                    15,
                    6,
                    2,
                    2,
                    3,
                    2,
                    2,
                    2,
                    1,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.759,
                    -0.72,
                    -0.682,
                    -0.643,
                    -0.605,
                    -0.566,
                    -0.528,
                    -0.489,
                    -0.45,
                    -0.412,
                    -0.373,
                    -0.335,
                    -0.296,
                    -0.258,
                    -0.219,
                    -0.181,
                    -0.142,
                    -0.104,
                    -0.065,
                    -0.026,
                    0.012,
                    0.051,
                    0.089,
                    0.128,
                    0.166,
                    0.205,
                    0.243,
                    0.282,
                    0.32,
                    0.359,
                    0.398,
                    0.436,
                    0.475,
                    0.513,
                    0.552,
                    0.59,
                    0.629,
                    0.667,
                    0.706,
                    0.745,
                    0.783,
                    0.822,
                    0.86,
                    0.899,
                    0.937,
                    0.976,
                    1.014,
                    1.053,
                    1.091,
                    1.13
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to \"crack\" related to drugs or crack-cocaine",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " references to crack cocaine",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygiapvhvywi10exy0gmg0mq",
                        "tokens": [
                            " or",
                            " to",
                            " drink",
                            " than",
                            " those",
                            " ten",
                            " years",
                            " older",
                            " were",
                            " at",
                            " their",
                            " age",
                            ",",
                            " and",
                            " the",
                            " same",
                            " is",
                            " true",
                            " in",
                            " most",
                            " European",
                            " countries",
                            ".",
                            " In",
                            " most",
                            " countries",
                            " wife",
                            "-",
                            "be",
                            "ating",
                            " has",
                            " become",
                            " more",
                            " stigmat",
                            "ised",
                            " and",
                            " less",
                            " common",
                            ":",
                            " since",
                            " 1994",
                            ",",
                            " self",
                            "-",
                            "reported",
                            " domestic",
                            " violence",
                            " has",
                            " fallen",
                            " by",
                            " three",
                            "-",
                            "quarters",
                            " in",
                            " Britain",
                            " and",
                            " two",
                            "-",
                            "thirds",
                            " in",
                            " America",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " America",
                            ",",
                            " the",
                            " end",
                            " of",
                            " the",
                            " crack",
                            "-",
                            "c",
                            "oc",
                            "aine",
                            " epidemic",
                            " in",
                            " the",
                            " 1990",
                            "s",
                            " is",
                            " widely",
                            " credited",
                            " with",
                            " reducing",
                            " crime",
                            ".",
                            " In",
                            " Europe",
                            ",",
                            " the",
                            " explosion",
                            " in",
                            " heroin",
                            " use",
                            " that",
                            " accompanied",
                            " the",
                            " high",
                            " unemployment",
                            " of",
                            " the",
                            " 1980",
                            "s",
                            " has",
                            " largely",
                            " rec",
                            "eded",
                            ",",
                            " even",
                            " though",
                            " hard",
                            " economic",
                            " times",
                            " are",
                            " back",
                            ".",
                            " Junk",
                            "ies",
                            " are",
                            " older",
                            " and",
                            " fewer",
                            ";",
                            " in",
                            " Rot"
                        ],
                        "dataIndex": null,
                        "index": "74706",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 57.362,
                        "maxValueTokenIndex": 71,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            57.362,
                            6.479,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:03:57.398Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 57.362,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiapvjvyx310ex9q2coicm",
                        "tokens": [
                            " or",
                            " to",
                            " drink",
                            " than",
                            " those",
                            " ten",
                            " years",
                            " older",
                            " were",
                            " at",
                            " their",
                            " age",
                            ",",
                            " and",
                            " the",
                            " same",
                            " is",
                            " true",
                            " in",
                            " most",
                            " European",
                            " countries",
                            ".",
                            " In",
                            " most",
                            " countries",
                            " wife",
                            "-",
                            "be",
                            "ating",
                            " has",
                            " become",
                            " more",
                            " stigmat",
                            "ised",
                            " and",
                            " less",
                            " common",
                            ":",
                            " since",
                            " 1994",
                            ",",
                            " self",
                            "-",
                            "reported",
                            " domestic",
                            " violence",
                            " has",
                            " fallen",
                            " by",
                            " three",
                            "-",
                            "quarters",
                            " in",
                            " Britain",
                            " and",
                            " two",
                            "-",
                            "thirds",
                            " in",
                            " America",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " America",
                            ",",
                            " the",
                            " end",
                            " of",
                            " the",
                            " crack",
                            "-",
                            "c",
                            "oc",
                            "aine",
                            " epidemic",
                            " in",
                            " the",
                            " 1990",
                            "s",
                            " is",
                            " widely",
                            " credited",
                            " with",
                            " reducing",
                            " crime",
                            ".",
                            " In",
                            " Europe",
                            ",",
                            " the",
                            " explosion",
                            " in",
                            " heroin",
                            " use",
                            " that",
                            " accompanied",
                            " the",
                            " high",
                            " unemployment",
                            " of",
                            " the",
                            " 1980",
                            "s",
                            " has",
                            " largely",
                            " rec",
                            "eded",
                            ",",
                            " even",
                            " though",
                            " hard",
                            " economic",
                            " times",
                            " are",
                            " back",
                            ".",
                            " Junk",
                            "ies",
                            " are",
                            " older",
                            " and",
                            " fewer",
                            ";",
                            " in",
                            " Rot"
                        ],
                        "dataIndex": null,
                        "index": "74706",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 57.362,
                        "maxValueTokenIndex": 71,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            57.362,
                            6.479,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:03:57.398Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 45.89,
                        "binMax": 57.362,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiapvhvywj10exnsqapebv",
                        "tokens": [
                            " per",
                            " cent",
                            " of",
                            " people",
                            " between",
                            " 15",
                            " and",
                            " 65",
                            " years",
                            " old",
                            " reported",
                            " they",
                            " had",
                            " smoked",
                            " marijuana",
                            " at",
                            " least",
                            " once",
                            " and",
                            " about",
                            " 5",
                            " per",
                            " cent",
                            " of",
                            " respondents",
                            " were",
                            " habitual",
                            " users",
                            ".",
                            "\n",
                            "\n",
                            "A",
                            " government",
                            " survey",
                            " puts",
                            " the",
                            " percentage",
                            " of",
                            " the",
                            " population",
                            " that",
                            " consumed",
                            " marijuana",
                            " over",
                            " the",
                            " last",
                            " year",
                            " at",
                            " 8",
                            ".",
                            "3",
                            " per",
                            " cent",
                            ",",
                            " compared",
                            " to",
                            " one",
                            " per",
                            " cent",
                            " who",
                            " consumed",
                            " cocaine",
                            " in",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " proposal",
                            " to",
                            " legal",
                            "ise",
                            " the",
                            " marijuana",
                            " market",
                            " is",
                            " one",
                            " of",
                            " 15",
                            " crime",
                            "-",
                            "fighting",
                            " measures",
                            " that",
                            " include",
                            " tougher",
                            " penalties",
                            " for",
                            " police",
                            " corruption",
                            ",",
                            " crack",
                            "-",
                            "c",
                            "oc",
                            "aine",
                            " trafficking",
                            " and",
                            " juvenile",
                            " offenders",
                            ".",
                            "<|endoftext|>",
                            "CLOSE",
                            " An",
                            "he",
                            "user",
                            "-",
                            "Bus",
                            "ch",
                            " In",
                            "B",
                            "ev",
                            " sealed",
                            " a",
                            " deal",
                            " months",
                            " in",
                            " the",
                            " making",
                            " to",
                            " acquire",
                            " its",
                            " biggest",
                            " rival",
                            ","
                        ],
                        "dataIndex": null,
                        "index": "74706",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 57.215,
                        "maxValueTokenIndex": 93,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            57.215,
                            6.272,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:03:57.398Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 57.362,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs6144-jb",
            "index": "5289",
            "description": "words related to drug use, specifically snorting",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5343440930349856,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs6144-jb",
                "index": "5289",
                "sourceSetName": "res_fs6144-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:13:26.905Z",
                "maxActApprox": 74.402,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    5289,
                    2596,
                    3750,
                    1276,
                    2583,
                    2587,
                    4876,
                    4390,
                    1467,
                    1800,
                    1158,
                    4857,
                    815,
                    5225,
                    3620,
                    3391,
                    872,
                    1764,
                    5536,
                    6029,
                    182,
                    3207,
                    5292,
                    1810,
                    1747
                ],
                "topkCosSimValues": [
                    1,
                    0.4266,
                    0.3731,
                    0.342,
                    0.325,
                    0.3217,
                    0.3194,
                    0.307,
                    0.2943,
                    0.2844,
                    0.2752,
                    0.2733,
                    0.2732,
                    0.2721,
                    0.2656,
                    0.2593,
                    0.2571,
                    0.2535,
                    0.2527,
                    0.2505,
                    0.2486,
                    0.2455,
                    0.2441,
                    0.2421,
                    0.2409
                ],
                "neuron_alignment_indices": [
                    719,
                    129,
                    0
                ],
                "neuron_alignment_values": [
                    0.11,
                    0.105,
                    0.104
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    326,
                    129,
                    0
                ],
                "correlated_neurons_pearson": [
                    0.03,
                    0.028,
                    0.027
                ],
                "correlated_neurons_l1": [
                    0.021,
                    0.027,
                    0.028
                ],
                "correlated_features_indices": [
                    5251,
                    5357,
                    5331
                ],
                "correlated_features_pearson": [
                    0.02,
                    0.012,
                    0.006
                ],
                "correlated_features_l1": [
                    0.021,
                    0.013,
                    0.007
                ],
                "neg_str": [
                    "heid",
                    "xual",
                    " Britann",
                    "shire",
                    " limited",
                    "EMENT",
                    " Centauri",
                    "minus",
                    " Templar",
                    " Cerberus"
                ],
                "neg_values": [
                    -0.917,
                    -0.686,
                    -0.679,
                    -0.662,
                    -0.631,
                    -0.61,
                    -0.587,
                    -0.586,
                    -0.578,
                    -0.576
                ],
                "pos_str": [
                    "appy",
                    "ipes",
                    "ugg",
                    "uggle",
                    "atches",
                    "agging",
                    "obb",
                    "atching",
                    "appers",
                    "igger"
                ],
                "pos_values": [
                    1.236,
                    1.196,
                    1.167,
                    1.167,
                    1.164,
                    1.162,
                    1.122,
                    1.115,
                    1.11,
                    1.108
                ],
                "frac_nonzero": 0.00118,
                "freq_hist_data_bar_heights": [
                    1375,
                    863,
                    506,
                    337,
                    177,
                    93,
                    48,
                    35,
                    32,
                    15,
                    12,
                    10,
                    14,
                    3,
                    2,
                    0,
                    0,
                    5,
                    3,
                    3,
                    4,
                    1,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1,
                    4,
                    3,
                    2,
                    1,
                    6,
                    2,
                    3,
                    3,
                    12,
                    13,
                    5,
                    12,
                    15,
                    16,
                    18,
                    18,
                    13,
                    13,
                    4,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.744,
                    2.232,
                    3.72,
                    5.208,
                    6.696,
                    8.184,
                    9.672,
                    11.16,
                    12.648,
                    14.137,
                    15.625,
                    17.113,
                    18.601,
                    20.089,
                    21.577,
                    23.065,
                    24.553,
                    26.041,
                    27.529,
                    29.017,
                    30.505,
                    31.993,
                    33.481,
                    34.969,
                    36.457,
                    37.945,
                    39.433,
                    40.921,
                    42.409,
                    43.897,
                    45.385,
                    46.873,
                    48.361,
                    49.849,
                    51.337,
                    52.826,
                    54.314,
                    55.802,
                    57.29,
                    58.778,
                    60.266,
                    61.754,
                    63.242,
                    64.73,
                    66.218,
                    67.706,
                    69.194,
                    70.682,
                    72.17,
                    73.658
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    0,
                    0,
                    3,
                    1,
                    5,
                    16,
                    42,
                    103,
                    208,
                    420,
                    735,
                    1277,
                    1905,
                    2814,
                    3854,
                    4705,
                    5229,
                    5212,
                    4720,
                    4153,
                    3429,
                    2648,
                    1978,
                    1588,
                    1139,
                    904,
                    698,
                    562,
                    436,
                    347,
                    268,
                    219,
                    199,
                    124,
                    86,
                    65,
                    45,
                    31,
                    24,
                    15,
                    18,
                    9,
                    4,
                    8,
                    4,
                    4,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.896,
                    -0.853,
                    -0.81,
                    -0.767,
                    -0.724,
                    -0.68,
                    -0.637,
                    -0.594,
                    -0.551,
                    -0.508,
                    -0.465,
                    -0.422,
                    -0.379,
                    -0.336,
                    -0.293,
                    -0.25,
                    -0.207,
                    -0.164,
                    -0.121,
                    -0.077,
                    -0.034,
                    0.009,
                    0.052,
                    0.095,
                    0.138,
                    0.181,
                    0.224,
                    0.267,
                    0.31,
                    0.353,
                    0.396,
                    0.439,
                    0.482,
                    0.526,
                    0.569,
                    0.612,
                    0.655,
                    0.698,
                    0.741,
                    0.784,
                    0.827,
                    0.87,
                    0.913,
                    0.956,
                    0.999,
                    1.042,
                    1.085,
                    1.128,
                    1.172,
                    1.215
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "words related to drug use, specifically snorting",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtgnzdxmt5i666awyxn0wq",
                        "tokens": [
                            " in",
                            " a",
                            " pound",
                            " then",
                            " sn",
                            "orting",
                            " through",
                            " his",
                            " nose",
                            " as",
                            " he",
                            " draws",
                            " a",
                            " penis",
                            " murdering",
                            " a",
                            " tr",
                            "amp",
                            " on",
                            " his",
                            " sat",
                            "chel",
                            ".",
                            " Steve",
                            " id",
                            "ly",
                            " tossing",
                            " a",
                            " Hack",
                            "y",
                            " Sack",
                            " around",
                            " and",
                            " suggesting",
                            " the",
                            " next",
                            " cabinet",
                            " meeting",
                            " should",
                            " be",
                            " held",
                            " in",
                            " a",
                            " bir",
                            "thing",
                            " pool",
                            ".",
                            " Talk",
                            " about",
                            " conflicting",
                            " approaches",
                            ".",
                            " The",
                            " cognitive",
                            " disson",
                            "ance",
                            " would",
                            " grow",
                            " so",
                            " loud",
                            " you",
                            "'d",
                            " turn",
                            " olive",
                            " and",
                            " g",
                            "iddy",
                            ".",
                            " And",
                            " then",
                            " you",
                            " wouldn",
                            "'t",
                            " know",
                            " which",
                            " one",
                            " to",
                            " vomit",
                            " over",
                            " first",
                            ".",
                            " (",
                            "Although",
                            " since",
                            " you",
                            "'re",
                            " David",
                            " Cameron",
                            ",",
                            " the",
                            " correct",
                            " answer",
                            " is",
                            " \"",
                            "your",
                            "self",
                            "\".",
                            ")",
                            "\n",
                            "\n",
                            "Andy",
                            " and",
                            " Gideon",
                            " we",
                            "'re",
                            " familiar",
                            " with",
                            ",",
                            " of",
                            " course",
                            ".",
                            " Andy",
                            " is",
                            " the",
                            " sinister",
                            " man",
                            " in",
                            " the",
                            " slow",
                            "-",
                            "mo",
                            " shots",
                            " on",
                            " the",
                            " news",
                            ",",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "5289",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 74.402,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            74.402,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:13:29.791Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 74.402,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtgnzdxmt6i6665jy8gd2n",
                        "tokens": [
                            "J",
                            "iri",
                            " Hud",
                            "ler",
                            " had",
                            " quite",
                            " the",
                            " flight",
                            " during",
                            " his",
                            " recent",
                            " trip",
                            " to",
                            " Europe",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " free",
                            "-",
                            "agent",
                            " NHL",
                            " forward",
                            " has",
                            " been",
                            " accused",
                            " by",
                            " the",
                            " Delta",
                            " Airlines",
                            " staff",
                            " of",
                            " behaving",
                            " bellig",
                            "erent",
                            "ly",
                            " during",
                            " his",
                            " flight",
                            " from",
                            " New",
                            " York",
                            " to",
                            " Prague",
                            ",",
                            " a",
                            " Czech",
                            " newspaper",
                            " reported",
                            " Wednesday",
                            ".",
                            "\n",
                            "\n",
                            "According",
                            " to",
                            " the",
                            " report",
                            ",",
                            " it",
                            " all",
                            " started",
                            " when",
                            " Hud",
                            "ler",
                            "'s",
                            " demand",
                            " for",
                            " \"",
                            "co",
                            "ke",
                            "\"",
                            " was",
                            " denied",
                            " by",
                            " a",
                            " flight",
                            " attendant",
                            " after",
                            " it",
                            " was",
                            " initially",
                            " presumed",
                            " that",
                            " his",
                            " request",
                            " was",
                            " in",
                            " reference",
                            " to",
                            " the",
                            " beverage",
                            ".",
                            " Hud",
                            "ler",
                            " then",
                            " threatened",
                            " to",
                            " have",
                            " the",
                            " woman",
                            " killed",
                            " by",
                            " his",
                            " friends",
                            " upon",
                            " their",
                            " arrival",
                            ".",
                            "\n",
                            "\n",
                            "Things",
                            " only",
                            " got",
                            " worse",
                            " from",
                            " there",
                            ".",
                            " Hud",
                            "ler",
                            " has",
                            " also",
                            " been",
                            " accused",
                            " of",
                            " sn",
                            "orting",
                            " cocaine"
                        ],
                        "dataIndex": null,
                        "index": "5289",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 74.365,
                        "maxValueTokenIndex": 124,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            74.365,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:13:29.791Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 74.402,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtgnzexmt7i666cdrkspiw",
                        "tokens": [
                            " Didn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " I",
                            " say",
                            " they",
                            " were",
                            " super",
                            "-",
                            "sp",
                            "ies",
                            "?",
                            "\n",
                            "\n",
                            "The",
                            " target",
                            " was",
                            " Hassan",
                            " Gh",
                            "ul",
                            ",",
                            " an",
                            " al",
                            "-",
                            "Qaeda",
                            " operative",
                            " who",
                            " was",
                            " once",
                            " in",
                            " American",
                            " custody",
                            " but",
                            " was",
                            " released",
                            " after",
                            " giving",
                            " his",
                            " capt",
                            "ors",
                            " the",
                            " tip",
                            " that",
                            " eventually",
                            " led",
                            " them",
                            " to",
                            " Osama",
                            " bin",
                            " Laden",
                            ".",
                            " (",
                            "He",
                            " was",
                            " also",
                            " tortured",
                            " after",
                            " giving",
                            " the",
                            " information",
                            " \u2014",
                            " because",
                            ",",
                            " hey",
                            ",",
                            " why",
                            " not",
                            "?",
                            " Even",
                            " super",
                            "-",
                            "powerful",
                            " brains",
                            " need",
                            " to",
                            " let",
                            " off",
                            " steam",
                            " once",
                            " in",
                            " a",
                            " while",
                            ",",
                            " right",
                            "?)",
                            " Return",
                            "ed",
                            " to",
                            " his",
                            " native",
                            " Pakistan",
                            ",",
                            " Gh",
                            "ul",
                            " evidently",
                            " became",
                            " a",
                            " bad",
                            " In",
                            "jun",
                            " again",
                            " in",
                            " eyes",
                            " of",
                            " the",
                            " imper",
                            "ium",
                            ",",
                            " so",
                            ",",
                            " after",
                            " sn",
                            "oop",
                            "ing",
                            " on",
                            " his",
                            " wife",
                            ",",
                            " they",
                            " found",
                            " out",
                            " where",
                            " he",
                            " was",
                            " and",
                            " ordered"
                        ],
                        "dataIndex": null,
                        "index": "5289",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 72.495,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            72.495,
                            4.827,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:13:29.791Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 74.402,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "35043",
            "description": " references to drug paraphernalia and related substances",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.534503475859865,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "35043",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:15:19.725Z",
                "maxActApprox": 40.166,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    35043,
                    62438,
                    47273,
                    82479,
                    26772,
                    67486,
                    47134,
                    29957,
                    18296,
                    79986,
                    47797,
                    36254,
                    11125,
                    50353,
                    63963,
                    83442,
                    44489,
                    59102,
                    80405,
                    81362,
                    11466,
                    44169,
                    19780,
                    65036,
                    22949
                ],
                "topkCosSimValues": [
                    1,
                    0.5575,
                    0.3722,
                    0.3664,
                    0.358,
                    0.355,
                    0.3488,
                    0.3396,
                    0.3386,
                    0.3384,
                    0.3347,
                    0.334,
                    0.3263,
                    0.319,
                    0.3189,
                    0.3161,
                    0.313,
                    0.3118,
                    0.3104,
                    0.3093,
                    0.3074,
                    0.3062,
                    0.3055,
                    0.3055,
                    0.3033
                ],
                "neuron_alignment_indices": [
                    158,
                    705,
                    527
                ],
                "neuron_alignment_values": [
                    0.113,
                    0.108,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    705,
                    289,
                    555
                ],
                "correlated_neurons_pearson": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_l1": [
                    0.007,
                    0.004,
                    0.006
                ],
                "correlated_features_indices": [
                    35043,
                    35149,
                    35153
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    " Jesuit",
                    " GOODMAN",
                    "din",
                    "\u00e9\u0125",
                    "furt",
                    " Sioux",
                    "DERR",
                    " Feder",
                    "CVE",
                    " Valent"
                ],
                "neg_values": [
                    -0.727,
                    -0.697,
                    -0.664,
                    -0.659,
                    -0.644,
                    -0.626,
                    -0.624,
                    -0.623,
                    -0.615,
                    -0.613
                ],
                "pos_str": [
                    "hern",
                    "apers",
                    "aque",
                    "etry",
                    "olitics",
                    "heres",
                    "ixel",
                    "inct",
                    "rote",
                    "hiba"
                ],
                "pos_values": [
                    1.211,
                    1.117,
                    1.021,
                    1.004,
                    0.936,
                    0.901,
                    0.891,
                    0.877,
                    0.876,
                    0.873
                ],
                "frac_nonzero": 1e-05,
                "freq_hist_data_bar_heights": [
                    11,
                    5,
                    3,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    4,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.436,
                    1.239,
                    2.042,
                    2.844,
                    3.647,
                    4.449,
                    5.252,
                    6.055,
                    6.857,
                    7.66,
                    8.463,
                    9.265,
                    10.068,
                    10.87,
                    11.673,
                    12.476,
                    13.278,
                    14.081,
                    14.884,
                    15.686,
                    16.489,
                    17.291,
                    18.094,
                    18.897,
                    19.699,
                    20.502,
                    21.305,
                    22.107,
                    22.91,
                    23.712,
                    24.515,
                    25.318,
                    26.12,
                    26.923,
                    27.726,
                    28.528,
                    29.331,
                    30.133,
                    30.936,
                    31.739,
                    32.541,
                    33.344,
                    34.146,
                    34.949,
                    35.752,
                    36.554,
                    37.357,
                    38.16,
                    38.962,
                    39.765
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    2,
                    6,
                    5,
                    22,
                    29,
                    80,
                    140,
                    228,
                    446,
                    683,
                    1125,
                    1636,
                    2343,
                    3056,
                    3807,
                    4292,
                    4758,
                    4764,
                    4405,
                    4023,
                    3432,
                    2801,
                    2267,
                    1679,
                    1261,
                    891,
                    620,
                    444,
                    330,
                    229,
                    153,
                    108,
                    76,
                    39,
                    30,
                    15,
                    6,
                    7,
                    2,
                    5,
                    4,
                    2,
                    0,
                    1,
                    1,
                    0,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.707,
                    -0.669,
                    -0.63,
                    -0.591,
                    -0.552,
                    -0.514,
                    -0.475,
                    -0.436,
                    -0.397,
                    -0.359,
                    -0.32,
                    -0.281,
                    -0.242,
                    -0.204,
                    -0.165,
                    -0.126,
                    -0.087,
                    -0.049,
                    -0.01,
                    0.029,
                    0.068,
                    0.106,
                    0.145,
                    0.184,
                    0.223,
                    0.261,
                    0.3,
                    0.339,
                    0.378,
                    0.416,
                    0.455,
                    0.494,
                    0.533,
                    0.571,
                    0.61,
                    0.649,
                    0.688,
                    0.726,
                    0.765,
                    0.804,
                    0.842,
                    0.881,
                    0.92,
                    0.959,
                    0.997,
                    1.036,
                    1.075,
                    1.114,
                    1.152,
                    1.191
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " references to drug paraphernalia and related substances",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to drug-related items and paraphernalia",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggk7391v3d10exawd4txrz",
                        "tokens": [
                            " judge",
                            " signed",
                            " off",
                            " on",
                            " a",
                            " search",
                            " warrant",
                            " for",
                            " police",
                            " to",
                            " obtain",
                            " blood",
                            " or",
                            " urine",
                            ".",
                            "\n",
                            "\n",
                            "After",
                            " Sparks",
                            " refused",
                            " to",
                            " cooperate",
                            ",",
                            " police",
                            " transported",
                            " him",
                            " to",
                            " A",
                            "ver",
                            "a",
                            " St",
                            ".",
                            " Mary",
                            "'s",
                            " Hospital",
                            " in",
                            " Pierre",
                            ",",
                            " where",
                            " he",
                            " was",
                            " strapped",
                            " to",
                            " a",
                            " bed",
                            " while",
                            " a",
                            " cat",
                            "heter",
                            " was",
                            " forced",
                            " into",
                            " his",
                            " penis",
                            " so",
                            " that",
                            " officers",
                            " could",
                            " obtain",
                            " a",
                            " urine",
                            " sample",
                            ".",
                            "\n",
                            "\n",
                            "S",
                            "par",
                            "ks",
                            "'",
                            " urine",
                            " tested",
                            " positive",
                            " for",
                            " THC",
                            " and",
                            " methamphetamine",
                            ".",
                            " He",
                            " was",
                            " charged",
                            " with",
                            " obstruction",
                            ",",
                            " two",
                            " counts",
                            " of",
                            " felony",
                            " drug",
                            " ingestion",
                            ",",
                            " and",
                            " possession",
                            " of",
                            " marijuana",
                            " and",
                            " drug",
                            " parap",
                            "hern",
                            "alia",
                            ".",
                            "\n",
                            "\n",
                            "IN",
                            "V",
                            "EST",
                            "IG",
                            "ATION",
                            ":",
                            "Arg",
                            "us",
                            " Leader",
                            " coverage",
                            " on",
                            " Human",
                            " Services",
                            " Center",
                            "\n",
                            "\n",
                            "S",
                            "par",
                            "ks",
                            "'",
                            " attorney",
                            ",",
                            " Jeremy",
                            " Lund",
                            ","
                        ],
                        "dataIndex": null,
                        "index": "35043",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.166,
                        "maxValueTokenIndex": 96,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.166,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:15:20.358Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 40.166,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggk73b1v3x10exqlvh42ft",
                        "tokens": [
                            " judge",
                            " signed",
                            " off",
                            " on",
                            " a",
                            " search",
                            " warrant",
                            " for",
                            " police",
                            " to",
                            " obtain",
                            " blood",
                            " or",
                            " urine",
                            ".",
                            "\n",
                            "\n",
                            "After",
                            " Sparks",
                            " refused",
                            " to",
                            " cooperate",
                            ",",
                            " police",
                            " transported",
                            " him",
                            " to",
                            " A",
                            "ver",
                            "a",
                            " St",
                            ".",
                            " Mary",
                            "'s",
                            " Hospital",
                            " in",
                            " Pierre",
                            ",",
                            " where",
                            " he",
                            " was",
                            " strapped",
                            " to",
                            " a",
                            " bed",
                            " while",
                            " a",
                            " cat",
                            "heter",
                            " was",
                            " forced",
                            " into",
                            " his",
                            " penis",
                            " so",
                            " that",
                            " officers",
                            " could",
                            " obtain",
                            " a",
                            " urine",
                            " sample",
                            ".",
                            "\n",
                            "\n",
                            "S",
                            "par",
                            "ks",
                            "'",
                            " urine",
                            " tested",
                            " positive",
                            " for",
                            " THC",
                            " and",
                            " methamphetamine",
                            ".",
                            " He",
                            " was",
                            " charged",
                            " with",
                            " obstruction",
                            ",",
                            " two",
                            " counts",
                            " of",
                            " felony",
                            " drug",
                            " ingestion",
                            ",",
                            " and",
                            " possession",
                            " of",
                            " marijuana",
                            " and",
                            " drug",
                            " parap",
                            "hern",
                            "alia",
                            ".",
                            "\n",
                            "\n",
                            "IN",
                            "V",
                            "EST",
                            "IG",
                            "ATION",
                            ":",
                            "Arg",
                            "us",
                            " Leader",
                            " coverage",
                            " on",
                            " Human",
                            " Services",
                            " Center",
                            "\n",
                            "\n",
                            "S",
                            "par",
                            "ks",
                            "'",
                            " attorney",
                            ",",
                            " Jeremy",
                            " Lund",
                            ","
                        ],
                        "dataIndex": null,
                        "index": "35043",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.166,
                        "maxValueTokenIndex": 96,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.166,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:15:20.358Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 32.133,
                        "binMax": 40.166,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggk7391v3e10ex7lnuq5xg",
                        "tokens": [
                            " his",
                            " hands",
                            " on",
                            " his",
                            " head",
                            ",",
                            " he",
                            " refused",
                            " and",
                            " tried",
                            " to",
                            " walk",
                            " away",
                            ".",
                            " Police",
                            " moved",
                            " to",
                            " handc",
                            "uff",
                            " him",
                            ",",
                            " but",
                            " he",
                            " resisted",
                            " and",
                            " had",
                            " to",
                            " be",
                            " wrest",
                            "led",
                            " to",
                            " the",
                            " ground",
                            ".",
                            "\n",
                            "\n",
                            "Hen",
                            "io",
                            " was",
                            " taken",
                            " to",
                            " the",
                            " Mesa",
                            " City",
                            " Jail",
                            " where",
                            " he",
                            " was",
                            " booked",
                            " on",
                            " charges",
                            " of",
                            " possession",
                            " of",
                            " a",
                            " vapor",
                            " releasing",
                            " substance",
                            ",",
                            " possession",
                            " of",
                            " drug",
                            " parap",
                            "hern",
                            "alia",
                            " and",
                            " tresp",
                            "assing",
                            ".",
                            "<|endoftext|>",
                            "(",
                            "Image",
                            ":",
                            " Dou",
                            "gal",
                            " Waters",
                            "/",
                            "Getty",
                            ")",
                            "\n",
                            "\n",
                            "The",
                            " fastest",
                            " thing",
                            " in",
                            " the",
                            " universe",
                            " has",
                            " come",
                            " to",
                            " a",
                            " complete",
                            " stop",
                            " for",
                            " a",
                            " record",
                            "-",
                            "breaking",
                            " minute",
                            ".",
                            " At",
                            " full",
                            " p",
                            "elt",
                            ",",
                            " light",
                            " would",
                            " travel",
                            " about",
                            " 18",
                            " million",
                            " kilometres",
                            " in",
                            " that",
                            " time",
                            " \u2013",
                            " that",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " more",
                            " than",
                            " 20",
                            " round",
                            " trips",
                            " to",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "35043",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.069,
                        "maxValueTokenIndex": 62,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.069,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:15:20.358Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 40.166,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "35043",
            "description": "references to drug-related items and paraphernalia",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5212929404167219,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "35043",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:15:19.725Z",
                "maxActApprox": 40.166,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    35043,
                    62438,
                    47273,
                    82479,
                    26772,
                    67486,
                    47134,
                    29957,
                    18296,
                    79986,
                    47797,
                    36254,
                    11125,
                    50353,
                    63963,
                    83442,
                    44489,
                    59102,
                    80405,
                    81362,
                    11466,
                    44169,
                    19780,
                    65036,
                    22949
                ],
                "topkCosSimValues": [
                    1,
                    0.5575,
                    0.3722,
                    0.3664,
                    0.358,
                    0.355,
                    0.3488,
                    0.3396,
                    0.3386,
                    0.3384,
                    0.3347,
                    0.334,
                    0.3263,
                    0.319,
                    0.3189,
                    0.3161,
                    0.313,
                    0.3118,
                    0.3104,
                    0.3093,
                    0.3074,
                    0.3062,
                    0.3055,
                    0.3055,
                    0.3033
                ],
                "neuron_alignment_indices": [
                    158,
                    705,
                    527
                ],
                "neuron_alignment_values": [
                    0.113,
                    0.108,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    705,
                    289,
                    555
                ],
                "correlated_neurons_pearson": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_l1": [
                    0.007,
                    0.004,
                    0.006
                ],
                "correlated_features_indices": [
                    35043,
                    35149,
                    35153
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    " Jesuit",
                    " GOODMAN",
                    "din",
                    "\u00e9\u0125",
                    "furt",
                    " Sioux",
                    "DERR",
                    " Feder",
                    "CVE",
                    " Valent"
                ],
                "neg_values": [
                    -0.727,
                    -0.697,
                    -0.664,
                    -0.659,
                    -0.644,
                    -0.626,
                    -0.624,
                    -0.623,
                    -0.615,
                    -0.613
                ],
                "pos_str": [
                    "hern",
                    "apers",
                    "aque",
                    "etry",
                    "olitics",
                    "heres",
                    "ixel",
                    "inct",
                    "rote",
                    "hiba"
                ],
                "pos_values": [
                    1.211,
                    1.117,
                    1.021,
                    1.004,
                    0.936,
                    0.901,
                    0.891,
                    0.877,
                    0.876,
                    0.873
                ],
                "frac_nonzero": 1e-05,
                "freq_hist_data_bar_heights": [
                    11,
                    5,
                    3,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    4,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.436,
                    1.239,
                    2.042,
                    2.844,
                    3.647,
                    4.449,
                    5.252,
                    6.055,
                    6.857,
                    7.66,
                    8.463,
                    9.265,
                    10.068,
                    10.87,
                    11.673,
                    12.476,
                    13.278,
                    14.081,
                    14.884,
                    15.686,
                    16.489,
                    17.291,
                    18.094,
                    18.897,
                    19.699,
                    20.502,
                    21.305,
                    22.107,
                    22.91,
                    23.712,
                    24.515,
                    25.318,
                    26.12,
                    26.923,
                    27.726,
                    28.528,
                    29.331,
                    30.133,
                    30.936,
                    31.739,
                    32.541,
                    33.344,
                    34.146,
                    34.949,
                    35.752,
                    36.554,
                    37.357,
                    38.16,
                    38.962,
                    39.765
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    2,
                    6,
                    5,
                    22,
                    29,
                    80,
                    140,
                    228,
                    446,
                    683,
                    1125,
                    1636,
                    2343,
                    3056,
                    3807,
                    4292,
                    4758,
                    4764,
                    4405,
                    4023,
                    3432,
                    2801,
                    2267,
                    1679,
                    1261,
                    891,
                    620,
                    444,
                    330,
                    229,
                    153,
                    108,
                    76,
                    39,
                    30,
                    15,
                    6,
                    7,
                    2,
                    5,
                    4,
                    2,
                    0,
                    1,
                    1,
                    0,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.707,
                    -0.669,
                    -0.63,
                    -0.591,
                    -0.552,
                    -0.514,
                    -0.475,
                    -0.436,
                    -0.397,
                    -0.359,
                    -0.32,
                    -0.281,
                    -0.242,
                    -0.204,
                    -0.165,
                    -0.126,
                    -0.087,
                    -0.049,
                    -0.01,
                    0.029,
                    0.068,
                    0.106,
                    0.145,
                    0.184,
                    0.223,
                    0.261,
                    0.3,
                    0.339,
                    0.378,
                    0.416,
                    0.455,
                    0.494,
                    0.533,
                    0.571,
                    0.61,
                    0.649,
                    0.688,
                    0.726,
                    0.765,
                    0.804,
                    0.842,
                    0.881,
                    0.92,
                    0.959,
                    0.997,
                    1.036,
                    1.075,
                    1.114,
                    1.152,
                    1.191
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " references to drug paraphernalia and related substances",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to drug-related items and paraphernalia",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggk7391v3d10exawd4txrz",
                        "tokens": [
                            " judge",
                            " signed",
                            " off",
                            " on",
                            " a",
                            " search",
                            " warrant",
                            " for",
                            " police",
                            " to",
                            " obtain",
                            " blood",
                            " or",
                            " urine",
                            ".",
                            "\n",
                            "\n",
                            "After",
                            " Sparks",
                            " refused",
                            " to",
                            " cooperate",
                            ",",
                            " police",
                            " transported",
                            " him",
                            " to",
                            " A",
                            "ver",
                            "a",
                            " St",
                            ".",
                            " Mary",
                            "'s",
                            " Hospital",
                            " in",
                            " Pierre",
                            ",",
                            " where",
                            " he",
                            " was",
                            " strapped",
                            " to",
                            " a",
                            " bed",
                            " while",
                            " a",
                            " cat",
                            "heter",
                            " was",
                            " forced",
                            " into",
                            " his",
                            " penis",
                            " so",
                            " that",
                            " officers",
                            " could",
                            " obtain",
                            " a",
                            " urine",
                            " sample",
                            ".",
                            "\n",
                            "\n",
                            "S",
                            "par",
                            "ks",
                            "'",
                            " urine",
                            " tested",
                            " positive",
                            " for",
                            " THC",
                            " and",
                            " methamphetamine",
                            ".",
                            " He",
                            " was",
                            " charged",
                            " with",
                            " obstruction",
                            ",",
                            " two",
                            " counts",
                            " of",
                            " felony",
                            " drug",
                            " ingestion",
                            ",",
                            " and",
                            " possession",
                            " of",
                            " marijuana",
                            " and",
                            " drug",
                            " parap",
                            "hern",
                            "alia",
                            ".",
                            "\n",
                            "\n",
                            "IN",
                            "V",
                            "EST",
                            "IG",
                            "ATION",
                            ":",
                            "Arg",
                            "us",
                            " Leader",
                            " coverage",
                            " on",
                            " Human",
                            " Services",
                            " Center",
                            "\n",
                            "\n",
                            "S",
                            "par",
                            "ks",
                            "'",
                            " attorney",
                            ",",
                            " Jeremy",
                            " Lund",
                            ","
                        ],
                        "dataIndex": null,
                        "index": "35043",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.166,
                        "maxValueTokenIndex": 96,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.166,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:15:20.358Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 40.166,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggk73b1v3x10exqlvh42ft",
                        "tokens": [
                            " judge",
                            " signed",
                            " off",
                            " on",
                            " a",
                            " search",
                            " warrant",
                            " for",
                            " police",
                            " to",
                            " obtain",
                            " blood",
                            " or",
                            " urine",
                            ".",
                            "\n",
                            "\n",
                            "After",
                            " Sparks",
                            " refused",
                            " to",
                            " cooperate",
                            ",",
                            " police",
                            " transported",
                            " him",
                            " to",
                            " A",
                            "ver",
                            "a",
                            " St",
                            ".",
                            " Mary",
                            "'s",
                            " Hospital",
                            " in",
                            " Pierre",
                            ",",
                            " where",
                            " he",
                            " was",
                            " strapped",
                            " to",
                            " a",
                            " bed",
                            " while",
                            " a",
                            " cat",
                            "heter",
                            " was",
                            " forced",
                            " into",
                            " his",
                            " penis",
                            " so",
                            " that",
                            " officers",
                            " could",
                            " obtain",
                            " a",
                            " urine",
                            " sample",
                            ".",
                            "\n",
                            "\n",
                            "S",
                            "par",
                            "ks",
                            "'",
                            " urine",
                            " tested",
                            " positive",
                            " for",
                            " THC",
                            " and",
                            " methamphetamine",
                            ".",
                            " He",
                            " was",
                            " charged",
                            " with",
                            " obstruction",
                            ",",
                            " two",
                            " counts",
                            " of",
                            " felony",
                            " drug",
                            " ingestion",
                            ",",
                            " and",
                            " possession",
                            " of",
                            " marijuana",
                            " and",
                            " drug",
                            " parap",
                            "hern",
                            "alia",
                            ".",
                            "\n",
                            "\n",
                            "IN",
                            "V",
                            "EST",
                            "IG",
                            "ATION",
                            ":",
                            "Arg",
                            "us",
                            " Leader",
                            " coverage",
                            " on",
                            " Human",
                            " Services",
                            " Center",
                            "\n",
                            "\n",
                            "S",
                            "par",
                            "ks",
                            "'",
                            " attorney",
                            ",",
                            " Jeremy",
                            " Lund",
                            ","
                        ],
                        "dataIndex": null,
                        "index": "35043",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.166,
                        "maxValueTokenIndex": 96,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.166,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:15:20.358Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 32.133,
                        "binMax": 40.166,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggk7391v3e10ex7lnuq5xg",
                        "tokens": [
                            " his",
                            " hands",
                            " on",
                            " his",
                            " head",
                            ",",
                            " he",
                            " refused",
                            " and",
                            " tried",
                            " to",
                            " walk",
                            " away",
                            ".",
                            " Police",
                            " moved",
                            " to",
                            " handc",
                            "uff",
                            " him",
                            ",",
                            " but",
                            " he",
                            " resisted",
                            " and",
                            " had",
                            " to",
                            " be",
                            " wrest",
                            "led",
                            " to",
                            " the",
                            " ground",
                            ".",
                            "\n",
                            "\n",
                            "Hen",
                            "io",
                            " was",
                            " taken",
                            " to",
                            " the",
                            " Mesa",
                            " City",
                            " Jail",
                            " where",
                            " he",
                            " was",
                            " booked",
                            " on",
                            " charges",
                            " of",
                            " possession",
                            " of",
                            " a",
                            " vapor",
                            " releasing",
                            " substance",
                            ",",
                            " possession",
                            " of",
                            " drug",
                            " parap",
                            "hern",
                            "alia",
                            " and",
                            " tresp",
                            "assing",
                            ".",
                            "<|endoftext|>",
                            "(",
                            "Image",
                            ":",
                            " Dou",
                            "gal",
                            " Waters",
                            "/",
                            "Getty",
                            ")",
                            "\n",
                            "\n",
                            "The",
                            " fastest",
                            " thing",
                            " in",
                            " the",
                            " universe",
                            " has",
                            " come",
                            " to",
                            " a",
                            " complete",
                            " stop",
                            " for",
                            " a",
                            " record",
                            "-",
                            "breaking",
                            " minute",
                            ".",
                            " At",
                            " full",
                            " p",
                            "elt",
                            ",",
                            " light",
                            " would",
                            " travel",
                            " about",
                            " 18",
                            " million",
                            " kilometres",
                            " in",
                            " that",
                            " time",
                            " \u2013",
                            " that",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " more",
                            " than",
                            " 20",
                            " round",
                            " trips",
                            " to",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "35043",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.069,
                        "maxValueTokenIndex": 62,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.069,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:15:20.358Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 40.166,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "32046",
            "description": "references to heroin and related drugs",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5167091334846895,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "32046",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:56:27.041Z",
                "maxActApprox": 61.158,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    32046,
                    30639,
                    37288,
                    36761,
                    47759,
                    22479,
                    47962,
                    6388,
                    27285,
                    709,
                    37692,
                    39169,
                    12971,
                    46260,
                    1849,
                    27366,
                    13385,
                    7006,
                    16144,
                    3168,
                    29007,
                    14632,
                    9429,
                    2998,
                    46426
                ],
                "topkCosSimValues": [
                    1,
                    0.7064,
                    0.6516,
                    0.5795,
                    0.5709,
                    0.549,
                    0.5192,
                    0.5104,
                    0.5095,
                    0.4936,
                    0.4828,
                    0.4639,
                    0.4627,
                    0.4604,
                    0.4485,
                    0.4477,
                    0.4446,
                    0.4422,
                    0.4418,
                    0.4415,
                    0.4387,
                    0.4271,
                    0.4249,
                    0.4208,
                    0.4202
                ],
                "neuron_alignment_indices": [
                    481,
                    447,
                    635
                ],
                "neuron_alignment_values": [
                    0.164,
                    0.141,
                    0.122
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.007,
                    0.006
                ],
                "correlated_neurons_indices": [
                    343,
                    537,
                    635
                ],
                "correlated_neurons_pearson": [
                    0.013,
                    0.011,
                    0.011
                ],
                "correlated_neurons_l1": [
                    0.013,
                    0.012,
                    0.01
                ],
                "correlated_features_indices": [
                    32093,
                    32106,
                    32042
                ],
                "correlated_features_pearson": [
                    0.001,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "eor",
                    "\u0143\u0136",
                    "tten",
                    "acular",
                    " newcom",
                    "ntil",
                    "ouf",
                    "quartered",
                    "semble",
                    "STEM"
                ],
                "neg_values": [
                    -0.81,
                    -0.751,
                    -0.739,
                    -0.724,
                    -0.715,
                    -0.714,
                    -0.711,
                    -0.704,
                    -0.701,
                    -0.688
                ],
                "pos_str": [
                    " addict",
                    " addiction",
                    " overdose",
                    " addicts",
                    " overdoses",
                    " heroin",
                    " relapse",
                    " poppy",
                    " needles",
                    " addicted"
                ],
                "pos_values": [
                    1.197,
                    1.156,
                    1.115,
                    1.113,
                    1.106,
                    0.989,
                    0.938,
                    0.933,
                    0.901,
                    0.899
                ],
                "frac_nonzero": 8e-05,
                "freq_hist_data_bar_heights": [
                    76,
                    29,
                    20,
                    19,
                    12,
                    13,
                    11,
                    12,
                    7,
                    4,
                    2,
                    1,
                    2,
                    1,
                    0,
                    0,
                    3,
                    4,
                    2,
                    0,
                    1,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    2,
                    1,
                    2,
                    5,
                    4,
                    2,
                    7,
                    4,
                    8,
                    3,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.625,
                    1.848,
                    3.07,
                    4.293,
                    5.516,
                    6.739,
                    7.962,
                    9.185,
                    10.408,
                    11.631,
                    12.854,
                    14.077,
                    15.299,
                    16.522,
                    17.745,
                    18.968,
                    20.191,
                    21.414,
                    22.637,
                    23.86,
                    25.083,
                    26.306,
                    27.528,
                    28.751,
                    29.974,
                    31.197,
                    32.42,
                    33.643,
                    34.866,
                    36.089,
                    37.312,
                    38.535,
                    39.757,
                    40.98,
                    42.203,
                    43.426,
                    44.649,
                    45.872,
                    47.095,
                    48.318,
                    49.541,
                    50.764,
                    51.986,
                    53.209,
                    54.432,
                    55.655,
                    56.878,
                    58.101,
                    59.324,
                    60.547
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    6,
                    12,
                    13,
                    39,
                    46,
                    102,
                    155,
                    246,
                    434,
                    668,
                    939,
                    1410,
                    1806,
                    2482,
                    3161,
                    3604,
                    4378,
                    4796,
                    4768,
                    4579,
                    3976,
                    3358,
                    2740,
                    2009,
                    1525,
                    983,
                    688,
                    468,
                    303,
                    181,
                    128,
                    83,
                    35,
                    49,
                    30,
                    12,
                    12,
                    6,
                    8,
                    5,
                    3,
                    2,
                    1,
                    0,
                    0,
                    3,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.79,
                    -0.75,
                    -0.71,
                    -0.67,
                    -0.63,
                    -0.59,
                    -0.549,
                    -0.509,
                    -0.469,
                    -0.429,
                    -0.389,
                    -0.349,
                    -0.308,
                    -0.268,
                    -0.228,
                    -0.188,
                    -0.148,
                    -0.108,
                    -0.068,
                    -0.027,
                    0.013,
                    0.053,
                    0.093,
                    0.133,
                    0.173,
                    0.214,
                    0.254,
                    0.294,
                    0.334,
                    0.374,
                    0.414,
                    0.455,
                    0.495,
                    0.535,
                    0.575,
                    0.615,
                    0.655,
                    0.695,
                    0.736,
                    0.776,
                    0.816,
                    0.856,
                    0.896,
                    0.936,
                    0.977,
                    1.017,
                    1.057,
                    1.097,
                    1.137,
                    1.177
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to heroin and related drugs",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk671au56evi6666iwxrlb2",
                        "tokens": [
                            "s",
                            " been",
                            " suspicious",
                            " about",
                            " the",
                            " Elk",
                            "ridge",
                            " clinic",
                            " for",
                            " months",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "They",
                            " would",
                            " conduct",
                            " drug",
                            " deals",
                            " in",
                            " the",
                            " parking",
                            " lot",
                            " in",
                            " plain",
                            " sight",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " she",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "Officials",
                            " say",
                            " Oxy",
                            "cod",
                            "one",
                            " is",
                            " a",
                            " gateway",
                            " drug",
                            " to",
                            " heroin",
                            " and",
                            " in",
                            " the",
                            " last",
                            " few",
                            " years",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " noticed",
                            " a",
                            " spike",
                            " in",
                            " heroin",
                            " overdoses",
                            " in",
                            " Maryland",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " DOJ",
                            " is",
                            " still",
                            " investigating",
                            " whether",
                            " others",
                            " were",
                            " knowingly",
                            " participating",
                            " in",
                            " the",
                            " scheme",
                            ".",
                            "<|endoftext|>",
                            "Bruce",
                            " Arena",
                            " and",
                            " Av",
                            "ram",
                            " Grant",
                            " are",
                            " on",
                            " the",
                            " short",
                            "list",
                            " to",
                            " take",
                            " over",
                            " as",
                            " USA",
                            " coach",
                            "\n",
                            "\n",
                            "Bruce",
                            " Arena",
                            " is",
                            " the",
                            " favourite",
                            " to",
                            " replace",
                            " J",
                            "urg",
                            "en",
                            " Kl",
                            "ins",
                            "mann",
                            " as",
                            " USA",
                            " coach",
                            "\n",
                            "\n",
                            "Bruce",
                            " Arena",
                            " and",
                            " Av",
                            "ram",
                            " Grant",
                            " are",
                            " on"
                        ],
                        "dataIndex": null,
                        "index": "32046",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 61.158,
                        "maxValueTokenIndex": 45,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.349,
                            0,
                            0,
                            0,
                            0.176,
                            0,
                            61.158,
                            4.63,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            55.613,
                            0.987,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:56:32.540Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 61.158,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk671au56ewi666vludhz3j",
                        "tokens": [
                            " with",
                            " the",
                            " wrongful",
                            " deaths",
                            " of",
                            " four",
                            " young",
                            " people",
                            " due",
                            " to",
                            " overd",
                            "osing",
                            " on",
                            " the",
                            " drugs",
                            " he",
                            " provided",
                            ".",
                            " But",
                            " it",
                            " only",
                            " got",
                            " worse",
                            " from",
                            " there",
                            ".",
                            " After",
                            " the",
                            " authorities",
                            " started",
                            " cracking",
                            " down",
                            " on",
                            " bad",
                            " doctors",
                            " and",
                            " shutting",
                            " down",
                            " the",
                            " clinics",
                            ",",
                            " the",
                            " heroin",
                            " came",
                            " along",
                            ".",
                            "\n",
                            "\n",
                            "No",
                            " one",
                            " has",
                            " any",
                            " idea",
                            " the",
                            " extent",
                            " of",
                            " the",
                            " addiction",
                            " problem",
                            " unless",
                            " they",
                            " are",
                            " right",
                            " in",
                            " the",
                            " middle",
                            " of",
                            " it",
                            ",",
                            " as",
                            " all",
                            " of",
                            " my",
                            " coworkers",
                            " and",
                            " I",
                            " are",
                            " every",
                            " day",
                            ".",
                            " There",
                            " are",
                            " so",
                            " many",
                            " drug",
                            " addicts",
                            ",",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " almost",
                            " impossible",
                            " to",
                            " wrap",
                            " your",
                            " head",
                            " around",
                            " it",
                            " until",
                            " you",
                            " see",
                            " it",
                            ".",
                            " Day",
                            " after",
                            " day",
                            ",",
                            " we",
                            " get",
                            " one",
                            " overdose",
                            " after",
                            " another",
                            " through",
                            " the",
                            " ER",
                            " doors",
                            ".",
                            " We",
                            " see",
                            " people",
                            " as",
                            " old",
                            " as",
                            " 70",
                            "s"
                        ],
                        "dataIndex": null,
                        "index": "32046",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 60.801,
                        "maxValueTokenIndex": 42,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            60.801,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.86,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:56:32.540Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 61.158,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk671au56exi6661iivag8q",
                        "tokens": [
                            " with",
                            " heroin",
                            " users",
                            " because",
                            " they",
                            " could",
                            " easily",
                            " sn",
                            "ort",
                            " it",
                            " like",
                            " cocaine",
                            " or",
                            " inject",
                            " it",
                            " like",
                            " heroin",
                            " for",
                            " a",
                            " quick",
                            " high",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " Globe",
                            " investigation",
                            " found",
                            " that",
                            " demand",
                            " for",
                            " a",
                            " replacement",
                            " for",
                            " Oxy",
                            "Contin",
                            " gave",
                            " rise",
                            " to",
                            " a",
                            " counterfeit",
                            " version",
                            " of",
                            " the",
                            " drug",
                            ".",
                            " Ill",
                            "icit",
                            " fentanyl",
                            " powder",
                            " is",
                            " smuggled",
                            " into",
                            " Canada",
                            " from",
                            " China",
                            " and",
                            " processed",
                            " for",
                            " street",
                            " sale",
                            " in",
                            " clandestine",
                            " labs",
                            ",",
                            " which",
                            " typically",
                            " put",
                            " the",
                            " powder",
                            " through",
                            " a",
                            " pill",
                            " press",
                            " machine",
                            " and",
                            " dye",
                            " the",
                            " tablets",
                            " green",
                            " to",
                            " mimic",
                            " the",
                            " 80",
                            "-",
                            "mill",
                            "ig",
                            "ram",
                            " Oxy",
                            "Contin",
                            " pills",
                            " favoured",
                            " by",
                            " opioid",
                            " abusers",
                            ".",
                            "\n",
                            "\n",
                            "Story",
                            " continues",
                            " below",
                            " advertisement",
                            "\n",
                            "\n",
                            "Health",
                            "-",
                            "care",
                            " workers",
                            " and",
                            " police",
                            " say",
                            " a",
                            " sharp",
                            " spike",
                            " in",
                            " the",
                            " number",
                            " of",
                            " samples",
                            " containing",
                            " fentanyl",
                            " in",
                            " Ontario",
                            " reflects",
                            " what",
                            " they",
                            " are"
                        ],
                        "dataIndex": null,
                        "index": "32046",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.947,
                        "maxValueTokenIndex": 1,
                        "minValue": 0,
                        "values": [
                            0,
                            59.947,
                            0.13,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.69,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.075,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            10.096,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.071,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.404,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:56:32.540Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 61.158,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "82591",
            "description": "references to the drug \"Ketamine\" and its various forms or related substances",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.512642100830141,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "82591",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:12:18.604Z",
                "maxActApprox": 61.962,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    82591,
                    2649,
                    45510,
                    56745,
                    71454,
                    40782,
                    52680,
                    3009,
                    31443,
                    92663,
                    5193,
                    59170,
                    69000,
                    67104,
                    53447,
                    29032,
                    65577,
                    59172,
                    13010,
                    91002,
                    5037,
                    69608,
                    31984,
                    90558,
                    12751
                ],
                "topkCosSimValues": [
                    1,
                    0.5212,
                    0.4553,
                    0.4366,
                    0.4331,
                    0.4318,
                    0.4276,
                    0.415,
                    0.4124,
                    0.4089,
                    0.4058,
                    0.4052,
                    0.402,
                    0.4013,
                    0.3979,
                    0.3967,
                    0.3958,
                    0.3922,
                    0.3837,
                    0.3829,
                    0.3801,
                    0.3785,
                    0.3781,
                    0.3776,
                    0.3739
                ],
                "neuron_alignment_indices": [
                    288,
                    651,
                    585
                ],
                "neuron_alignment_values": [
                    0.13,
                    0.107,
                    0.1
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    585,
                    702,
                    145
                ],
                "correlated_neurons_pearson": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_features_indices": [
                    82591,
                    82600,
                    82618
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "\u00e3\u0123\u012f",
                    " Forbidden",
                    "\u00e3\u0123\u0126",
                    "IBLE",
                    " Armory",
                    " Rasm",
                    "\u00e6\u0122",
                    " Tyson",
                    "\u00e6\u0143",
                    " Ange"
                ],
                "neg_values": [
                    -0.787,
                    -0.735,
                    -0.695,
                    -0.692,
                    -0.687,
                    -0.649,
                    -0.631,
                    -0.628,
                    -0.627,
                    -0.62
                ],
                "pos_str": [
                    "tering",
                    "amine",
                    "ogenic",
                    "ropolis",
                    "osis",
                    "ocon",
                    "ron",
                    "lein",
                    "alk",
                    "ram"
                ],
                "pos_values": [
                    1.369,
                    1.205,
                    1.01,
                    0.971,
                    0.969,
                    0.944,
                    0.941,
                    0.908,
                    0.906,
                    0.89
                ],
                "frac_nonzero": 1e-05,
                "freq_hist_data_bar_heights": [
                    4,
                    1,
                    0,
                    0,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.759,
                    1.996,
                    3.232,
                    4.468,
                    5.705,
                    6.941,
                    8.178,
                    9.414,
                    10.651,
                    11.887,
                    13.123,
                    14.36,
                    15.596,
                    16.833,
                    18.069,
                    19.305,
                    20.542,
                    21.778,
                    23.015,
                    24.251,
                    25.488,
                    26.724,
                    27.96,
                    29.197,
                    30.433,
                    31.67,
                    32.906,
                    34.143,
                    35.379,
                    36.615,
                    37.852,
                    39.088,
                    40.325,
                    41.561,
                    42.798,
                    44.034,
                    45.27,
                    46.507,
                    47.743,
                    48.98,
                    50.216,
                    51.452,
                    52.689,
                    53.925,
                    55.162,
                    56.398,
                    57.635,
                    58.871,
                    60.107,
                    61.344
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    3,
                    7,
                    10,
                    25,
                    51,
                    118,
                    223,
                    411,
                    770,
                    1215,
                    1841,
                    2824,
                    3635,
                    4440,
                    5185,
                    5145,
                    5053,
                    4335,
                    3504,
                    2782,
                    2086,
                    1722,
                    1163,
                    906,
                    749,
                    549,
                    415,
                    329,
                    232,
                    165,
                    127,
                    72,
                    67,
                    36,
                    34,
                    8,
                    9,
                    2,
                    4,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.766,
                    -0.723,
                    -0.679,
                    -0.636,
                    -0.593,
                    -0.55,
                    -0.507,
                    -0.464,
                    -0.421,
                    -0.378,
                    -0.334,
                    -0.291,
                    -0.248,
                    -0.205,
                    -0.162,
                    -0.119,
                    -0.076,
                    -0.032,
                    0.011,
                    0.054,
                    0.097,
                    0.14,
                    0.183,
                    0.226,
                    0.269,
                    0.313,
                    0.356,
                    0.399,
                    0.442,
                    0.485,
                    0.528,
                    0.571,
                    0.614,
                    0.658,
                    0.701,
                    0.744,
                    0.787,
                    0.83,
                    0.873,
                    0.916,
                    0.96,
                    1.003,
                    1.046,
                    1.089,
                    1.132,
                    1.175,
                    1.218,
                    1.261,
                    1.305,
                    1.348
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to specific chemical substances, particularly drugs",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to the drug \"Ketamine\" and its various forms or related substances",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygillsd1xfn10exlgky2i18",
                        "tokens": [
                            "mt",
                            ",",
                            " ket",
                            "amine",
                            ",",
                            " 2",
                            "c",
                            "'s",
                            ",",
                            " l",
                            "sa",
                            ",",
                            " a",
                            " variety",
                            " of",
                            " others",
                            " as",
                            " well",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " need",
                            " to",
                            " break",
                            " it",
                            " down",
                            ":",
                            "\n",
                            "\n",
                            "LS",
                            "D",
                            " 6",
                            "\n",
                            "\n",
                            "m",
                            "ush",
                            " 15",
                            "\n",
                            "\n",
                            "c",
                            "actus",
                            " 6",
                            "\n",
                            "\n",
                            "d",
                            "mt",
                            " 20",
                            "\n",
                            "\n",
                            "ket",
                            "amine",
                            " 30",
                            "\n",
                            "\n",
                            "2",
                            "c",
                            "'s",
                            " 8",
                            "\n",
                            "\n",
                            "ls",
                            "a",
                            " 4",
                            "\n",
                            "\n",
                            "Under",
                            "stand",
                            " why",
                            " you",
                            " are",
                            " here",
                            ".",
                            " What",
                            " has",
                            " brought",
                            " you",
                            " to",
                            " this",
                            " forum",
                            "?",
                            " You",
                            "'re",
                            " life",
                            " is",
                            " guiding",
                            " you",
                            " here",
                            " for",
                            " a",
                            " reason",
                            ".",
                            " Whether",
                            " you",
                            "'re",
                            " curious",
                            ",",
                            " a",
                            " party",
                            "-",
                            "go",
                            "er",
                            ",",
                            " on",
                            " a",
                            " spiritual",
                            " path",
                            " or",
                            " drug",
                            " abuser",
                            " you",
                            "'re",
                            " here",
                            " for",
                            " a",
                            " reason",
                            ".",
                            "\n",
                            "\n",
                            "Psy",
                            "chedel",
                            "ics",
                            " are",
                            " powerful",
                            " tools",
                            " with"
                        ],
                        "dataIndex": null,
                        "index": "82591",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 61.962,
                        "maxValueTokenIndex": 2,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            61.962,
                            0.531,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            23.02,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:12:25.225Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 61.962,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygillsd1xft10exngv6jzjn",
                        "tokens": [
                            "mt",
                            ",",
                            " ket",
                            "amine",
                            ",",
                            " 2",
                            "c",
                            "'s",
                            ",",
                            " l",
                            "sa",
                            ",",
                            " a",
                            " variety",
                            " of",
                            " others",
                            " as",
                            " well",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " need",
                            " to",
                            " break",
                            " it",
                            " down",
                            ":",
                            "\n",
                            "\n",
                            "LS",
                            "D",
                            " 6",
                            "\n",
                            "\n",
                            "m",
                            "ush",
                            " 15",
                            "\n",
                            "\n",
                            "c",
                            "actus",
                            " 6",
                            "\n",
                            "\n",
                            "d",
                            "mt",
                            " 20",
                            "\n",
                            "\n",
                            "ket",
                            "amine",
                            " 30",
                            "\n",
                            "\n",
                            "2",
                            "c",
                            "'s",
                            " 8",
                            "\n",
                            "\n",
                            "ls",
                            "a",
                            " 4",
                            "\n",
                            "\n",
                            "Under",
                            "stand",
                            " why",
                            " you",
                            " are",
                            " here",
                            ".",
                            " What",
                            " has",
                            " brought",
                            " you",
                            " to",
                            " this",
                            " forum",
                            "?",
                            " You",
                            "'re",
                            " life",
                            " is",
                            " guiding",
                            " you",
                            " here",
                            " for",
                            " a",
                            " reason",
                            ".",
                            " Whether",
                            " you",
                            "'re",
                            " curious",
                            ",",
                            " a",
                            " party",
                            "-",
                            "go",
                            "er",
                            ",",
                            " on",
                            " a",
                            " spiritual",
                            " path",
                            " or",
                            " drug",
                            " abuser",
                            " you",
                            "'re",
                            " here",
                            " for",
                            " a",
                            " reason",
                            ".",
                            "\n",
                            "\n",
                            "Psy",
                            "chedel",
                            "ics",
                            " are",
                            " powerful",
                            " tools",
                            " with"
                        ],
                        "dataIndex": null,
                        "index": "82591",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 61.962,
                        "maxValueTokenIndex": 2,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            61.962,
                            0.531,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            23.02,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:12:25.225Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 61.962,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygillse1xg010exqai4qx82",
                        "tokens": [
                            "mt",
                            ",",
                            " ket",
                            "amine",
                            ",",
                            " 2",
                            "c",
                            "'s",
                            ",",
                            " l",
                            "sa",
                            ",",
                            " a",
                            " variety",
                            " of",
                            " others",
                            " as",
                            " well",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " need",
                            " to",
                            " break",
                            " it",
                            " down",
                            ":",
                            "\n",
                            "\n",
                            "LS",
                            "D",
                            " 6",
                            "\n",
                            "\n",
                            "m",
                            "ush",
                            " 15",
                            "\n",
                            "\n",
                            "c",
                            "actus",
                            " 6",
                            "\n",
                            "\n",
                            "d",
                            "mt",
                            " 20",
                            "\n",
                            "\n",
                            "ket",
                            "amine",
                            " 30",
                            "\n",
                            "\n",
                            "2",
                            "c",
                            "'s",
                            " 8",
                            "\n",
                            "\n",
                            "ls",
                            "a",
                            " 4",
                            "\n",
                            "\n",
                            "Under",
                            "stand",
                            " why",
                            " you",
                            " are",
                            " here",
                            ".",
                            " What",
                            " has",
                            " brought",
                            " you",
                            " to",
                            " this",
                            " forum",
                            "?",
                            " You",
                            "'re",
                            " life",
                            " is",
                            " guiding",
                            " you",
                            " here",
                            " for",
                            " a",
                            " reason",
                            ".",
                            " Whether",
                            " you",
                            "'re",
                            " curious",
                            ",",
                            " a",
                            " party",
                            "-",
                            "go",
                            "er",
                            ",",
                            " on",
                            " a",
                            " spiritual",
                            " path",
                            " or",
                            " drug",
                            " abuser",
                            " you",
                            "'re",
                            " here",
                            " for",
                            " a",
                            " reason",
                            ".",
                            "\n",
                            "\n",
                            "Psy",
                            "chedel",
                            "ics",
                            " are",
                            " powerful",
                            " tools",
                            " with"
                        ],
                        "dataIndex": null,
                        "index": "82591",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 61.962,
                        "maxValueTokenIndex": 2,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            61.962,
                            0.531,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            23.02,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:12:25.225Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 61.962,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "56716",
            "description": "mentions of drug use",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5087065252276222,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "56716",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:44:23.220Z",
                "maxActApprox": 33.523,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    56716,
                    24448,
                    88066,
                    40976,
                    95484,
                    38053,
                    68321,
                    17946,
                    15608,
                    31179,
                    63565,
                    33770,
                    60364,
                    72014,
                    2255,
                    21319,
                    45137,
                    98229,
                    85971,
                    36654,
                    78380,
                    93763,
                    14460,
                    65727,
                    89840
                ],
                "topkCosSimValues": [
                    1,
                    0.6776,
                    0.6751,
                    0.6676,
                    0.6462,
                    0.5741,
                    0.569,
                    0.5377,
                    0.5237,
                    0.519,
                    0.5129,
                    0.5074,
                    0.4989,
                    0.4931,
                    0.4908,
                    0.4821,
                    0.4806,
                    0.48,
                    0.4739,
                    0.4582,
                    0.4539,
                    0.4449,
                    0.4354,
                    0.4281,
                    0.4265
                ],
                "neuron_alignment_indices": [
                    481,
                    447,
                    206
                ],
                "neuron_alignment_values": [
                    0.162,
                    0.104,
                    0.104
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    318,
                    329,
                    146
                ],
                "correlated_neurons_pearson": [
                    0.02,
                    0.02,
                    0.02
                ],
                "correlated_neurons_l1": [
                    0.021,
                    0.02,
                    0.019
                ],
                "correlated_features_indices": [
                    56848,
                    56822,
                    56796
                ],
                "correlated_features_pearson": [
                    0.008,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.009,
                    0.001,
                    0
                ],
                "neg_str": [
                    "arine",
                    " awarding",
                    " Barron",
                    " Uri",
                    "mand",
                    " notch",
                    " Tale",
                    " swoop",
                    " foss",
                    " Barg"
                ],
                "neg_values": [
                    -0.76,
                    -0.663,
                    -0.661,
                    -0.631,
                    -0.628,
                    -0.614,
                    -0.611,
                    -0.609,
                    -0.608,
                    -0.608
                ],
                "pos_str": [
                    "fulness",
                    " disorders",
                    " disorder",
                    " habits",
                    " Disorder",
                    " Disorders",
                    "FUL",
                    " cessation",
                    " behaviors",
                    "ful"
                ],
                "pos_values": [
                    1.192,
                    1.097,
                    1.082,
                    1.079,
                    1.009,
                    0.94,
                    0.882,
                    0.869,
                    0.828,
                    0.818
                ],
                "frac_nonzero": 0.00025,
                "freq_hist_data_bar_heights": [
                    137,
                    80,
                    74,
                    66,
                    53,
                    46,
                    44,
                    25,
                    26,
                    25,
                    16,
                    10,
                    15,
                    12,
                    4,
                    7,
                    6,
                    10,
                    10,
                    8,
                    8,
                    7,
                    6,
                    4,
                    5,
                    6,
                    7,
                    7,
                    3,
                    4,
                    2,
                    4,
                    3,
                    3,
                    5,
                    2,
                    4,
                    5,
                    2,
                    5,
                    7,
                    2,
                    1,
                    6,
                    4,
                    1,
                    1,
                    2,
                    2,
                    4
                ],
                "freq_hist_data_bar_values": [
                    0.335,
                    1.006,
                    1.676,
                    2.347,
                    3.017,
                    3.688,
                    4.358,
                    5.029,
                    5.699,
                    6.369,
                    7.04,
                    7.71,
                    8.381,
                    9.051,
                    9.722,
                    10.392,
                    11.063,
                    11.733,
                    12.404,
                    13.074,
                    13.744,
                    14.415,
                    15.085,
                    15.756,
                    16.426,
                    17.097,
                    17.767,
                    18.438,
                    19.108,
                    19.778,
                    20.449,
                    21.119,
                    21.79,
                    22.46,
                    23.131,
                    23.801,
                    24.472,
                    25.142,
                    25.813,
                    26.483,
                    27.153,
                    27.824,
                    28.494,
                    29.165,
                    29.835,
                    30.506,
                    31.176,
                    31.847,
                    32.517,
                    33.187
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    9,
                    7,
                    21,
                    30,
                    84,
                    167,
                    229,
                    454,
                    724,
                    1139,
                    1742,
                    2430,
                    3070,
                    3978,
                    4532,
                    4791,
                    4872,
                    4647,
                    4079,
                    3575,
                    2796,
                    2121,
                    1537,
                    1084,
                    802,
                    488,
                    315,
                    211,
                    112,
                    77,
                    51,
                    32,
                    17,
                    8,
                    8,
                    2,
                    2,
                    3,
                    1,
                    1,
                    1,
                    0,
                    1,
                    0,
                    3,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.741,
                    -0.702,
                    -0.663,
                    -0.623,
                    -0.584,
                    -0.545,
                    -0.506,
                    -0.467,
                    -0.428,
                    -0.389,
                    -0.35,
                    -0.311,
                    -0.272,
                    -0.233,
                    -0.194,
                    -0.155,
                    -0.116,
                    -0.077,
                    -0.038,
                    0.001,
                    0.04,
                    0.079,
                    0.118,
                    0.157,
                    0.197,
                    0.236,
                    0.275,
                    0.314,
                    0.353,
                    0.392,
                    0.431,
                    0.47,
                    0.509,
                    0.548,
                    0.587,
                    0.626,
                    0.665,
                    0.704,
                    0.743,
                    0.782,
                    0.821,
                    0.86,
                    0.899,
                    0.938,
                    0.977,
                    1.017,
                    1.056,
                    1.095,
                    1.134,
                    1.173
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " occurrences of the word \"use\" in various contexts related to substance use",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "mentions of drug use",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "terms related to drug use",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghlkeii9qj10ex6n7t90uv",
                        "tokens": [
                            "\n",
                            "The",
                            " trouble",
                            " is",
                            ",",
                            " there",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " also",
                            " research",
                            " that",
                            " shows",
                            " marijuana",
                            " use",
                            " can",
                            " have",
                            " negative",
                            " effects",
                            ",",
                            " especially",
                            " among",
                            " those",
                            " who",
                            " begin",
                            " using",
                            " the",
                            " drug",
                            " before",
                            " they",
                            " turn",
                            " 18",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Pers",
                            "istent",
                            " cannabis",
                            " use",
                            "\u00e2\u0122",
                            "\u013f",
                            " among",
                            " young",
                            " people",
                            " was",
                            " associated",
                            " with",
                            " \u00e2\u0122",
                            "\u013e",
                            "ne",
                            "uro",
                            "psych",
                            "ological",
                            " decline",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " a",
                            " Duke",
                            " University",
                            " survey",
                            " of",
                            " more",
                            " than",
                            " 1",
                            ",",
                            "000",
                            " individuals",
                            " at",
                            " various",
                            " ages",
                            " found",
                            ".",
                            "\n",
                            "\n",
                            "Purchase",
                            " and",
                            " K",
                            "ren",
                            "z",
                            "ler",
                            " are",
                            " unb",
                            "owed",
                            ",",
                            " though",
                            ".",
                            " They",
                            " say",
                            " their",
                            " daughter",
                            " is",
                            " not",
                            " addicted",
                            " to",
                            " cannabis",
                            " and",
                            " that",
                            " she",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " only",
                            " use",
                            " it",
                            " as",
                            " long",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " necessary",
                            ",",
                            " as",
                            " long",
                            " as",
                            " she",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " undergoing",
                            " chem",
                            "o",
                            " treatment",
                            " or",
                            " suffers",
                            " from"
                        ],
                        "dataIndex": null,
                        "index": "56716",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 33.523,
                        "maxValueTokenIndex": 14,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            33.523,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.438,
                            0,
                            1.287,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            27.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            10.523,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:44:23.884Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 26.818,
                        "binMax": 33.523,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghlkefi9px10exif694oo2",
                        "tokens": [
                            "\n",
                            "The",
                            " trouble",
                            " is",
                            ",",
                            " there",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " also",
                            " research",
                            " that",
                            " shows",
                            " marijuana",
                            " use",
                            " can",
                            " have",
                            " negative",
                            " effects",
                            ",",
                            " especially",
                            " among",
                            " those",
                            " who",
                            " begin",
                            " using",
                            " the",
                            " drug",
                            " before",
                            " they",
                            " turn",
                            " 18",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Pers",
                            "istent",
                            " cannabis",
                            " use",
                            "\u00e2\u0122",
                            "\u013f",
                            " among",
                            " young",
                            " people",
                            " was",
                            " associated",
                            " with",
                            " \u00e2\u0122",
                            "\u013e",
                            "ne",
                            "uro",
                            "psych",
                            "ological",
                            " decline",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " a",
                            " Duke",
                            " University",
                            " survey",
                            " of",
                            " more",
                            " than",
                            " 1",
                            ",",
                            "000",
                            " individuals",
                            " at",
                            " various",
                            " ages",
                            " found",
                            ".",
                            "\n",
                            "\n",
                            "Purchase",
                            " and",
                            " K",
                            "ren",
                            "z",
                            "ler",
                            " are",
                            " unb",
                            "owed",
                            ",",
                            " though",
                            ".",
                            " They",
                            " say",
                            " their",
                            " daughter",
                            " is",
                            " not",
                            " addicted",
                            " to",
                            " cannabis",
                            " and",
                            " that",
                            " she",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " only",
                            " use",
                            " it",
                            " as",
                            " long",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " necessary",
                            ",",
                            " as",
                            " long",
                            " as",
                            " she",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " undergoing",
                            " chem",
                            "o",
                            " treatment",
                            " or",
                            " suffers",
                            " from"
                        ],
                        "dataIndex": null,
                        "index": "56716",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 33.523,
                        "maxValueTokenIndex": 14,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            33.523,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.438,
                            0,
                            1.287,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            27.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            10.523,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:44:23.884Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 33.523,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghlkegi9py10exha7d5qsw",
                        "tokens": [
                            " and",
                            " he",
                            "'s",
                            " not",
                            " cheating",
                            " any",
                            " other",
                            " athletes",
                            ".",
                            " He",
                            "'s",
                            " not",
                            " bothering",
                            " anybody",
                            ".",
                            " Yet",
                            " I",
                            " know",
                            " for",
                            " sure",
                            " that",
                            " the",
                            " nation",
                            "'s",
                            " top",
                            " steroid",
                            " law",
                            " firms",
                            "'",
                            " files",
                            " would",
                            " support",
                            " the",
                            " claim",
                            " that",
                            " it",
                            " is",
                            " he",
                            ",",
                            " not",
                            " the",
                            " cheating",
                            " athlete",
                            ",",
                            " being",
                            " sn",
                            "ared",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " light",
                            " of",
                            " the",
                            " number",
                            " of",
                            " big",
                            "-",
                            "named",
                            " athletes",
                            " not",
                            " appearing",
                            " in",
                            " the",
                            " press",
                            " on",
                            " steroid",
                            " charges",
                            ",",
                            " there",
                            " were",
                            ",",
                            " nevertheless",
                            ",",
                            " widespread",
                            " reports",
                            " of",
                            " steroid",
                            " use",
                            " among",
                            " athletes",
                            " using",
                            " them",
                            " to",
                            " cheat",
                            ".",
                            " There",
                            " was",
                            " not",
                            " yet",
                            " any",
                            " real",
                            " danger",
                            " associated",
                            " with",
                            " them",
                            ".",
                            " Of",
                            " course",
                            " there",
                            " were",
                            " reports",
                            " of",
                            " side",
                            " effects",
                            " and",
                            " overd",
                            "rawn",
                            " reports",
                            " of",
                            " rage",
                            ",",
                            " but",
                            " nothing",
                            " to",
                            " really",
                            " ir",
                            "k",
                            " the",
                            " public",
                            " in",
                            " terms",
                            " of",
                            " the",
                            " dangers",
                            " steroids",
                            " represent"
                        ],
                        "dataIndex": null,
                        "index": "56716",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 33.278,
                        "maxValueTokenIndex": 78,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            33.278,
                            0,
                            0,
                            1.123,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:44:23.884Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 33.523,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "12946",
            "description": "mentions of drug use",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5086597507393211,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "12946",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:01:23.412Z",
                "maxActApprox": 34.102,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    12946,
                    23513,
                    12987,
                    4849,
                    15005,
                    7477,
                    9318,
                    6877,
                    3713,
                    21307,
                    18076,
                    12513,
                    3691,
                    3863,
                    11688,
                    10491,
                    16244,
                    18680,
                    5240,
                    14610,
                    8820,
                    10267,
                    19717,
                    20146,
                    5551
                ],
                "topkCosSimValues": [
                    1,
                    0.4758,
                    0.4336,
                    0.4322,
                    0.4309,
                    0.4192,
                    0.3777,
                    0.3772,
                    0.3739,
                    0.3725,
                    0.3602,
                    0.3602,
                    0.3594,
                    0.3592,
                    0.358,
                    0.3571,
                    0.3564,
                    0.3517,
                    0.3477,
                    0.3461,
                    0.3446,
                    0.3424,
                    0.3394,
                    0.3392,
                    0.3389
                ],
                "neuron_alignment_indices": [
                    481,
                    447,
                    255
                ],
                "neuron_alignment_values": [
                    0.167,
                    0.123,
                    0.108
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    439,
                    255,
                    288
                ],
                "correlated_neurons_pearson": [
                    0.029,
                    0.028,
                    0.027
                ],
                "correlated_neurons_l1": [
                    0.028,
                    0.029,
                    0.032
                ],
                "correlated_features_indices": [
                    12987,
                    12996,
                    12980
                ],
                "correlated_features_pearson": [
                    0.059,
                    0.004,
                    0.002
                ],
                "correlated_features_l1": [
                    0.059,
                    0.005,
                    0.002
                ],
                "neg_str": [
                    "arine",
                    "ube",
                    " swoop",
                    "named",
                    "\u00a3\u0131",
                    "IRC",
                    "\u012a\u0134",
                    " awarding",
                    "printed",
                    "etheless"
                ],
                "neg_values": [
                    -0.809,
                    -0.698,
                    -0.684,
                    -0.679,
                    -0.669,
                    -0.651,
                    -0.65,
                    -0.643,
                    -0.64,
                    -0.639
                ],
                "pos_str": [
                    " habits",
                    " disorders",
                    " Disorder",
                    " disorder",
                    " Disorders",
                    " cessation",
                    " behaviors",
                    " Addiction",
                    " behaviours",
                    " Prevention"
                ],
                "pos_values": [
                    1.188,
                    1.125,
                    1.124,
                    1.1,
                    0.999,
                    0.957,
                    0.849,
                    0.848,
                    0.833,
                    0.825
                ],
                "frac_nonzero": 0.001,
                "freq_hist_data_bar_heights": [
                    790,
                    593,
                    398,
                    320,
                    200,
                    160,
                    109,
                    90,
                    84,
                    56,
                    42,
                    37,
                    28,
                    19,
                    19,
                    19,
                    14,
                    14,
                    16,
                    12,
                    14,
                    14,
                    8,
                    10,
                    4,
                    9,
                    6,
                    3,
                    8,
                    7,
                    2,
                    1,
                    5,
                    1,
                    3,
                    2,
                    3,
                    4,
                    2,
                    4,
                    2,
                    4,
                    3,
                    2,
                    4,
                    2,
                    1,
                    1,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.342,
                    1.024,
                    1.706,
                    2.388,
                    3.07,
                    3.752,
                    4.434,
                    5.116,
                    5.798,
                    6.48,
                    7.162,
                    7.844,
                    8.526,
                    9.208,
                    9.89,
                    10.572,
                    11.254,
                    11.936,
                    12.618,
                    13.3,
                    13.982,
                    14.664,
                    15.346,
                    16.028,
                    16.711,
                    17.393,
                    18.075,
                    18.757,
                    19.439,
                    20.121,
                    20.803,
                    21.485,
                    22.167,
                    22.849,
                    23.531,
                    24.213,
                    24.895,
                    25.577,
                    26.259,
                    26.941,
                    27.623,
                    28.305,
                    28.987,
                    29.669,
                    30.351,
                    31.033,
                    31.715,
                    32.397,
                    33.079,
                    33.761
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    5,
                    8,
                    6,
                    26,
                    50,
                    91,
                    169,
                    336,
                    522,
                    878,
                    1305,
                    1810,
                    2575,
                    3197,
                    4009,
                    4435,
                    4707,
                    4768,
                    4654,
                    4251,
                    3402,
                    2739,
                    2007,
                    1474,
                    1004,
                    633,
                    438,
                    302,
                    194,
                    109,
                    69,
                    28,
                    13,
                    13,
                    11,
                    3,
                    3,
                    2,
                    3,
                    0,
                    0,
                    1,
                    1,
                    0,
                    1,
                    2,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.789,
                    -0.749,
                    -0.709,
                    -0.669,
                    -0.629,
                    -0.589,
                    -0.549,
                    -0.509,
                    -0.469,
                    -0.429,
                    -0.389,
                    -0.349,
                    -0.309,
                    -0.27,
                    -0.23,
                    -0.19,
                    -0.15,
                    -0.11,
                    -0.07,
                    -0.03,
                    0.01,
                    0.05,
                    0.09,
                    0.13,
                    0.17,
                    0.21,
                    0.25,
                    0.29,
                    0.33,
                    0.37,
                    0.41,
                    0.449,
                    0.489,
                    0.529,
                    0.569,
                    0.609,
                    0.649,
                    0.689,
                    0.729,
                    0.769,
                    0.809,
                    0.849,
                    0.889,
                    0.929,
                    0.969,
                    1.009,
                    1.049,
                    1.089,
                    1.129,
                    1.168
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "mentions of drug use",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmlna6cawvi666869bgo86",
                        "tokens": [
                            " suggested",
                            " various",
                            " other",
                            " venues",
                            " for",
                            " survey",
                            " workers",
                            " to",
                            " request",
                            " and",
                            " collect",
                            " data",
                            ",",
                            " such",
                            " as",
                            " highway",
                            " rest",
                            " stops",
                            " or",
                            " toll",
                            " booths",
                            ".",
                            "\n",
                            "\n",
                            "Despite",
                            " the",
                            " complaints",
                            ",",
                            " however",
                            ",",
                            " the",
                            " N",
                            "HT",
                            "SA",
                            " has",
                            " defended",
                            " its",
                            " actions",
                            ",",
                            " citing",
                            " the",
                            " large",
                            " number",
                            " of",
                            " Americans",
                            " \u2013",
                            " nearly",
                            " 10",
                            ",",
                            "000",
                            " \u2013",
                            " who",
                            " are",
                            " killed",
                            " in",
                            " drunk",
                            " driving",
                            " crashes",
                            " every",
                            " year",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "The",
                            " survey",
                            " provides",
                            " useful",
                            " data",
                            " about",
                            " alcohol",
                            " and",
                            " drug",
                            " use",
                            " by",
                            " drivers",
                            ",",
                            " and",
                            " participation",
                            " is",
                            " completely",
                            " voluntary",
                            " and",
                            " anonymous",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " read",
                            " a",
                            " statement",
                            " by",
                            " the",
                            " agency",
                            " to",
                            " USA",
                            " Today",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "More",
                            " than",
                            " 60",
                            " communities",
                            " across",
                            " the",
                            " country",
                            " will",
                            " participate",
                            " this",
                            " year",
                            ",",
                            " many",
                            " of",
                            " which",
                            " participated",
                            " in",
                            " the",
                            " previous",
                            " survey",
                            " in",
                            " 2007",
                            ".",
                            " N",
                            "HT",
                            "SA",
                            " always",
                            " works"
                        ],
                        "dataIndex": null,
                        "index": "12946",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 34.102,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.154,
                            0.17,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.086,
                            34.102,
                            0,
                            2.269,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:01:24.851Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 34.102,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmlna6cawwi666nrou5m93",
                        "tokens": [
                            " of",
                            " authoritative",
                            " studies",
                            " that",
                            " have",
                            " shown",
                            " a",
                            " link",
                            " between",
                            " cannabis",
                            " use",
                            " in",
                            " adolescence",
                            " and",
                            " the",
                            " onset",
                            " of",
                            " schizophrenia",
                            " later",
                            ",",
                            " for",
                            " instance",
                            " the",
                            " recent",
                            " South",
                            " London",
                            " study",
                            "1",
                            " by",
                            " Sir",
                            " Robin",
                            " Murray",
                            " and",
                            " colleagues",
                            " from",
                            " the",
                            " Institute",
                            " of",
                            " Psychiatry",
                            " at",
                            " Kings",
                            " College",
                            ",",
                            " London",
                            " which",
                            " looked",
                            " at",
                            " over",
                            " 400",
                            " people",
                            " with",
                            " schizophrenia",
                            " and",
                            " found",
                            " that",
                            " use",
                            " of",
                            " Sk",
                            "unk",
                            " (",
                            "a",
                            " type",
                            " of",
                            " cannabis",
                            " produced",
                            " from",
                            " genetically",
                            " modified",
                            " plants",
                            ")",
                            " increased",
                            " the",
                            " risk",
                            " of",
                            " developing",
                            " psychotic",
                            " illness",
                            " three",
                            "fold",
                            ".",
                            " This",
                            " more",
                            " or",
                            " less",
                            " confirmed",
                            " the",
                            " findings",
                            " of",
                            " previous",
                            " work",
                            " done",
                            " in",
                            " the",
                            " UK",
                            " and",
                            " overseas",
                            " and",
                            " was",
                            " very",
                            " close",
                            " to",
                            " the",
                            " 2",
                            ".",
                            "4",
                            " times",
                            " increased",
                            " risk",
                            " reported",
                            " in",
                            " one",
                            " of",
                            " the",
                            " earliest",
                            " studies",
                            " carried",
                            " out",
                            " on",
                            " this",
                            " subject",
                            " which",
                            " looked",
                            " at",
                            " over",
                            " 45",
                            ",",
                            "000"
                        ],
                        "dataIndex": null,
                        "index": "12946",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 33.934,
                        "maxValueTokenIndex": 10,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            33.934,
                            1.547,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            17.84,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:01:24.851Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 34.102,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmlna6cawxi666bei2rgxd",
                        "tokens": [
                            " soldiers",
                            " in",
                            " Sweden",
                            ".",
                            "2",
                            " It",
                            " also",
                            " supported",
                            " the",
                            " findings",
                            " of",
                            " a",
                            " three",
                            " year",
                            " study",
                            " of",
                            " over",
                            " 4",
                            ",",
                            "800",
                            " people",
                            " carried",
                            " out",
                            " in",
                            " the",
                            " Netherlands",
                            ".",
                            "\n",
                            "\n",
                            "However",
                            " these",
                            " studies",
                            " do",
                            " not",
                            " answer",
                            " all",
                            " the",
                            " questions",
                            ".",
                            " For",
                            " instance",
                            ",",
                            " is",
                            " it",
                            " the",
                            " case",
                            " that",
                            " the",
                            " people",
                            " most",
                            " likely",
                            " to",
                            " resort",
                            " to",
                            " cannabis",
                            " in",
                            " adolescence",
                            " are",
                            " also",
                            " those",
                            " most",
                            " prone",
                            " to",
                            " developing",
                            " schizophrenia",
                            " later",
                            "?",
                            " That",
                            " is",
                            " young",
                            " people",
                            " who",
                            " have",
                            " already",
                            " started",
                            " to",
                            " develop",
                            " the",
                            " prod",
                            "rom",
                            "al",
                            " symptoms",
                            ".",
                            " But",
                            " here",
                            " again",
                            " there",
                            " is",
                            " a",
                            " weight",
                            " of",
                            " research",
                            " evidence",
                            " that",
                            " suggests",
                            " that",
                            " cannabis",
                            " use",
                            " will",
                            " lead",
                            " to",
                            " schizophrenia",
                            " even",
                            " in",
                            " those",
                            " who",
                            " have",
                            " not",
                            " yet",
                            " developed",
                            " any",
                            " prod",
                            "rom",
                            "al",
                            " symptoms",
                            " (",
                            "sym",
                            "ptoms",
                            " that",
                            " can",
                            " appear",
                            " in",
                            " the",
                            " very",
                            " earliest",
                            " stages",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "12946",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 33.288,
                        "maxValueTokenIndex": 97,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.8,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            33.288,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:01:24.851Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 34.102,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "43878",
            "description": "references to the substance \"ketamine.\"",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5060384575151478,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "43878",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:17:13.539Z",
                "maxActApprox": 59.47,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    43878,
                    44177,
                    32809,
                    13373,
                    34463,
                    40322,
                    38444,
                    46018,
                    17328,
                    7275,
                    7281,
                    39950,
                    3090,
                    21631,
                    37657,
                    4755,
                    26477,
                    25890,
                    16477,
                    276,
                    24661,
                    7947,
                    14920,
                    44452,
                    48757
                ],
                "topkCosSimValues": [
                    1,
                    0.4359,
                    0.4263,
                    0.4255,
                    0.4232,
                    0.4033,
                    0.4028,
                    0.4014,
                    0.3803,
                    0.38,
                    0.3785,
                    0.3776,
                    0.3763,
                    0.3695,
                    0.3688,
                    0.3645,
                    0.3563,
                    0.3537,
                    0.3532,
                    0.3509,
                    0.3495,
                    0.3424,
                    0.3387,
                    0.3379,
                    0.3318
                ],
                "neuron_alignment_indices": [
                    283,
                    420,
                    421
                ],
                "neuron_alignment_values": [
                    0.13,
                    0.099,
                    0.097
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    651,
                    48,
                    585
                ],
                "correlated_neurons_pearson": [
                    0.009,
                    0.007,
                    0.007
                ],
                "correlated_neurons_l1": [
                    0.009,
                    0.007,
                    0.007
                ],
                "correlated_features_indices": [
                    43801,
                    43874,
                    43898
                ],
                "correlated_features_pearson": [
                    0.062,
                    0.005,
                    0.003
                ],
                "correlated_features_l1": [
                    0.062,
                    0.005,
                    0.003
                ],
                "neg_str": [
                    "\u00e3\u0123\u012f",
                    "\u00e7\u0136\u00b0",
                    "\u00e3\u0123\u0126",
                    " Tyson",
                    "IBLE",
                    "\u00e6\u0143",
                    " Shinra",
                    " Directorate",
                    " rece",
                    " Telecommunications"
                ],
                "neg_values": [
                    -0.836,
                    -0.784,
                    -0.777,
                    -0.774,
                    -0.769,
                    -0.752,
                    -0.694,
                    -0.679,
                    -0.674,
                    -0.662
                ],
                "pos_str": [
                    "eers",
                    "tering",
                    "eer",
                    "ters",
                    "ter",
                    "amine",
                    "ted",
                    "ropolis",
                    "cher",
                    "chel"
                ],
                "pos_values": [
                    1.38,
                    1.336,
                    1.204,
                    1.037,
                    1.028,
                    1.02,
                    0.99,
                    0.979,
                    0.971,
                    0.96
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    25,
                    14,
                    5,
                    4,
                    1,
                    7,
                    4,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    2,
                    2,
                    0,
                    0,
                    1,
                    0,
                    2,
                    1,
                    0,
                    2,
                    3,
                    3,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.597,
                    1.786,
                    2.975,
                    4.165,
                    5.354,
                    6.543,
                    7.733,
                    8.922,
                    10.111,
                    11.301,
                    12.49,
                    13.68,
                    14.869,
                    16.058,
                    17.248,
                    18.437,
                    19.626,
                    20.816,
                    22.005,
                    23.194,
                    24.384,
                    25.573,
                    26.763,
                    27.952,
                    29.141,
                    30.331,
                    31.52,
                    32.709,
                    33.899,
                    35.088,
                    36.277,
                    37.467,
                    38.656,
                    39.845,
                    41.035,
                    42.224,
                    43.414,
                    44.603,
                    45.792,
                    46.982,
                    48.171,
                    49.36,
                    50.55,
                    51.739,
                    52.928,
                    54.118,
                    55.307,
                    56.497,
                    57.686,
                    58.875
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    5,
                    0,
                    4,
                    7,
                    13,
                    27,
                    57,
                    112,
                    215,
                    397,
                    710,
                    1269,
                    1995,
                    3003,
                    4116,
                    4991,
                    5614,
                    5565,
                    4999,
                    4280,
                    3311,
                    2503,
                    1863,
                    1366,
                    961,
                    717,
                    543,
                    413,
                    352,
                    243,
                    176,
                    132,
                    102,
                    80,
                    40,
                    29,
                    21,
                    11,
                    3,
                    4,
                    2,
                    2,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.814,
                    -0.769,
                    -0.725,
                    -0.681,
                    -0.636,
                    -0.592,
                    -0.548,
                    -0.503,
                    -0.459,
                    -0.415,
                    -0.37,
                    -0.326,
                    -0.282,
                    -0.238,
                    -0.193,
                    -0.149,
                    -0.105,
                    -0.06,
                    -0.016,
                    0.028,
                    0.073,
                    0.117,
                    0.161,
                    0.206,
                    0.25,
                    0.294,
                    0.338,
                    0.383,
                    0.427,
                    0.471,
                    0.516,
                    0.56,
                    0.604,
                    0.649,
                    0.693,
                    0.737,
                    0.782,
                    0.826,
                    0.87,
                    0.914,
                    0.959,
                    1.003,
                    1.047,
                    1.092,
                    1.136,
                    1.18,
                    1.225,
                    1.269,
                    1.313,
                    1.358
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to the substance \"ketamine.\"",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk6xrhvg3c0i666pbzcu3hk",
                        "tokens": [
                            "The",
                            " combined",
                            " ingestion",
                            " of",
                            " ket",
                            "amine",
                            " (",
                            "K",
                            "et",
                            ")",
                            " and",
                            " amp",
                            "hetamine",
                            " (",
                            "Am",
                            "ph",
                            ")",
                            " by",
                            " drug",
                            "-",
                            "users",
                            " has",
                            " been",
                            " rampant",
                            " and",
                            " produced",
                            " more",
                            " severe",
                            " behavioral",
                            " abnorm",
                            "ality",
                            ".",
                            " However",
                            ",",
                            " the",
                            " interactive",
                            " consequences",
                            " of",
                            " the",
                            " two",
                            " drugs",
                            " are",
                            " still",
                            " unclear",
                            ".",
                            " In",
                            " this",
                            " study",
                            ",",
                            " we",
                            " treated",
                            " adult",
                            " male",
                            " mice",
                            " with",
                            " a",
                            " single",
                            " i",
                            ".",
                            "p",
                            ".",
                            " injection",
                            " of",
                            " saline",
                            ",",
                            " Amph",
                            " (",
                            "5",
                            " mg",
                            "/",
                            "kg",
                            "),",
                            " low",
                            " Ket",
                            " (",
                            "L",
                            "K",
                            ",",
                            " 10",
                            " mg",
                            "/",
                            "kg",
                            "),",
                            " high",
                            " Ket",
                            " (",
                            "HK",
                            ",",
                            " 50",
                            " mg",
                            "/",
                            "kg",
                            "),",
                            " or",
                            " Amph",
                            " and",
                            " L",
                            "K",
                            " or",
                            " HK",
                            " (",
                            "ALK",
                            " or",
                            " AH",
                            "K",
                            ")",
                            " and",
                            " examined",
                            " their",
                            " behavioral",
                            " and",
                            " neuro",
                            "chemical",
                            " changes",
                            " at",
                            " 0",
                            ".",
                            "5",
                            " and",
                            " 2",
                            " h",
                            " post",
                            "-",
                            "in",
                            "jection",
                            ".",
                            " Compared"
                        ],
                        "dataIndex": null,
                        "index": "43878",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.47,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            59.47,
                            0,
                            0,
                            0,
                            6.904,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.05,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.255,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:17:19.261Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 59.47,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6xrhxg3cii666n53bu4ai",
                        "tokens": [
                            "The",
                            " combined",
                            " ingestion",
                            " of",
                            " ket",
                            "amine",
                            " (",
                            "K",
                            "et",
                            ")",
                            " and",
                            " amp",
                            "hetamine",
                            " (",
                            "Am",
                            "ph",
                            ")",
                            " by",
                            " drug",
                            "-",
                            "users",
                            " has",
                            " been",
                            " rampant",
                            " and",
                            " produced",
                            " more",
                            " severe",
                            " behavioral",
                            " abnorm",
                            "ality",
                            ".",
                            " However",
                            ",",
                            " the",
                            " interactive",
                            " consequences",
                            " of",
                            " the",
                            " two",
                            " drugs",
                            " are",
                            " still",
                            " unclear",
                            ".",
                            " In",
                            " this",
                            " study",
                            ",",
                            " we",
                            " treated",
                            " adult",
                            " male",
                            " mice",
                            " with",
                            " a",
                            " single",
                            " i",
                            ".",
                            "p",
                            ".",
                            " injection",
                            " of",
                            " saline",
                            ",",
                            " Amph",
                            " (",
                            "5",
                            " mg",
                            "/",
                            "kg",
                            "),",
                            " low",
                            " Ket",
                            " (",
                            "L",
                            "K",
                            ",",
                            " 10",
                            " mg",
                            "/",
                            "kg",
                            "),",
                            " high",
                            " Ket",
                            " (",
                            "HK",
                            ",",
                            " 50",
                            " mg",
                            "/",
                            "kg",
                            "),",
                            " or",
                            " Amph",
                            " and",
                            " L",
                            "K",
                            " or",
                            " HK",
                            " (",
                            "ALK",
                            " or",
                            " AH",
                            "K",
                            ")",
                            " and",
                            " examined",
                            " their",
                            " behavioral",
                            " and",
                            " neuro",
                            "chemical",
                            " changes",
                            " at",
                            " 0",
                            ".",
                            "5",
                            " and",
                            " 2",
                            " h",
                            " post",
                            "-",
                            "in",
                            "jection",
                            ".",
                            " Compared"
                        ],
                        "dataIndex": null,
                        "index": "43878",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.47,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            59.47,
                            0,
                            0,
                            0,
                            6.904,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.05,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.255,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:17:19.261Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 59.47,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6xrhxg3cji666w7nhqg18",
                        "tokens": [
                            "The",
                            " combined",
                            " ingestion",
                            " of",
                            " ket",
                            "amine",
                            " (",
                            "K",
                            "et",
                            ")",
                            " and",
                            " amp",
                            "hetamine",
                            " (",
                            "Am",
                            "ph",
                            ")",
                            " by",
                            " drug",
                            "-",
                            "users",
                            " has",
                            " been",
                            " rampant",
                            " and",
                            " produced",
                            " more",
                            " severe",
                            " behavioral",
                            " abnorm",
                            "ality",
                            ".",
                            " However",
                            ",",
                            " the",
                            " interactive",
                            " consequences",
                            " of",
                            " the",
                            " two",
                            " drugs",
                            " are",
                            " still",
                            " unclear",
                            ".",
                            " In",
                            " this",
                            " study",
                            ",",
                            " we",
                            " treated",
                            " adult",
                            " male",
                            " mice",
                            " with",
                            " a",
                            " single",
                            " i",
                            ".",
                            "p",
                            ".",
                            " injection",
                            " of",
                            " saline",
                            ",",
                            " Amph",
                            " (",
                            "5",
                            " mg",
                            "/",
                            "kg",
                            "),",
                            " low",
                            " Ket",
                            " (",
                            "L",
                            "K",
                            ",",
                            " 10",
                            " mg",
                            "/",
                            "kg",
                            "),",
                            " high",
                            " Ket",
                            " (",
                            "HK",
                            ",",
                            " 50",
                            " mg",
                            "/",
                            "kg",
                            "),",
                            " or",
                            " Amph",
                            " and",
                            " L",
                            "K",
                            " or",
                            " HK",
                            " (",
                            "ALK",
                            " or",
                            " AH",
                            "K",
                            ")",
                            " and",
                            " examined",
                            " their",
                            " behavioral",
                            " and",
                            " neuro",
                            "chemical",
                            " changes",
                            " at",
                            " 0",
                            ".",
                            "5",
                            " and",
                            " 2",
                            " h",
                            " post",
                            "-",
                            "in",
                            "jection",
                            ".",
                            " Compared"
                        ],
                        "dataIndex": null,
                        "index": "43878",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.47,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            59.47,
                            0,
                            0,
                            0,
                            6.904,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.05,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.255,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:17:19.261Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 59.47,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "2442",
            "description": "phrases related to drug use involving snorting or inhaling substances",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5054335744808192,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "2442",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:18:28.890Z",
                "maxActApprox": 74.597,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    2442,
                    5906,
                    2358,
                    1103,
                    4071,
                    5412,
                    5318,
                    11046,
                    1216,
                    740,
                    2661,
                    11047,
                    351,
                    6952,
                    10881,
                    11417,
                    12182,
                    2296,
                    6707,
                    4388,
                    9531,
                    9773,
                    2046,
                    10232,
                    4865
                ],
                "topkCosSimValues": [
                    1,
                    0.4543,
                    0.3889,
                    0.3887,
                    0.3752,
                    0.3426,
                    0.3367,
                    0.3221,
                    0.3206,
                    0.3187,
                    0.3152,
                    0.3133,
                    0.3079,
                    0.3043,
                    0.3019,
                    0.2993,
                    0.2991,
                    0.2988,
                    0.2972,
                    0.2903,
                    0.2871,
                    0.2831,
                    0.2809,
                    0.2784,
                    0.2769
                ],
                "neuron_alignment_indices": [
                    0,
                    719,
                    129
                ],
                "neuron_alignment_values": [
                    0.112,
                    0.108,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    129,
                    326,
                    128
                ],
                "correlated_neurons_pearson": [
                    0.025,
                    0.025,
                    0.025
                ],
                "correlated_neurons_l1": [
                    0.025,
                    0.017,
                    0.024
                ],
                "correlated_features_indices": [
                    2505,
                    2536,
                    2556
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.002,
                    0.002
                ],
                "correlated_features_l1": [
                    0.009,
                    0.003,
                    0.002
                ],
                "neg_str": [
                    "heid",
                    "xual",
                    "shire",
                    " Britann",
                    " limited",
                    " Centauri",
                    "EMENT",
                    "upon",
                    "minus",
                    "FORM"
                ],
                "neg_values": [
                    -0.933,
                    -0.733,
                    -0.653,
                    -0.652,
                    -0.634,
                    -0.617,
                    -0.607,
                    -0.606,
                    -0.603,
                    -0.588
                ],
                "pos_str": [
                    "appy",
                    "ipes",
                    "agging",
                    "ugg",
                    "uggle",
                    "oot",
                    "apping",
                    "atches",
                    "atching",
                    "appers"
                ],
                "pos_values": [
                    1.264,
                    1.224,
                    1.203,
                    1.196,
                    1.162,
                    1.154,
                    1.134,
                    1.132,
                    1.128,
                    1.124
                ],
                "frac_nonzero": 0.00064,
                "freq_hist_data_bar_heights": [
                    747,
                    432,
                    264,
                    163,
                    102,
                    44,
                    34,
                    15,
                    10,
                    11,
                    10,
                    9,
                    2,
                    0,
                    0,
                    1,
                    5,
                    4,
                    3,
                    5,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    4,
                    1,
                    3,
                    2,
                    2,
                    3,
                    7,
                    7,
                    10,
                    9,
                    12,
                    12,
                    20,
                    25,
                    12,
                    16,
                    8,
                    6
                ],
                "freq_hist_data_bar_values": [
                    0.747,
                    2.239,
                    3.731,
                    5.222,
                    6.714,
                    8.206,
                    9.698,
                    11.19,
                    12.682,
                    14.174,
                    15.666,
                    17.158,
                    18.65,
                    20.142,
                    21.634,
                    23.126,
                    24.618,
                    26.109,
                    27.601,
                    29.093,
                    30.585,
                    32.077,
                    33.569,
                    35.061,
                    36.553,
                    38.045,
                    39.537,
                    41.029,
                    42.521,
                    44.013,
                    45.504,
                    46.996,
                    48.488,
                    49.98,
                    51.472,
                    52.964,
                    54.456,
                    55.948,
                    57.44,
                    58.932,
                    60.424,
                    61.916,
                    63.408,
                    64.9,
                    66.391,
                    67.883,
                    69.375,
                    70.867,
                    72.359,
                    73.851
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    3,
                    5,
                    13,
                    37,
                    92,
                    210,
                    392,
                    741,
                    1262,
                    1940,
                    2847,
                    3836,
                    4850,
                    5381,
                    5300,
                    4760,
                    4087,
                    3413,
                    2650,
                    1944,
                    1504,
                    1115,
                    857,
                    670,
                    493,
                    456,
                    324,
                    256,
                    221,
                    177,
                    129,
                    76,
                    67,
                    39,
                    23,
                    23,
                    18,
                    13,
                    12,
                    4,
                    7,
                    4,
                    2,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.911,
                    -0.867,
                    -0.823,
                    -0.779,
                    -0.735,
                    -0.691,
                    -0.647,
                    -0.603,
                    -0.559,
                    -0.515,
                    -0.471,
                    -0.428,
                    -0.384,
                    -0.34,
                    -0.296,
                    -0.252,
                    -0.208,
                    -0.164,
                    -0.12,
                    -0.076,
                    -0.032,
                    0.012,
                    0.056,
                    0.1,
                    0.144,
                    0.187,
                    0.231,
                    0.275,
                    0.319,
                    0.363,
                    0.407,
                    0.451,
                    0.495,
                    0.539,
                    0.583,
                    0.627,
                    0.671,
                    0.715,
                    0.759,
                    0.803,
                    0.846,
                    0.89,
                    0.934,
                    0.978,
                    1.022,
                    1.066,
                    1.11,
                    1.154,
                    1.198,
                    1.242
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases related to drug use involving snorting or inhaling substances",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtn3mh0suli666zehwaagg",
                        "tokens": [
                            " U",
                            ".",
                            "S",
                            ".",
                            " at",
                            " the",
                            " FDA",
                            "'s",
                            " behest",
                            " began",
                            " releasing",
                            " versions",
                            " of",
                            " their",
                            " opioid",
                            " drugs",
                            " that",
                            " users",
                            " could",
                            " not",
                            " easily",
                            " crush",
                            " and",
                            " then",
                            " sn",
                            "ort",
                            " or",
                            " inject",
                            ".",
                            " Back",
                            " in",
                            " the",
                            " hal",
                            "cy",
                            "on",
                            " days",
                            " of",
                            " the",
                            " opioid",
                            " crisis",
                            ",",
                            " when",
                            " more",
                            " Americans",
                            " were",
                            " dying",
                            " of",
                            " car",
                            " accidents",
                            " than",
                            " overdoses",
                            ",",
                            " crushing",
                            " and",
                            " sn",
                            "orting",
                            " opioids",
                            " was",
                            " the",
                            " most",
                            " popular",
                            " way",
                            " to",
                            " use",
                            " them",
                            " illicit",
                            "ly",
                            ".",
                            "\n",
                            "\n",
                            "Introdu",
                            "cing",
                            " tam",
                            "per",
                            "-",
                            "proof",
                            "ing",
                            " was",
                            " at",
                            " the",
                            " time",
                            " considered",
                            " a",
                            " huge",
                            " public",
                            " health",
                            " victory",
                            ".",
                            " \"",
                            "Some",
                            " of",
                            " the",
                            " most",
                            " widely",
                            " abused",
                            " drugs",
                            ",",
                            " including",
                            " Oxy",
                            "Contin",
                            ",",
                            " have",
                            " been",
                            " re",
                            "-",
                            "engine",
                            "ered",
                            " in",
                            " tam",
                            "per",
                            "-",
                            "resistant",
                            " formulations",
                            " and",
                            " introduced",
                            " in",
                            " place",
                            " of",
                            " their",
                            " original",
                            " versions",
                            ",\"",
                            " wrote",
                            " former",
                            " Sen",
                            ".",
                            " Tom"
                        ],
                        "dataIndex": null,
                        "index": "2442",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 74.597,
                        "maxValueTokenIndex": 24,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            74.597,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            70.058,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:18:29.900Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 74.597,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtn3mj0sv8i666v68gmd7r",
                        "tokens": [
                            " U",
                            ".",
                            "S",
                            ".",
                            " at",
                            " the",
                            " FDA",
                            "'s",
                            " behest",
                            " began",
                            " releasing",
                            " versions",
                            " of",
                            " their",
                            " opioid",
                            " drugs",
                            " that",
                            " users",
                            " could",
                            " not",
                            " easily",
                            " crush",
                            " and",
                            " then",
                            " sn",
                            "ort",
                            " or",
                            " inject",
                            ".",
                            " Back",
                            " in",
                            " the",
                            " hal",
                            "cy",
                            "on",
                            " days",
                            " of",
                            " the",
                            " opioid",
                            " crisis",
                            ",",
                            " when",
                            " more",
                            " Americans",
                            " were",
                            " dying",
                            " of",
                            " car",
                            " accidents",
                            " than",
                            " overdoses",
                            ",",
                            " crushing",
                            " and",
                            " sn",
                            "orting",
                            " opioids",
                            " was",
                            " the",
                            " most",
                            " popular",
                            " way",
                            " to",
                            " use",
                            " them",
                            " illicit",
                            "ly",
                            ".",
                            "\n",
                            "\n",
                            "Introdu",
                            "cing",
                            " tam",
                            "per",
                            "-",
                            "proof",
                            "ing",
                            " was",
                            " at",
                            " the",
                            " time",
                            " considered",
                            " a",
                            " huge",
                            " public",
                            " health",
                            " victory",
                            ".",
                            " \"",
                            "Some",
                            " of",
                            " the",
                            " most",
                            " widely",
                            " abused",
                            " drugs",
                            ",",
                            " including",
                            " Oxy",
                            "Contin",
                            ",",
                            " have",
                            " been",
                            " re",
                            "-",
                            "engine",
                            "ered",
                            " in",
                            " tam",
                            "per",
                            "-",
                            "resistant",
                            " formulations",
                            " and",
                            " introduced",
                            " in",
                            " place",
                            " of",
                            " their",
                            " original",
                            " versions",
                            ",\"",
                            " wrote",
                            " former",
                            " Sen",
                            ".",
                            " Tom"
                        ],
                        "dataIndex": null,
                        "index": "2442",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 74.597,
                        "maxValueTokenIndex": 24,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            74.597,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            70.058,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:18:29.900Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 59.678,
                        "binMax": 74.597,
                        "binContains": 4e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtn3mh0sumi666p1zucve4",
                        "tokens": [
                            "J",
                            "iri",
                            " Hud",
                            "ler",
                            " had",
                            " quite",
                            " the",
                            " flight",
                            " during",
                            " his",
                            " recent",
                            " trip",
                            " to",
                            " Europe",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " free",
                            "-",
                            "agent",
                            " NHL",
                            " forward",
                            " has",
                            " been",
                            " accused",
                            " by",
                            " the",
                            " Delta",
                            " Airlines",
                            " staff",
                            " of",
                            " behaving",
                            " bellig",
                            "erent",
                            "ly",
                            " during",
                            " his",
                            " flight",
                            " from",
                            " New",
                            " York",
                            " to",
                            " Prague",
                            ",",
                            " a",
                            " Czech",
                            " newspaper",
                            " reported",
                            " Wednesday",
                            ".",
                            "\n",
                            "\n",
                            "According",
                            " to",
                            " the",
                            " report",
                            ",",
                            " it",
                            " all",
                            " started",
                            " when",
                            " Hud",
                            "ler",
                            "'s",
                            " demand",
                            " for",
                            " \"",
                            "co",
                            "ke",
                            "\"",
                            " was",
                            " denied",
                            " by",
                            " a",
                            " flight",
                            " attendant",
                            " after",
                            " it",
                            " was",
                            " initially",
                            " presumed",
                            " that",
                            " his",
                            " request",
                            " was",
                            " in",
                            " reference",
                            " to",
                            " the",
                            " beverage",
                            ".",
                            " Hud",
                            "ler",
                            " then",
                            " threatened",
                            " to",
                            " have",
                            " the",
                            " woman",
                            " killed",
                            " by",
                            " his",
                            " friends",
                            " upon",
                            " their",
                            " arrival",
                            ".",
                            "\n",
                            "\n",
                            "Things",
                            " only",
                            " got",
                            " worse",
                            " from",
                            " there",
                            ".",
                            " Hud",
                            "ler",
                            " has",
                            " also",
                            " been",
                            " accused",
                            " of",
                            " sn",
                            "orting",
                            " cocaine"
                        ],
                        "dataIndex": null,
                        "index": "2442",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 74.156,
                        "maxValueTokenIndex": 124,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            74.156,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:18:29.900Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 74.597,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "84341",
            "description": " mentions of drug paraphernalia",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5053549854351604,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "84341",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:14:20.421Z",
                "maxActApprox": 47.302,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    84341,
                    82242,
                    6240,
                    7443,
                    73082,
                    95270,
                    61227,
                    15195,
                    16216,
                    36691,
                    12176,
                    9868,
                    76888,
                    244,
                    97167,
                    29839,
                    73904,
                    10286,
                    4120,
                    55842,
                    8713,
                    30536,
                    55397,
                    5557,
                    75998
                ],
                "topkCosSimValues": [
                    1,
                    0.5927,
                    0.41,
                    0.4005,
                    0.3767,
                    0.3619,
                    0.3541,
                    0.3381,
                    0.3322,
                    0.3301,
                    0.3285,
                    0.3251,
                    0.3241,
                    0.3236,
                    0.3189,
                    0.3171,
                    0.3159,
                    0.3155,
                    0.3137,
                    0.3116,
                    0.3108,
                    0.3076,
                    0.3022,
                    0.2996,
                    0.2994
                ],
                "neuron_alignment_indices": [
                    649,
                    288,
                    301
                ],
                "neuron_alignment_values": [
                    0.173,
                    0.124,
                    0.116
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    591,
                    332,
                    649
                ],
                "correlated_neurons_pearson": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_features_indices": [
                    84341,
                    84319,
                    84401
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "\u00c4\u0141",
                    "\u00d8\u00a7\u00d9\u0126",
                    "erred",
                    " Jiu",
                    "Duration",
                    "unct",
                    "0000000",
                    "EED",
                    " Phi",
                    "EFF"
                ],
                "neg_values": [
                    -0.811,
                    -0.671,
                    -0.66,
                    -0.651,
                    -0.64,
                    -0.632,
                    -0.624,
                    -0.606,
                    -0.592,
                    -0.589
                ],
                "pos_str": [
                    "obyl",
                    "alia",
                    "atural",
                    "opol",
                    "abilia",
                    "ophon",
                    "igan",
                    "iece",
                    "oval",
                    "algia"
                ],
                "pos_values": [
                    1.302,
                    1.222,
                    1.07,
                    0.965,
                    0.874,
                    0.872,
                    0.828,
                    0.787,
                    0.785,
                    0.784
                ],
                "frac_nonzero": 1e-05,
                "freq_hist_data_bar_heights": [
                    7,
                    3,
                    0,
                    2,
                    0,
                    1,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    3,
                    0,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.498,
                    1.443,
                    2.389,
                    3.334,
                    4.28,
                    5.226,
                    6.171,
                    7.117,
                    8.062,
                    9.008,
                    9.953,
                    10.899,
                    11.844,
                    12.79,
                    13.735,
                    14.681,
                    15.626,
                    16.572,
                    17.517,
                    18.463,
                    19.408,
                    20.354,
                    21.3,
                    22.245,
                    23.191,
                    24.136,
                    25.082,
                    26.027,
                    26.973,
                    27.918,
                    28.864,
                    29.809,
                    30.755,
                    31.7,
                    32.646,
                    33.591,
                    34.537,
                    35.482,
                    36.428,
                    37.374,
                    38.319,
                    39.265,
                    40.21,
                    41.156,
                    42.101,
                    43.047,
                    43.992,
                    44.938,
                    45.883,
                    46.829
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    3,
                    4,
                    7,
                    18,
                    37,
                    83,
                    172,
                    314,
                    577,
                    1026,
                    1729,
                    2575,
                    3583,
                    4637,
                    5380,
                    5600,
                    5261,
                    4733,
                    3867,
                    3014,
                    2148,
                    1529,
                    1153,
                    834,
                    605,
                    408,
                    308,
                    233,
                    156,
                    93,
                    74,
                    40,
                    24,
                    11,
                    13,
                    1,
                    2,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.79,
                    -0.747,
                    -0.705,
                    -0.663,
                    -0.621,
                    -0.578,
                    -0.536,
                    -0.494,
                    -0.452,
                    -0.409,
                    -0.367,
                    -0.325,
                    -0.283,
                    -0.24,
                    -0.198,
                    -0.156,
                    -0.114,
                    -0.071,
                    -0.029,
                    0.013,
                    0.056,
                    0.098,
                    0.14,
                    0.182,
                    0.225,
                    0.267,
                    0.309,
                    0.351,
                    0.394,
                    0.436,
                    0.478,
                    0.52,
                    0.563,
                    0.605,
                    0.647,
                    0.689,
                    0.732,
                    0.774,
                    0.816,
                    0.858,
                    0.901,
                    0.943,
                    0.985,
                    1.027,
                    1.07,
                    1.112,
                    1.154,
                    1.196,
                    1.239,
                    1.281
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " mentions of drug paraphernalia",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "terms related to illegal substances and addiction",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygio62o39ib10ex8dkm1zd9",
                        "tokens": [
                            "\n",
                            "\n",
                            "\"",
                            "C",
                            "hern",
                            "obyl",
                            " was",
                            " a",
                            " good",
                            " place",
                            " to",
                            " hide",
                            ".",
                            " But",
                            " it",
                            " wasn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " a",
                            " good",
                            " place",
                            " to",
                            " heal",
                            ",",
                            " especially",
                            " for",
                            " someone",
                            " who",
                            " already",
                            " suffered",
                            " from",
                            " depression",
                            ".",
                            " She",
                            " wasn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " happy",
                            " with",
                            " her",
                            " new",
                            " tree",
                            "\u2013",
                            "in",
                            " one",
                            " of",
                            " her",
                            " more",
                            " lucid",
                            " moments",
                            ",",
                            " she",
                            " really",
                            " che",
                            "wed",
                            " me",
                            " out",
                            " for",
                            " the",
                            " arrogance",
                            " of",
                            " daring",
                            " to",
                            " pick",
                            " a",
                            " tree",
                            " for",
                            " her",
                            ".",
                            " I",
                            " asked",
                            " what",
                            " I",
                            " was",
                            " supposed",
                            " to",
                            " have",
                            " done",
                            ",",
                            " and",
                            " she",
                            " said",
                            " I",
                            " should",
                            " have",
                            " let",
                            " her",
                            " die",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "O",
                            "uch",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Yeah",
                            ".",
                            " I",
                            " did",
                            " what",
                            " I",
                            " could",
                            " to",
                            " help",
                            " her",
                            ",",
                            " but",
                            " it",
                            " wasn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " much",
                            ".",
                            " I",
                            " arranged"
                        ],
                        "dataIndex": null,
                        "index": "84341",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 47.302,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            47.302,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:24.905Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 47.302,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygio62q39iw10ex10cxlzi7",
                        "tokens": [
                            "\n",
                            "\n",
                            "\"",
                            "C",
                            "hern",
                            "obyl",
                            " was",
                            " a",
                            " good",
                            " place",
                            " to",
                            " hide",
                            ".",
                            " But",
                            " it",
                            " wasn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " a",
                            " good",
                            " place",
                            " to",
                            " heal",
                            ",",
                            " especially",
                            " for",
                            " someone",
                            " who",
                            " already",
                            " suffered",
                            " from",
                            " depression",
                            ".",
                            " She",
                            " wasn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " happy",
                            " with",
                            " her",
                            " new",
                            " tree",
                            "\u2013",
                            "in",
                            " one",
                            " of",
                            " her",
                            " more",
                            " lucid",
                            " moments",
                            ",",
                            " she",
                            " really",
                            " che",
                            "wed",
                            " me",
                            " out",
                            " for",
                            " the",
                            " arrogance",
                            " of",
                            " daring",
                            " to",
                            " pick",
                            " a",
                            " tree",
                            " for",
                            " her",
                            ".",
                            " I",
                            " asked",
                            " what",
                            " I",
                            " was",
                            " supposed",
                            " to",
                            " have",
                            " done",
                            ",",
                            " and",
                            " she",
                            " said",
                            " I",
                            " should",
                            " have",
                            " let",
                            " her",
                            " die",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "O",
                            "uch",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Yeah",
                            ".",
                            " I",
                            " did",
                            " what",
                            " I",
                            " could",
                            " to",
                            " help",
                            " her",
                            ",",
                            " but",
                            " it",
                            " wasn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " much",
                            ".",
                            " I",
                            " arranged"
                        ],
                        "dataIndex": null,
                        "index": "84341",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 47.302,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            47.302,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:24.905Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 37.841,
                        "binMax": 47.302,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygio62o39ic10exmdk7q0so",
                        "tokens": [
                            "\u013f",
                            " which",
                            " was",
                            " covered",
                            " in",
                            " season",
                            " one",
                            " by",
                            " Todd",
                            " Griffin",
                            " before",
                            " Cheap",
                            " Trick",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " version",
                            " kicked",
                            " things",
                            " off",
                            " starting",
                            " in",
                            " season",
                            " two",
                            ".",
                            " With",
                            " the",
                            " name",
                            " of",
                            " the",
                            " show",
                            " in",
                            " mind",
                            ",",
                            " Ch",
                            "ilton",
                            " found",
                            " the",
                            " dollar",
                            " amount",
                            " ironic",
                            ".",
                            "\n",
                            "\n",
                            "9",
                            ".",
                            " L",
                            "EO",
                            " WAS",
                            " WR",
                            "ITT",
                            "EN",
                            " WITH",
                            " TOM",
                            "MY",
                            " CH",
                            "ONG",
                            " IN",
                            " M",
                            "IND",
                            ".",
                            "\n",
                            "\n",
                            "Ch",
                            "ong",
                            " claimed",
                            " in",
                            " 2003",
                            " that",
                            " his",
                            " st",
                            "oner",
                            " character",
                            " Leo",
                            " was",
                            " starting",
                            " to",
                            " get",
                            " written",
                            " out",
                            " more",
                            " because",
                            " of",
                            " 9",
                            "/",
                            "11",
                            ".",
                            " After",
                            " disappearing",
                            " for",
                            " a",
                            " few",
                            " seasons",
                            " while",
                            " serving",
                            " a",
                            " jail",
                            " sentence",
                            " for",
                            " selling",
                            " \u00e2\u0122",
                            "\u013e",
                            "drug",
                            " parap",
                            "hern",
                            "alia",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Mickey",
                            " \u00e2\u0122",
                            "\u013e",
                            "Le",
                            "o",
                            "\u00e2\u0122",
                            "\u013f",
                            " Ch",
                            "ing",
                            "kw",
                            "ake",
                            " returned",
                            ",",
                            " and",
                            " was",
                            " credited",
                            " as",
                            " a"
                        ],
                        "dataIndex": null,
                        "index": "84341",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.221,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.221,
                            6.343,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:24.905Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 47.302,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}