{
    "modelId": "llama3.1-8b",
    "layer": "29-eleuther_gp-res-262k",
    "index": "34399",
    "sourceSetName": "eleuther_gp-res-262k",
    "creatorId": "cljj57d3c000076ei38vwnv35",
    "createdAt": "2024-11-04T18:22:31.206Z",
    "maxActApprox": 0,
    "hasVector": false,
    "vector": [],
    "vectorLabel": null,
    "vectorDefaultSteerStrength": 10,
    "hookName": null,
    "topkCosSimIndices": [],
    "topkCosSimValues": [],
    "neuron_alignment_indices": [],
    "neuron_alignment_values": [],
    "neuron_alignment_l1": [],
    "correlated_neurons_indices": [],
    "correlated_neurons_pearson": [],
    "correlated_neurons_l1": [],
    "correlated_features_indices": [],
    "correlated_features_pearson": [],
    "correlated_features_l1": [],
    "neg_str": [],
    "neg_values": [],
    "pos_str": [],
    "pos_values": [],
    "frac_nonzero": 0,
    "freq_hist_data_bar_heights": [],
    "freq_hist_data_bar_values": [],
    "logits_hist_data_bar_heights": [],
    "logits_hist_data_bar_values": [],
    "decoder_weights_dist": [],
    "umap_cluster": null,
    "umap_log_feature_sparsity": null,
    "umap_x": null,
    "umap_y": null,
    "model": {
        "id": "llama3.1-8b",
        "displayNameShort": "LLAMA3.1-8B",
        "displayName": "Llama3.1-8B",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "tlensId": "meta-llama/Llama-3.1-8B",
        "dimension": 4096,
        "visibility": "PUBLIC",
        "inferenceEnabled": true,
        "instruct": false,
        "layers": 32,
        "neuronsPerLayer": 14336,
        "createdAt": "2024-05-16T23:51:14.848Z",
        "owner": "Meta",
        "updatedAt": "2024-05-16T23:51:14.848Z",
        "website": null
    },
    "lists": [],
    "creator": {
        "name": "bot-activations"
    },
    "source": {
        "id": "29-eleuther_gp-res-262k",
        "modelId": "llama3.1-8b",
        "hasDashboards": true,
        "inferenceEnabled": false,
        "saelensConfig": null,
        "saelensRelease": null,
        "saelensSaeId": null,
        "hfRepoId": "EleutherAI/sae-llama-3.1-8b-64x",
        "hfFolderId": "layers.29",
        "visibility": "PUBLIC",
        "setName": "eleuther_gp-res-262k",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "hasUmap": false,
        "hasUmapLogSparsity": false,
        "hasUmapClusters": false,
        "num_prompts": 39039,
        "num_tokens_in_prompt": 32,
        "dataset": "EleutherAI/rpj-v2-sample",
        "notes": null,
        "createdAt": "2024-11-04T20:56:09.889Z"
    },
    "sourceSet": {
        "modelId": "llama3.1-8b",
        "name": "eleuther_gp-res-262k",
        "hasDashboards": true,
        "visibility": "PUBLIC",
        "description": "Multi TopK SAE for Llama3.1-8B",
        "type": "Residual Stream - 262k",
        "creatorName": "EleutherAI",
        "urls": [],
        "creatorEmail": null,
        "creatorId": "cljgamm90000076zdchicy6zj",
        "releaseName": "llama3.1-8b-eleuther_gp",
        "defaultRange": 1,
        "defaultShowBreaks": false,
        "showDfa": false,
        "showCorrelated": false,
        "showHeadAttribution": false,
        "showUmap": false,
        "createdAt": "2024-08-09T16:00:45.527Z"
    },
    "activations": [],
    "explanations": [
        {
            "id": "tvnqy0vxp99ry1he513abbbg1",
            "description": "The token \"sac\" or \"acr\" often appears as part of a word related to something considered sacred or holy, such as \"sacrament\", \"sacrilegious\", or \"sacred\".",
            "explanationModelName": "llama-3.1-70b-instruct",
            "typeName": "eleuther_acts",
            "scores": []
        }
    ]
}