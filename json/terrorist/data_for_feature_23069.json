{
    "modelId": "gpt2-small",
    "layer": "1-res-jb",
    "index": "23069",
    "sourceSetName": "res-jb",
    "creatorId": null,
    "createdAt": "2024-02-09T23:22:03.027Z",
    "maxActApprox": 41.65463638305664,
    "hasVector": false,
    "vector": [],
    "vectorLabel": null,
    "vectorDefaultSteerStrength": 10,
    "hookName": null,
    "topkCosSimIndices": [
        23069,
        7198,
        4774,
        20406,
        15323,
        670,
        4766,
        16176,
        5819,
        7616,
        17521,
        13351,
        15177,
        16840,
        9983,
        11392,
        5290,
        10995,
        2466,
        8624,
        12818,
        12500,
        22571,
        8074,
        21762
    ],
    "topkCosSimValues": [
        1,
        0.5589,
        0.5226,
        0.509,
        0.4449,
        0.4445,
        0.4402,
        0.4352,
        0.4327,
        0.4193,
        0.417,
        0.4154,
        0.4131,
        0.4014,
        0.3945,
        0.3939,
        0.3896,
        0.3885,
        0.3811,
        0.3811,
        0.3788,
        0.3755,
        0.3742,
        0.3722,
        0.3694
    ],
    "neuron_alignment_indices": [
        288,
        566,
        289
    ],
    "neuron_alignment_values": [
        0.293187141418457,
        0.116915188729763,
        0.1145090609788895
    ],
    "neuron_alignment_l1": [
        0.0143332788720727,
        0.005715728271752596,
        0.005598098039627075
    ],
    "correlated_neurons_indices": [
        658,
        621,
        289
    ],
    "correlated_neurons_pearson": [
        0.00986285787075758,
        0.009386351332068443,
        0.008409983478486538
    ],
    "correlated_neurons_l1": [
        0.009649652987718582,
        0.009611218236386776,
        0.007668364327400923
    ],
    "correlated_features_indices": [],
    "correlated_features_pearson": [],
    "correlated_features_l1": [],
    "neg_str": [
        "hetti",
        "packing",
        "ships",
        " Chrom",
        "phrine",
        "Acknowled",
        "maid",
        " Wiley",
        "tumblr",
        "nesota"
    ],
    "neg_values": [
        -0.7784937620162964,
        -0.6890025734901428,
        -0.6587541699409485,
        -0.6502296924591064,
        -0.6477577090263367,
        -0.6307423114776611,
        -0.6257391571998596,
        -0.6226557493209839,
        -0.6210771799087524,
        -0.6208926439285278
    ],
    "pos_str": [
        " Daesh",
        "rolet",
        "ignty",
        " Beir",
        "renheit",
        "sov",
        "merga",
        "anie",
        "ISIS",
        "imi"
    ],
    "pos_values": [
        1.420959115028381,
        0.850699245929718,
        0.8371223211288452,
        0.8211454749107361,
        0.7530646324157715,
        0.7469066977500916,
        0.7356109023094177,
        0.7296401262283325,
        0.7221769094467163,
        0.718487024307251
    ],
    "frac_nonzero": 4.482269287109375e-05,
    "freq_hist_data_bar_heights": [
        46,
        31,
        29,
        12,
        1,
        9,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        6,
        3,
        3
    ],
    "freq_hist_data_bar_values": [
        0.5227088332176208,
        1.564023494720459,
        2.605338096618652,
        3.646652698516846,
        4.687967300415039,
        5.729281425476074,
        6.770596504211426,
        7.811910629272461,
        8.853225708007812,
        9.894540786743164,
        10.9358549118042,
        11.97716903686523,
        13.01848411560059,
        14.05979919433594,
        15.10111331939697,
        16.14242744445801,
        17.18374252319336,
        18.22505760192871,
        19.26637268066406,
        20.30768585205078,
        21.34900093078613,
        22.39031600952148,
        23.4316291809082,
        24.47294425964355,
        25.51425933837891,
        26.55557441711426,
        27.59688949584961,
        28.63820266723633,
        29.67951774597168,
        30.72083282470703,
        31.76214599609375,
        32.80346298217773,
        33.84477615356445,
        34.88608932495117,
        35.92740631103516,
        36.96871948242188,
        38.01003646850586,
        39.05134963989258,
        40.0926628112793,
        41.13397979736328
    ],
    "logits_hist_data_bar_heights": [
        1,
        1,
        12,
        19,
        64,
        132,
        304,
        625,
        1185,
        2027,
        3257,
        4541,
        5625,
        6595,
        6494,
        5829,
        4801,
        3389,
        2263,
        1405,
        785,
        484,
        205,
        116,
        54,
        24,
        10,
        6,
        0,
        3,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1
    ],
    "logits_hist_data_bar_values": [
        -0.7510005831718445,
        -0.6960142850875854,
        -0.6410279273986816,
        -0.5860416293144226,
        -0.5310552716255188,
        -0.4760690033435822,
        -0.4210827052593231,
        -0.3660963773727417,
        -0.3111100494861603,
        -0.2561237215995789,
        -0.2011373788118362,
        -0.1461510807275772,
        -0.09116478264331818,
        -0.03617842867970467,
        0.01880786940455437,
        0.07379423081874847,
        0.1287805289030075,
        0.1837668269872665,
        0.2387531846761703,
        0.2937394678592682,
        0.348725825548172,
        0.4037121832370758,
        0.4586984813213348,
        0.513684868812561,
        0.5686711668968201,
        0.6236574649810791,
        0.6786438226699829,
        0.7336301207542419,
        0.7886164784431458,
        0.8436027765274048,
        0.8985890746116638,
        0.9535754323005676,
        1.008561730384827,
        1.063547968864441,
        1.118534326553345,
        1.173520684242249,
        1.228506922721863,
        1.283493280410767,
        1.33847963809967,
        1.393465876579285
    ],
    "decoder_weights_dist": [],
    "umap_cluster": null,
    "umap_log_feature_sparsity": null,
    "umap_x": null,
    "umap_y": null,
    "model": {
        "id": "gpt2-small",
        "displayNameShort": "GPT2-SM",
        "displayName": "GPT2-Small",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "tlensId": null,
        "dimension": 768,
        "visibility": "PUBLIC",
        "inferenceEnabled": true,
        "instruct": false,
        "layers": 12,
        "neuronsPerLayer": 3072,
        "createdAt": "2023-07-06T00:01:44.843Z",
        "owner": "OpenAI",
        "updatedAt": "2023-07-06T00:01:44.843Z",
        "website": "https://openai.com"
    },
    "lists": [],
    "creator": null,
    "source": {
        "id": "1-res-jb",
        "modelId": "gpt2-small",
        "hasDashboards": true,
        "inferenceEnabled": true,
        "saelensConfig": {
            "lr": 0.0004,
            "d_in": 768,
            "seed": 42,
            "d_sae": 24576,
            "dtype": "torch.float32",
            "device": "mps",
            "run_name": "24576-L1-8e-05-LR-0.0004-Tokens-3.000e+08",
            "hook_point": "blocks.1.hook_resid_pre",
            "model_name": "gpt2-small",
            "prepend_bos": true,
            "architecture": "standard",
            "context_size": 128,
            "dataset_path": "Skylion007/openwebtext",
            "log_to_wandb": true,
            "wandb_entity": null,
            "n_checkpoints": 10,
            "wandb_project": "mats_sae_training_gpt2_small_resid_pre_5",
            "l1_coefficient": 8e-05,
            "neuronpedia_id": "gpt2-small/1-res-jb",
            "checkpoint_path": "checkpoints/mm179kd2",
            "use_ghost_grads": false,
            "expansion_factor": 32,
            "hook_point_layer": 1,
            "lr_warm_up_steps": 5000,
            "resample_batches": 1028,
            "store_batch_size": 32,
            "train_batch_size": 4096,
            "activation_fn_str": "relu",
            "b_dec_init_method": "geometric_median",
            "lr_scheduler_name": null,
            "tokens_per_buffer": 67108864,
            "dead_feature_window": 5000,
            "n_batches_in_buffer": 128,
            "wandb_log_frequency": 100,
            "apply_b_dec_to_input": true,
            "feature_reinit_scale": 0.2,
            "from_pretrained_path": null,
            "is_dataset_tokenized": false,
            "hook_point_head_index": null,
            "normalize_activations": "none",
            "total_training_tokens": 300000000,
            "dead_feature_threshold": 1e-08,
            "use_cached_activations": false,
            "cached_activations_path": "activations/Skylion007_openwebtext/gpt2-small/blocks.1.hook_resid_pre",
            "feature_sampling_method": null,
            "feature_sampling_window": 1000,
            "dataset_trust_remote_code": true,
            "finetuning_scaling_factor": false,
            "sae_lens_training_version": null,
            "model_from_pretrained_kwargs": {
                "center_writing_weights": true
            },
            "dead_feature_estimation_method": "no_fire"
        },
        "saelensRelease": "gpt2-small-res-jb",
        "saelensSaeId": "blocks.1.hook_resid_pre",
        "hfRepoId": "jbloom/GPT2-Small-SAEs-Reformatted",
        "hfFolderId": "blocks.1.hook_resid_pre",
        "visibility": "PUBLIC",
        "setName": "res-jb",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "hasUmap": true,
        "hasUmapLogSparsity": true,
        "hasUmapClusters": true,
        "num_prompts": 24576,
        "num_tokens_in_prompt": 128,
        "dataset": "Skylion007/openwebtext",
        "notes": null,
        "createdAt": "2024-07-10T04:46:32.069Z"
    },
    "sourceSet": {
        "modelId": "gpt2-small",
        "name": "res-jb",
        "hasDashboards": true,
        "visibility": "PUBLIC",
        "description": "Open Source Sparse Autoencoders for all Residual Stream Layers of GPT2-Small",
        "type": "Residual Stream",
        "creatorName": "Joseph Bloom",
        "urls": [
            "https://www.lesswrong.com/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream",
            "https://huggingface.co/jbloom/GPT2-Small-SAEs/tree/main",
            "https://github.com/jbloomAus/mats_sae_training"
        ],
        "creatorEmail": null,
        "creatorId": "cljgamm90000076zdchicy6zj",
        "releaseName": "gpt2sm-res-jb",
        "defaultRange": 2,
        "defaultShowBreaks": true,
        "showDfa": false,
        "showCorrelated": false,
        "showHeadAttribution": false,
        "showUmap": true,
        "serverHost": "https://1ynud2kk7vnhjo-5002.proxy.runpod.net",
        "createdAt": "2024-07-10T04:46:32.075Z"
    },
    "activations": [
        {
            "id": "clsf9vghoqvium2qvr88knfdj",
            "tokens": [
                ",",
                " you",
                "'re",
                "<|endoftext|>",
                " unit",
                " repe",
                "lled",
                " a",
                " Daesh",
                " militant",
                " assault",
                ",",
                " killing",
                " scores",
                " of",
                " the",
                " terrorists"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 41.65463638305664,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                41.65463638305664,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.612199306488037,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \" Beir\", \"ignty\", \"renheit\"], \"v\": [12.039770126342773, 4.047104835510254, 3.9233474731445312, 3.333242416381836, 1.8454227447509766]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Chrom\", \"hetti\", \"packing\", \"phrine\", \"maid\"], \"v\": [-20.12678337097168, -20.121379852294922, -20.050033569335938, -19.88919448852539, -19.498958587646484]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghoqvivm2qvt6xxowb8",
            "tokens": [
                " carry",
                " out",
                " airstrikes",
                " against",
                " a",
                " large",
                " group",
                " of",
                " Daesh",
                " terrorists",
                " advancing",
                " to",
                " the",
                " east",
                " of",
                " Pal",
                "myra"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 41.39764022827148,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                41.39764022827148,
                0,
                0,
                0,
                0.05268341302871704,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.575506210327148,
                0,
                0,
                0,
                -0.002608299255371094,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \"ignty\", \" Beir\", \"sov\"], \"v\": [11.766254425048828, 5.3580322265625, 3.7549076080322266, 2.4008779525756836, 1.4447107315063477]}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \"ignty\", \" Beir\", \"renheit\"], \"v\": [0.043476104736328125, 0.026767730712890625, 0.026536941528320312, 0.02613067626953125, 0.024087905883789062]}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"packing\", \" Chrom\", \"hetti\", \" Bucks\", \" Circuit\"], \"v\": [-23.442665100097656, -23.10572052001953, -23.099401473999023, -22.643396377563477, -22.60702133178711]}, {}, {}, {}, {\"t\": [\"hetti\", \"packing\", \"ships\", \"phrine\", \" Chrom\"], \"v\": [-0.020380020141601562, -0.01760101318359375, -0.01674652099609375, -0.016523361206054688, -0.016414642333984375]}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghoqviwm2qvkve0d58m",
            "tokens": [
                " helicopter",
                " repe",
                "lled",
                " the",
                " attack",
                " of",
                " a",
                " large",
                " Daesh",
                " group",
                " of",
                " fighters",
                " on",
                " the",
                " Syrian",
                " government",
                " forces"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 40.70547485351562,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                40.70547485351562,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                10.57650756835938,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \"ignty\", \" Beir\", \"sov\"], \"v\": [13.116004943847656, 6.045892715454102, 5.4306745529174805, 3.319683074951172, 2.1706924438476562]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"packing\", \"hetti\", \" Circuit\", \" Bucks\", \" Chrom\"], \"v\": [-22.712825775146484, -22.076122283935547, -21.92669105529785, -21.862812042236328, -21.746784210205078]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghoqvixm2qvisxrf7ah",
            "tokens": [
                "<|endoftext|>",
                "The",
                " Russian",
                " Defense",
                " Ministry",
                " said",
                " Saturday",
                " that",
                " Daesh",
                " terrorists",
                " shot",
                " down",
                " a",
                " helicopter",
                " near",
                " Syria",
                "'s"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 40.41902160644531,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                40.41902160644531,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.3604946136474609,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \"ignty\", \" Beir\", \"renheit\"], \"v\": [13.290423393249512, 5.584827423095703, 5.102160453796387, 3.6138553619384766, 2.5896730422973633]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"packing\", \"hetti\", \" Chrom\", \"maid\", \" Circuit\"], \"v\": [-22.891014099121094, -22.2047176361084, -21.461801528930664, -21.031925201416016, -20.94567108154297]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghoqviym2qvu73mx24t",
            "tokens": [
                " of",
                " evidence",
                " of",
                " the",
                " horrific",
                " mass",
                " murder",
                " by",
                " Daesh",
                " of",
                " former",
                " law",
                " enforcement",
                " officers",
                " in",
                " and",
                " around"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 40.14429092407227,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                40.14429092407227,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                12.58626556396484,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"ignty\", \"rolet\", \" Beir\", \"renheit\"], \"v\": [14.40766716003418, 6.486042022705078, 5.867762565612793, 3.9053878784179688, 3.0326099395751953]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"packing\", \"hetti\", \"maid\", \" Rabbit\", \" Chrom\"], \"v\": [-23.236671447753906, -22.825937271118164, -22.060094833374023, -21.861845016479492, -21.76144027709961]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghoqvizm2qvtq0wcopx",
            "tokens": [
                " A",
                " UN",
                " official",
                " said",
                " the",
                " next",
                " day",
                " that",
                " Daesh",
                " had",
                " abducted",
                " 295",
                " former",
                " members",
                " of",
                " Iraqi",
                " security"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 39.75315856933594,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                39.75315856933594,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                10.61745262145996,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \"ignty\", \" Beir\", \"sov\"], \"v\": [11.071855545043945, 4.644927978515625, 3.102306365966797, 2.6117563247680664, 1.0490407943725586]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"packing\", \" Chrom\", \"hetti\", \"pired\", \" Circuit\"], \"v\": [-22.691986083984375, -21.935930252075195, -21.80712127685547, -21.57827377319336, -21.479074478149414]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghoqvj0m2qv04u4yxh9",
            "tokens": [
                "Human",
                " Rights",
                " Watch",
                " (",
                "HR",
                "W",
                ")",
                " says",
                " Daesh",
                " terrorists",
                " have",
                " executed",
                " more",
                " than",
                " 300",
                " former",
                " Iraqi"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 39.17916870117188,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                39.17916870117188,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.3255157470703125,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \" Beir\", \"ignty\", \"renheit\"], \"v\": [12.015612602233887, 4.436744689941406, 3.317403793334961, 2.966280937194824, 1.7639150619506836]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Chrom\", \"hetti\", \"packing\", \"ships\", \"Shot\"], \"v\": [-21.03904914855957, -20.626754760742188, -20.58918571472168, -19.944355010986328, -19.839183807373047]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghoqvj1m2qv1e29xcqh",
            "tokens": [
                " while",
                " allegedly",
                " fighting",
                " with",
                " Pesh",
                "merga",
                " forces",
                " against",
                " Daesh",
                " (",
                "Islamic",
                " State",
                "),",
                "\u00e2\u0122",
                "\u013f",
                " Defence",
                " said"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 39.12419509887695,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                39.12419509887695,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                10.20544338226318,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \"ignty\", \" Beir\", \"atform\"], \"v\": [12.26320743560791, 5.593147277832031, 4.397819519042969, 2.265557289123535, 1.8085784912109375]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"hetti\", \"packing\", \" Chrom\", \"maid\", \" Circuit\"], \"v\": [-23.35170555114746, -23.219951629638672, -22.44658851623535, -22.26633071899414, -22.2414493560791]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghoqvj2m2qv4dytc80w",
            "tokens": [
                " retake",
                " Mosul",
                ",",
                " the",
                " last",
                " stronghold",
                " of",
                " the",
                " Daesh",
                " terrorists",
                " in",
                " the",
                " country",
                ".",
                "\u010a",
                "\u010a",
                "On"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 38.94865417480469,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                38.94865417480469,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.4354419708251953,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \"ignty\", \" Beir\", \"sov\"], \"v\": [13.340831756591797, 6.24411678314209, 5.542532920837402, 3.6023664474487305, 3.13614559173584]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"packing\", \"hetti\", \" Bucks\", \" Rabbit\", \" Circuit\"], \"v\": [-21.17717170715332, -20.330713272094727, -20.191143035888672, -20.150043487548828, -20.098604202270508]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghoqvj3m2qvf0j7qbew",
            "tokens": [
                " with",
                " far",
                " more",
                " geopolitical",
                " import",
                " and",
                " risk",
                ".",
                " Daesh",
                " [",
                "ISIS",
                "]",
                " is",
                " expected",
                " to",
                " make",
                " its"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 38.86209487915039,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                38.86209487915039,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                9.293327331542969,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \"ignty\", \" Beir\", \"nikov\"], \"v\": [12.164436340332031, 5.03095817565918, 4.465305328369141, 3.3110532760620117, 1.8473777770996094]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"packing\", \" Chrom\", \"hetti\", \" Fly\", \"Shot\"], \"v\": [-22.95231056213379, -22.587730407714844, -22.549882888793945, -21.857017517089844, -21.855810165405273]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghoqvj4m2qvcm9hc1wm",
            "tokens": [
                "nd",
                " Division",
                " run",
                " for",
                " cover",
                " under",
                " fire",
                " from",
                " Daesh",
                " militants",
                " as",
                " they",
                " push",
                " into",
                " the",
                " Aden",
                " neighborhood"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 38.55131912231445,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                38.55131912231445,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.693865776062012,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \"ignty\", \" Beir\", \"sov\"], \"v\": [12.035056114196777, 5.9457550048828125, 4.459392547607422, 2.4631309509277344, 1.9442529678344727]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"packing\", \" Circuit\", \"hetti\", \" Bucks\", \" Chrom\"], \"v\": [-22.12380027770996, -21.504119873046875, -21.419605255126953, -21.369720458984375, -21.316247940063477]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghoqvj5m2qv9iald8oy",
            "tokens": [
                " by",
                " name",
                ")",
                " as",
                " a",
                " minority",
                " opinion",
                " (",
                "Da",
                "'",
                "as",
                " Y",
                "ach",
                "id",
                ")",
                " that",
                " should"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 6.642125129699707,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.642125129699707,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.8806705474853516,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \" Beir\", \"ignty\", \"sov\"], \"v\": [3.014406204223633, 1.3255157470703125, 1.3049564361572266, 1.185546875, 1.1462173461914062]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"Wheel\", \"maid\", \"hetti\", \" Circuit\", \" Chrom\"], \"v\": [-3.013948440551758, -2.9994735717773438, -2.9931869506835938, -2.985471725463867, -2.975849151611328]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvj6m2qvmrylnrkw",
            "tokens": [
                " 8",
                "01",
                " \u00e2\u0122\u0135",
                " 8",
                "15",
                " .",
                "\u010a",
                "\u010a",
                "Da",
                "al",
                "der",
                " ,",
                " I",
                "vo",
                " .",
                " 2000",
                " ."
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 6.1800217628479,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.1800217628479,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.9625701904296875,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \" Beir\", \"ignty\", \"renheit\"], \"v\": [3.0656166076660156, 1.310628890991211, 1.24517822265625, 1.2112808227539062, 1.1568012237548828]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"hetti\", \"Wheel\", \" Circuit\", \" Fly\", \"maid\"], \"v\": [-3.0630264282226562, -3.0107650756835938, -3.0091209411621094, -3.0035877227783203, -2.9857826232910156]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvj7m2qvcgxgq0zn",
            "tokens": [
                " St",
                " Anthony",
                "-",
                "in",
                "-",
                "Rose",
                "land",
                ",",
                " Cornwall",
                ".",
                " He",
                " enlisted",
                " after",
                " war",
                " broke",
                " out",
                " in"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 6.035109043121338,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.035109043121338,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.08450889587402344,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \"ignty\", \" Beir\", \"renheit\"], \"v\": [3.719684600830078, 2.248371124267578, 2.155975341796875, 2.091531753540039, 1.9496707916259766]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"hetti\", \" Circuit\", \" Chrom\", \"shire\", \"ships\"], \"v\": [-1.8647804260253906, -1.752847671508789, -1.7240314483642578, -1.7183856964111328, -1.7162742614746094]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvj8m2qvqqcf2gk8",
            "tokens": [
                " He",
                " was",
                " att",
                "ested",
                " into",
                " The",
                " Duke",
                " of",
                " Cornwall",
                "'s",
                " Light",
                " Infantry",
                " (",
                "D",
                "CL",
                "I",
                ")"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 5.742741584777832,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.742741584777832,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.1998271942138672,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \"ignty\", \" Beir\", \"renheit\"], \"v\": [3.547182083129883, 2.13671875, 2.085573196411133, 1.978506088256836, 1.8307323455810547]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"hetti\", \" Circuit\", \"packing\", \"shire\", \"ships\"], \"v\": [-1.7619285583496094, -1.6792335510253906, -1.6374588012695312, -1.6261787414550781, -1.6160717010498047]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvj9m2qvg4wpehnb",
            "tokens": [
                " for",
                " Hay",
                "<|endoftext|>",
                " had",
                " trapped",
                " Lieutenant",
                " General",
                " Charles",
                " Cornwall",
                "is",
                " in",
                " the",
                " Virgin",
                "ian",
                " coastal",
                " town",
                " of"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 5.536806583404541,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.536806583404541,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.4408798217773438,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \" Beir\", \"ignty\", \"renheit\"], \"v\": [2.997020721435547, 1.7604312896728516, 1.6910057067871094, 1.6670360565185547, 1.495462417602539]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"hetti\", \" Chrom\", \" Circuit\", \"shire\", \"phrine\"], \"v\": [-1.6359901428222656, -1.521169662475586, -1.5111961364746094, -1.5061264038085938, -1.501596450805664]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvjam2qv3m4blo9k",
            "tokens": [
                " far",
                " away",
                " on",
                " a",
                " seas",
                "ide",
                " hill",
                " in",
                " Cornwall",
                ",",
                " that",
                " plants",
                " need",
                " to",
                " struggle",
                " to",
                " develop"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 5.431037425994873,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.431037425994873,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.04992866516113281,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \"ignty\", \" Beir\", \"renheit\"], \"v\": [3.4957332611083984, 2.0773086547851562, 2.0434703826904297, 1.9237194061279297, 1.8340587615966797]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"hetti\", \" Circuit\", \"packing\", \"ships\", \" Chrom\"], \"v\": [-1.7298431396484375, -1.5902576446533203, -1.5659961700439453, -1.5585002899169922, -1.5562458038330078]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvjbm2qvad3xby5u",
            "tokens": [
                " says",
                " Moh",
                "d",
                " Na",
                "'",
                "im",
                " M",
                "ok",
                "htar",
                ",",
                " the",
                " former",
                " chief",
                " judge",
                " in",
                " the",
                " state"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 5.420467853546143,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.420467853546143,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.6109104156494141,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \"ignty\", \" Beir\", \"apons\"], \"v\": [2.9751644134521484, 1.6446647644042969, 1.5356693267822266, 1.4218292236328125, 1.3110103607177734]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"hetti\", \"phrine\", \" Chrom\", \"ships\", \"packing\"], \"v\": [-2.260934829711914, -2.1163864135742188, -2.095914840698242, -2.0904064178466797, -2.0852298736572266]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvjcm2qva79245i1",
            "tokens": [
                "K",
                "atherine",
                " Sh",
                "aver",
                ",",
                "Mon",
                "ica",
                " Ak",
                "htar",
                ",",
                "Mc",
                "K",
                "enna",
                " E",
                "wen",
                "/",
                "The"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 5.368722915649414,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.368722915649414,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.6083908081054688,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \"ignty\", \" Beir\", \"apons\"], \"v\": [2.8744335174560547, 1.5793685913085938, 1.4636650085449219, 1.3607006072998047, 1.2375965118408203]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"hetti\", \"phrine\", \" Chrom\", \"ships\", \"shire\"], \"v\": [-2.194110870361328, -2.0890674591064453, -2.065469741821289, -2.047779083251953, -2.023143768310547]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvjdm2qvrgzjxbxy",
            "tokens": [
                " out",
                "-",
                "of",
                "-",
                "hours",
                " doctor",
                " services",
                " in",
                " Cornwall",
                ",",
                " which",
                " had",
                " \"",
                "f",
                "als",
                "ified",
                " data"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 5.296557426452637,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.296557426452637,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.05267524719238281,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Daesh\", \"rolet\", \"ignty\", \" Beir\", \"renheit\"], \"v\": [3.242706298828125, 1.9863319396972656, 1.8918304443359375, 1.8274650573730469, 1.688222885131836]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"hetti\", \" Circuit\", \"ships\", \" Chrom\", \"shire\"], \"v\": [-1.5956077575683594, -1.4890613555908203, -1.4847965240478516, -1.464324951171875, -1.4535026550292969]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghqqvjtm2qv3awxeq7w",
            "tokens": [
                " and",
                " those",
                " departments",
                ".",
                "\u010a",
                "\u010a",
                "In",
                " many",
                " respects",
                ",",
                " Hicks",
                " and",
                " general",
                " counsel",
                " Jeff",
                " P",
                "ash"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghqqvjum2qvcplxif38",
            "tokens": [
                " those",
                " departments",
                ".",
                "\u010a",
                "\u010a",
                "In",
                " many",
                " respects",
                ",",
                " Hicks",
                " and",
                " general",
                " counsel",
                " Jeff",
                " P",
                "ash",
                " served"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghqqvjvm2qvupj2zm93",
            "tokens": [
                " departments",
                ".",
                "\u010a",
                "\u010a",
                "In",
                " many",
                " respects",
                ",",
                " Hicks",
                " and",
                " general",
                " counsel",
                " Jeff",
                " P",
                "ash",
                " served",
                " previously"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghqqvjwm2qvmh2a4z7a",
            "tokens": [
                ".",
                "\u010a",
                "\u010a",
                "In",
                " many",
                " respects",
                ",",
                " Hicks",
                " and",
                " general",
                " counsel",
                " Jeff",
                " P",
                "ash",
                " served",
                " previously",
                " as"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghqqvjxm2qvb9nmoxup",
            "tokens": [
                "\u010a",
                "\u010a",
                "In",
                " many",
                " respects",
                ",",
                " Hicks",
                " and",
                " general",
                " counsel",
                " Jeff",
                " P",
                "ash",
                " served",
                " previously",
                " as",
                " the"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghqqvk8m2qvtynid7xy",
            "tokens": [
                " (",
                "Reuters",
                ")",
                " -",
                " Myanmar",
                " leader",
                " A",
                "ung",
                " San",
                " Su",
                "u",
                " Ky",
                "i",
                " told",
                " the",
                " U",
                "."
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghqqvk9m2qv11fij8tz",
            "tokens": [
                " with",
                " darkness",
                " ,",
                "you",
                " may",
                " use",
                " the",
                " God",
                "bound",
                " (",
                "5",
                "e",
                " Class",
                ")",
                " class",
                ".(",
                "with"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghqqvkam2qvax8ocd9h",
            "tokens": [
                ",",
                " it",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " not",
                " so",
                " much",
                " the",
                " technical",
                " advantages",
                " of",
                " EP",
                "YC",
                "/",
                "Na",
                "ples"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghqqvkbm2qvhxtdsdrg",
            "tokens": [
                " on",
                " T",
                "aks",
                "im",
                " Square",
                ".",
                "\u010a",
                "\u010a",
                "\u00e2\u0122",
                "\u013e",
                "We",
                " will",
                " be",
                " in",
                " T",
                "aks",
                "im"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghqqvkcm2qvi91rdj1q",
            "tokens": [
                " cards",
                "!",
                "\u010a",
                "\u010a",
                "Ind",
                "ul",
                "ge",
                " your",
                " me",
                "gal",
                "oman",
                "ia",
                " in",
                " Ze",
                "ppelin",
                " Attack",
                "!,"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvjlm2qvqjbh5ibb",
            "tokens": [
                " departments",
                " while",
                " serving",
                " as",
                " the",
                " conduit",
                " between",
                " Goodell",
                " and",
                " those",
                " departments",
                ".",
                "\u010a",
                "\u010a",
                "In",
                " many",
                " respects"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvjkm2qvebmqu8ru",
            "tokens": [
                " between",
                " departments",
                " while",
                " serving",
                " as",
                " the",
                " conduit",
                " between",
                " Goodell",
                " and",
                " those",
                " departments",
                ".",
                "\u010a",
                "\u010a",
                "In",
                " many"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvjjm2qve15xatd7",
            "tokens": [
                " coordination",
                " between",
                " departments",
                " while",
                " serving",
                " as",
                " the",
                " conduit",
                " between",
                " Goodell",
                " and",
                " those",
                " departments",
                ".",
                "\u010a",
                "\u010a",
                "In"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvjim2qvbs3eyxuk",
            "tokens": [
                " and",
                " coordination",
                " between",
                " departments",
                " while",
                " serving",
                " as",
                " the",
                " conduit",
                " between",
                " Goodell",
                " and",
                " those",
                " departments",
                ".",
                "\u010a",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvjhm2qvqxghbfhk",
            "tokens": [
                "<|endoftext|>",
                " and",
                " coordination",
                " between",
                " departments",
                " while",
                " serving",
                " as",
                " the",
                " conduit",
                " between",
                " Goodell",
                " and",
                " those",
                " departments",
                ".",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvjgm2qvazod46y3",
            "tokens": [
                " for",
                "<|endoftext|>",
                " and",
                " coordination",
                " between",
                " departments",
                " while",
                " serving",
                " as",
                " the",
                " conduit",
                " between",
                " Goodell",
                " and",
                " those",
                " departments",
                "."
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvjfm2qv6i375tqk",
            "tokens": [
                " search",
                " for",
                "<|endoftext|>",
                " and",
                " coordination",
                " between",
                " departments",
                " while",
                " serving",
                " as",
                " the",
                " conduit",
                " between",
                " Goodell",
                " and",
                " those",
                " departments"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvjem2qvgl3qr0ou",
            "tokens": [
                " the",
                " search",
                " for",
                "<|endoftext|>",
                " and",
                " coordination",
                " between",
                " departments",
                " while",
                " serving",
                " as",
                " the",
                " conduit",
                " between",
                " Goodell",
                " and",
                " those"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvjnm2qvx8lshf6b",
            "tokens": [
                " serving",
                " as",
                " the",
                " conduit",
                " between",
                " Goodell",
                " and",
                " those",
                " departments",
                ".",
                "\u010a",
                "\u010a",
                "In",
                " many",
                " respects",
                ",",
                " Hicks"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvjom2qv5dsh8d07",
            "tokens": [
                " as",
                " the",
                " conduit",
                " between",
                " Goodell",
                " and",
                " those",
                " departments",
                ".",
                "\u010a",
                "\u010a",
                "In",
                " many",
                " respects",
                ",",
                " Hicks",
                " and"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvjmm2qvcbxc9zs9",
            "tokens": [
                " while",
                " serving",
                " as",
                " the",
                " conduit",
                " between",
                " Goodell",
                " and",
                " those",
                " departments",
                ".",
                "\u010a",
                "\u010a",
                "In",
                " many",
                " respects",
                ","
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghqqvjrm2qvqnny6np6",
            "tokens": [
                " between",
                " Goodell",
                " and",
                " those",
                " departments",
                ".",
                "\u010a",
                "\u010a",
                "In",
                " many",
                " respects",
                ",",
                " Hicks",
                " and",
                " general",
                " counsel",
                " Jeff"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvjpm2qvsh0ed4ak",
            "tokens": [
                " the",
                " conduit",
                " between",
                " Goodell",
                " and",
                " those",
                " departments",
                ".",
                "\u010a",
                "\u010a",
                "In",
                " many",
                " respects",
                ",",
                " Hicks",
                " and",
                " general"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghpqvjqm2qvbg1bk7g9",
            "tokens": [
                " conduit",
                " between",
                " Goodell",
                " and",
                " those",
                " departments",
                ".",
                "\u010a",
                "\u010a",
                "In",
                " many",
                " respects",
                ",",
                " Hicks",
                " and",
                " general",
                " counsel"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9vghqqvjsm2qv5ch02mx3",
            "tokens": [
                " Goodell",
                " and",
                " those",
                " departments",
                ".",
                "\u010a",
                "\u010a",
                "In",
                " many",
                " respects",
                ",",
                " Hicks",
                " and",
                " general",
                " counsel",
                " Jeff",
                " P"
            ],
            "dataIndex": null,
            "index": "23069",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:22:07.849Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        }
    ],
    "explanations": [
        {
            "id": "clsy6ol0r7tfzkad10an8psui",
            "modelId": "gpt2-small",
            "layer": "1-res-jb",
            "index": "23069",
            "description": "mentions of the terrorist group \"Daesh\" (ISIS)",
            "authorId": "clsxqq2xd0000vvp2k5itlhqj",
            "triggeredByUserId": null,
            "notes": null,
            "scoreV1": 0,
            "scoreV2": null,
            "umap_x": -0.6622694,
            "umap_y": 0.3700048,
            "umap_cluster": 4,
            "umap_log_feature_sparsity": -4.1990595,
            "typeName": "oai_token-act-pair",
            "explanationModelName": "gpt-3.5-turbo",
            "createdAt": "2024-02-23T05:00:26.091Z",
            "updatedAt": "2024-02-23T05:00:26.091Z",
            "triggeredByUser": null,
            "scores": []
        }
    ]
}