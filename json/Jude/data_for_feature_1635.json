{
    "modelId": "gpt2-small",
    "layer": "1-res-jb",
    "index": "1635",
    "sourceSetName": "res-jb",
    "creatorId": null,
    "createdAt": "2024-02-09T23:09:29.955Z",
    "maxActApprox": 45.58410263061523,
    "hasVector": false,
    "vector": [],
    "vectorLabel": null,
    "vectorDefaultSteerStrength": 10,
    "hookName": null,
    "topkCosSimIndices": [
        1635,
        1009,
        17378,
        18747,
        1990,
        2893,
        8766,
        20678,
        14897,
        8218,
        20844,
        23840,
        1157,
        11703,
        9895,
        9209,
        8058,
        19712,
        11428,
        2723,
        12982,
        19610,
        16075,
        14334,
        3191
    ],
    "topkCosSimValues": [
        1,
        0.4646,
        0.4051,
        0.3967,
        0.3841,
        0.3835,
        0.3715,
        0.3699,
        0.3663,
        0.3647,
        0.3632,
        0.3564,
        0.3518,
        0.3515,
        0.3481,
        0.3448,
        0.3435,
        0.3431,
        0.3426,
        0.3412,
        0.3369,
        0.3368,
        0.3357,
        0.3348,
        0.3343
    ],
    "neuron_alignment_indices": [
        288,
        527,
        316
    ],
    "neuron_alignment_values": [
        0.2110821902751923,
        0.1224537864327431,
        0.1201118603348732
    ],
    "neuron_alignment_l1": [
        0.01032803393900394,
        0.005991537589579821,
        0.005876949522644281
    ],
    "correlated_neurons_indices": [
        200,
        316,
        516
    ],
    "correlated_neurons_pearson": [
        0.01661419309675694,
        0.01243021991103888,
        0.01122394483536482
    ],
    "correlated_neurons_l1": [
        0.01625939272344112,
        0.01253790780901909,
        0.01130067743360996
    ],
    "correlated_features_indices": [],
    "correlated_features_pearson": [],
    "correlated_features_l1": [],
    "neg_str": [
        "ickr",
        "asks",
        "rings",
        "ending",
        "aired",
        "\u0123\u00ab",
        "recomm",
        "aken",
        "haps",
        "display"
    ],
    "neg_values": [
        -0.8957586884498596,
        -0.8176394701004028,
        -0.7687857747077942,
        -0.760083794593811,
        -0.7555390000343323,
        -0.7171199917793274,
        -0.7113534808158875,
        -0.7050713300704956,
        -0.7035143971443176,
        -0.6901588439941406
    ],
    "pos_str": [
        " Jude",
        " Galile",
        " Whe",
        " Caesar",
        "geist",
        " Cornwall",
        " Faw",
        " Gad",
        " Jonah",
        " Geo"
    ],
    "pos_values": [
        1.302852511405945,
        1.272281527519226,
        0.8571589589118958,
        0.7412488460540771,
        0.7304599285125732,
        0.718474805355072,
        0.6770927309989929,
        0.6680989861488342,
        0.6567058563232422,
        0.6557477712631226
    ],
    "frac_nonzero": 0.0001169840494791667,
    "freq_hist_data_bar_heights": [
        157,
        100,
        61,
        12,
        5,
        11,
        1,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        6,
        1,
        1,
        0,
        0,
        2,
        4,
        4
    ],
    "freq_hist_data_bar_values": [
        0.5721725225448608,
        1.71171510219574,
        2.851257801055908,
        3.990800380706787,
        5.130342960357666,
        6.269885540008545,
        7.409428119659424,
        8.548971176147461,
        9.688512802124023,
        10.82805633544922,
        11.96759796142578,
        13.10714149475098,
        14.24668312072754,
        15.38622665405273,
        16.5257682800293,
        17.66531181335449,
        18.80485343933105,
        19.94439506530762,
        21.08393859863281,
        22.22348213195801,
        23.36302185058594,
        24.5025634765625,
        25.6421070098877,
        26.78165054321289,
        27.92119216918945,
        29.06073379516602,
        30.20027732849121,
        31.33982086181641,
        32.47936248779297,
        33.61890411376953,
        34.75844573974609,
        35.89799118041992,
        37.03753280639648,
        38.17707443237305,
        39.31661987304688,
        40.45616149902344,
        41.595703125,
        42.73524475097656,
        43.87478637695312,
        45.01433181762695
    ],
    "logits_hist_data_bar_heights": [
        1,
        1,
        3,
        7,
        24,
        46,
        116,
        215,
        405,
        782,
        1234,
        1897,
        2918,
        4049,
        5266,
        6117,
        6342,
        5836,
        4927,
        3749,
        2661,
        1624,
        946,
        572,
        278,
        138,
        62,
        31,
        4,
        3,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        2
    ],
    "logits_hist_data_bar_values": [
        -0.868276059627533,
        -0.8133108019828796,
        -0.7583454847335815,
        -0.7033802270889282,
        -0.6484149694442749,
        -0.5934496521949768,
        -0.5384843945503235,
        -0.4835190773010254,
        -0.4285538196563721,
        -0.3735885322093964,
        -0.3186232447624207,
        -0.2636579871177673,
        -0.2086927145719528,
        -0.1537273973226547,
        -0.0987621396780014,
        -0.04379682615399361,
        0.01116843149065971,
        0.06613369286060333,
        0.1210990101099014,
        0.1760643273591995,
        0.2310295253992081,
        0.2859947681427002,
        0.3409600853919983,
        0.3959254026412964,
        0.4508906602859497,
        0.505855917930603,
        0.5608212351799011,
        0.6157864928245544,
        0.6707518100738525,
        0.7257170677185059,
        0.7806823253631592,
        0.8356475830078125,
        0.8906129002571106,
        0.9455782175064087,
        1.000543475151062,
        1.055508732795715,
        1.110473990440369,
        1.165439248085022,
        1.220404624938965,
        1.275369882583618
    ],
    "decoder_weights_dist": [],
    "umap_cluster": null,
    "umap_log_feature_sparsity": null,
    "umap_x": null,
    "umap_y": null,
    "model": {
        "id": "gpt2-small",
        "displayNameShort": "GPT2-SM",
        "displayName": "GPT2-Small",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "tlensId": null,
        "dimension": 768,
        "visibility": "PUBLIC",
        "inferenceEnabled": true,
        "instruct": false,
        "layers": 12,
        "neuronsPerLayer": 3072,
        "createdAt": "2023-07-06T00:01:44.843Z",
        "owner": "OpenAI",
        "updatedAt": "2023-07-06T00:01:44.843Z",
        "website": "https://openai.com"
    },
    "lists": [],
    "creator": null,
    "source": {
        "id": "1-res-jb",
        "modelId": "gpt2-small",
        "hasDashboards": true,
        "inferenceEnabled": true,
        "saelensConfig": {
            "lr": 0.0004,
            "d_in": 768,
            "seed": 42,
            "d_sae": 24576,
            "dtype": "torch.float32",
            "device": "mps",
            "run_name": "24576-L1-8e-05-LR-0.0004-Tokens-3.000e+08",
            "hook_point": "blocks.1.hook_resid_pre",
            "model_name": "gpt2-small",
            "prepend_bos": true,
            "architecture": "standard",
            "context_size": 128,
            "dataset_path": "Skylion007/openwebtext",
            "log_to_wandb": true,
            "wandb_entity": null,
            "n_checkpoints": 10,
            "wandb_project": "mats_sae_training_gpt2_small_resid_pre_5",
            "l1_coefficient": 8e-05,
            "neuronpedia_id": "gpt2-small/1-res-jb",
            "checkpoint_path": "checkpoints/mm179kd2",
            "use_ghost_grads": false,
            "expansion_factor": 32,
            "hook_point_layer": 1,
            "lr_warm_up_steps": 5000,
            "resample_batches": 1028,
            "store_batch_size": 32,
            "train_batch_size": 4096,
            "activation_fn_str": "relu",
            "b_dec_init_method": "geometric_median",
            "lr_scheduler_name": null,
            "tokens_per_buffer": 67108864,
            "dead_feature_window": 5000,
            "n_batches_in_buffer": 128,
            "wandb_log_frequency": 100,
            "apply_b_dec_to_input": true,
            "feature_reinit_scale": 0.2,
            "from_pretrained_path": null,
            "is_dataset_tokenized": false,
            "hook_point_head_index": null,
            "normalize_activations": "none",
            "total_training_tokens": 300000000,
            "dead_feature_threshold": 1e-08,
            "use_cached_activations": false,
            "cached_activations_path": "activations/Skylion007_openwebtext/gpt2-small/blocks.1.hook_resid_pre",
            "feature_sampling_method": null,
            "feature_sampling_window": 1000,
            "dataset_trust_remote_code": true,
            "finetuning_scaling_factor": false,
            "sae_lens_training_version": null,
            "model_from_pretrained_kwargs": {
                "center_writing_weights": true
            },
            "dead_feature_estimation_method": "no_fire"
        },
        "saelensRelease": "gpt2-small-res-jb",
        "saelensSaeId": "blocks.1.hook_resid_pre",
        "hfRepoId": "jbloom/GPT2-Small-SAEs-Reformatted",
        "hfFolderId": "blocks.1.hook_resid_pre",
        "visibility": "PUBLIC",
        "setName": "res-jb",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "hasUmap": true,
        "hasUmapLogSparsity": true,
        "hasUmapClusters": true,
        "num_prompts": 24576,
        "num_tokens_in_prompt": 128,
        "dataset": "Skylion007/openwebtext",
        "notes": null,
        "createdAt": "2024-07-10T04:46:32.069Z"
    },
    "sourceSet": {
        "modelId": "gpt2-small",
        "name": "res-jb",
        "hasDashboards": true,
        "visibility": "PUBLIC",
        "description": "Open Source Sparse Autoencoders for all Residual Stream Layers of GPT2-Small",
        "type": "Residual Stream",
        "creatorName": "Joseph Bloom",
        "urls": [
            "https://www.lesswrong.com/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream",
            "https://huggingface.co/jbloom/GPT2-Small-SAEs/tree/main",
            "https://github.com/jbloomAus/mats_sae_training"
        ],
        "creatorEmail": null,
        "creatorId": "cljgamm90000076zdchicy6zj",
        "releaseName": "gpt2sm-res-jb",
        "defaultRange": 2,
        "defaultShowBreaks": true,
        "showDfa": false,
        "showCorrelated": false,
        "showHeadAttribution": false,
        "showUmap": true,
        "serverHost": "https://1ynud2kk7vnhjo-5002.proxy.runpod.net",
        "createdAt": "2024-07-10T04:46:32.075Z"
    },
    "activations": [
        {
            "id": "clsf9fbkrx2m1m2qvyg8rxzcf",
            "tokens": [
                " who",
                " were",
                " responding",
                " to",
                " a",
                " riot",
                " at",
                " the",
                " Jude",
                "a",
                " and",
                " Sam",
                "aria",
                " Square",
                " in",
                " Ram",
                "allah"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 45.58410263061523,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                45.58410263061523,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                9.134944915771484,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Galile\", \" Jude\", \"geist\", \" Whe\", \" Cornwall\"], \"v\": [10.376222610473633, 8.367480278015137, 2.0564231872558594, 1.811422348022461, -0.17790603637695312]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"ending\", \"asks\", \"ounter\", \"rings\"], \"v\": [-28.636890411376953, -27.706401824951172, -27.528350830078125, -27.47980499267578, -27.300830841064453]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2m2m2qvns1nad9c",
            "tokens": [
                ".",
                "In",
                " the",
                " SM",
                "T",
                " games",
                ",",
                " the",
                " Jude",
                "o",
                "-",
                "Christian",
                " faiths",
                " seem",
                " portrayed",
                " as",
                " being"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 45.16016387939453,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                45.16016387939453,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.443055152893066,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Galile\", \" Jude\", \" Whe\", \"geist\", \" Cornwall\"], \"v\": [9.65750503540039, 7.341212272644043, 0.2892189025878906, -0.4058513641357422, -1.565709114074707]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"ending\", \"ounter\", \"rings\"], \"v\": [-31.531564712524414, -29.993005752563477, -29.860824584960938, -29.61698341369629, -29.347904205322266]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2m3m2qv5058xszd",
            "tokens": [
                "\u010a",
                "In",
                " the",
                " SM",
                "T",
                " games",
                ",",
                " the",
                " Jude",
                "o",
                "-",
                "Christian",
                " faiths",
                " seem",
                " portrayed",
                " as",
                " being"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 44.69380950927734,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                44.69380950927734,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.13863754272461,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Galile\", \" Jude\", \" Whe\", \"geist\", \" Cornwall\"], \"v\": [10.07128620147705, 7.582959175109863, 0.2475719451904297, -0.0528411865234375, -1.4174776077270508]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"ounter\", \"ending\", \"rings\"], \"v\": [-31.119796752929688, -29.574745178222656, -29.44261360168457, -29.363201141357422, -29.05350112915039]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2m4m2qv47fekr24",
            "tokens": [
                " games",
                ",",
                " there",
                " is",
                " evident",
                " criticism",
                " against",
                " the",
                " Jude",
                "o",
                "-",
                "Christian",
                " faiths",
                " that",
                " is",
                " not",
                " fair"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 44.58247375488281,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                44.58247375488281,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.816810607910156,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Galile\", \" Jude\", \" Whe\", \"geist\", \" Cornwall\"], \"v\": [9.647261619567871, 7.606232166290283, 0.4425163269042969, -0.30077171325683594, -1.2119007110595703]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"ending\", \"rings\", \"ounter\"], \"v\": [-30.35674476623535, -28.72007942199707, -28.59490966796875, -28.212188720703125, -27.86375617980957]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2m5m2qvf5r65kiv",
            "tokens": [
                " taken",
                " to",
                " court",
                " by",
                " Toronto",
                " resident",
                " and",
                " activist",
                " Jude",
                " MacDonald",
                " for",
                " allegedly",
                " violating",
                " the",
                " Municipal",
                " Conflict",
                " Of"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 44.22674560546875,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                44.22674560546875,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                13.23023509979248,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Galile\", \" Jude\", \"geist\", \" Whe\", \" Cornwall\"], \"v\": [12.693477630615234, 8.949461936950684, 1.7264537811279297, 1.2086820602416992, -0.8600311279296875]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"rings\", \"ending\", \"ounter\"], \"v\": [-30.416418075561523, -28.70000648498535, -28.647476196289062, -28.572277069091797, -28.131664276123047]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2m6m2qvdor9ccp6",
            "tokens": [
                " Britain",
                ".",
                " \"",
                "Products",
                " from",
                " our",
                " communities",
                " in",
                " Jude",
                "a",
                " and",
                " Sam",
                "aria",
                " should",
                " be",
                " treated",
                " as"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 43.69897079467773,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                43.69897079467773,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                10.28203964233398,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Galile\", \" Jude\", \" Whe\", \"geist\", \" Cornwall\"], \"v\": [8.823872566223145, 6.840348720550537, 0.042464256286621094, -0.3720855712890625, -1.7175483703613281]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"ending\", \"rings\", \"display\"], \"v\": [-30.105607986450195, -28.429048538208008, -28.161848068237305, -27.935550689697266, -27.175945281982422]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2m7m2qv9s0h1age",
            "tokens": [
                " the",
                " games",
                " were",
                " NOT",
                " to",
                " have",
                " criticism",
                " against",
                " Jude",
                "o",
                "-",
                "Christian",
                " faiths",
                ",",
                " why",
                " research",
                " in"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 43.54659271240234,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                43.54659271240234,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.655330657958984,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Galile\", \" Jude\", \" Whe\", \"geist\", \" Cornwall\"], \"v\": [12.02458381652832, 10.566790580749512, 2.5782032012939453, 1.7706117630004883, 0.7484064102172852]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"rings\", \"ending\", \"ounter\"], \"v\": [-28.09379005432129, -27.509342193603516, -26.79231071472168, -26.751157760620117, -26.6401424407959]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2m8m2qvv4uhzb6x",
            "tokens": [
                " the",
                " Romans",
                " officially",
                " renamed",
                " their",
                " administrative",
                " province",
                " of",
                " Jude",
                "a",
                ",",
                " which",
                " included",
                " much",
                " of",
                " the",
                " Land"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 43.16075897216797,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                43.16075897216797,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                9.019405364990234,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Galile\", \" Jude\", \" Whe\", \"geist\", \" Cornwall\"], \"v\": [9.986241340637207, 8.644566535949707, 1.437662124633789, 1.1792144775390625, -0.7086277008056641]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"ending\", \"rings\", \"ounter\"], \"v\": [-29.00568389892578, -28.11800765991211, -27.543739318847656, -27.457107543945312, -27.432933807373047]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2m9m2qv6skwyi1s",
            "tokens": [
                ":",
                "20",
                ",",
                " and",
                " possibly",
                " the",
                " entirety",
                " of",
                " Jude",
                ".",
                " Ign",
                "at",
                "ius",
                " of",
                " Antioch",
                " writes",
                " against"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 42.48386764526367,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                42.48386764526367,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                12.16820621490479,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Galile\", \" Jude\", \" Whe\", \"geist\", \" Faw\"], \"v\": [10.91545295715332, 9.456493377685547, 1.6553497314453125, 0.3946552276611328, -0.3535594940185547]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"ounter\", \"rings\", \"ending\"], \"v\": [-28.87514877319336, -28.492937088012695, -27.8952693939209, -27.618562698364258, -27.26343536376953]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2mam2qvmp584148",
            "tokens": [
                " the",
                " cancer",
                " returned",
                ".",
                "\u010a",
                "\u010a",
                "St",
                ".",
                " Jude",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " Children",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " Hospital"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 39.38016891479492,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                39.38016891479492,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                17.82601737976074,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Galile\", \" Jude\", \" Whe\", \"geist\", \" Cornwall\"], \"v\": [8.764451026916504, 6.253530025482178, 0.3264589309692383, -0.5817489624023438, -1.8472013473510742]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"ending\", \"display\", \"rings\"], \"v\": [-30.04856300354004, -28.840038299560547, -28.560348510742188, -28.116432189941406, -27.731708526611328]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2mbm2qvalaxxw5e",
            "tokens": [
                "\u010a",
                "8",
                ".",
                " Danny",
                " Sut",
                "cliffe",
                " (",
                "St",
                " Jude",
                "\u00e2\u0122",
                "\u013b",
                "s",
                ")",
                "\u010a",
                "\u010a",
                "9",
                "."
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 38.27997970581055,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                38.27997970581055,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                16.64530944824219,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Galile\", \" Jude\", \" Whe\", \"geist\", \" Cornwall\"], \"v\": [8.998353958129883, 6.812139987945557, 0.816920280456543, -0.8288135528564453, -1.5502281188964844]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"ending\", \"display\", \"rings\"], \"v\": [-28.294780731201172, -28.10392951965332, -27.319175720214844, -27.022705078125, -26.907249450683594]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2mcm2qv0f4or5dx",
            "tokens": [
                ":",
                " In",
                "patient",
                " Hospital",
                "ization",
                " to",
                " St",
                ".",
                " Jude",
                " Hospital",
                " from",
                " 10",
                "/",
                "4",
                "/",
                "2017",
                "-"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 37.35935211181641,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                37.35935211181641,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                12.53716850280762,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Galile\", \" Jude\", \" Whe\", \"geist\", \" Cornwall\"], \"v\": [10.093809127807617, 7.593238830566406, 1.3997983932495117, -0.4768953323364258, -0.752284049987793]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"display\", \"ending\", \"rings\"], \"v\": [-27.528114318847656, -27.40302276611328, -27.06602668762207, -26.550214767456055, -26.42481803894043]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2mdm2qvvt57jh40",
            "tokens": [
                "ne",
                " Richardson",
                " said",
                " that",
                " he",
                " believes",
                " St",
                ".",
                " Jude",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " should",
                " be",
                " paid",
                " the",
                " denied"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 37.21200180053711,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                37.21200180053711,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                16.60494995117188,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Galile\", \" Jude\", \" Whe\", \"geist\", \" Caesar\"], \"v\": [9.333091735839844, 6.724968433380127, 0.6701450347900391, -0.2701396942138672, -1.5129899978637695]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"ending\", \"display\", \"rings\"], \"v\": [-28.289142608642578, -27.48305320739746, -27.17436408996582, -26.95223045349121, -26.402856826782227]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2mem2qvv93d92bk",
            "tokens": [
                " \u00e2\u0122",
                "\u013e",
                "With",
                " the",
                " St",
                "\u00c3\u00bcr",
                "mer",
                " against",
                " Jude",
                "a",
                ".",
                "\u00e2\u0122",
                "\u013f",
                " The",
                " caption",
                " underneath",
                " reads"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 37.14406967163086,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                37.14406967163086,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                9.047751426696777,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Galile\", \" Jude\", \" Whe\", \"geist\", \" Caesar\"], \"v\": [9.823461532592773, 7.898046016693115, 1.5991716384887695, -0.9022808074951172, -1.0094575881958008]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"display\", \"ending\", \"rings\"], \"v\": [-28.599010467529297, -28.33839988708496, -27.66080093383789, -27.20705223083496, -27.187686920166016]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2mfm2qv07sb8muv",
            "tokens": [
                " request",
                " for",
                " clinical",
                " trial",
                " treatment",
                " at",
                " St",
                ".",
                " Jude",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " hospital",
                " is",
                " not",
                " medically",
                " necessary"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 37.04389953613281,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                37.04389953613281,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                16.20237731933594,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Galile\", \" Jude\", \" Whe\", \"geist\", \" Cornwall\"], \"v\": [9.385979652404785, 7.191549777984619, 1.328474998474121, -0.6196441650390625, -0.9438133239746094]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"display\", \"ending\", \"rings\"], \"v\": [-28.089868545532227, -27.64563751220703, -27.272367477416992, -27.13029670715332, -26.408594131469727]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2mgm2qvt4yccc2j",
            "tokens": [
                "Fortunately",
                " for",
                " the",
                " Richards",
                "ons",
                ",",
                " St",
                ".",
                " Jude",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " does",
                " not",
                " charge",
                " patients",
                " for"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 36.96829223632812,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                36.96829223632812,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                14.62055397033691,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Galile\", \" Jude\", \" Whe\", \"geist\", \" Caesar\"], \"v\": [10.703117370605469, 9.004385948181152, 2.3344764709472656, 0.31452369689941406, 0.15511226654052734]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"asks\", \"ickr\", \"display\", \"ending\", \"rings\"], \"v\": [-26.895244598388672, -26.804141998291016, -26.362987518310547, -26.11284828186035, -25.80247688293457]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2mhm2qvxy0o7yfg",
            "tokens": [
                " him",
                " in",
                " a",
                " clinical",
                " trial",
                " at",
                " St",
                ".",
                " Jude",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " hospital",
                ".",
                " The",
                " principal",
                " investigator"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 36.96041870117188,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                36.96041870117188,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                15.5684928894043,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Galile\", \" Jude\", \" Whe\", \"geist\", \" Cornwall\"], \"v\": [9.972220420837402, 7.742511749267578, 1.5498476028442383, -0.6103744506835938, -0.8240699768066406]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"display\", \"ending\", \"rings\"], \"v\": [-27.774696350097656, -27.61554718017578, -27.01188087463379, -26.661422729492188, -26.542842864990234]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2mim2qv1d0bol5i",
            "tokens": [
                "ain",
                ",",
                " is",
                " named",
                " after",
                " N",
                "ain",
                " in",
                " Galile",
                "e",
                ".",
                " When",
                " the",
                " Princ",
                "ip",
                "ality",
                " of"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 19.32970428466797,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                19.32970428466797,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.489101409912109,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Jude\", \" Galile\", \" Whe\", \" Caesar\", \" Geo\"], \"v\": [3.7017879486083984, 3.4570634852570947e-06, -0.46039581298828125, -0.7425708770751953, -1.1137428283691406]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"rings\", \"asks\", \"ickr\", \"hips\", \"\\u0123\\u00ab\"], \"v\": [-12.746923446655273, -12.582916259765625, -12.244529724121094, -12.175621032714844, -12.056442260742188]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbkrx2mjm2qv36ycs67e",
            "tokens": [
                " however",
                ".",
                " Frances",
                "co",
                " Red",
                "i",
                " and",
                " Galileo",
                " Galile",
                "i",
                " demonstrated",
                " their",
                " methods",
                " using",
                " very",
                " simple",
                " experiments"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 14.51242160797119,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                14.51242160797119,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.046218872070312,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Jude\", \" Galile\", \" Whe\", \" Caesar\", \" Faw\"], \"v\": [2.6471004486083984, 9.536738616588991e-07, -0.5750331878662109, -0.9553928375244141, -1.1832695007324219]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"rings\", \"ickr\", \"asks\", \"quished\", \"\\u0123\\u00ab\"], \"v\": [-10.687063217163086, -10.607723236083984, -10.588096618652344, -10.318771362304688, -10.08670425415039]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2mkm2qvplo8el9x",
            "tokens": [
                " mean",
                " that",
                " the",
                " con",
                "clave",
                " in",
                " the",
                " S",
                "istine",
                " Chapel",
                ",",
                " where",
                " card",
                "inals",
                " will",
                " choose",
                " the"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 6.912674427032471,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.912674427032471,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.5889129638671875,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Jude\", \" Galile\", \" Whe\", \" Cornwall\", \" Faw\"], \"v\": [3.2942237854003906, 3.1267786026000977, 2.0008487701416016, 1.7018566131591797, 1.6108455657958984]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"ounter\", \"aired\", \"rings\"], \"v\": [-3.1363868713378906, -3.0553083419799805, -2.6723413467407227, -2.654653549194336, -2.6446895599365234]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbktx2nlm2qv86w6ap84",
            "tokens": [
                " political",
                " and",
                " religious",
                " affiliation",
                " as",
                " a",
                " proxy",
                " for",
                " bene",
                "vol",
                "ence",
                " is",
                " adaptive",
                ",",
                " in",
                "asm",
                "uch"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 6.529860496520996,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.529860496520996,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.3533167839050293,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Jude\", \" Galile\", \" Whe\", \"geist\", \" Cornwall\"], \"v\": [3.1851539611816406, 3.147500991821289, 1.8284130096435547, 1.7505722045898438, 1.6151237487792969]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"haps\", \"meet\", \"\\u0123\\u00ab\"], \"v\": [-2.771451950073242, -2.5256214141845703, -2.3877716064453125, -2.3695850372314453, -2.364286422729492]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbktx2njm2qvmvay5mkx",
            "tokens": [
                " outlook",
                " is",
                " continuous",
                " with",
                " the",
                " disposition",
                " to",
                " use",
                " bene",
                "vol",
                "ence",
                " as",
                " a",
                " cue",
                " to",
                " reliability",
                ";"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 6.263164520263672,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.263164520263672,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.3142623901367188,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Jude\", \" Galile\", \" Whe\", \"geist\", \" Cornwall\"], \"v\": [3.1535167694091797, 3.078205108642578, 1.8175029754638672, 1.6710891723632812, 1.5875988006591797]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"meet\", \"haps\", \"\\u0123\\u00ab\"], \"v\": [-2.6956138610839844, -2.4704113006591797, -2.306131362915039, -2.2861080169677734, -2.2611045837402344]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbktx2nkm2qvbxz1vde2",
            "tokens": [
                " rational",
                " as",
                " a",
                " function",
                " of",
                " perceived",
                " reliability",
                " and",
                " bene",
                "vol",
                "ence",
                " of",
                " sources",
                ").",
                "\u010a",
                "\u010a",
                "Both"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 5.777492046356201,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.777492046356201,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.2885189056396484,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Jude\", \" Galile\", \" Whe\", \"geist\", \" Cornwall\"], \"v\": [2.5838184356689453, 2.5793113708496094, 1.4817848205566406, 1.3865833282470703, 1.321533203125]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"haps\", \"meet\", \"ending\"], \"v\": [-2.4753780364990234, -2.2186737060546875, -2.0832958221435547, -2.076456069946289, -2.0571842193603516]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbktx2nhm2qv1itnki58",
            "tokens": [
                " in",
                " nature",
                ".",
                "\u010a",
                "\u010a",
                "They",
                " missed",
                " the",
                " benign",
                "-",
                "sounding",
                " homegrown",
                " versions",
                " of",
                " deeply",
                " radical",
                " political"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 5.389199733734131,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.389199733734131,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.1768360137939453,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Jude\", \" Galile\", \" Whe\", \"geist\", \" Cornwall\"], \"v\": [2.2191162109375, 2.14284610748291, 1.1998310089111328, 1.0994987487792969, 0.9306678771972656]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ickr\", \"asks\", \"ending\", \"meet\", \"aired\"], \"v\": [-2.592967987060547, -2.4576873779296875, -2.4239120483398438, -2.304372787475586, -2.2767982482910156]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbktx2nqm2qv9o8w16ws",
            "tokens": [
                " have",
                " fought",
                " this",
                " tax",
                " tooth",
                " and",
                " nail",
                ",",
                " and",
                " who",
                " will",
                " gear",
                " up",
                " to",
                " fight",
                " it",
                " now"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2mxm2qvjoj1mp35",
            "tokens": [
                "\u010a",
                "\u010a",
                "With",
                " all",
                " that",
                " said",
                ",",
                " of",
                " all",
                " the",
                " knock",
                "offs",
                " I",
                " received",
                ",",
                " this",
                " is"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2mlm2qviifh5mon",
            "tokens": [
                " link",
                " to",
                " adjust",
                "<|endoftext|>",
                " on",
                " the",
                " left",
                ",",
                " real",
                " on",
                " the",
                " right",
                "\u010a",
                "\u010a",
                "With",
                " all",
                " that"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2mmm2qvleva4wxg",
            "tokens": [
                " to",
                " adjust",
                "<|endoftext|>",
                " on",
                " the",
                " left",
                ",",
                " real",
                " on",
                " the",
                " right",
                "\u010a",
                "\u010a",
                "With",
                " all",
                " that",
                " said"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2mnm2qvj64mvk9y",
            "tokens": [
                " adjust",
                "<|endoftext|>",
                " on",
                " the",
                " left",
                ",",
                " real",
                " on",
                " the",
                " right",
                "\u010a",
                "\u010a",
                "With",
                " all",
                " that",
                " said",
                ","
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2mom2qv19q4cn65",
            "tokens": [
                "<|endoftext|>",
                " on",
                " the",
                " left",
                ",",
                " real",
                " on",
                " the",
                " right",
                "\u010a",
                "\u010a",
                "With",
                " all",
                " that",
                " said",
                ",",
                " of"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2mpm2qv9fqiaje2",
            "tokens": [
                " on",
                " the",
                " left",
                ",",
                " real",
                " on",
                " the",
                " right",
                "\u010a",
                "\u010a",
                "With",
                " all",
                " that",
                " said",
                ",",
                " of",
                " all"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2mqm2qvq8gojp06",
            "tokens": [
                " the",
                " left",
                ",",
                " real",
                " on",
                " the",
                " right",
                "\u010a",
                "\u010a",
                "With",
                " all",
                " that",
                " said",
                ",",
                " of",
                " all",
                " the"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2mrm2qvh4m2zdlr",
            "tokens": [
                " left",
                ",",
                " real",
                " on",
                " the",
                " right",
                "\u010a",
                "\u010a",
                "With",
                " all",
                " that",
                " said",
                ",",
                " of",
                " all",
                " the",
                " knock"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2msm2qv9vvek7cy",
            "tokens": [
                ",",
                " real",
                " on",
                " the",
                " right",
                "\u010a",
                "\u010a",
                "With",
                " all",
                " that",
                " said",
                ",",
                " of",
                " all",
                " the",
                " knock",
                "offs"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2mtm2qvq76udmso",
            "tokens": [
                " real",
                " on",
                " the",
                " right",
                "\u010a",
                "\u010a",
                "With",
                " all",
                " that",
                " said",
                ",",
                " of",
                " all",
                " the",
                " knock",
                "offs",
                " I"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2mum2qvva80hj4g",
            "tokens": [
                " on",
                " the",
                " right",
                "\u010a",
                "\u010a",
                "With",
                " all",
                " that",
                " said",
                ",",
                " of",
                " all",
                " the",
                " knock",
                "offs",
                " I",
                " received"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2mvm2qvb415eh54",
            "tokens": [
                " the",
                " right",
                "\u010a",
                "\u010a",
                "With",
                " all",
                " that",
                " said",
                ",",
                " of",
                " all",
                " the",
                " knock",
                "offs",
                " I",
                " received",
                ","
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2mwm2qvycg3ya7g",
            "tokens": [
                " right",
                "\u010a",
                "\u010a",
                "With",
                " all",
                " that",
                " said",
                ",",
                " of",
                " all",
                " the",
                " knock",
                "offs",
                " I",
                " received",
                ",",
                " this"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2mym2qvktphvoi7",
            "tokens": [
                "\u010a",
                "With",
                " all",
                " that",
                " said",
                ",",
                " of",
                " all",
                " the",
                " knock",
                "offs",
                " I",
                " received",
                ",",
                " this",
                " is",
                " without"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2mzm2qvffpzb36l",
            "tokens": [
                "With",
                " all",
                " that",
                " said",
                ",",
                " of",
                " all",
                " the",
                " knock",
                "offs",
                " I",
                " received",
                ",",
                " this",
                " is",
                " without",
                " a"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2n0m2qvlb1rbi5a",
            "tokens": [
                " all",
                " that",
                " said",
                ",",
                " of",
                " all",
                " the",
                " knock",
                "offs",
                " I",
                " received",
                ",",
                " this",
                " is",
                " without",
                " a",
                " doubt"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2n1m2qvd3jl2ow5",
            "tokens": [
                " that",
                " said",
                ",",
                " of",
                " all",
                " the",
                " knock",
                "offs",
                " I",
                " received",
                ",",
                " this",
                " is",
                " without",
                " a",
                " doubt",
                " my"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2n2m2qvcorsnkob",
            "tokens": [
                " said",
                ",",
                " of",
                " all",
                " the",
                " knock",
                "offs",
                " I",
                " received",
                ",",
                " this",
                " is",
                " without",
                " a",
                " doubt",
                " my",
                " favorite"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2n3m2qvu14ng9s4",
            "tokens": [
                ",",
                " of",
                " all",
                " the",
                " knock",
                "offs",
                " I",
                " received",
                ",",
                " this",
                " is",
                " without",
                " a",
                " doubt",
                " my",
                " favorite",
                " and"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbksx2n4m2qv2zq5xrqz",
            "tokens": [
                " of",
                " all",
                " the",
                " knock",
                "offs",
                " I",
                " received",
                ",",
                " this",
                " is",
                " without",
                " a",
                " doubt",
                " my",
                " favorite",
                " and",
                " the"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbktx2nmm2qv6jj59bbb",
            "tokens": [
                " of",
                " religious",
                " Americans",
                ",",
                " their",
                " communities",
                ",",
                " and",
                " their",
                " faith",
                "-",
                "based",
                " institutions",
                ",",
                " and",
                " threatens",
                " the"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbktx2nnm2qv3zm0sf4b",
            "tokens": [
                " wife",
                " possesses",
                " a",
                " much",
                " higher",
                " degree",
                " of",
                " emotional",
                " intelligence",
                " than",
                " I",
                " do",
                ".",
                "\u010a",
                "\u010a",
                "Che",
                "ss"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbktx2nom2qvvks45loe",
            "tokens": [
                "mobile",
                ".",
                " Other",
                " rum",
                "oured",
                " features",
                " for",
                " the",
                " Note",
                " 6",
                " include",
                " a",
                " 5",
                ".",
                "8",
                "in",
                " Slim"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsf9fbktx2npm2qvc1nb2uby",
            "tokens": [
                " house",
                ".",
                "\u010a",
                "\u010a",
                "\u00e2\u0122",
                "\u013e",
                "Fans",
                " of",
                " the",
                " Green",
                " Bay",
                " Packers",
                " are",
                " frequently",
                " seen",
                " wearing",
                " obnoxious"
            ],
            "dataIndex": null,
            "index": "1635",
            "layer": "1-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-09T23:09:34.778Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        }
    ],
    "explanations": [
        {
            "id": "clsxssrt90n0lenuxjh5dxsgt",
            "modelId": "gpt2-small",
            "layer": "1-res-jb",
            "index": "1635",
            "description": "keywords related to the term \"Jude\"",
            "authorId": "clsxqq2xd0000vvp2k5itlhqj",
            "triggeredByUserId": null,
            "notes": null,
            "scoreV1": 0,
            "scoreV2": null,
            "umap_x": -0.86788285,
            "umap_y": -0.86109746,
            "umap_cluster": 15,
            "umap_log_feature_sparsity": -4.0847297,
            "typeName": "oai_token-act-pair",
            "explanationModelName": "gpt-3.5-turbo",
            "createdAt": "2024-02-22T22:31:46.893Z",
            "updatedAt": "2024-02-22T22:31:46.893Z",
            "triggeredByUser": null,
            "scores": []
        }
    ]
}