{
    "request": {
        "modelId": "gpt2-small",
        "query": "jew"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "19765",
            "description": "references to the term \"Fal\" or variations of it, indicating a focus on Ethiopian Jews or the Falasha community",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 68.02,
            "frac_nonzero": 2e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "19765",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:33:57.468Z",
                "maxActApprox": 68.02,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    19765,
                    20079,
                    14733,
                    2352,
                    22467,
                    4569,
                    16106,
                    35691,
                    19169,
                    7813,
                    2619,
                    17284,
                    19556,
                    46661,
                    34994,
                    49014,
                    6271,
                    26880,
                    35748,
                    24259,
                    1139,
                    26305,
                    18004,
                    32168,
                    39262
                ],
                "topkCosSimValues": [
                    1,
                    0.6377,
                    0.4924,
                    0.4669,
                    0.4266,
                    0.4106,
                    0.3986,
                    0.3935,
                    0.3901,
                    0.3891,
                    0.387,
                    0.3786,
                    0.3743,
                    0.369,
                    0.3654,
                    0.3585,
                    0.3583,
                    0.3576,
                    0.3568,
                    0.355,
                    0.3516,
                    0.3471,
                    0.3466,
                    0.3427,
                    0.3417
                ],
                "neuron_alignment_indices": [
                    288,
                    57,
                    255
                ],
                "neuron_alignment_values": [
                    0.136,
                    0.118,
                    0.109
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    702,
                    57,
                    211
                ],
                "correlated_neurons_pearson": [
                    0.01,
                    0.01,
                    0.01
                ],
                "correlated_neurons_l1": [
                    0.01,
                    0.009,
                    0.007
                ],
                "correlated_features_indices": [
                    19765,
                    19691,
                    19693
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "LESS",
                    " NETWORK",
                    " Universities",
                    " Annotations",
                    " fabricated",
                    " nursery",
                    " lockout",
                    " Yankee",
                    " Tycoon",
                    " newborn"
                ],
                "neg_values": [
                    -0.705,
                    -0.637,
                    -0.633,
                    -0.622,
                    -0.619,
                    -0.618,
                    -0.617,
                    -0.616,
                    -0.613,
                    -0.598
                ],
                "pos_str": [
                    "cohol",
                    "stad",
                    "quet",
                    "tering",
                    "ters",
                    "phe",
                    "vey",
                    "renheit",
                    "itz",
                    "thy"
                ],
                "pos_values": [
                    1.09,
                    1.073,
                    1.072,
                    1.047,
                    0.981,
                    0.972,
                    0.941,
                    0.94,
                    0.932,
                    0.93
                ],
                "frac_nonzero": 2e-05,
                "freq_hist_data_bar_heights": [
                    11,
                    8,
                    6,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    1,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    3,
                    0,
                    0,
                    0,
                    4,
                    3,
                    2,
                    1,
                    0,
                    0,
                    4,
                    0,
                    2,
                    3,
                    2,
                    2,
                    3,
                    0,
                    3,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.715,
                    2.075,
                    3.435,
                    4.794,
                    6.154,
                    7.514,
                    8.873,
                    10.233,
                    11.593,
                    12.952,
                    14.312,
                    15.672,
                    17.032,
                    18.391,
                    19.751,
                    21.111,
                    22.47,
                    23.83,
                    25.19,
                    26.549,
                    27.909,
                    29.269,
                    30.629,
                    31.988,
                    33.348,
                    34.708,
                    36.067,
                    37.427,
                    38.787,
                    40.146,
                    41.506,
                    42.866,
                    44.226,
                    45.585,
                    46.945,
                    48.305,
                    49.664,
                    51.024,
                    52.384,
                    53.743,
                    55.103,
                    56.463,
                    57.823,
                    59.182,
                    60.542,
                    61.902,
                    63.261,
                    64.621,
                    65.981,
                    67.34
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    7,
                    16,
                    30,
                    51,
                    97,
                    180,
                    339,
                    557,
                    849,
                    1273,
                    1865,
                    2274,
                    2899,
                    3268,
                    3727,
                    3943,
                    3839,
                    3669,
                    3411,
                    3083,
                    2587,
                    2193,
                    1821,
                    1581,
                    1222,
                    1076,
                    899,
                    709,
                    560,
                    476,
                    447,
                    305,
                    268,
                    176,
                    162,
                    128,
                    105,
                    56,
                    43,
                    21,
                    16,
                    6,
                    5,
                    9,
                    2,
                    0,
                    1,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.687,
                    -0.651,
                    -0.615,
                    -0.579,
                    -0.543,
                    -0.507,
                    -0.472,
                    -0.436,
                    -0.4,
                    -0.364,
                    -0.328,
                    -0.292,
                    -0.256,
                    -0.22,
                    -0.184,
                    -0.149,
                    -0.113,
                    -0.077,
                    -0.041,
                    -0.005,
                    0.031,
                    0.067,
                    0.103,
                    0.139,
                    0.174,
                    0.21,
                    0.246,
                    0.282,
                    0.318,
                    0.354,
                    0.39,
                    0.426,
                    0.462,
                    0.497,
                    0.533,
                    0.569,
                    0.605,
                    0.641,
                    0.677,
                    0.713,
                    0.749,
                    0.785,
                    0.82,
                    0.856,
                    0.892,
                    0.928,
                    0.964,
                    1,
                    1.036,
                    1.072
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyv7kpcm19g8nba6js4vxux5",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs49152-jb",
                        "index": "19765",
                        "description": "references to the term \"Fal\" or variations of it, indicating a focus on Ethiopian Jews or the Falasha community",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-21T07:00:20.182Z",
                        "updatedAt": "2024-07-21T07:00:20.182Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk5e6kqtv6hi666nv395hzb",
                        "tokens": [
                            "While",
                            " Fal",
                            "com",
                            " are",
                            " a",
                            " more",
                            " niche",
                            " team",
                            " then",
                            " most",
                            " other",
                            " JR",
                            "PG",
                            " developers",
                            ",",
                            " they",
                            " still",
                            " manage",
                            " to",
                            " make",
                            " some",
                            " all",
                            "-",
                            "round",
                            " amazing",
                            " games",
                            " that",
                            " are",
                            " enjoyable",
                            ".",
                            " Recently",
                            " their",
                            " titles",
                            ",",
                            " both",
                            " new",
                            " ones",
                            " and",
                            " older",
                            " ones",
                            ",",
                            " are",
                            " slowly",
                            " coming",
                            " out",
                            " in",
                            " english",
                            " more",
                            " and",
                            " more",
                            ".",
                            " After",
                            " a",
                            " two",
                            " years",
                            " wait",
                            ",",
                            " Tokyo",
                            " Xan",
                            "ad",
                            "u",
                            ",",
                            " a",
                            " recent",
                            " title",
                            " they",
                            " developed",
                            ",",
                            " was",
                            " released",
                            " on",
                            " the",
                            " PS",
                            " Vita",
                            " in",
                            " English",
                            ".",
                            " The",
                            " PS",
                            "4",
                            " version",
                            " is",
                            " to",
                            " be",
                            " released",
                            " later",
                            " in",
                            " the",
                            " year",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " review",
                            " will",
                            " focus",
                            " on",
                            " the",
                            " Vita",
                            " version",
                            ",",
                            " but",
                            " once",
                            " the",
                            " PS",
                            "4",
                            " version",
                            " releases",
                            " and",
                            " I",
                            " have",
                            " finished",
                            " all",
                            " the",
                            " new",
                            " content",
                            ",",
                            " I",
                            " will",
                            " add",
                            " an",
                            " extra",
                            " section",
                            " down",
                            " the",
                            " bottom",
                            " that"
                        ],
                        "dataIndex": null,
                        "index": "19765",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 68.02,
                        "maxValueTokenIndex": 1,
                        "minValue": 0,
                        "values": [
                            0,
                            68.02,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:34:06.066Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 68.02,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5e6kqtv6ii666p7zgxsr4",
                        "tokens": [
                            "\u013b",
                            "s",
                            " visit",
                            ",",
                            " he",
                            " was",
                            " able",
                            " to",
                            " prove",
                            " that",
                            " the",
                            " leaked",
                            " online",
                            " version",
                            " of",
                            " Stephen",
                            " Paddock",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " room",
                            " service",
                            " receipt",
                            " was",
                            ",",
                            " in",
                            " fact",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "authent",
                            "ic",
                            "\u00e2\u0122",
                            "\u013f",
                            " after",
                            " comparing",
                            " it",
                            " to",
                            " a",
                            " receipt",
                            " he",
                            " himself",
                            " received",
                            " after",
                            " ordering",
                            " room",
                            " service",
                            " Saturday",
                            " morning",
                            ".",
                            "\n",
                            "\n",
                            "Here",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " the",
                            " series",
                            " of",
                            " tweets",
                            " from",
                            " Fal",
                            "co",
                            " with",
                            " links",
                            " to",
                            " each",
                            " tweet",
                            ".",
                            "\n",
                            "\n",
                            "2",
                            ".",
                            " I",
                            " stayed",
                            " at",
                            " Mandal",
                            "ay",
                            " P",
                            "add",
                            "ocks",
                            " room",
                            " service",
                            " receipt",
                            " was",
                            " leaked",
                            " online",
                            ".",
                            " It",
                            " is",
                            " authentic",
                            ".",
                            "https",
                            "://",
                            "t",
                            ".",
                            "co",
                            "/",
                            "us",
                            "9",
                            "z",
                            "D",
                            "Go",
                            "U",
                            "57",
                            " Here",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " mine",
                            "-",
                            " ONE",
                            " guest",
                            " pic",
                            ".",
                            "twitter",
                            ".",
                            "com",
                            "/",
                            "J",
                            "EA",
                            "yu",
                            "E",
                            "z",
                            "p",
                            "K",
                            "M"
                        ],
                        "dataIndex": null,
                        "index": "19765",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 66.13,
                        "maxValueTokenIndex": 61,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            66.13,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:34:06.066Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 68.02,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5e6kttv73i6668u5weum5",
                        "tokens": [
                            "\u013b",
                            "s",
                            " visit",
                            ",",
                            " he",
                            " was",
                            " able",
                            " to",
                            " prove",
                            " that",
                            " the",
                            " leaked",
                            " online",
                            " version",
                            " of",
                            " Stephen",
                            " Paddock",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " room",
                            " service",
                            " receipt",
                            " was",
                            ",",
                            " in",
                            " fact",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "authent",
                            "ic",
                            "\u00e2\u0122",
                            "\u013f",
                            " after",
                            " comparing",
                            " it",
                            " to",
                            " a",
                            " receipt",
                            " he",
                            " himself",
                            " received",
                            " after",
                            " ordering",
                            " room",
                            " service",
                            " Saturday",
                            " morning",
                            ".",
                            "\n",
                            "\n",
                            "Here",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " the",
                            " series",
                            " of",
                            " tweets",
                            " from",
                            " Fal",
                            "co",
                            " with",
                            " links",
                            " to",
                            " each",
                            " tweet",
                            ".",
                            "\n",
                            "\n",
                            "2",
                            ".",
                            " I",
                            " stayed",
                            " at",
                            " Mandal",
                            "ay",
                            " P",
                            "add",
                            "ocks",
                            " room",
                            " service",
                            " receipt",
                            " was",
                            " leaked",
                            " online",
                            ".",
                            " It",
                            " is",
                            " authentic",
                            ".",
                            "https",
                            "://",
                            "t",
                            ".",
                            "co",
                            "/",
                            "us",
                            "9",
                            "z",
                            "D",
                            "Go",
                            "U",
                            "57",
                            " Here",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " mine",
                            "-",
                            " ONE",
                            " guest",
                            " pic",
                            ".",
                            "twitter",
                            ".",
                            "com",
                            "/",
                            "J",
                            "EA",
                            "yu",
                            "E",
                            "z",
                            "p",
                            "K",
                            "M"
                        ],
                        "dataIndex": null,
                        "index": "19765",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 66.13,
                        "maxValueTokenIndex": 61,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            66.13,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:34:06.066Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 54.416,
                        "binMax": 68.02,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "24636",
            "description": " occurrences of the word 'jew' in various contexts",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 61.691,
            "frac_nonzero": 1e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "24636",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:00:24.000Z",
                "maxActApprox": 61.691,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    24636,
                    86795,
                    36896,
                    63187,
                    6573,
                    39819,
                    85294,
                    51431,
                    20305,
                    59581,
                    78226,
                    21296,
                    41873,
                    49087,
                    72221,
                    16216,
                    26137,
                    70018,
                    66679,
                    97950,
                    24484,
                    35992,
                    7916,
                    24052,
                    6018
                ],
                "topkCosSimValues": [
                    1,
                    0.6017,
                    0.5037,
                    0.4973,
                    0.4561,
                    0.4518,
                    0.4398,
                    0.4101,
                    0.3985,
                    0.3812,
                    0.3762,
                    0.3744,
                    0.3682,
                    0.3604,
                    0.3553,
                    0.3519,
                    0.3507,
                    0.3499,
                    0.3499,
                    0.349,
                    0.3467,
                    0.3464,
                    0.3439,
                    0.3422,
                    0.3398
                ],
                "neuron_alignment_indices": [
                    361,
                    326,
                    420
                ],
                "neuron_alignment_values": [
                    0.109,
                    0.107,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    361,
                    251,
                    0
                ],
                "correlated_neurons_pearson": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_features_indices": [
                    24631,
                    24636,
                    24568
                ],
                "correlated_features_pearson": [
                    0.001,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0,
                    0
                ],
                "neg_str": [
                    " ERA",
                    " Archdemon",
                    " NCT",
                    " Dul",
                    " Wolves",
                    " McGee",
                    " Feedback",
                    " Situation",
                    " ABV",
                    " NAD"
                ],
                "neg_values": [
                    -0.788,
                    -0.773,
                    -0.72,
                    -0.704,
                    -0.702,
                    -0.686,
                    -0.678,
                    -0.675,
                    -0.657,
                    -0.656
                ],
                "pos_str": [
                    "ellery",
                    "smith",
                    "eller",
                    "ish",
                    "elled",
                    "jew",
                    "s",
                    " jew",
                    "artisan",
                    "itsch"
                ],
                "pos_values": [
                    1.919,
                    1.153,
                    1.114,
                    1.08,
                    1.048,
                    1.019,
                    1.008,
                    0.96,
                    0.958,
                    0.949
                ],
                "frac_nonzero": 1e-05,
                "freq_hist_data_bar_heights": [
                    21,
                    5,
                    4,
                    2,
                    5,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.666,
                    1.898,
                    3.131,
                    4.364,
                    5.597,
                    6.83,
                    8.063,
                    9.296,
                    10.528,
                    11.761,
                    12.994,
                    14.227,
                    15.46,
                    16.693,
                    17.925,
                    19.158,
                    20.391,
                    21.624,
                    22.857,
                    24.09,
                    25.322,
                    26.555,
                    27.788,
                    29.021,
                    30.254,
                    31.487,
                    32.719,
                    33.952,
                    35.185,
                    36.418,
                    37.651,
                    38.884,
                    40.117,
                    41.349,
                    42.582,
                    43.815,
                    45.048,
                    46.281,
                    47.514,
                    48.746,
                    49.979,
                    51.212,
                    52.445,
                    53.678,
                    54.911,
                    56.143,
                    57.376,
                    58.609,
                    59.842,
                    61.075
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    4,
                    8,
                    36,
                    70,
                    147,
                    345,
                    709,
                    1322,
                    2247,
                    3510,
                    4665,
                    5638,
                    5821,
                    5550,
                    4751,
                    3862,
                    2877,
                    2246,
                    1672,
                    1299,
                    1001,
                    742,
                    588,
                    391,
                    302,
                    172,
                    111,
                    79,
                    40,
                    21,
                    18,
                    4,
                    3,
                    1,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.761,
                    -0.707,
                    -0.653,
                    -0.599,
                    -0.545,
                    -0.491,
                    -0.437,
                    -0.382,
                    -0.328,
                    -0.274,
                    -0.22,
                    -0.166,
                    -0.112,
                    -0.058,
                    -0.003,
                    0.051,
                    0.105,
                    0.159,
                    0.213,
                    0.267,
                    0.321,
                    0.376,
                    0.43,
                    0.484,
                    0.538,
                    0.592,
                    0.646,
                    0.7,
                    0.755,
                    0.809,
                    0.863,
                    0.917,
                    0.971,
                    1.025,
                    1.079,
                    1.134,
                    1.188,
                    1.242,
                    1.296,
                    1.35,
                    1.404,
                    1.458,
                    1.513,
                    1.567,
                    1.621,
                    1.675,
                    1.729,
                    1.783,
                    1.837,
                    1.891
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clz02zqya28r65q0z6vp5h85m",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "24636",
                        "description": " occurrences of the word 'jew' in various contexts",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-24T16:50:54.820Z",
                        "updatedAt": "2024-07-24T16:50:54.820Z"
                    },
                    {
                        "id": "clzea433y40ybv3wq8mrhsss8",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "24636",
                        "description": " references to valuable items or possessions",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T15:19:01.054Z",
                        "updatedAt": "2024-08-03T15:19:01.054Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygg154ttz7u10exotoz5fnt",
                        "tokens": [
                            " out",
                            " that",
                            " in",
                            " the",
                            " 1950",
                            "s",
                            " and",
                            " 1960",
                            "s",
                            " millions",
                            " of",
                            " people",
                            " across",
                            " the",
                            " Western",
                            " world",
                            " acquired",
                            " cars",
                            ",",
                            " telev",
                            "isions",
                            ",",
                            " record",
                            " players",
                            ",",
                            " jew",
                            "ellery",
                            " and",
                            " so",
                            " on",
                            " for",
                            " the",
                            " first",
                            " time",
                            ";",
                            " rich",
                            " pick",
                            "ings",
                            " for",
                            " those",
                            " who",
                            " would",
                            " steal",
                            " them",
                            ".",
                            " In",
                            " the",
                            " decades",
                            " since",
                            ",",
                            " those",
                            " same",
                            " people",
                            " have",
                            " added",
                            " burg",
                            "lar",
                            " alarms",
                            ",",
                            " window",
                            " locks",
                            " and",
                            " safe",
                            " deposit",
                            " boxes",
                            ".",
                            " Between",
                            " 1995",
                            " and",
                            " 2011",
                            ",",
                            " the",
                            " proportion",
                            " of",
                            " British",
                            " households",
                            " with",
                            " burg",
                            "lar",
                            " alarms",
                            " increased",
                            " by",
                            " half",
                            ",",
                            " to",
                            " 29",
                            "%.",
                            " And",
                            " some",
                            " things",
                            " once",
                            " worth",
                            " stealing",
                            " from",
                            " people",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " homes",
                            " have",
                            " become",
                            " less",
                            " valuable",
                            ".",
                            " There",
                            " is",
                            " little",
                            " point",
                            " in",
                            " burg",
                            "ling",
                            " a",
                            " house",
                            " to",
                            " steal",
                            " a",
                            " DVD",
                            " player",
                            " worth",
                            " $",
                            "30",
                            ".",
                            "\n",
                            "\n",
                            "Bell",
                            "man",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "24636",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 61.691,
                        "maxValueTokenIndex": 25,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            61.691,
                            3.086,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:00:31.382Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 61.691,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygg154vtz8a10exw9lfsckk",
                        "tokens": [
                            " out",
                            " that",
                            " in",
                            " the",
                            " 1950",
                            "s",
                            " and",
                            " 1960",
                            "s",
                            " millions",
                            " of",
                            " people",
                            " across",
                            " the",
                            " Western",
                            " world",
                            " acquired",
                            " cars",
                            ",",
                            " telev",
                            "isions",
                            ",",
                            " record",
                            " players",
                            ",",
                            " jew",
                            "ellery",
                            " and",
                            " so",
                            " on",
                            " for",
                            " the",
                            " first",
                            " time",
                            ";",
                            " rich",
                            " pick",
                            "ings",
                            " for",
                            " those",
                            " who",
                            " would",
                            " steal",
                            " them",
                            ".",
                            " In",
                            " the",
                            " decades",
                            " since",
                            ",",
                            " those",
                            " same",
                            " people",
                            " have",
                            " added",
                            " burg",
                            "lar",
                            " alarms",
                            ",",
                            " window",
                            " locks",
                            " and",
                            " safe",
                            " deposit",
                            " boxes",
                            ".",
                            " Between",
                            " 1995",
                            " and",
                            " 2011",
                            ",",
                            " the",
                            " proportion",
                            " of",
                            " British",
                            " households",
                            " with",
                            " burg",
                            "lar",
                            " alarms",
                            " increased",
                            " by",
                            " half",
                            ",",
                            " to",
                            " 29",
                            "%.",
                            " And",
                            " some",
                            " things",
                            " once",
                            " worth",
                            " stealing",
                            " from",
                            " people",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " homes",
                            " have",
                            " become",
                            " less",
                            " valuable",
                            ".",
                            " There",
                            " is",
                            " little",
                            " point",
                            " in",
                            " burg",
                            "ling",
                            " a",
                            " house",
                            " to",
                            " steal",
                            " a",
                            " DVD",
                            " player",
                            " worth",
                            " $",
                            "30",
                            ".",
                            "\n",
                            "\n",
                            "Bell",
                            "man",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "24636",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 61.691,
                        "maxValueTokenIndex": 25,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            61.691,
                            3.086,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:00:31.382Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 61.691,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygg154vtz8e10exxbu7bljy",
                        "tokens": [
                            " out",
                            " that",
                            " in",
                            " the",
                            " 1950",
                            "s",
                            " and",
                            " 1960",
                            "s",
                            " millions",
                            " of",
                            " people",
                            " across",
                            " the",
                            " Western",
                            " world",
                            " acquired",
                            " cars",
                            ",",
                            " telev",
                            "isions",
                            ",",
                            " record",
                            " players",
                            ",",
                            " jew",
                            "ellery",
                            " and",
                            " so",
                            " on",
                            " for",
                            " the",
                            " first",
                            " time",
                            ";",
                            " rich",
                            " pick",
                            "ings",
                            " for",
                            " those",
                            " who",
                            " would",
                            " steal",
                            " them",
                            ".",
                            " In",
                            " the",
                            " decades",
                            " since",
                            ",",
                            " those",
                            " same",
                            " people",
                            " have",
                            " added",
                            " burg",
                            "lar",
                            " alarms",
                            ",",
                            " window",
                            " locks",
                            " and",
                            " safe",
                            " deposit",
                            " boxes",
                            ".",
                            " Between",
                            " 1995",
                            " and",
                            " 2011",
                            ",",
                            " the",
                            " proportion",
                            " of",
                            " British",
                            " households",
                            " with",
                            " burg",
                            "lar",
                            " alarms",
                            " increased",
                            " by",
                            " half",
                            ",",
                            " to",
                            " 29",
                            "%.",
                            " And",
                            " some",
                            " things",
                            " once",
                            " worth",
                            " stealing",
                            " from",
                            " people",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " homes",
                            " have",
                            " become",
                            " less",
                            " valuable",
                            ".",
                            " There",
                            " is",
                            " little",
                            " point",
                            " in",
                            " burg",
                            "ling",
                            " a",
                            " house",
                            " to",
                            " steal",
                            " a",
                            " DVD",
                            " player",
                            " worth",
                            " $",
                            "30",
                            ".",
                            "\n",
                            "\n",
                            "Bell",
                            "man",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "24636",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 61.691,
                        "maxValueTokenIndex": 25,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            61.691,
                            3.086,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:00:31.382Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 49.353,
                        "binMax": 61.691,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "51431",
            "description": "references to Jews and Jewish identity",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 50.276,
            "frac_nonzero": 8e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "51431",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:38:43.271Z",
                "maxActApprox": 50.276,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    51431,
                    59581,
                    36896,
                    53386,
                    85962,
                    2177,
                    40828,
                    71538,
                    13862,
                    63225,
                    86795,
                    79841,
                    6018,
                    4266,
                    74705,
                    46814,
                    97682,
                    21226,
                    11172,
                    39189,
                    65426,
                    85294,
                    532,
                    44644,
                    86894
                ],
                "topkCosSimValues": [
                    1,
                    0.7955,
                    0.6415,
                    0.6089,
                    0.5857,
                    0.5524,
                    0.5442,
                    0.5414,
                    0.5362,
                    0.5191,
                    0.5173,
                    0.4977,
                    0.4938,
                    0.4893,
                    0.4859,
                    0.4846,
                    0.4836,
                    0.4755,
                    0.4659,
                    0.4537,
                    0.4445,
                    0.4444,
                    0.4431,
                    0.443,
                    0.4404
                ],
                "neuron_alignment_indices": [
                    481,
                    447,
                    289
                ],
                "neuron_alignment_values": [
                    0.14,
                    0.135,
                    0.124
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.006
                ],
                "correlated_neurons_indices": [
                    289,
                    132,
                    592
                ],
                "correlated_neurons_pearson": [
                    0.012,
                    0.012,
                    0.012
                ],
                "correlated_neurons_l1": [
                    0.008,
                    0.012,
                    0.011
                ],
                "correlated_features_indices": [
                    51445,
                    51489,
                    51512
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.003,
                    0
                ],
                "correlated_features_l1": [
                    0.005,
                    0.003,
                    0
                ],
                "neg_str": [
                    "inventoryQuantity",
                    "Accessory",
                    "aneously",
                    "ctive",
                    " ERA",
                    "ttes",
                    "SPONSORED",
                    "quickShipAvailable",
                    "amina",
                    "shown"
                ],
                "neg_values": [
                    -0.818,
                    -0.747,
                    -0.719,
                    -0.709,
                    -0.699,
                    -0.665,
                    -0.651,
                    -0.648,
                    -0.648,
                    -0.638
                ],
                "pos_str": [
                    "ellery",
                    "ophobia",
                    " worsh",
                    "ophobic",
                    "geist",
                    "eller",
                    " settlers",
                    "esses",
                    " Refugees",
                    "eni"
                ],
                "pos_values": [
                    0.833,
                    0.829,
                    0.816,
                    0.815,
                    0.796,
                    0.727,
                    0.726,
                    0.717,
                    0.717,
                    0.716
                ],
                "frac_nonzero": 8e-05,
                "freq_hist_data_bar_heights": [
                    61,
                    43,
                    26,
                    12,
                    9,
                    7,
                    3,
                    5,
                    3,
                    2,
                    0,
                    0,
                    0,
                    3,
                    4,
                    1,
                    0,
                    1,
                    0,
                    1,
                    1,
                    1,
                    2,
                    0,
                    0,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    1,
                    0,
                    2,
                    2,
                    2,
                    5,
                    2,
                    7,
                    3,
                    6,
                    7,
                    4,
                    8,
                    5,
                    2,
                    4
                ],
                "freq_hist_data_bar_values": [
                    0.519,
                    1.525,
                    2.53,
                    3.535,
                    4.54,
                    5.545,
                    6.55,
                    7.556,
                    8.561,
                    9.566,
                    10.571,
                    11.576,
                    12.582,
                    13.587,
                    14.592,
                    15.597,
                    16.602,
                    17.607,
                    18.613,
                    19.618,
                    20.623,
                    21.628,
                    22.633,
                    23.639,
                    24.644,
                    25.649,
                    26.654,
                    27.659,
                    28.664,
                    29.67,
                    30.675,
                    31.68,
                    32.685,
                    33.69,
                    34.696,
                    35.701,
                    36.706,
                    37.711,
                    38.716,
                    39.721,
                    40.727,
                    41.732,
                    42.737,
                    43.742,
                    44.747,
                    45.753,
                    46.758,
                    47.763,
                    48.768,
                    49.773
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    2,
                    1,
                    10,
                    12,
                    20,
                    35,
                    44,
                    81,
                    94,
                    178,
                    295,
                    487,
                    682,
                    1009,
                    1302,
                    1834,
                    2312,
                    2734,
                    3319,
                    3841,
                    3940,
                    4051,
                    4053,
                    3784,
                    3355,
                    2972,
                    2551,
                    2006,
                    1524,
                    1176,
                    820,
                    559,
                    403,
                    277,
                    165,
                    112,
                    72,
                    42,
                    36,
                    19,
                    16,
                    13,
                    4,
                    7,
                    0,
                    1,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.802,
                    -0.768,
                    -0.735,
                    -0.702,
                    -0.669,
                    -0.636,
                    -0.603,
                    -0.57,
                    -0.537,
                    -0.504,
                    -0.471,
                    -0.438,
                    -0.405,
                    -0.372,
                    -0.339,
                    -0.306,
                    -0.273,
                    -0.24,
                    -0.207,
                    -0.174,
                    -0.141,
                    -0.108,
                    -0.075,
                    -0.042,
                    -0.009,
                    0.024,
                    0.057,
                    0.09,
                    0.123,
                    0.156,
                    0.189,
                    0.222,
                    0.255,
                    0.288,
                    0.322,
                    0.355,
                    0.388,
                    0.421,
                    0.454,
                    0.487,
                    0.52,
                    0.553,
                    0.586,
                    0.619,
                    0.652,
                    0.685,
                    0.718,
                    0.751,
                    0.784,
                    0.817
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clz1hggni2kj9weoxnqf8n3p4",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "51431",
                        "description": "references to Jews and Jewish identity",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-25T16:23:35.502Z",
                        "updatedAt": "2024-07-25T16:23:35.502Z"
                    },
                    {
                        "id": "clze3c0cl3eejv3wqfqcz68nv",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "51431",
                        "description": "mentions of Jews and Judaism",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T12:09:13.413Z",
                        "updatedAt": "2024-08-03T12:09:13.413Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghea3ge9li10exok38lect",
                        "tokens": [
                            "Your",
                            " national",
                            " aspirations",
                            " lie",
                            " elsewhere",
                            ".'\"",
                            "\n",
                            "\n",
                            "The",
                            " distinction",
                            " that",
                            " Morris",
                            " makes",
                            " between",
                            " ethnic",
                            " cleansing",
                            " and",
                            " genocide",
                            " is",
                            " a",
                            " false",
                            " one",
                            ".",
                            " One",
                            " practice",
                            " leads",
                            " to",
                            " the",
                            " other",
                            ".",
                            " The",
                            " Nazis",
                            "'",
                            " \"",
                            "final",
                            " solution",
                            "\"",
                            " initially",
                            " called",
                            " for",
                            " forced",
                            " em",
                            "igration",
                            ",",
                            " the",
                            " expulsion",
                            " of",
                            " Jews",
                            " from",
                            " Germany",
                            ".",
                            " Then",
                            " came",
                            " the",
                            " death",
                            " camps",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " Times",
                            "'",
                            " publication",
                            " of",
                            " Morris",
                            "'s",
                            " column",
                            " only",
                            " underscores",
                            " its",
                            " own",
                            " opportun",
                            "istic",
                            " and",
                            " cynical",
                            " attitude",
                            " towards",
                            " ethnic",
                            " cleansing",
                            " and",
                            " genocide",
                            ".",
                            " Whether",
                            " it",
                            " opposes",
                            " these",
                            " practices",
                            " or",
                            " tacit",
                            "ly",
                            " accepts",
                            " them",
                            " is",
                            " entirely",
                            " dependent",
                            " on",
                            " who",
                            " is",
                            " carrying",
                            " them",
                            " out",
                            " and",
                            " whose",
                            " interests",
                            " are",
                            " served",
                            ".",
                            "\n",
                            "\n",
                            "Thus",
                            ",",
                            " on",
                            " Sunday",
                            " it",
                            " published",
                            " a",
                            " piece",
                            " by",
                            " its",
                            " columnist",
                            " Nicholas",
                            " Krist",
                            "of",
                            " urging",
                            " Obama",
                            " to",
                            " take"
                        ],
                        "dataIndex": null,
                        "index": "51431",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.276,
                        "maxValueTokenIndex": 47,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.083,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.276,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:43.950Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 50.276,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghea3he9lj10ex6q08mrld",
                        "tokens": [
                            " little",
                            " villages",
                            " cut",
                            " off",
                            " from",
                            " the",
                            " world",
                            ".",
                            " Time",
                            " stood",
                            " still",
                            " as",
                            " he",
                            " told",
                            " me",
                            " fabulous",
                            " things",
                            " about",
                            " those",
                            " parts",
                            " of",
                            " the",
                            " world",
                            " and",
                            " the",
                            " people",
                            " who",
                            " live",
                            " there",
                            ".",
                            "\n",
                            "\n",
                            "After",
                            " a",
                            " few",
                            " hours",
                            " I",
                            " told",
                            " him",
                            " how",
                            " wonderful",
                            " it",
                            " was",
                            " to",
                            " sit",
                            " and",
                            " listen",
                            " to",
                            " all",
                            " he",
                            " has",
                            " to",
                            " tell",
                            ",",
                            " but",
                            " that",
                            " the",
                            " time",
                            " had",
                            " come",
                            " to",
                            " return",
                            " to",
                            " my",
                            " hotel",
                            ".",
                            " He",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "All",
                            " this",
                            " food",
                            " is",
                            " still",
                            " here",
                            " and",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " already",
                            " looking",
                            " for",
                            " another",
                            " place",
                            "?",
                            " Even",
                            " if",
                            " they",
                            " had",
                            " prepared",
                            " a",
                            " big",
                            " meal",
                            " for",
                            " you",
                            " at",
                            " the",
                            " hotel",
                            " others",
                            " have",
                            " surely",
                            " come",
                            " and",
                            " eaten",
                            " it",
                            " already",
                            ",",
                            " for",
                            " a",
                            " boat",
                            "load",
                            " of",
                            " Jews",
                            " d",
                            "ocked",
                            " just",
                            " last",
                            " night",
                            ".",
                            " Ships",
                            " come",
                            " and",
                            " ships",
                            " go"
                        ],
                        "dataIndex": null,
                        "index": "51431",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.155,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.155,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:43.950Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 50.276,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghea3he9lk10ex75jlf1a2",
                        "tokens": [
                            " of",
                            " the",
                            " settlers",
                            ".",
                            "\n",
                            "\n",
                            "At",
                            " a",
                            " DC",
                            " conference",
                            " two",
                            " weeks",
                            " ago",
                            ",",
                            " Friedman",
                            " compared",
                            " members",
                            " of",
                            " \"",
                            "J",
                            " Street",
                            ",\"",
                            " prominent",
                            " American",
                            " Jewish",
                            " leaders",
                            " who",
                            " support",
                            " a",
                            " two",
                            "-",
                            "state",
                            " solution",
                            ",",
                            " to",
                            " Jews",
                            " who",
                            " collaborated",
                            " with",
                            " the",
                            " Nazis",
                            " in",
                            " concentration",
                            " camps",
                            ".",
                            "\n",
                            "\n",
                            "F",
                            "ried",
                            "man",
                            "'s",
                            " nomination",
                            " requires",
                            " confirmation",
                            " by",
                            " the",
                            " Senate",
                            ".",
                            "<|endoftext|>",
                            "New",
                            " York",
                            " Red",
                            " Bulls",
                            " Home",
                            "grown",
                            " midfielder",
                            " Tyler",
                            " Adams",
                            " earned",
                            " a",
                            " start",
                            " for",
                            " the",
                            " United",
                            " States",
                            " Under",
                            "-",
                            "18",
                            " National",
                            " Team",
                            " yesterday",
                            " in",
                            " a",
                            " 4",
                            "-",
                            "0",
                            " win",
                            " over",
                            " a",
                            " youth",
                            " side",
                            " from",
                            " Ch",
                            "ivas",
                            " Gu",
                            "adal",
                            "aj",
                            "ara",
                            ".",
                            "\n",
                            "\n",
                            "Adams",
                            " joined",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " U",
                            "-",
                            "18",
                            "s",
                            " over",
                            " the",
                            " weekend",
                            " for",
                            " camp",
                            " in",
                            " Gu",
                            "adal",
                            "aj",
                            "ara",
                            ",",
                            " Mexico",
                            ".",
                            "\n",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "51431",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.634,
                        "maxValueTokenIndex": 35,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.634,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:43.950Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 50.276,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "51431",
            "description": "mentions of Jews and Judaism",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 50.276,
            "frac_nonzero": 8e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "51431",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:38:43.271Z",
                "maxActApprox": 50.276,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    51431,
                    59581,
                    36896,
                    53386,
                    85962,
                    2177,
                    40828,
                    71538,
                    13862,
                    63225,
                    86795,
                    79841,
                    6018,
                    4266,
                    74705,
                    46814,
                    97682,
                    21226,
                    11172,
                    39189,
                    65426,
                    85294,
                    532,
                    44644,
                    86894
                ],
                "topkCosSimValues": [
                    1,
                    0.7955,
                    0.6415,
                    0.6089,
                    0.5857,
                    0.5524,
                    0.5442,
                    0.5414,
                    0.5362,
                    0.5191,
                    0.5173,
                    0.4977,
                    0.4938,
                    0.4893,
                    0.4859,
                    0.4846,
                    0.4836,
                    0.4755,
                    0.4659,
                    0.4537,
                    0.4445,
                    0.4444,
                    0.4431,
                    0.443,
                    0.4404
                ],
                "neuron_alignment_indices": [
                    481,
                    447,
                    289
                ],
                "neuron_alignment_values": [
                    0.14,
                    0.135,
                    0.124
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.006
                ],
                "correlated_neurons_indices": [
                    289,
                    132,
                    592
                ],
                "correlated_neurons_pearson": [
                    0.012,
                    0.012,
                    0.012
                ],
                "correlated_neurons_l1": [
                    0.008,
                    0.012,
                    0.011
                ],
                "correlated_features_indices": [
                    51445,
                    51489,
                    51512
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.003,
                    0
                ],
                "correlated_features_l1": [
                    0.005,
                    0.003,
                    0
                ],
                "neg_str": [
                    "inventoryQuantity",
                    "Accessory",
                    "aneously",
                    "ctive",
                    " ERA",
                    "ttes",
                    "SPONSORED",
                    "quickShipAvailable",
                    "amina",
                    "shown"
                ],
                "neg_values": [
                    -0.818,
                    -0.747,
                    -0.719,
                    -0.709,
                    -0.699,
                    -0.665,
                    -0.651,
                    -0.648,
                    -0.648,
                    -0.638
                ],
                "pos_str": [
                    "ellery",
                    "ophobia",
                    " worsh",
                    "ophobic",
                    "geist",
                    "eller",
                    " settlers",
                    "esses",
                    " Refugees",
                    "eni"
                ],
                "pos_values": [
                    0.833,
                    0.829,
                    0.816,
                    0.815,
                    0.796,
                    0.727,
                    0.726,
                    0.717,
                    0.717,
                    0.716
                ],
                "frac_nonzero": 8e-05,
                "freq_hist_data_bar_heights": [
                    61,
                    43,
                    26,
                    12,
                    9,
                    7,
                    3,
                    5,
                    3,
                    2,
                    0,
                    0,
                    0,
                    3,
                    4,
                    1,
                    0,
                    1,
                    0,
                    1,
                    1,
                    1,
                    2,
                    0,
                    0,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    1,
                    0,
                    2,
                    2,
                    2,
                    5,
                    2,
                    7,
                    3,
                    6,
                    7,
                    4,
                    8,
                    5,
                    2,
                    4
                ],
                "freq_hist_data_bar_values": [
                    0.519,
                    1.525,
                    2.53,
                    3.535,
                    4.54,
                    5.545,
                    6.55,
                    7.556,
                    8.561,
                    9.566,
                    10.571,
                    11.576,
                    12.582,
                    13.587,
                    14.592,
                    15.597,
                    16.602,
                    17.607,
                    18.613,
                    19.618,
                    20.623,
                    21.628,
                    22.633,
                    23.639,
                    24.644,
                    25.649,
                    26.654,
                    27.659,
                    28.664,
                    29.67,
                    30.675,
                    31.68,
                    32.685,
                    33.69,
                    34.696,
                    35.701,
                    36.706,
                    37.711,
                    38.716,
                    39.721,
                    40.727,
                    41.732,
                    42.737,
                    43.742,
                    44.747,
                    45.753,
                    46.758,
                    47.763,
                    48.768,
                    49.773
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    2,
                    1,
                    10,
                    12,
                    20,
                    35,
                    44,
                    81,
                    94,
                    178,
                    295,
                    487,
                    682,
                    1009,
                    1302,
                    1834,
                    2312,
                    2734,
                    3319,
                    3841,
                    3940,
                    4051,
                    4053,
                    3784,
                    3355,
                    2972,
                    2551,
                    2006,
                    1524,
                    1176,
                    820,
                    559,
                    403,
                    277,
                    165,
                    112,
                    72,
                    42,
                    36,
                    19,
                    16,
                    13,
                    4,
                    7,
                    0,
                    1,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.802,
                    -0.768,
                    -0.735,
                    -0.702,
                    -0.669,
                    -0.636,
                    -0.603,
                    -0.57,
                    -0.537,
                    -0.504,
                    -0.471,
                    -0.438,
                    -0.405,
                    -0.372,
                    -0.339,
                    -0.306,
                    -0.273,
                    -0.24,
                    -0.207,
                    -0.174,
                    -0.141,
                    -0.108,
                    -0.075,
                    -0.042,
                    -0.009,
                    0.024,
                    0.057,
                    0.09,
                    0.123,
                    0.156,
                    0.189,
                    0.222,
                    0.255,
                    0.288,
                    0.322,
                    0.355,
                    0.388,
                    0.421,
                    0.454,
                    0.487,
                    0.52,
                    0.553,
                    0.586,
                    0.619,
                    0.652,
                    0.685,
                    0.718,
                    0.751,
                    0.784,
                    0.817
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clz1hggni2kj9weoxnqf8n3p4",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "51431",
                        "description": "references to Jews and Jewish identity",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-25T16:23:35.502Z",
                        "updatedAt": "2024-07-25T16:23:35.502Z"
                    },
                    {
                        "id": "clze3c0cl3eejv3wqfqcz68nv",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "51431",
                        "description": "mentions of Jews and Judaism",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T12:09:13.413Z",
                        "updatedAt": "2024-08-03T12:09:13.413Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghea3ge9li10exok38lect",
                        "tokens": [
                            "Your",
                            " national",
                            " aspirations",
                            " lie",
                            " elsewhere",
                            ".'\"",
                            "\n",
                            "\n",
                            "The",
                            " distinction",
                            " that",
                            " Morris",
                            " makes",
                            " between",
                            " ethnic",
                            " cleansing",
                            " and",
                            " genocide",
                            " is",
                            " a",
                            " false",
                            " one",
                            ".",
                            " One",
                            " practice",
                            " leads",
                            " to",
                            " the",
                            " other",
                            ".",
                            " The",
                            " Nazis",
                            "'",
                            " \"",
                            "final",
                            " solution",
                            "\"",
                            " initially",
                            " called",
                            " for",
                            " forced",
                            " em",
                            "igration",
                            ",",
                            " the",
                            " expulsion",
                            " of",
                            " Jews",
                            " from",
                            " Germany",
                            ".",
                            " Then",
                            " came",
                            " the",
                            " death",
                            " camps",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " Times",
                            "'",
                            " publication",
                            " of",
                            " Morris",
                            "'s",
                            " column",
                            " only",
                            " underscores",
                            " its",
                            " own",
                            " opportun",
                            "istic",
                            " and",
                            " cynical",
                            " attitude",
                            " towards",
                            " ethnic",
                            " cleansing",
                            " and",
                            " genocide",
                            ".",
                            " Whether",
                            " it",
                            " opposes",
                            " these",
                            " practices",
                            " or",
                            " tacit",
                            "ly",
                            " accepts",
                            " them",
                            " is",
                            " entirely",
                            " dependent",
                            " on",
                            " who",
                            " is",
                            " carrying",
                            " them",
                            " out",
                            " and",
                            " whose",
                            " interests",
                            " are",
                            " served",
                            ".",
                            "\n",
                            "\n",
                            "Thus",
                            ",",
                            " on",
                            " Sunday",
                            " it",
                            " published",
                            " a",
                            " piece",
                            " by",
                            " its",
                            " columnist",
                            " Nicholas",
                            " Krist",
                            "of",
                            " urging",
                            " Obama",
                            " to",
                            " take"
                        ],
                        "dataIndex": null,
                        "index": "51431",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.276,
                        "maxValueTokenIndex": 47,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.083,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.276,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:43.950Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 50.276,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghea3he9lj10ex6q08mrld",
                        "tokens": [
                            " little",
                            " villages",
                            " cut",
                            " off",
                            " from",
                            " the",
                            " world",
                            ".",
                            " Time",
                            " stood",
                            " still",
                            " as",
                            " he",
                            " told",
                            " me",
                            " fabulous",
                            " things",
                            " about",
                            " those",
                            " parts",
                            " of",
                            " the",
                            " world",
                            " and",
                            " the",
                            " people",
                            " who",
                            " live",
                            " there",
                            ".",
                            "\n",
                            "\n",
                            "After",
                            " a",
                            " few",
                            " hours",
                            " I",
                            " told",
                            " him",
                            " how",
                            " wonderful",
                            " it",
                            " was",
                            " to",
                            " sit",
                            " and",
                            " listen",
                            " to",
                            " all",
                            " he",
                            " has",
                            " to",
                            " tell",
                            ",",
                            " but",
                            " that",
                            " the",
                            " time",
                            " had",
                            " come",
                            " to",
                            " return",
                            " to",
                            " my",
                            " hotel",
                            ".",
                            " He",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "All",
                            " this",
                            " food",
                            " is",
                            " still",
                            " here",
                            " and",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " already",
                            " looking",
                            " for",
                            " another",
                            " place",
                            "?",
                            " Even",
                            " if",
                            " they",
                            " had",
                            " prepared",
                            " a",
                            " big",
                            " meal",
                            " for",
                            " you",
                            " at",
                            " the",
                            " hotel",
                            " others",
                            " have",
                            " surely",
                            " come",
                            " and",
                            " eaten",
                            " it",
                            " already",
                            ",",
                            " for",
                            " a",
                            " boat",
                            "load",
                            " of",
                            " Jews",
                            " d",
                            "ocked",
                            " just",
                            " last",
                            " night",
                            ".",
                            " Ships",
                            " come",
                            " and",
                            " ships",
                            " go"
                        ],
                        "dataIndex": null,
                        "index": "51431",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.155,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.155,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:43.950Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 50.276,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghea3he9lk10ex75jlf1a2",
                        "tokens": [
                            " of",
                            " the",
                            " settlers",
                            ".",
                            "\n",
                            "\n",
                            "At",
                            " a",
                            " DC",
                            " conference",
                            " two",
                            " weeks",
                            " ago",
                            ",",
                            " Friedman",
                            " compared",
                            " members",
                            " of",
                            " \"",
                            "J",
                            " Street",
                            ",\"",
                            " prominent",
                            " American",
                            " Jewish",
                            " leaders",
                            " who",
                            " support",
                            " a",
                            " two",
                            "-",
                            "state",
                            " solution",
                            ",",
                            " to",
                            " Jews",
                            " who",
                            " collaborated",
                            " with",
                            " the",
                            " Nazis",
                            " in",
                            " concentration",
                            " camps",
                            ".",
                            "\n",
                            "\n",
                            "F",
                            "ried",
                            "man",
                            "'s",
                            " nomination",
                            " requires",
                            " confirmation",
                            " by",
                            " the",
                            " Senate",
                            ".",
                            "<|endoftext|>",
                            "New",
                            " York",
                            " Red",
                            " Bulls",
                            " Home",
                            "grown",
                            " midfielder",
                            " Tyler",
                            " Adams",
                            " earned",
                            " a",
                            " start",
                            " for",
                            " the",
                            " United",
                            " States",
                            " Under",
                            "-",
                            "18",
                            " National",
                            " Team",
                            " yesterday",
                            " in",
                            " a",
                            " 4",
                            "-",
                            "0",
                            " win",
                            " over",
                            " a",
                            " youth",
                            " side",
                            " from",
                            " Ch",
                            "ivas",
                            " Gu",
                            "adal",
                            "aj",
                            "ara",
                            ".",
                            "\n",
                            "\n",
                            "Adams",
                            " joined",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " U",
                            "-",
                            "18",
                            "s",
                            " over",
                            " the",
                            " weekend",
                            " for",
                            " camp",
                            " in",
                            " Gu",
                            "adal",
                            "aj",
                            "ara",
                            ",",
                            " Mexico",
                            ".",
                            "\n",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "51431",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.634,
                        "maxValueTokenIndex": 35,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.634,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:43.950Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 50.276,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "12-res-jb",
            "index": "12392",
            "description": " information related to incidents of harassment and hate targeting specific groups like American Jews and Muslims",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 46.206,
            "frac_nonzero": 0.00471,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "12-res-jb",
                "index": "12392",
                "sourceSetName": "res-jb",
                "creatorId": null,
                "createdAt": "2024-05-30T06:03:48.930Z",
                "maxActApprox": 46.206,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    12392,
                    21168,
                    18534,
                    11287,
                    14228,
                    18686,
                    22263,
                    7165,
                    10495,
                    18921,
                    5576,
                    16502,
                    12944,
                    21542,
                    22871,
                    16550,
                    11845,
                    3269,
                    17326,
                    5090,
                    647,
                    20960,
                    12148,
                    12284,
                    19948
                ],
                "topkCosSimValues": [
                    1,
                    0.4572,
                    0.4468,
                    0.3985,
                    0.3688,
                    0.3667,
                    0.3539,
                    0.3539,
                    0.3501,
                    0.3413,
                    0.34,
                    0.3394,
                    0.3367,
                    0.3358,
                    0.3318,
                    0.3259,
                    0.321,
                    0.3199,
                    0.3173,
                    0.3141,
                    0.3087,
                    0.2948,
                    0.2872,
                    0.2841,
                    0.2821
                ],
                "neuron_alignment_indices": [
                    165,
                    252,
                    496
                ],
                "neuron_alignment_values": [
                    0.116,
                    0.115,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    616,
                    165,
                    103
                ],
                "correlated_neurons_pearson": [
                    0.046,
                    0.043,
                    0.04
                ],
                "correlated_neurons_l1": [
                    0.053,
                    0.022,
                    0.047
                ],
                "correlated_features_indices": [
                    12297,
                    12296,
                    12336
                ],
                "correlated_features_pearson": [
                    0.029,
                    0.012,
                    0.008
                ],
                "correlated_features_l1": [
                    0.032,
                    0.014,
                    0.011
                ],
                "neg_str": [
                    "ufact",
                    "enegger",
                    "soDeliveryDate",
                    "Medic",
                    "iago",
                    "imester",
                    "aird",
                    "wcsstore",
                    "natureconservancy",
                    "uta"
                ],
                "neg_values": [
                    -1.021,
                    -0.974,
                    -0.97,
                    -0.901,
                    -0.869,
                    -0.851,
                    -0.827,
                    -0.816,
                    -0.813,
                    -0.807
                ],
                "pos_str": [
                    " hate",
                    " Hate",
                    " hateful",
                    " bigotry",
                    " hatred",
                    "hate",
                    " swast",
                    " intolerance",
                    " racism",
                    " homophobic"
                ],
                "pos_values": [
                    1.891,
                    1.733,
                    1.587,
                    1.553,
                    1.531,
                    1.518,
                    1.441,
                    1.392,
                    1.391,
                    1.369
                ],
                "frac_nonzero": 0.00471,
                "freq_hist_data_bar_heights": [
                    3758,
                    2686,
                    2089,
                    1388,
                    1157,
                    789,
                    635,
                    480,
                    352,
                    295,
                    227,
                    194,
                    145,
                    106,
                    85,
                    72,
                    55,
                    50,
                    32,
                    35,
                    24,
                    23,
                    15,
                    14,
                    20,
                    7,
                    10,
                    14,
                    4,
                    8,
                    9,
                    3,
                    6,
                    1,
                    2,
                    3,
                    0,
                    2,
                    0,
                    2,
                    0,
                    1,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.462,
                    1.386,
                    2.31,
                    3.234,
                    4.159,
                    5.083,
                    6.007,
                    6.931,
                    7.855,
                    8.779,
                    9.703,
                    10.627,
                    11.552,
                    12.476,
                    13.4,
                    14.324,
                    15.248,
                    16.172,
                    17.096,
                    18.02,
                    18.944,
                    19.869,
                    20.793,
                    21.717,
                    22.641,
                    23.565,
                    24.489,
                    25.413,
                    26.337,
                    27.261,
                    28.186,
                    29.11,
                    30.034,
                    30.958,
                    31.882,
                    32.806,
                    33.73,
                    34.654,
                    35.578,
                    36.503,
                    37.427,
                    38.351,
                    39.275,
                    40.199,
                    41.123,
                    42.047,
                    42.971,
                    43.895,
                    44.82,
                    45.744
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    0,
                    3,
                    5,
                    8,
                    38,
                    72,
                    139,
                    245,
                    528,
                    779,
                    1447,
                    2129,
                    3042,
                    3874,
                    4769,
                    5495,
                    5676,
                    5538,
                    4673,
                    3729,
                    2701,
                    1870,
                    1179,
                    784,
                    505,
                    344,
                    215,
                    132,
                    97,
                    74,
                    44,
                    26,
                    24,
                    21,
                    12,
                    6,
                    8,
                    6,
                    4,
                    2,
                    4,
                    1,
                    2,
                    2,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.992,
                    -0.933,
                    -0.875,
                    -0.817,
                    -0.759,
                    -0.7,
                    -0.642,
                    -0.584,
                    -0.526,
                    -0.468,
                    -0.409,
                    -0.351,
                    -0.293,
                    -0.235,
                    -0.176,
                    -0.118,
                    -0.06,
                    -0.002,
                    0.056,
                    0.115,
                    0.173,
                    0.231,
                    0.289,
                    0.348,
                    0.406,
                    0.464,
                    0.522,
                    0.58,
                    0.639,
                    0.697,
                    0.755,
                    0.813,
                    0.872,
                    0.93,
                    0.988,
                    1.046,
                    1.104,
                    1.163,
                    1.221,
                    1.279,
                    1.337,
                    1.396,
                    1.454,
                    1.512,
                    1.57,
                    1.628,
                    1.687,
                    1.745,
                    1.803,
                    1.861
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clxkctjmxl15bi666634b0s0o",
                        "modelId": "gpt2-small",
                        "layer": "12-res-jb",
                        "index": "12392",
                        "description": " information related to incidents of harassment and hate targeting specific groups like American Jews and Muslims",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-06-18T12:02:00.490Z",
                        "updatedAt": "2024-06-18T12:02:00.490Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clwsunxeabsvrxgjqmrm1y43v",
                        "tokens": [
                            " the",
                            " United",
                            " States",
                            " rose",
                            " by",
                            " more",
                            " than",
                            " one",
                            "-",
                            "third",
                            " in",
                            " 2016",
                            " and",
                            " shot",
                            " up",
                            " 86",
                            " percent",
                            " in",
                            " the",
                            " first",
                            " three",
                            " months",
                            " of",
                            " 2017",
                            ",",
                            " the",
                            " Anti",
                            "-",
                            "Def",
                            "amation",
                            " League",
                            " reported",
                            ".",
                            "\n",
                            "\n",
                            "There",
                            " has",
                            " been",
                            " a",
                            " massive",
                            " increase",
                            " in",
                            " harassment",
                            " of",
                            " American",
                            " Jews",
                            ",",
                            " largely",
                            " since",
                            " November",
                            ",",
                            " and",
                            " at",
                            " least",
                            " 34",
                            " incidents",
                            " linked",
                            " to",
                            " the",
                            " presidential",
                            " election",
                            " in",
                            " November",
                            ",",
                            " the",
                            " AD",
                            "L",
                            " reported",
                            " Monday",
                            " in",
                            " its",
                            " annual",
                            " Audit",
                            " of",
                            " Anti",
                            "-",
                            "Semitic",
                            " incidents",
                            ".",
                            "\n",
                            "\n",
                            "There",
                            " were",
                            " a",
                            " total",
                            " of",
                            " 1",
                            ",",
                            "266",
                            " acts",
                            " targeting",
                            " Jews",
                            " and",
                            " Jewish",
                            " institutions",
                            " during",
                            " 2016",
                            ",",
                            " a",
                            " 34",
                            " percent",
                            " increase",
                            " of",
                            " incidents",
                            " of",
                            " assaults",
                            ",",
                            " vandalism",
                            ",",
                            " and",
                            " harassment",
                            " over",
                            " the",
                            " previous",
                            " year",
                            ".",
                            " Nearly",
                            " 30",
                            " percent",
                            " of",
                            " those",
                            " incidents",
                            ",",
                            " or",
                            " 369",
                            " of",
                            " them"
                        ],
                        "dataIndex": null,
                        "index": "12392",
                        "layer": "12-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.206,
                        "maxValueTokenIndex": 88,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.095,
                            1.649,
                            0,
                            7.452,
                            0,
                            4.415,
                            0,
                            0,
                            0,
                            0,
                            4.771,
                            0,
                            23.348,
                            11.301,
                            16.312,
                            13.822,
                            4.407,
                            20.882,
                            15.556,
                            22.834,
                            5.867,
                            18.131,
                            27.327,
                            11.715,
                            6.054,
                            22.342,
                            8.607,
                            18.938,
                            28.022,
                            25.192,
                            11.503,
                            7.514,
                            10.995,
                            13.898,
                            27.96,
                            26.215,
                            3.371,
                            11,
                            0,
                            0,
                            13.721,
                            20.306,
                            25.607,
                            0,
                            23.398,
                            15.865,
                            21.991,
                            21.322,
                            4.713,
                            25.492,
                            0,
                            21.316,
                            2.314,
                            13.971,
                            3.772,
                            3.375,
                            6.502,
                            6.234,
                            0,
                            46.206,
                            22.497,
                            24.63,
                            16.607,
                            22.072,
                            8.137,
                            14.008,
                            14.211,
                            4.986,
                            19.078,
                            12.005,
                            1.459,
                            0.31,
                            0,
                            24.043,
                            9.66,
                            35.036,
                            13.809,
                            26.683,
                            8.347,
                            21.215,
                            26.154,
                            14.952,
                            6.53,
                            6.277,
                            2.487,
                            0,
                            30.243,
                            0,
                            22.999,
                            18.428,
                            39.839,
                            38.363,
                            18.138,
                            19.764,
                            25.126,
                            32.382,
                            16.343,
                            26.973
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-05-30T06:03:58.453Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -0.04,
                            0,
                            -0.034,
                            0,
                            -0.019,
                            0,
                            0,
                            0,
                            0,
                            0.052,
                            0,
                            -0.975,
                            0.31,
                            0.583,
                            -0.341,
                            0.028,
                            0.247,
                            0.172,
                            0.033,
                            0.117,
                            0.088,
                            0.482,
                            0.014,
                            0.035,
                            -0.837,
                            -0.077,
                            0.614,
                            0.818,
                            0.497,
                            -0.024,
                            0.04,
                            0.092,
                            0.095,
                            0.021,
                            -0.13,
                            -0.001,
                            -0.226,
                            0,
                            0,
                            0.101,
                            0.059,
                            1.13,
                            0,
                            -1.051,
                            0.027,
                            -0.525,
                            -1.284,
                            0.072,
                            -0.049,
                            0,
                            -0.033,
                            -0.003,
                            0.008,
                            -0.012,
                            0.006,
                            -0.017,
                            -0.017,
                            0,
                            0.004,
                            -0.896,
                            -0.462,
                            0.111,
                            -0.893,
                            0.152,
                            0.113,
                            -0.076,
                            0.017,
                            -0.015,
                            0.095,
                            0,
                            0.001,
                            0,
                            -1.014,
                            0.003,
                            0.215,
                            0.216,
                            -1.126,
                            0.076,
                            1.101,
                            -0.498,
                            0.125,
                            0.086,
                            -0.001,
                            -0.001,
                            0,
                            0.225,
                            0,
                            0.232,
                            0.048,
                            1.069,
                            -0.434,
                            0.043,
                            0.044,
                            0.09,
                            1.521,
                            0.098
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.833, 0.752, 0.713, 0.694, 0.683]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.2, 0.181, 0.164, 0.16, 0.157]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.785, 0.712, 0.656, 0.64, 0.632]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.452, 0.416, 0.382, 0.373, 0.369]}, {}, {}, {}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.469, 0.428, 0.38, 0.368, 0.362]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.078, 1.878, 1.615, 1.562, 1.534]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.283, 1.175, 1.026, 0.993, 0.983]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.45, 1.288, 1.116, 1.077, 1.072]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.368, 1.212, 1.059, 1.013, 0.999]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.506, 0.464, 0.419, 0.409, 0.403]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.173, 1.977, 1.773, 1.718, 1.708]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [1.52, 1.406, 1.228, 1.212, 1.198]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.158, 1.956, 1.76, 1.711, 1.696]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.755, 0.678, 0.617, 0.602, 0.588]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.962, 1.773, 1.617, 1.58, 1.552]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [2.415, 2.206, 1.928, 1.872, 1.859]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.442, 1.318, 1.203, 1.174, 1.162]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [0.596, 0.552, 0.497, 0.487, 0.486]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.126, 1.928, 1.698, 1.664, 1.642]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.013, 0.93, 0.842, 0.827, 0.812]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.115, 1.898, 1.678, 1.626, 1.593]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.5, 2.235, 1.94, 1.86, 1.849]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.652, 2.391, 2.121, 2.065, 2.06]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.406, 1.266, 1.138, 1.095, 1.083]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.864, 0.79, 0.72, 0.701, 0.688]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.476, 1.338, 1.2, 1.173, 1.152]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.441, 1.312, 1.198, 1.171, 1.147]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.978, 2.703, 2.473, 2.42, 2.379]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.499, 2.232, 2.015, 1.968, 1.934]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.744, 0.685, 0.639, 0.626, 0.624]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.149, 1.039, 0.944, 0.921, 0.905]}, {}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.825, 1.655, 1.514, 1.478, 1.461]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.237, 2.014, 1.853, 1.817, 1.786]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.663, 2.37, 2.179, 2.114, 2.077]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.593, 2.24, 2.1, 2.033, 2.018]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" hatred\", \" bigotry\"], \"v\": [2.285, 2.064, 1.957, 1.879, 1.876]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.502, 2.181, 1.935, 1.827, 1.825]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.843, 2.479, 2.37, 2.274, 2.247]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.53, 0.48, 0.436, 0.424, 0.417]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.454, 2.19, 2.052, 2.003, 1.986]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.093, 1.914, 1.766, 1.719, 1.705]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.232, 0.212, 0.194, 0.189, 0.187]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.319, 1.227, 1.097, 1.077, 1.073]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.398, 0.366, 0.331, 0.325, 0.32]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.404, 0.374, 0.34, 0.332, 0.326]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.529, 0.49, 0.443, 0.434, 0.429]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.658, 0.605, 0.551, 0.541, 0.533]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.761, 2.458, 2.069, 2.033, 1.989]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.495, 2.281, 2.031, 1.995, 1.959]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.776, 1.586, 1.376, 1.325, 1.32]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.732, 1.586, 1.425, 1.398, 1.373]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [2.563, 2.355, 2.07, 2.028, 1.977]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.076, 0.978, 0.883, 0.843, 0.835]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.419, 1.304, 1.171, 1.15, 1.133]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.364, 1.228, 1.095, 1.068, 1.047]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.663, 0.608, 0.551, 0.539, 0.53]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.823, 1.671, 1.522, 1.489, 1.465]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.297, 1.185, 1.076, 1.054, 1.042]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.156, 0.141, 0.127, 0.124, 0.121]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.031, 0.028, 0.026, 0.025, 0.024]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.654, 2.441, 2.129, 2.082, 2.049]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.022, 0.94, 0.851, 0.835, 0.82]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [2.439, 2.183, 1.743, 1.693, 1.63]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.306, 1.19, 1.059, 1.031, 1.015]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [2.302, 2.106, 1.801, 1.757, 1.743]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.92, 0.838, 0.753, 0.736, 0.722]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [1.626, 1.455, 1.168, 1.13, 1.12]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [1.875, 1.683, 1.318, 1.306, 1.268]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.293, 1.187, 1.064, 1.04, 1.024]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.688, 0.624, 0.556, 0.543, 0.531]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.653, 0.598, 0.538, 0.529, 0.521]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.306, 0.282, 0.255, 0.25, 0.248]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.89, 2.55, 2.414, 2.358, 2.336]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.43, 2.215, 1.977, 1.934, 1.907]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.058, 1.863, 1.689, 1.645, 1.62]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.637, 2.356, 1.986, 1.931, 1.89]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.566, 2.277, 1.886, 1.838, 1.787]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.624, 1.501, 1.359, 1.337, 1.307]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.316, 2.114, 1.917, 1.881, 1.853]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.653, 2.465, 2.193, 2.158, 2.137]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.045, 1.79, 1.453, 1.423, 1.38]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.613, 1.478, 1.329, 1.3, 1.283]}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"imester\"], \"v\": [-0.447, -0.42, -0.419, -0.398, -0.381]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.15, -0.145, -0.143, -0.137, -0.131]}, {}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.459, -0.442, -0.44, -0.415, -0.395]}, {}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.221, -0.217, -0.212, -0.205, -0.19]}, {}, {}, {}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.412, -0.404, -0.396, -0.384, -0.375]}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.489, -2.439, -2.416, -2.334, -2.296]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.256, -1.218, -1.204, -1.164, -1.13]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.727, -1.703, -1.69, -1.61, -1.594]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.662, -1.608, -1.59, -1.547, -1.504]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.337, -0.327, -0.326, -0.304, -0.293]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.632, -1.571, -1.56, -1.509, -1.45]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.21, -1.16, -1.16, -1.101, -1.06]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.648, -1.61, -1.594, -1.496, -1.464]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-0.6, -0.59, -0.585, -0.56, -0.541]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"imester\"], \"v\": [-1.349, -1.314, -1.293, -1.234, -1.185]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-2.223, -2.168, -2.145, -2.068, -2.014]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.887, -0.853, -0.852, -0.801, -0.778]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.356, -0.342, -0.339, -0.328, -0.311]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-2.077, -2.03, -2.016, -1.951, -1.886]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.679, -0.647, -0.646, -0.613, -0.588]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-2.107, -2.046, -2.038, -1.954, -1.896]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-2.901, -2.84, -2.821, -2.714, -2.663]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-2.368, -2.332, -2.31, -2.213, -2.169]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.24, -1.216, -1.213, -1.134, -1.115]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.575, -0.555, -0.55, -0.52, -0.498]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-1.195, -1.171, -1.169, -1.102, -1.069]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.985, -0.959, -0.952, -0.894, -0.864]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"imester\"], \"v\": [-1.936, -1.866, -1.822, -1.769, -1.689]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.199, -2.139, -2.136, -2.028, -1.974]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"Medic\", \"enegger\", \"iago\"], \"v\": [-0.303, -0.297, -0.291, -0.285, -0.258]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.863, -0.828, -0.813, -0.786, -0.754]}, {}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.2, -1.159, -1.141, -1.09, -1.045]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.56, -1.509, -1.506, -1.44, -1.363]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.242, -2.184, -2.173, -2.088, -1.981]}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-2.26, -2.216, -2.178, -2.106, -2.043]}, {\"t\": [\"Medic\", \"soDeliveryDate\", \"ufact\", \"enegger\", \"iago\"], \"v\": [-1.121, -1.107, -1.08, -1.068, -1.011]}, {\"t\": [\"Medic\", \"soDeliveryDate\", \"ufact\", \"enegger\", \"iago\"], \"v\": [-2.871, -2.87, -2.87, -2.774, -2.664]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \" Nurs\"], \"v\": [-2.006, -1.959, -1.888, -1.862, -1.853]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.405, -0.389, -0.388, -0.373, -0.357]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-1.429, -1.384, -1.384, -1.32, -1.239]}, {}, {\"t\": [\"soDeliveryDate\", \"ufact\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.046, -1.027, -1.001, -1.0, -0.9]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.143, -0.138, -0.136, -0.128, -0.124]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.805, -0.774, -0.766, -0.737, -0.715]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.248, -0.236, -0.235, -0.226, -0.218]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.239, -0.234, -0.232, -0.221, -0.211]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.318, -0.31, -0.306, -0.293, -0.281]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.366, -0.354, -0.349, -0.328, -0.316]}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-3.937, -3.928, -3.877, -3.805, -3.685]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.916, -1.845, -1.838, -1.768, -1.692]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.074, -2.053, -2.026, -1.964, -1.928]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.213, -1.188, -1.168, -1.114, -1.073]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.208, -2.106, -2.103, -2.062, -1.954]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.876, -0.844, -0.843, -0.82, -0.777]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.978, -0.941, -0.94, -0.888, -0.854]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.208, -1.181, -1.173, -1.114, -1.09]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.424, -0.408, -0.408, -0.382, -0.368]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.116, -1.053, -1.044, -1.009, -0.965]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.82, -0.774, -0.773, -0.747, -0.725]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.122, -0.118, -0.118, -0.11, -0.107]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.023, -0.022, -0.022, -0.021, -0.02]}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.504, -2.475, -2.404, -2.356, -2.293]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.643, -0.616, -0.611, -0.576, -0.562]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-4.323, -4.27, -4.219, -4.192, -4.068]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.086, -1.042, -1.035, -0.99, -0.959]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.459, -2.377, -2.33, -2.328, -2.232]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.681, -0.653, -0.651, -0.616, -0.596]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.708, -2.65, -2.616, -2.571, -2.484]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-3.323, -3.246, -3.215, -3.162, -3.059]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.919, -0.884, -0.881, -0.834, -0.806]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.582, -0.564, -0.561, -0.531, -0.52]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.442, -0.427, -0.425, -0.4, -0.391]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.177, -0.169, -0.168, -0.159, -0.154]}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-1.729, -1.673, -1.661, -1.625, -1.511]}, {}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.971, -1.91, -1.906, -1.829, -1.758]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.482, -1.421, -1.419, -1.332, -1.294]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-3.669, -3.61, -3.592, -3.49, -3.411]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-3.993, -3.909, -3.867, -3.82, -3.735]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.026, -0.988, -0.95, -0.915, -0.895]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.507, -1.467, -1.419, -1.382, -1.324]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.793, -1.744, -1.692, -1.662, -1.576]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-3.676, -3.665, -3.631, -3.535, -3.435]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.068, -1.05, -1.024, -0.981, -0.944]}]}",
                        "binMin": -1,
                        "binMax": 46.206,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clwsunxebbsvtxgjqw0e1svfu",
                        "tokens": [
                            " the",
                            " United",
                            " States",
                            " rose",
                            " by",
                            " more",
                            " than",
                            " one",
                            "-",
                            "third",
                            " in",
                            " 2016",
                            " and",
                            " shot",
                            " up",
                            " 86",
                            " percent",
                            " in",
                            " the",
                            " first",
                            " three",
                            " months",
                            " of",
                            " 2017",
                            ",",
                            " the",
                            " Anti",
                            "-",
                            "Def",
                            "amation",
                            " League",
                            " reported",
                            ".",
                            "\n",
                            "\n",
                            "There",
                            " has",
                            " been",
                            " a",
                            " massive",
                            " increase",
                            " in",
                            " harassment",
                            " of",
                            " American",
                            " Jews",
                            ",",
                            " largely",
                            " since",
                            " November",
                            ",",
                            " and",
                            " at",
                            " least",
                            " 34",
                            " incidents",
                            " linked",
                            " to",
                            " the",
                            " presidential",
                            " election",
                            " in",
                            " November",
                            ",",
                            " the",
                            " AD",
                            "L",
                            " reported",
                            " Monday",
                            " in",
                            " its",
                            " annual",
                            " Audit",
                            " of",
                            " Anti",
                            "-",
                            "Semitic",
                            " incidents",
                            ".",
                            "\n",
                            "\n",
                            "There",
                            " were",
                            " a",
                            " total",
                            " of",
                            " 1",
                            ",",
                            "266",
                            " acts",
                            " targeting",
                            " Jews",
                            " and",
                            " Jewish",
                            " institutions",
                            " during",
                            " 2016",
                            ",",
                            " a",
                            " 34",
                            " percent",
                            " increase",
                            " of",
                            " incidents",
                            " of",
                            " assaults",
                            ",",
                            " vandalism",
                            ",",
                            " and",
                            " harassment",
                            " over",
                            " the",
                            " previous",
                            " year",
                            ".",
                            " Nearly",
                            " 30",
                            " percent",
                            " of",
                            " those",
                            " incidents",
                            ",",
                            " or",
                            " 369",
                            " of",
                            " them"
                        ],
                        "dataIndex": null,
                        "index": "12392",
                        "layer": "12-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.206,
                        "maxValueTokenIndex": 88,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.095,
                            1.649,
                            0,
                            7.452,
                            0,
                            4.415,
                            0,
                            0,
                            0,
                            0,
                            4.771,
                            0,
                            23.348,
                            11.301,
                            16.312,
                            13.822,
                            4.407,
                            20.882,
                            15.556,
                            22.834,
                            5.867,
                            18.131,
                            27.327,
                            11.715,
                            6.054,
                            22.342,
                            8.607,
                            18.938,
                            28.022,
                            25.192,
                            11.503,
                            7.514,
                            10.995,
                            13.898,
                            27.96,
                            26.215,
                            3.371,
                            11,
                            0,
                            0,
                            13.721,
                            20.306,
                            25.607,
                            0,
                            23.398,
                            15.865,
                            21.991,
                            21.322,
                            4.713,
                            25.492,
                            0,
                            21.316,
                            2.314,
                            13.971,
                            3.772,
                            3.375,
                            6.502,
                            6.234,
                            0,
                            46.206,
                            22.497,
                            24.63,
                            16.607,
                            22.072,
                            8.137,
                            14.008,
                            14.211,
                            4.986,
                            19.078,
                            12.005,
                            1.459,
                            0.31,
                            0,
                            24.043,
                            9.66,
                            35.036,
                            13.809,
                            26.683,
                            8.347,
                            21.215,
                            26.154,
                            14.952,
                            6.53,
                            6.277,
                            2.487,
                            0,
                            30.243,
                            0,
                            22.999,
                            18.428,
                            39.839,
                            38.363,
                            18.138,
                            19.764,
                            25.126,
                            32.382,
                            16.343,
                            26.973
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-05-30T06:03:58.453Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -0.04,
                            0,
                            -0.034,
                            0,
                            -0.019,
                            0,
                            0,
                            0,
                            0,
                            0.052,
                            0,
                            -0.975,
                            0.31,
                            0.583,
                            -0.341,
                            0.028,
                            0.247,
                            0.172,
                            0.033,
                            0.117,
                            0.088,
                            0.482,
                            0.014,
                            0.035,
                            -0.837,
                            -0.077,
                            0.614,
                            0.818,
                            0.497,
                            -0.024,
                            0.04,
                            0.092,
                            0.095,
                            0.021,
                            -0.13,
                            -0.001,
                            -0.226,
                            0,
                            0,
                            0.101,
                            0.059,
                            1.13,
                            0,
                            -1.051,
                            0.027,
                            -0.525,
                            -1.284,
                            0.072,
                            -0.049,
                            0,
                            -0.033,
                            -0.003,
                            0.008,
                            -0.012,
                            0.006,
                            -0.017,
                            -0.017,
                            0,
                            0.004,
                            -0.896,
                            -0.462,
                            0.111,
                            -0.893,
                            0.152,
                            0.113,
                            -0.076,
                            0.017,
                            -0.015,
                            0.095,
                            0,
                            0.001,
                            0,
                            -1.014,
                            0.003,
                            0.215,
                            0.216,
                            -1.126,
                            0.076,
                            1.101,
                            -0.498,
                            0.125,
                            0.086,
                            -0.001,
                            -0.001,
                            0,
                            0.225,
                            0,
                            0.232,
                            0.048,
                            1.069,
                            -0.434,
                            0.043,
                            0.044,
                            0.09,
                            1.521,
                            0.098
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.833, 0.752, 0.713, 0.694, 0.683]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.2, 0.181, 0.164, 0.16, 0.157]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.785, 0.712, 0.656, 0.64, 0.632]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.452, 0.416, 0.382, 0.373, 0.369]}, {}, {}, {}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.469, 0.428, 0.38, 0.368, 0.362]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.078, 1.878, 1.615, 1.562, 1.534]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.283, 1.175, 1.026, 0.993, 0.983]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.45, 1.288, 1.116, 1.077, 1.072]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.368, 1.212, 1.059, 1.013, 0.999]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.506, 0.464, 0.419, 0.409, 0.403]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.173, 1.977, 1.773, 1.718, 1.708]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [1.52, 1.406, 1.228, 1.212, 1.198]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.158, 1.956, 1.76, 1.711, 1.696]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.755, 0.678, 0.617, 0.602, 0.588]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.962, 1.773, 1.617, 1.58, 1.552]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [2.415, 2.206, 1.928, 1.872, 1.859]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.442, 1.318, 1.203, 1.174, 1.162]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [0.596, 0.552, 0.497, 0.487, 0.486]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.126, 1.928, 1.698, 1.664, 1.642]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.013, 0.93, 0.842, 0.827, 0.812]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.115, 1.898, 1.678, 1.626, 1.593]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.5, 2.235, 1.94, 1.86, 1.849]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.652, 2.391, 2.121, 2.065, 2.06]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.406, 1.266, 1.138, 1.095, 1.083]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.864, 0.79, 0.72, 0.701, 0.688]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.476, 1.338, 1.2, 1.173, 1.152]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.441, 1.312, 1.198, 1.171, 1.147]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.978, 2.703, 2.473, 2.42, 2.379]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.499, 2.232, 2.015, 1.968, 1.934]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.744, 0.685, 0.639, 0.626, 0.624]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.149, 1.039, 0.944, 0.921, 0.905]}, {}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.825, 1.655, 1.514, 1.478, 1.461]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.237, 2.014, 1.853, 1.817, 1.786]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.663, 2.37, 2.179, 2.114, 2.077]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.593, 2.24, 2.1, 2.033, 2.018]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" hatred\", \" bigotry\"], \"v\": [2.285, 2.064, 1.957, 1.879, 1.876]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.502, 2.181, 1.935, 1.827, 1.825]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.843, 2.479, 2.37, 2.274, 2.247]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.53, 0.48, 0.436, 0.424, 0.417]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.454, 2.19, 2.052, 2.003, 1.986]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.093, 1.914, 1.766, 1.719, 1.705]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.232, 0.212, 0.194, 0.189, 0.187]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.319, 1.227, 1.097, 1.077, 1.073]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.398, 0.366, 0.331, 0.325, 0.32]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.404, 0.374, 0.34, 0.332, 0.326]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.529, 0.49, 0.443, 0.434, 0.429]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.658, 0.605, 0.551, 0.541, 0.533]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.761, 2.458, 2.069, 2.033, 1.989]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.495, 2.281, 2.031, 1.995, 1.959]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.776, 1.586, 1.376, 1.325, 1.32]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.732, 1.586, 1.425, 1.398, 1.373]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [2.563, 2.355, 2.07, 2.028, 1.977]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.076, 0.978, 0.883, 0.843, 0.835]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.419, 1.304, 1.171, 1.15, 1.133]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.364, 1.228, 1.095, 1.068, 1.047]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.663, 0.608, 0.551, 0.539, 0.53]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.823, 1.671, 1.522, 1.489, 1.465]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.297, 1.185, 1.076, 1.054, 1.042]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.156, 0.141, 0.127, 0.124, 0.121]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.031, 0.028, 0.026, 0.025, 0.024]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.654, 2.441, 2.129, 2.082, 2.049]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.022, 0.94, 0.851, 0.835, 0.82]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [2.439, 2.183, 1.743, 1.693, 1.63]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.306, 1.19, 1.059, 1.031, 1.015]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [2.302, 2.106, 1.801, 1.757, 1.743]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.92, 0.838, 0.753, 0.736, 0.722]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [1.626, 1.455, 1.168, 1.13, 1.12]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [1.875, 1.683, 1.318, 1.306, 1.268]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.293, 1.187, 1.064, 1.04, 1.024]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.688, 0.624, 0.556, 0.543, 0.531]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.653, 0.598, 0.538, 0.529, 0.521]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.306, 0.282, 0.255, 0.25, 0.248]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.89, 2.55, 2.414, 2.358, 2.336]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.43, 2.215, 1.977, 1.934, 1.907]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.058, 1.863, 1.689, 1.645, 1.62]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.637, 2.356, 1.986, 1.931, 1.89]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.566, 2.277, 1.886, 1.838, 1.787]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.624, 1.501, 1.359, 1.337, 1.307]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.316, 2.114, 1.917, 1.881, 1.853]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.653, 2.465, 2.193, 2.158, 2.137]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.045, 1.79, 1.453, 1.423, 1.38]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.613, 1.478, 1.329, 1.3, 1.283]}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"imester\"], \"v\": [-0.447, -0.42, -0.419, -0.398, -0.381]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.15, -0.145, -0.143, -0.137, -0.131]}, {}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.459, -0.442, -0.44, -0.415, -0.395]}, {}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.221, -0.217, -0.212, -0.205, -0.19]}, {}, {}, {}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.412, -0.404, -0.396, -0.384, -0.375]}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.489, -2.439, -2.416, -2.334, -2.296]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.256, -1.218, -1.204, -1.164, -1.13]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.727, -1.703, -1.69, -1.61, -1.594]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.662, -1.608, -1.59, -1.547, -1.504]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.337, -0.327, -0.326, -0.304, -0.293]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.632, -1.571, -1.56, -1.509, -1.45]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.21, -1.16, -1.16, -1.101, -1.06]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.648, -1.61, -1.594, -1.496, -1.464]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-0.6, -0.59, -0.585, -0.56, -0.541]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"imester\"], \"v\": [-1.349, -1.314, -1.293, -1.234, -1.185]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-2.223, -2.168, -2.145, -2.068, -2.014]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.887, -0.853, -0.852, -0.801, -0.778]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.356, -0.342, -0.339, -0.328, -0.311]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-2.077, -2.03, -2.016, -1.951, -1.886]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.679, -0.647, -0.646, -0.613, -0.588]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-2.107, -2.046, -2.038, -1.954, -1.896]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-2.901, -2.84, -2.821, -2.714, -2.663]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-2.368, -2.332, -2.31, -2.213, -2.169]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.24, -1.216, -1.213, -1.134, -1.115]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.575, -0.555, -0.55, -0.52, -0.498]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-1.195, -1.171, -1.169, -1.102, -1.069]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.985, -0.959, -0.952, -0.894, -0.864]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"imester\"], \"v\": [-1.936, -1.866, -1.822, -1.769, -1.689]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.199, -2.139, -2.136, -2.028, -1.974]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"Medic\", \"enegger\", \"iago\"], \"v\": [-0.303, -0.297, -0.291, -0.285, -0.258]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.863, -0.828, -0.813, -0.786, -0.754]}, {}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.2, -1.159, -1.141, -1.09, -1.045]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.56, -1.509, -1.506, -1.44, -1.363]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.242, -2.184, -2.173, -2.088, -1.981]}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-2.26, -2.216, -2.178, -2.106, -2.043]}, {\"t\": [\"Medic\", \"soDeliveryDate\", \"ufact\", \"enegger\", \"iago\"], \"v\": [-1.121, -1.107, -1.08, -1.068, -1.011]}, {\"t\": [\"Medic\", \"soDeliveryDate\", \"ufact\", \"enegger\", \"iago\"], \"v\": [-2.871, -2.87, -2.87, -2.774, -2.664]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \" Nurs\"], \"v\": [-2.006, -1.959, -1.888, -1.862, -1.853]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.405, -0.389, -0.388, -0.373, -0.357]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-1.429, -1.384, -1.384, -1.32, -1.239]}, {}, {\"t\": [\"soDeliveryDate\", \"ufact\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.046, -1.027, -1.001, -1.0, -0.9]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.143, -0.138, -0.136, -0.128, -0.124]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.805, -0.774, -0.766, -0.737, -0.715]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.248, -0.236, -0.235, -0.226, -0.218]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.239, -0.234, -0.232, -0.221, -0.211]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.318, -0.31, -0.306, -0.293, -0.281]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.366, -0.354, -0.349, -0.328, -0.316]}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-3.937, -3.928, -3.877, -3.805, -3.685]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.916, -1.845, -1.838, -1.768, -1.692]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.074, -2.053, -2.026, -1.964, -1.928]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.213, -1.188, -1.168, -1.114, -1.073]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.208, -2.106, -2.103, -2.062, -1.954]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.876, -0.844, -0.843, -0.82, -0.777]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.978, -0.941, -0.94, -0.888, -0.854]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.208, -1.181, -1.173, -1.114, -1.09]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.424, -0.408, -0.408, -0.382, -0.368]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.116, -1.053, -1.044, -1.009, -0.965]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.82, -0.774, -0.773, -0.747, -0.725]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.122, -0.118, -0.118, -0.11, -0.107]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.023, -0.022, -0.022, -0.021, -0.02]}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.504, -2.475, -2.404, -2.356, -2.293]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.643, -0.616, -0.611, -0.576, -0.562]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-4.323, -4.27, -4.219, -4.192, -4.068]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.086, -1.042, -1.035, -0.99, -0.959]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.459, -2.377, -2.33, -2.328, -2.232]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.681, -0.653, -0.651, -0.616, -0.596]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.708, -2.65, -2.616, -2.571, -2.484]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-3.323, -3.246, -3.215, -3.162, -3.059]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.919, -0.884, -0.881, -0.834, -0.806]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.582, -0.564, -0.561, -0.531, -0.52]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.442, -0.427, -0.425, -0.4, -0.391]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.177, -0.169, -0.168, -0.159, -0.154]}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-1.729, -1.673, -1.661, -1.625, -1.511]}, {}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.971, -1.91, -1.906, -1.829, -1.758]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.482, -1.421, -1.419, -1.332, -1.294]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-3.669, -3.61, -3.592, -3.49, -3.411]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-3.993, -3.909, -3.867, -3.82, -3.735]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.026, -0.988, -0.95, -0.915, -0.895]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.507, -1.467, -1.419, -1.382, -1.324]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.793, -1.744, -1.692, -1.662, -1.576]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-3.676, -3.665, -3.631, -3.535, -3.435]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.068, -1.05, -1.024, -0.981, -0.944]}]}",
                        "binMin": -1,
                        "binMax": 46.206,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clwsunxebbsvuxgjqz0y3zw5j",
                        "tokens": [
                            " the",
                            " United",
                            " States",
                            " rose",
                            " by",
                            " more",
                            " than",
                            " one",
                            "-",
                            "third",
                            " in",
                            " 2016",
                            " and",
                            " shot",
                            " up",
                            " 86",
                            " percent",
                            " in",
                            " the",
                            " first",
                            " three",
                            " months",
                            " of",
                            " 2017",
                            ",",
                            " the",
                            " Anti",
                            "-",
                            "Def",
                            "amation",
                            " League",
                            " reported",
                            ".",
                            "\n",
                            "\n",
                            "There",
                            " has",
                            " been",
                            " a",
                            " massive",
                            " increase",
                            " in",
                            " harassment",
                            " of",
                            " American",
                            " Jews",
                            ",",
                            " largely",
                            " since",
                            " November",
                            ",",
                            " and",
                            " at",
                            " least",
                            " 34",
                            " incidents",
                            " linked",
                            " to",
                            " the",
                            " presidential",
                            " election",
                            " in",
                            " November",
                            ",",
                            " the",
                            " AD",
                            "L",
                            " reported",
                            " Monday",
                            " in",
                            " its",
                            " annual",
                            " Audit",
                            " of",
                            " Anti",
                            "-",
                            "Semitic",
                            " incidents",
                            ".",
                            "\n",
                            "\n",
                            "There",
                            " were",
                            " a",
                            " total",
                            " of",
                            " 1",
                            ",",
                            "266",
                            " acts",
                            " targeting",
                            " Jews",
                            " and",
                            " Jewish",
                            " institutions",
                            " during",
                            " 2016",
                            ",",
                            " a",
                            " 34",
                            " percent",
                            " increase",
                            " of",
                            " incidents",
                            " of",
                            " assaults",
                            ",",
                            " vandalism",
                            ",",
                            " and",
                            " harassment",
                            " over",
                            " the",
                            " previous",
                            " year",
                            ".",
                            " Nearly",
                            " 30",
                            " percent",
                            " of",
                            " those",
                            " incidents",
                            ",",
                            " or",
                            " 369",
                            " of",
                            " them"
                        ],
                        "dataIndex": null,
                        "index": "12392",
                        "layer": "12-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.206,
                        "maxValueTokenIndex": 88,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.095,
                            1.649,
                            0,
                            7.452,
                            0,
                            4.415,
                            0,
                            0,
                            0,
                            0,
                            4.771,
                            0,
                            23.348,
                            11.301,
                            16.312,
                            13.822,
                            4.407,
                            20.882,
                            15.556,
                            22.834,
                            5.867,
                            18.131,
                            27.327,
                            11.715,
                            6.054,
                            22.342,
                            8.607,
                            18.938,
                            28.022,
                            25.192,
                            11.503,
                            7.514,
                            10.995,
                            13.898,
                            27.96,
                            26.215,
                            3.371,
                            11,
                            0,
                            0,
                            13.721,
                            20.306,
                            25.607,
                            0,
                            23.398,
                            15.865,
                            21.991,
                            21.322,
                            4.713,
                            25.492,
                            0,
                            21.316,
                            2.314,
                            13.971,
                            3.772,
                            3.375,
                            6.502,
                            6.234,
                            0,
                            46.206,
                            22.497,
                            24.63,
                            16.607,
                            22.072,
                            8.137,
                            14.008,
                            14.211,
                            4.986,
                            19.078,
                            12.005,
                            1.459,
                            0.31,
                            0,
                            24.043,
                            9.66,
                            35.036,
                            13.809,
                            26.683,
                            8.347,
                            21.215,
                            26.154,
                            14.952,
                            6.53,
                            6.277,
                            2.487,
                            0,
                            30.243,
                            0,
                            22.999,
                            18.428,
                            39.839,
                            38.363,
                            18.138,
                            19.764,
                            25.126,
                            32.382,
                            16.343,
                            26.973
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-05-30T06:03:58.453Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -0.04,
                            0,
                            -0.034,
                            0,
                            -0.019,
                            0,
                            0,
                            0,
                            0,
                            0.052,
                            0,
                            -0.975,
                            0.31,
                            0.583,
                            -0.341,
                            0.028,
                            0.247,
                            0.172,
                            0.033,
                            0.117,
                            0.088,
                            0.482,
                            0.014,
                            0.035,
                            -0.837,
                            -0.077,
                            0.614,
                            0.818,
                            0.497,
                            -0.024,
                            0.04,
                            0.092,
                            0.095,
                            0.021,
                            -0.13,
                            -0.001,
                            -0.226,
                            0,
                            0,
                            0.101,
                            0.059,
                            1.13,
                            0,
                            -1.051,
                            0.027,
                            -0.525,
                            -1.284,
                            0.072,
                            -0.049,
                            0,
                            -0.033,
                            -0.003,
                            0.008,
                            -0.012,
                            0.006,
                            -0.017,
                            -0.017,
                            0,
                            0.004,
                            -0.896,
                            -0.462,
                            0.111,
                            -0.893,
                            0.152,
                            0.113,
                            -0.076,
                            0.017,
                            -0.015,
                            0.095,
                            0,
                            0.001,
                            0,
                            -1.014,
                            0.003,
                            0.215,
                            0.216,
                            -1.126,
                            0.076,
                            1.101,
                            -0.498,
                            0.125,
                            0.086,
                            -0.001,
                            -0.001,
                            0,
                            0.225,
                            0,
                            0.232,
                            0.048,
                            1.069,
                            -0.434,
                            0.043,
                            0.044,
                            0.09,
                            1.521,
                            0.098
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.833, 0.752, 0.713, 0.694, 0.683]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.2, 0.181, 0.164, 0.16, 0.157]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.785, 0.712, 0.656, 0.64, 0.632]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.452, 0.416, 0.382, 0.373, 0.369]}, {}, {}, {}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.469, 0.428, 0.38, 0.368, 0.362]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.078, 1.878, 1.615, 1.562, 1.534]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.283, 1.175, 1.026, 0.993, 0.983]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.45, 1.288, 1.116, 1.077, 1.072]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.368, 1.212, 1.059, 1.013, 0.999]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.506, 0.464, 0.419, 0.409, 0.403]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.173, 1.977, 1.773, 1.718, 1.708]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [1.52, 1.406, 1.228, 1.212, 1.198]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.158, 1.956, 1.76, 1.711, 1.696]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.755, 0.678, 0.617, 0.602, 0.588]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.962, 1.773, 1.617, 1.58, 1.552]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [2.415, 2.206, 1.928, 1.872, 1.859]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.442, 1.318, 1.203, 1.174, 1.162]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [0.596, 0.552, 0.497, 0.487, 0.486]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.126, 1.928, 1.698, 1.664, 1.642]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.013, 0.93, 0.842, 0.827, 0.812]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.115, 1.898, 1.678, 1.626, 1.593]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.5, 2.235, 1.94, 1.86, 1.849]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.652, 2.391, 2.121, 2.065, 2.06]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.406, 1.266, 1.138, 1.095, 1.083]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.864, 0.79, 0.72, 0.701, 0.688]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.476, 1.338, 1.2, 1.173, 1.152]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.441, 1.312, 1.198, 1.171, 1.147]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.978, 2.703, 2.473, 2.42, 2.379]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.499, 2.232, 2.015, 1.968, 1.934]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.744, 0.685, 0.639, 0.626, 0.624]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.149, 1.039, 0.944, 0.921, 0.905]}, {}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.825, 1.655, 1.514, 1.478, 1.461]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.237, 2.014, 1.853, 1.817, 1.786]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.663, 2.37, 2.179, 2.114, 2.077]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.593, 2.24, 2.1, 2.033, 2.018]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" hatred\", \" bigotry\"], \"v\": [2.285, 2.064, 1.957, 1.879, 1.876]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.502, 2.181, 1.935, 1.827, 1.825]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.843, 2.479, 2.37, 2.274, 2.247]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.53, 0.48, 0.436, 0.424, 0.417]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.454, 2.19, 2.052, 2.003, 1.986]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.093, 1.914, 1.766, 1.719, 1.705]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.232, 0.212, 0.194, 0.189, 0.187]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.319, 1.227, 1.097, 1.077, 1.073]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.398, 0.366, 0.331, 0.325, 0.32]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.404, 0.374, 0.34, 0.332, 0.326]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.529, 0.49, 0.443, 0.434, 0.429]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.658, 0.605, 0.551, 0.541, 0.533]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.761, 2.458, 2.069, 2.033, 1.989]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.495, 2.281, 2.031, 1.995, 1.959]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.776, 1.586, 1.376, 1.325, 1.32]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.732, 1.586, 1.425, 1.398, 1.373]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [2.563, 2.355, 2.07, 2.028, 1.977]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.076, 0.978, 0.883, 0.843, 0.835]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.419, 1.304, 1.171, 1.15, 1.133]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.364, 1.228, 1.095, 1.068, 1.047]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.663, 0.608, 0.551, 0.539, 0.53]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.823, 1.671, 1.522, 1.489, 1.465]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.297, 1.185, 1.076, 1.054, 1.042]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.156, 0.141, 0.127, 0.124, 0.121]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.031, 0.028, 0.026, 0.025, 0.024]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.654, 2.441, 2.129, 2.082, 2.049]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.022, 0.94, 0.851, 0.835, 0.82]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [2.439, 2.183, 1.743, 1.693, 1.63]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.306, 1.19, 1.059, 1.031, 1.015]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [2.302, 2.106, 1.801, 1.757, 1.743]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.92, 0.838, 0.753, 0.736, 0.722]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [1.626, 1.455, 1.168, 1.13, 1.12]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \"hate\", \" bigotry\"], \"v\": [1.875, 1.683, 1.318, 1.306, 1.268]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [1.293, 1.187, 1.064, 1.04, 1.024]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [0.688, 0.624, 0.556, 0.543, 0.531]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.653, 0.598, 0.538, 0.529, 0.521]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [0.306, 0.282, 0.255, 0.25, 0.248]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.89, 2.55, 2.414, 2.358, 2.336]}, {}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.43, 2.215, 1.977, 1.934, 1.907]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.058, 1.863, 1.689, 1.645, 1.62]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.637, 2.356, 1.986, 1.931, 1.89]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.566, 2.277, 1.886, 1.838, 1.787]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.624, 1.501, 1.359, 1.337, 1.307]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.316, 2.114, 1.917, 1.881, 1.853]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \"hate\"], \"v\": [2.653, 2.465, 2.193, 2.158, 2.137]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [2.045, 1.79, 1.453, 1.423, 1.38]}, {\"t\": [\" hate\", \" Hate\", \" hateful\", \" bigotry\", \" hatred\"], \"v\": [1.613, 1.478, 1.329, 1.3, 1.283]}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"imester\"], \"v\": [-0.447, -0.42, -0.419, -0.398, -0.381]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.15, -0.145, -0.143, -0.137, -0.131]}, {}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.459, -0.442, -0.44, -0.415, -0.395]}, {}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.221, -0.217, -0.212, -0.205, -0.19]}, {}, {}, {}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.412, -0.404, -0.396, -0.384, -0.375]}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.489, -2.439, -2.416, -2.334, -2.296]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.256, -1.218, -1.204, -1.164, -1.13]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.727, -1.703, -1.69, -1.61, -1.594]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.662, -1.608, -1.59, -1.547, -1.504]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.337, -0.327, -0.326, -0.304, -0.293]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.632, -1.571, -1.56, -1.509, -1.45]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.21, -1.16, -1.16, -1.101, -1.06]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.648, -1.61, -1.594, -1.496, -1.464]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-0.6, -0.59, -0.585, -0.56, -0.541]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"imester\"], \"v\": [-1.349, -1.314, -1.293, -1.234, -1.185]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-2.223, -2.168, -2.145, -2.068, -2.014]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.887, -0.853, -0.852, -0.801, -0.778]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.356, -0.342, -0.339, -0.328, -0.311]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-2.077, -2.03, -2.016, -1.951, -1.886]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.679, -0.647, -0.646, -0.613, -0.588]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-2.107, -2.046, -2.038, -1.954, -1.896]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-2.901, -2.84, -2.821, -2.714, -2.663]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-2.368, -2.332, -2.31, -2.213, -2.169]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.24, -1.216, -1.213, -1.134, -1.115]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.575, -0.555, -0.55, -0.52, -0.498]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-1.195, -1.171, -1.169, -1.102, -1.069]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.985, -0.959, -0.952, -0.894, -0.864]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"imester\"], \"v\": [-1.936, -1.866, -1.822, -1.769, -1.689]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.199, -2.139, -2.136, -2.028, -1.974]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"Medic\", \"enegger\", \"iago\"], \"v\": [-0.303, -0.297, -0.291, -0.285, -0.258]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.863, -0.828, -0.813, -0.786, -0.754]}, {}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.2, -1.159, -1.141, -1.09, -1.045]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.56, -1.509, -1.506, -1.44, -1.363]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.242, -2.184, -2.173, -2.088, -1.981]}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-2.26, -2.216, -2.178, -2.106, -2.043]}, {\"t\": [\"Medic\", \"soDeliveryDate\", \"ufact\", \"enegger\", \"iago\"], \"v\": [-1.121, -1.107, -1.08, -1.068, -1.011]}, {\"t\": [\"Medic\", \"soDeliveryDate\", \"ufact\", \"enegger\", \"iago\"], \"v\": [-2.871, -2.87, -2.87, -2.774, -2.664]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \" Nurs\"], \"v\": [-2.006, -1.959, -1.888, -1.862, -1.853]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.405, -0.389, -0.388, -0.373, -0.357]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-1.429, -1.384, -1.384, -1.32, -1.239]}, {}, {\"t\": [\"soDeliveryDate\", \"ufact\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.046, -1.027, -1.001, -1.0, -0.9]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.143, -0.138, -0.136, -0.128, -0.124]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.805, -0.774, -0.766, -0.737, -0.715]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.248, -0.236, -0.235, -0.226, -0.218]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.239, -0.234, -0.232, -0.221, -0.211]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.318, -0.31, -0.306, -0.293, -0.281]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.366, -0.354, -0.349, -0.328, -0.316]}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-3.937, -3.928, -3.877, -3.805, -3.685]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.916, -1.845, -1.838, -1.768, -1.692]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.074, -2.053, -2.026, -1.964, -1.928]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.213, -1.188, -1.168, -1.114, -1.073]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.208, -2.106, -2.103, -2.062, -1.954]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.876, -0.844, -0.843, -0.82, -0.777]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.978, -0.941, -0.94, -0.888, -0.854]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.208, -1.181, -1.173, -1.114, -1.09]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.424, -0.408, -0.408, -0.382, -0.368]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.116, -1.053, -1.044, -1.009, -0.965]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.82, -0.774, -0.773, -0.747, -0.725]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.122, -0.118, -0.118, -0.11, -0.107]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.023, -0.022, -0.022, -0.021, -0.02]}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.504, -2.475, -2.404, -2.356, -2.293]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.643, -0.616, -0.611, -0.576, -0.562]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-4.323, -4.27, -4.219, -4.192, -4.068]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.086, -1.042, -1.035, -0.99, -0.959]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.459, -2.377, -2.33, -2.328, -2.232]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.681, -0.653, -0.651, -0.616, -0.596]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-2.708, -2.65, -2.616, -2.571, -2.484]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-3.323, -3.246, -3.215, -3.162, -3.059]}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-0.919, -0.884, -0.881, -0.834, -0.806]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.582, -0.564, -0.561, -0.531, -0.52]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.442, -0.427, -0.425, -0.4, -0.391]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-0.177, -0.169, -0.168, -0.159, -0.154]}, {}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-1.729, -1.673, -1.661, -1.625, -1.511]}, {}, {\"t\": [\"ufact\", \"soDeliveryDate\", \"enegger\", \"Medic\", \"iago\"], \"v\": [-1.971, -1.91, -1.906, -1.829, -1.758]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.482, -1.421, -1.419, -1.332, -1.294]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-3.669, -3.61, -3.592, -3.49, -3.411]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-3.993, -3.909, -3.867, -3.82, -3.735]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.026, -0.988, -0.95, -0.915, -0.895]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.507, -1.467, -1.419, -1.382, -1.324]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.793, -1.744, -1.692, -1.662, -1.576]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"imester\"], \"v\": [-3.676, -3.665, -3.631, -3.535, -3.435]}, {\"t\": [\"ufact\", \"enegger\", \"soDeliveryDate\", \"Medic\", \"iago\"], \"v\": [-1.068, -1.05, -1.024, -0.981, -0.944]}]}",
                        "binMin": -1,
                        "binMax": 46.206,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "12-res-jb",
            "index": "11632",
            "description": "discussions or mentions of specific religious or ethnic groups, particularly focusing on Jews",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 46.083,
            "frac_nonzero": 0.00244,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "12-res-jb",
                "index": "11632",
                "sourceSetName": "res-jb",
                "creatorId": null,
                "createdAt": "2024-05-30T06:02:12.631Z",
                "maxActApprox": 46.083,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    11632,
                    16742,
                    23475,
                    8278,
                    23501,
                    16325,
                    15702,
                    804,
                    21765,
                    12351,
                    2626,
                    22057,
                    16434,
                    11043,
                    23233,
                    18390,
                    20916,
                    6117,
                    6956,
                    507,
                    21648,
                    22338,
                    16174,
                    23369,
                    13568
                ],
                "topkCosSimValues": [
                    1,
                    0.5123,
                    0.475,
                    0.4491,
                    0.4443,
                    0.4435,
                    0.4424,
                    0.4284,
                    0.401,
                    0.3974,
                    0.3936,
                    0.3923,
                    0.3899,
                    0.3871,
                    0.3858,
                    0.3857,
                    0.3842,
                    0.3799,
                    0.3765,
                    0.3741,
                    0.3696,
                    0.3669,
                    0.3492,
                    0.3489,
                    0.3462
                ],
                "neuron_alignment_indices": [
                    224,
                    55,
                    447
                ],
                "neuron_alignment_values": [
                    0.158,
                    0.155,
                    0.15
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.007,
                    0.007
                ],
                "correlated_neurons_indices": [
                    224,
                    132,
                    575
                ],
                "correlated_neurons_pearson": [
                    0.056,
                    0.049,
                    0.047
                ],
                "correlated_neurons_l1": [
                    0.062,
                    0.047,
                    0.054
                ],
                "correlated_features_indices": [
                    11529,
                    11551,
                    11571
                ],
                "correlated_features_pearson": [
                    0.033,
                    0.017,
                    0.006
                ],
                "correlated_features_l1": [
                    0.035,
                    0.019,
                    0.008
                ],
                "neg_str": [
                    "inventoryQuantity",
                    " LX",
                    " increments",
                    "\u00e6\u00a9\u0141",
                    "yrinth",
                    "gency",
                    " Gadget",
                    "rament",
                    " Titanium",
                    " FTC"
                ],
                "neg_values": [
                    -0.775,
                    -0.711,
                    -0.681,
                    -0.671,
                    -0.664,
                    -0.641,
                    -0.64,
                    -0.624,
                    -0.624,
                    -0.613
                ],
                "pos_str": [
                    " living",
                    " fleeing",
                    " residing",
                    "ervatives",
                    " who",
                    " persecuted",
                    " migrating",
                    " deported",
                    "ervative",
                    " inhab"
                ],
                "pos_values": [
                    1.355,
                    1.296,
                    1.248,
                    1.164,
                    1.072,
                    1.066,
                    1.056,
                    1.029,
                    1.025,
                    1.003
                ],
                "frac_nonzero": 0.00244,
                "freq_hist_data_bar_heights": [
                    1239,
                    999,
                    846,
                    662,
                    539,
                    427,
                    354,
                    318,
                    302,
                    240,
                    195,
                    162,
                    136,
                    138,
                    109,
                    99,
                    87,
                    52,
                    77,
                    62,
                    61,
                    40,
                    55,
                    57,
                    54,
                    31,
                    40,
                    34,
                    37,
                    36,
                    31,
                    34,
                    21,
                    23,
                    10,
                    16,
                    9,
                    11,
                    9,
                    9,
                    7,
                    4,
                    0,
                    0,
                    2,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.461,
                    1.383,
                    2.305,
                    3.226,
                    4.148,
                    5.07,
                    5.991,
                    6.913,
                    7.835,
                    8.756,
                    9.678,
                    10.6,
                    11.521,
                    12.443,
                    13.365,
                    14.286,
                    15.208,
                    16.129,
                    17.051,
                    17.973,
                    18.894,
                    19.816,
                    20.738,
                    21.659,
                    22.581,
                    23.503,
                    24.424,
                    25.346,
                    26.268,
                    27.189,
                    28.111,
                    29.033,
                    29.954,
                    30.876,
                    31.798,
                    32.719,
                    33.641,
                    34.563,
                    35.484,
                    36.406,
                    37.327,
                    38.249,
                    39.171,
                    40.092,
                    41.014,
                    41.936,
                    42.857,
                    43.779,
                    44.701,
                    45.622
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    3,
                    6,
                    11,
                    28,
                    88,
                    170,
                    323,
                    632,
                    1065,
                    1556,
                    2298,
                    3134,
                    3684,
                    4131,
                    4423,
                    4497,
                    4261,
                    3690,
                    3480,
                    2874,
                    2399,
                    1903,
                    1477,
                    1135,
                    876,
                    602,
                    451,
                    300,
                    232,
                    174,
                    106,
                    79,
                    53,
                    28,
                    23,
                    19,
                    16,
                    11,
                    4,
                    4,
                    3,
                    2,
                    0,
                    1,
                    0,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.753,
                    -0.711,
                    -0.668,
                    -0.626,
                    -0.583,
                    -0.54,
                    -0.498,
                    -0.455,
                    -0.413,
                    -0.37,
                    -0.327,
                    -0.285,
                    -0.242,
                    -0.2,
                    -0.157,
                    -0.114,
                    -0.072,
                    -0.029,
                    0.013,
                    0.056,
                    0.098,
                    0.141,
                    0.184,
                    0.226,
                    0.269,
                    0.311,
                    0.354,
                    0.397,
                    0.439,
                    0.482,
                    0.524,
                    0.567,
                    0.61,
                    0.652,
                    0.695,
                    0.737,
                    0.78,
                    0.823,
                    0.865,
                    0.908,
                    0.95,
                    0.993,
                    1.036,
                    1.078,
                    1.121,
                    1.163,
                    1.206,
                    1.249,
                    1.291,
                    1.334
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clxkajfhwkzz3i66673iz0p9p",
                        "modelId": "gpt2-small",
                        "layer": "12-res-jb",
                        "index": "11632",
                        "description": "discussions or mentions of specific religious or ethnic groups, particularly focusing on Jews",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-06-18T10:58:09.332Z",
                        "updatedAt": "2024-06-18T10:58:09.332Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clwsulvwob2swxgjqqro88cug",
                        "tokens": [
                            " the",
                            " so",
                            "-",
                            "called",
                            " philosopher",
                            " who",
                            " \u00e2\u0122",
                            "\u013a",
                            "liber",
                            "ated",
                            " Libya",
                            " as",
                            " a",
                            " Jew",
                            "\u00e2\u0122",
                            "\u013b",
                            ",",
                            " did",
                            " he",
                            " call",
                            " for",
                            " Jews",
                            " to",
                            " join",
                            " the",
                            " French",
                            " legions",
                            "?",
                            " I",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " think",
                            " so",
                            ".",
                            "\n",
                            "\n",
                            "Here",
                            " we",
                            " see",
                            " a",
                            " clear",
                            " discrepancy",
                            " between",
                            " the",
                            " contemporary",
                            " Jewish",
                            " right",
                            " wing",
                            " appetite",
                            " for",
                            " immoral",
                            " intervention",
                            "ist",
                            " wars",
                            " and",
                            " a",
                            " general",
                            " absence",
                            " of",
                            " patriotism",
                            " amongst",
                            " the",
                            " Jewish",
                            " masses",
                            ".",
                            " This",
                            " surely",
                            " demands",
                            " an",
                            " explanation",
                            ".",
                            " Is",
                            " this",
                            " really",
                            " parasitic",
                            " aggression",
                            " on",
                            " A",
                            "IP",
                            "AC",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " part",
                            "?",
                            " Do",
                            " they",
                            " really",
                            " try",
                            " to",
                            " send",
                            " America",
                            " into",
                            " a",
                            " Zionist",
                            " war",
                            " yet",
                            " refrain",
                            " from",
                            " sending",
                            " their",
                            " kids",
                            " to",
                            " the",
                            " same",
                            " war",
                            "?",
                            " Or",
                            " is",
                            " it",
                            " that",
                            " A",
                            "IP",
                            "AC",
                            " and",
                            " the",
                            " other",
                            " bellig",
                            "erent",
                            " Jewish",
                            " lobb",
                            "ies",
                            " are",
                            " totally",
                            " detached"
                        ],
                        "dataIndex": null,
                        "index": "11632",
                        "layer": "12-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.083,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.548,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.083,
                            1.497,
                            0,
                            0,
                            0,
                            2.786,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.33,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-05-30T06:02:23.258Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -0.04,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.419,
                            0.003,
                            0,
                            0,
                            0,
                            0.009,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.003,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" living\", \" fleeing\", \" residing\", \"ervatives\", \" who\"], \"v\": [0.853, 0.803, 0.778, 0.744, 0.649]}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" living\", \" fleeing\", \" residing\", \"ervatives\", \"ervative\"], \"v\": [2.878, 2.648, 2.549, 2.454, 2.041]}, {\"t\": [\" living\", \" fleeing\", \" residing\", \"ervatives\", \"ervative\"], \"v\": [0.092, 0.086, 0.083, 0.08, 0.069]}, {}, {}, {}, {\"t\": [\" living\", \" fleeing\", \" residing\", \"ervatives\", \" persecuted\"], \"v\": [0.172, 0.157, 0.153, 0.143, 0.125]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" living\", \" fleeing\", \" residing\", \"ervatives\", \" persecuted\"], \"v\": [0.436, 0.41, 0.38, 0.353, 0.326]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"inventoryQuantity\", \" LX\", \"yrinth\", \"\\u00e6\\u00a9\\u0141\", \" increments\"], \"v\": [-0.647, -0.627, -0.609, -0.597, -0.592]}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"inventoryQuantity\", \" LX\", \" increments\", \"\\u00e6\\u00a9\\u0141\", \"gency\"], \"v\": [-3.062, -3.049, -3.017, -2.913, -2.818]}, {\"t\": [\"inventoryQuantity\", \" LX\", \" increments\", \"\\u00e6\\u00a9\\u0141\", \"yrinth\"], \"v\": [-0.077, -0.076, -0.075, -0.071, -0.071]}, {}, {}, {}, {\"t\": [\" LX\", \"inventoryQuantity\", \"\\u00e6\\u00a9\\u0141\", \" increments\", \"yrinth\"], \"v\": [-0.157, -0.156, -0.151, -0.149, -0.144]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" LX\", \"inventoryQuantity\", \" increments\", \"\\u00e6\\u00a9\\u0141\", \"gency\"], \"v\": [-0.416, -0.415, -0.402, -0.402, -0.385]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": -1,
                        "binMax": 46.083,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clwsulvwrb2tkxgjqa3svbweq",
                        "tokens": [
                            " the",
                            " so",
                            "-",
                            "called",
                            " philosopher",
                            " who",
                            " \u00e2\u0122",
                            "\u013a",
                            "liber",
                            "ated",
                            " Libya",
                            " as",
                            " a",
                            " Jew",
                            "\u00e2\u0122",
                            "\u013b",
                            ",",
                            " did",
                            " he",
                            " call",
                            " for",
                            " Jews",
                            " to",
                            " join",
                            " the",
                            " French",
                            " legions",
                            "?",
                            " I",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " think",
                            " so",
                            ".",
                            "\n",
                            "\n",
                            "Here",
                            " we",
                            " see",
                            " a",
                            " clear",
                            " discrepancy",
                            " between",
                            " the",
                            " contemporary",
                            " Jewish",
                            " right",
                            " wing",
                            " appetite",
                            " for",
                            " immoral",
                            " intervention",
                            "ist",
                            " wars",
                            " and",
                            " a",
                            " general",
                            " absence",
                            " of",
                            " patriotism",
                            " amongst",
                            " the",
                            " Jewish",
                            " masses",
                            ".",
                            " This",
                            " surely",
                            " demands",
                            " an",
                            " explanation",
                            ".",
                            " Is",
                            " this",
                            " really",
                            " parasitic",
                            " aggression",
                            " on",
                            " A",
                            "IP",
                            "AC",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " part",
                            "?",
                            " Do",
                            " they",
                            " really",
                            " try",
                            " to",
                            " send",
                            " America",
                            " into",
                            " a",
                            " Zionist",
                            " war",
                            " yet",
                            " refrain",
                            " from",
                            " sending",
                            " their",
                            " kids",
                            " to",
                            " the",
                            " same",
                            " war",
                            "?",
                            " Or",
                            " is",
                            " it",
                            " that",
                            " A",
                            "IP",
                            "AC",
                            " and",
                            " the",
                            " other",
                            " bellig",
                            "erent",
                            " Jewish",
                            " lobb",
                            "ies",
                            " are",
                            " totally",
                            " detached"
                        ],
                        "dataIndex": null,
                        "index": "11632",
                        "layer": "12-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.083,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.548,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.083,
                            1.497,
                            0,
                            0,
                            0,
                            2.786,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.33,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-05-30T06:02:23.258Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -0.04,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.419,
                            0.003,
                            0,
                            0,
                            0,
                            0.009,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.003,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" living\", \" fleeing\", \" residing\", \"ervatives\", \" who\"], \"v\": [0.853, 0.803, 0.778, 0.744, 0.649]}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" living\", \" fleeing\", \" residing\", \"ervatives\", \"ervative\"], \"v\": [2.878, 2.648, 2.549, 2.454, 2.041]}, {\"t\": [\" living\", \" fleeing\", \" residing\", \"ervatives\", \"ervative\"], \"v\": [0.092, 0.086, 0.083, 0.08, 0.069]}, {}, {}, {}, {\"t\": [\" living\", \" fleeing\", \" residing\", \"ervatives\", \" persecuted\"], \"v\": [0.172, 0.157, 0.153, 0.143, 0.125]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" living\", \" fleeing\", \" residing\", \"ervatives\", \" persecuted\"], \"v\": [0.436, 0.41, 0.38, 0.353, 0.326]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"inventoryQuantity\", \" LX\", \"yrinth\", \"\\u00e6\\u00a9\\u0141\", \" increments\"], \"v\": [-0.647, -0.627, -0.609, -0.597, -0.592]}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"inventoryQuantity\", \" LX\", \" increments\", \"\\u00e6\\u00a9\\u0141\", \"gency\"], \"v\": [-3.062, -3.049, -3.017, -2.913, -2.818]}, {\"t\": [\"inventoryQuantity\", \" LX\", \" increments\", \"\\u00e6\\u00a9\\u0141\", \"yrinth\"], \"v\": [-0.077, -0.076, -0.075, -0.071, -0.071]}, {}, {}, {}, {\"t\": [\" LX\", \"inventoryQuantity\", \"\\u00e6\\u00a9\\u0141\", \" increments\", \"yrinth\"], \"v\": [-0.157, -0.156, -0.151, -0.149, -0.144]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" LX\", \"inventoryQuantity\", \" increments\", \"\\u00e6\\u00a9\\u0141\", \"gency\"], \"v\": [-0.416, -0.415, -0.402, -0.402, -0.385]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": 36.867,
                        "binMax": 46.083,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clwsulvwob2sxxgjqzpy70lo8",
                        "tokens": [
                            " faction",
                            " that",
                            " attempted",
                            " to",
                            " ref",
                            "ocus",
                            " society",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " moral",
                            " compass",
                            " with",
                            " a",
                            " particular",
                            " emphasis",
                            " on",
                            " sex",
                            " and",
                            " marriage",
                            "\n",
                            "\n",
                            "With",
                            " the",
                            " Act",
                            " in",
                            " force",
                            " after",
                            " 17",
                            "53",
                            ",",
                            " for",
                            " the",
                            " first",
                            " time",
                            " in",
                            " British",
                            " history",
                            ",",
                            " all",
                            " marriages",
                            " in",
                            " England",
                            " and",
                            " Wales",
                            " had",
                            " to",
                            " take",
                            " place",
                            " in",
                            " their",
                            " parish",
                            " church",
                            ".",
                            " (",
                            "The",
                            " law",
                            " also",
                            " applied",
                            " to",
                            " Catholics",
                            ",",
                            " but",
                            " Jews",
                            " and",
                            " Qu",
                            "akers",
                            " were",
                            " exempt",
                            ".)",
                            " I",
                            " would",
                            " point",
                            " out",
                            " that",
                            " this",
                            " was",
                            " an",
                            " act",
                            " of",
                            " Parliament",
                            " and",
                            " bore",
                            " only",
                            " a",
                            " fig",
                            "leaf",
                            " of",
                            " theological",
                            " thought",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " Act",
                            " combined",
                            " the",
                            " sp",
                            "ous",
                            "als",
                            " and",
                            " nu",
                            "pt",
                            "ials",
                            " and",
                            ",",
                            " by",
                            " the",
                            " start",
                            " of",
                            " the",
                            " 19",
                            "th",
                            " century",
                            ",",
                            " social",
                            " convention",
                            " prescribed",
                            " that",
                            " br",
                            "ides",
                            " be",
                            " vir",
                            "gins",
                            " at",
                            " marriage",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "11632",
                        "layer": "12-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.457,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.55,
                            0,
                            0,
                            42.457,
                            0,
                            0,
                            28.37,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.084,
                            0,
                            0,
                            5.525,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-05-30T06:02:23.258Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -0.353,
                            0,
                            0,
                            -0.329,
                            0,
                            0,
                            -0.022,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.174,
                            0,
                            0,
                            0.016,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" living\", \" fleeing\", \" residing\", \"ervatives\", \"ervative\"], \"v\": [2.359, 2.324, 2.118, 2.1, 1.831]}, {}, {}, {\"t\": [\" living\", \" fleeing\", \" residing\", \"ervatives\", \"ervative\"], \"v\": [2.707, 2.576, 2.423, 2.306, 2.003]}, {}, {}, {\"t\": [\" living\", \" fleeing\", \" residing\", \"ervatives\", \"ervative\"], \"v\": [1.452, 1.396, 1.304, 1.241, 1.062]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" living\", \" fleeing\", \" residing\", \"ervatives\", \" persecuted\"], \"v\": [0.623, 0.603, 0.542, 0.522, 0.46]}, {}, {}, {\"t\": [\" living\", \" fleeing\", \" residing\", \"ervatives\", \" persecuted\"], \"v\": [0.327, 0.318, 0.288, 0.285, 0.242]}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" LX\", \" increments\", \"inventoryQuantity\", \"\\u00e6\\u00a9\\u0141\", \" Gadget\"], \"v\": [-1.981, -1.956, -1.906, -1.805, -1.746]}, {}, {}, {\"t\": [\" LX\", \" increments\", \"inventoryQuantity\", \"\\u00e6\\u00a9\\u0141\", \"gency\"], \"v\": [-2.327, -2.323, -2.262, -2.176, -2.106]}, {}, {}, {\"t\": [\" LX\", \" increments\", \"inventoryQuantity\", \"\\u00e6\\u00a9\\u0141\", \"rament\"], \"v\": [-1.408, -1.406, -1.383, -1.309, -1.287]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"inventoryQuantity\", \" LX\", \" increments\", \"gency\", \"\\u00e6\\u00a9\\u0141\"], \"v\": [-0.652, -0.648, -0.641, -0.603, -0.602]}, {}, {}, {\"t\": [\" LX\", \" increments\", \"inventoryQuantity\", \"\\u00e6\\u00a9\\u0141\", \"gency\"], \"v\": [-0.34, -0.34, -0.334, -0.308, -0.308]}, {}, {}]}",
                        "binMin": -1,
                        "binMax": 46.083,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "1-res-jb",
            "index": "11991",
            "description": "references to the term \"Jew\" and related topics",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 45.02151870727539,
            "frac_nonzero": 3.528594970703125e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "1-res-jb",
                "index": "11991",
                "sourceSetName": "res-jb",
                "creatorId": null,
                "createdAt": "2024-02-09T23:15:06.127Z",
                "maxActApprox": 45.02151870727539,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    11991,
                    2723,
                    18747,
                    22913,
                    15893,
                    14833,
                    21814,
                    11317,
                    1187,
                    7531,
                    8964,
                    2042,
                    1990,
                    11293,
                    23391,
                    17517,
                    12056,
                    19378,
                    9209,
                    19127,
                    17378,
                    15658,
                    24343,
                    7395,
                    23508
                ],
                "topkCosSimValues": [
                    1,
                    0.7188,
                    0.6223,
                    0.5808,
                    0.5271,
                    0.4872,
                    0.4677,
                    0.4353,
                    0.4341,
                    0.4186,
                    0.4167,
                    0.4044,
                    0.4021,
                    0.4008,
                    0.3976,
                    0.3888,
                    0.3817,
                    0.3734,
                    0.3724,
                    0.3613,
                    0.3603,
                    0.3588,
                    0.3568,
                    0.355,
                    0.3545
                ],
                "neuron_alignment_indices": [
                    526,
                    289,
                    99
                ],
                "neuron_alignment_values": [
                    0.2018280327320099,
                    0.1288821995258331,
                    0.1155143678188324
                ],
                "neuron_alignment_l1": [
                    0.00968260783702135,
                    0.006183065008372068,
                    0.00554174929857254
                ],
                "correlated_neurons_indices": [
                    289,
                    202,
                    80
                ],
                "correlated_neurons_pearson": [
                    0.01139313634485006,
                    0.01111119706183672,
                    0.01044228114187717
                ],
                "correlated_neurons_l1": [
                    0.01058430597186089,
                    0.01134360022842884,
                    0.01048800349235535
                ],
                "correlated_features_indices": [],
                "correlated_features_pearson": [],
                "correlated_features_l1": [],
                "neg_str": [
                    " ERA",
                    "urate",
                    " SPORTS",
                    "likely",
                    " Thai",
                    "ctica",
                    "IUM",
                    " Sask",
                    "doi",
                    "Interstitial"
                ],
                "neg_values": [
                    -0.7238631844520569,
                    -0.6981441974639893,
                    -0.6902064681053162,
                    -0.6628412008285522,
                    -0.6236613988876343,
                    -0.6215763688087463,
                    -0.6110134124755859,
                    -0.6058160662651062,
                    -0.6031152009963989,
                    -0.5909518003463745
                ],
                "pos_str": [
                    "ellery",
                    " Jew",
                    "Jew",
                    "geist",
                    "ard",
                    "els",
                    "eled",
                    "smith",
                    "ogi",
                    "ozo"
                ],
                "pos_values": [
                    1.293986082077026,
                    1.210175395011902,
                    0.9603456854820251,
                    0.8589319586753845,
                    0.8372403979301453,
                    0.8176207542419434,
                    0.8166743516921997,
                    0.8031387329101562,
                    0.782737672328949,
                    0.7783140540122986
                ],
                "frac_nonzero": 3.528594970703125e-05,
                "freq_hist_data_bar_heights": [
                    28,
                    29,
                    13,
                    15,
                    5,
                    4,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    3,
                    6,
                    2,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.5648471117019653,
                    1.690332412719727,
                    2.815817832946777,
                    3.941303014755249,
                    5.066788196563721,
                    6.192273616790771,
                    7.317758560180664,
                    8.443243980407715,
                    9.568729400634766,
                    10.69421482086182,
                    11.81970024108887,
                    12.94518566131592,
                    14.07067012786865,
                    15.1961555480957,
                    16.32164192199707,
                    17.4471263885498,
                    18.57261085510254,
                    19.69809532165527,
                    20.82358169555664,
                    21.94906616210938,
                    23.07455444335938,
                    24.20004081726074,
                    25.32552528381348,
                    26.45101165771484,
                    27.57649612426758,
                    28.70198059082031,
                    29.82746696472168,
                    30.95295143127441,
                    32.07843780517578,
                    33.20392608642578,
                    34.32941055297852,
                    35.45489501953125,
                    36.58037948608398,
                    37.70586395263672,
                    38.83135223388672,
                    39.95683670043945,
                    41.08232116699219,
                    42.20780563354492,
                    43.33329391479492,
                    44.45877838134766
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    2,
                    10,
                    27,
                    65,
                    155,
                    322,
                    661,
                    1280,
                    2118,
                    3293,
                    4560,
                    5421,
                    5901,
                    5976,
                    5388,
                    4541,
                    3510,
                    2543,
                    1729,
                    1142,
                    692,
                    384,
                    235,
                    145,
                    66,
                    34,
                    20,
                    14,
                    12,
                    4,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.6986400485038757,
                    -0.6481938362121582,
                    -0.5977475643157959,
                    -0.5473013520240784,
                    -0.4968551695346832,
                    -0.4464089274406433,
                    -0.3959626853466034,
                    -0.3455164730548859,
                    -0.2950702309608459,
                    -0.2446239739656448,
                    -0.1941777616739273,
                    -0.1437315493822098,
                    -0.09328528493642807,
                    -0.04283907264471054,
                    0.007607141509652138,
                    0.05805341154336929,
                    0.1084996238350868,
                    0.1589458435773849,
                    0.2093921154737473,
                    0.2598383128643036,
                    0.3102845847606659,
                    0.3607307970523834,
                    0.411177009344101,
                    0.4616232812404633,
                    0.5120695233345032,
                    0.5625157356262207,
                    0.612962007522583,
                    0.6634082198143005,
                    0.7138544321060181,
                    0.7643007040023804,
                    0.8147469162940979,
                    0.8651931285858154,
                    0.9156394004821777,
                    0.9660856127738953,
                    1.016531825065613,
                    1.066978096961975,
                    1.117424249649048,
                    1.16787052154541,
                    1.218316793441772,
                    1.268762946128845
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clsxzhdip2zyrkad1trs7gm6i",
                        "modelId": "gpt2-small",
                        "layer": "1-res-jb",
                        "index": "11991",
                        "description": "references to the term \"Jew\" and related topics",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": null,
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0.2820181,
                        "umap_y": -3.1224825,
                        "umap_cluster": 602,
                        "umap_log_feature_sparsity": -4.294296,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-02-23T01:38:52.465Z",
                        "updatedAt": "2024-02-23T01:38:52.465Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clsf9mj8nbhe1m2qvv917mt3q",
                        "tokens": [
                            ".",
                            "<|endoftext|>",
                            " by",
                            " a",
                            " hood",
                            "ed",
                            " gang",
                            ".",
                            " Jew",
                            "ellery",
                            ",",
                            " watches",
                            " and",
                            " clothes",
                            " were",
                            " taken",
                            "\u010a"
                        ],
                        "dataIndex": null,
                        "index": "11991",
                        "layer": "1-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 45.02151870727539,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.02151870727539,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-09T23:15:10.881Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -11.19770622253418,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"Jew\", \"geist\", \"ozo\"], \"v\": [11.19770622253418, 9.011152267456055, 5.147522926330566, 4.085844039916992, 3.3849964141845703]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" ERA\", \"urate\", \" SPORTS\", \"likely\", \" Thai\"], \"v\": [-25.49335479736328, -25.382904052734375, -24.602855682373047, -24.252208709716797, -24.03778076171875]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsf9mj8nbhe2m2qvf4y6h7w9",
                        "tokens": [
                            " I",
                            " said",
                            ":",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " Jew",
                            " a",
                            "foot",
                            ".",
                            " Come",
                            " on",
                            " home",
                            " with",
                            " me"
                        ],
                        "dataIndex": null,
                        "index": "11991",
                        "layer": "1-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.1710205078125,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.1710205078125,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-09T23:15:10.881Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.2734375,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"Jew\", \"itsch\", \"ozo\"], \"v\": [9.316545486450195, 7.119749546051025, 2.9770874977111816, 1.8058032989501953, 1.8016014099121094]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"urate\", \" ERA\", \"likely\", \" SPORTS\", \" Thai\"], \"v\": [-27.6198673248291, -27.602149963378906, -26.768535614013672, -26.47320556640625, -25.67588233947754]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsf9mj8nbhe3m2qv9cwhxv4d",
                        "tokens": [
                            " of",
                            " the",
                            " Council",
                            " on",
                            " Environmental",
                            " Quality",
                            ".",
                            " Sally",
                            " Jew",
                            "ell",
                            " is",
                            " Secretary",
                            " of",
                            " the",
                            " U",
                            ".",
                            "S"
                        ],
                        "dataIndex": null,
                        "index": "11991",
                        "layer": "1-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 41.95688629150391,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.95688629150391,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-09T23:15:10.881Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.873136520385742,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"Jew\", \"geist\", \"ozo\"], \"v\": [11.413804054260254, 9.55127239227295, 5.491744041442871, 4.322457313537598, 3.6734609603881836]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" ERA\", \"urate\", \" SPORTS\", \"likely\", \" Thai\"], \"v\": [-25.051456451416016, -25.018421173095703, -24.21673011779785, -23.532304763793945, -23.512462615966797]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "3-res-jb",
            "index": "2451",
            "description": "references to Jews and anti-Semitic content",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 44.51845550537109,
            "frac_nonzero": 7.724761962890625e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "3-res-jb",
                "index": "2451",
                "sourceSetName": "res-jb",
                "creatorId": null,
                "createdAt": "2024-02-09T23:50:08.754Z",
                "maxActApprox": 44.51845550537109,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    2451,
                    9840,
                    7149,
                    23699,
                    21850,
                    2840,
                    17725,
                    19596,
                    5152,
                    3481,
                    1496,
                    9779,
                    5617,
                    22891,
                    16905,
                    11040,
                    514,
                    9751,
                    8441,
                    10243,
                    3663,
                    8834,
                    627,
                    8349,
                    21059
                ],
                "topkCosSimValues": [
                    1,
                    0.8173,
                    0.6686,
                    0.6024,
                    0.5947,
                    0.5849,
                    0.5516,
                    0.5399,
                    0.5366,
                    0.5355,
                    0.5345,
                    0.5003,
                    0.4936,
                    0.4905,
                    0.4703,
                    0.4665,
                    0.4557,
                    0.4524,
                    0.4485,
                    0.4474,
                    0.4379,
                    0.437,
                    0.4358,
                    0.4313,
                    0.4262
                ],
                "neuron_alignment_indices": [
                    288,
                    526,
                    289
                ],
                "neuron_alignment_values": [
                    0.1327048391103745,
                    0.1316998600959778,
                    0.1273621469736099
                ],
                "neuron_alignment_l1": [
                    0.00630499143153429,
                    0.006257243454456329,
                    0.006051152478903532
                ],
                "correlated_neurons_indices": [
                    289,
                    527,
                    19
                ],
                "correlated_neurons_pearson": [
                    0.01868524961173534,
                    0.01800310984253883,
                    0.01712452992796898
                ],
                "correlated_neurons_l1": [
                    0.0143914707005024,
                    0.01718080975115299,
                    0.01638783514499664
                ],
                "correlated_features_indices": [],
                "correlated_features_pearson": [],
                "correlated_features_l1": [],
                "neg_str": [
                    "inventoryQuantity",
                    "URRENT",
                    "ctive",
                    "shown",
                    "tnc",
                    "nant",
                    "amina",
                    "ISTER",
                    "cer",
                    "NRS"
                ],
                "neg_values": [
                    -0.8259067535400391,
                    -0.7745349407196045,
                    -0.7433963418006897,
                    -0.705987274646759,
                    -0.6897789835929871,
                    -0.6801779866218567,
                    -0.6726738810539246,
                    -0.6692948937416077,
                    -0.6680846810340881,
                    -0.6680213212966919
                ],
                "pos_str": [
                    " Jews",
                    " Israelis",
                    "geist",
                    "ellery",
                    "ophobia",
                    "esses",
                    " Arabs",
                    "odus",
                    " Juda",
                    "Semitism"
                ],
                "pos_values": [
                    0.926304280757904,
                    0.8707727193832397,
                    0.8535169959068298,
                    0.8383060097694397,
                    0.7730944752693176,
                    0.7405411005020142,
                    0.7345811128616333,
                    0.7319588661193848,
                    0.7316097617149353,
                    0.7305923104286194
                ],
                "frac_nonzero": 7.724761962890625e-05,
                "freq_hist_data_bar_heights": [
                    66,
                    23,
                    10,
                    18,
                    11,
                    3,
                    2,
                    6,
                    5,
                    3,
                    7,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    3,
                    4,
                    6,
                    9,
                    16,
                    17,
                    13,
                    14,
                    1,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.5604877471923828,
                    1.67334771156311,
                    2.786207675933838,
                    3.899067401885986,
                    5.011927604675293,
                    6.124787330627441,
                    7.237647533416748,
                    8.350507736206055,
                    9.463367462158203,
                    10.57622718811035,
                    11.6890869140625,
                    12.80194759368896,
                    13.91480731964111,
                    15.02766704559326,
                    16.14052772521973,
                    17.25338745117188,
                    18.36624717712402,
                    19.47910690307617,
                    20.59196662902832,
                    21.70482635498047,
                    22.81768798828125,
                    23.9305477142334,
                    25.04340744018555,
                    26.1562671661377,
                    27.26912689208984,
                    28.38198661804199,
                    29.49484634399414,
                    30.60770797729492,
                    31.72056579589844,
                    32.83342742919922,
                    33.94628524780273,
                    35.05914688110352,
                    36.1720085144043,
                    37.28486633300781,
                    38.39772796630859,
                    39.51058578491211,
                    40.62344741821289,
                    41.73630523681641,
                    42.84916687011719,
                    43.9620246887207
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    1,
                    8,
                    13,
                    20,
                    33,
                    73,
                    147,
                    246,
                    501,
                    797,
                    1247,
                    1912,
                    2724,
                    3456,
                    4426,
                    5038,
                    5323,
                    5295,
                    4813,
                    4170,
                    3286,
                    2347,
                    1643,
                    1153,
                    663,
                    400,
                    210,
                    117,
                    86,
                    49,
                    21,
                    12,
                    10,
                    9,
                    1,
                    1,
                    2,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.8040041327476501,
                    -0.7601988315582275,
                    -0.7163935899734497,
                    -0.6725882887840271,
                    -0.6287830471992493,
                    -0.5849777460098267,
                    -0.541172444820404,
                    -0.4973671734333038,
                    -0.4535618722438812,
                    -0.409756600856781,
                    -0.3659513294696808,
                    -0.3221460282802582,
                    -0.2783407270908356,
                    -0.2345355004072189,
                    -0.1907301992177963,
                    -0.1469249576330185,
                    -0.1031196564435959,
                    -0.05931435525417328,
                    -0.0155091118067503,
                    0.02829618938267231,
                    0.07210136950016022,
                    0.115906611084938,
                    0.1597119122743607,
                    0.2035171538591385,
                    0.2473224550485611,
                    0.2911277711391449,
                    0.3349330127239227,
                    0.3787383139133453,
                    0.4225435554981232,
                    0.4663488566875458,
                    0.510154128074646,
                    0.5539594292640686,
                    0.5977646708488464,
                    0.6415699124336243,
                    0.6853752136230469,
                    0.7291805148124695,
                    0.7729857563972473,
                    0.8167910575866699,
                    0.8605963587760925,
                    0.9044016003608704
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clsxtdf6810bbenuxhxw0grqe",
                        "modelId": "gpt2-small",
                        "layer": "3-res-jb",
                        "index": "2451",
                        "description": "references to Jews and anti-Semitic content",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": null,
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 6.5495586,
                        "umap_y": 10.999252,
                        "umap_cluster": 676,
                        "umap_log_feature_sparsity": -4.1018143,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-02-22T22:47:50.209Z",
                        "updatedAt": "2024-02-22T22:47:50.209Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clsfavmovvx9wm2qv0gn84hn3",
                        "tokens": [
                            " various",
                            " forms",
                            ":",
                            " dem",
                            "e",
                            "aning",
                            " remarks",
                            " about",
                            " Jews",
                            ",",
                            " abhor",
                            "rence",
                            " of",
                            " the",
                            " presence",
                            " of",
                            " Jews"
                        ],
                        "dataIndex": null,
                        "index": "2451",
                        "layer": "3-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.51845550537109,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.51845550537109,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.68888092041016
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-09T23:50:14.202Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.129440307617188,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \"geist\", \" Jews\", \" Israelis\", \"esses\"], \"v\": [7.820397853851318, 7.819142818450928, 7.674551963806152, 7.431647300720215, 6.223543643951416]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"URRENT\", \"cer\", \"ctive\", \"inventoryQuantity\", \"nant\"], \"v\": [-16.922142028808594, -16.513519287109375, -16.505908966064453, -16.202354431152344, -15.94040298461914]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsfavmovvx9xm2qvurausqpt",
                        "tokens": [
                            " about",
                            " 8",
                            " million",
                            "<|endoftext|>",
                            " forcibly",
                            "-",
                            "con",
                            "verted",
                            " Jews",
                            " in",
                            " Spain",
                            " after",
                            " 14",
                            "92",
                            " (",
                            "many",
                            " I"
                        ],
                        "dataIndex": null,
                        "index": "2451",
                        "layer": "3-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.05907440185547,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.05907440185547,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-09T23:50:14.202Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.968585968017578,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"geist\", \"ellery\", \" Jews\", \" Israelis\", \"odus\"], \"v\": [8.413064956665039, 8.294246673583984, 7.7813591957092285, 7.5000433921813965, 6.839570045471191]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ctive\", \"URRENT\", \"cer\", \"NRS\", \"nant\"], \"v\": [-17.487869262695312, -17.341968536376953, -16.921791076660156, -16.488189697265625, -16.416786193847656]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsfavmovvx9ym2qv07vobuot",
                        "tokens": [
                            " screaming",
                            " headlines",
                            " introduced",
                            " the",
                            " most",
                            " rabid",
                            " attacks",
                            " on",
                            " Jews",
                            ",",
                            " full",
                            " of",
                            " sexual",
                            " inn",
                            "u",
                            "endo",
                            ","
                        ],
                        "dataIndex": null,
                        "index": "2451",
                        "layer": "3-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.53985977172852,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.53985977172852,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-09T23:50:14.202Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.535497665405273,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jews\", \"geist\", \" Israelis\", \"odus\"], \"v\": [9.113669395446777, 8.85226058959961, 8.544332504272461, 8.526701927185059, 7.395628929138184]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"URRENT\", \"cer\", \"ctive\", \"inventoryQuantity\", \"NRS\"], \"v\": [-16.29906463623047, -16.04631805419922, -15.799932479858398, -15.68655776977539, -15.403952598571777]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "10-res-jb",
            "index": "18881",
            "description": "mentions of the word \"jew\" or \"jewelry.\"",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 43.83152389526367,
            "frac_nonzero": 0.00049591064453125,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "10-res-jb",
                "index": "18881",
                "sourceSetName": "res-jb",
                "creatorId": null,
                "createdAt": "2024-02-12T04:21:37.186Z",
                "maxActApprox": 43.83152389526367,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    18881,
                    13688,
                    8125,
                    4943,
                    1881,
                    22169,
                    17543,
                    16083,
                    2834,
                    6013,
                    21068,
                    10521,
                    16462,
                    23640,
                    11412,
                    19418,
                    9738,
                    13419,
                    19165,
                    678,
                    9944,
                    7046,
                    4657,
                    11697,
                    14323
                ],
                "topkCosSimValues": [
                    1,
                    0.3603,
                    0.2892,
                    0.2887,
                    0.2724,
                    0.2704,
                    0.2558,
                    0.2535,
                    0.253,
                    0.2528,
                    0.2512,
                    0.2447,
                    0.2445,
                    0.2427,
                    0.2413,
                    0.2404,
                    0.2391,
                    0.239,
                    0.2365,
                    0.2362,
                    0.2355,
                    0.2334,
                    0.232,
                    0.2317,
                    0.2302
                ],
                "neuron_alignment_indices": [
                    314,
                    526,
                    0
                ],
                "neuron_alignment_values": [
                    0.1414098590612411,
                    0.1209051236510277,
                    0.1034116223454475
                ],
                "neuron_alignment_l1": [
                    0.006477525923401117,
                    0.005538270343095064,
                    0.004736950155347586
                ],
                "correlated_neurons_indices": [
                    526,
                    326,
                    314
                ],
                "correlated_neurons_pearson": [
                    0.01713639311492443,
                    0.01650589145720005,
                    0.0151332188397646
                ],
                "correlated_neurons_l1": [
                    0.003872076747938991,
                    0.01666516065597534,
                    0.0004222726856824011
                ],
                "correlated_features_indices": [],
                "correlated_features_pearson": [],
                "correlated_features_l1": [],
                "neg_str": [
                    " contin",
                    " Reality",
                    " Vietnam",
                    " setbacks",
                    " Allied",
                    "\u00e9\u00be",
                    " simultane",
                    " necessity",
                    " impossibility",
                    " inev"
                ],
                "neg_values": [
                    -0.7132264375686646,
                    -0.704287052154541,
                    -0.6164080500602722,
                    -0.6068561673164368,
                    -0.6065099239349365,
                    -0.6025049090385437,
                    -0.5999817848205566,
                    -0.5990490317344666,
                    -0.5976169109344482,
                    -0.592275083065033
                ],
                "pos_str": [
                    "ellery",
                    "elled",
                    "eller",
                    "eled",
                    "els",
                    "eling",
                    "ell",
                    "el",
                    "ett",
                    "elle"
                ],
                "pos_values": [
                    2.019766330718994,
                    1.504289388656616,
                    1.401335000991821,
                    1.401005029678345,
                    1.233928680419922,
                    1.228197574615479,
                    1.193684935569763,
                    1.118683576583862,
                    1.114320397377014,
                    1.082764983177185
                ],
                "frac_nonzero": 0.00049591064453125,
                "freq_hist_data_bar_heights": [
                    563,
                    338,
                    225,
                    131,
                    83,
                    61,
                    46,
                    26,
                    19,
                    15,
                    6,
                    3,
                    3,
                    0,
                    1,
                    4,
                    3,
                    2,
                    0,
                    1,
                    2,
                    1,
                    3,
                    2,
                    3,
                    5,
                    1,
                    1,
                    0,
                    3,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    2,
                    1,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.5481531620025635,
                    1.643934726715088,
                    2.739716529846191,
                    3.835497856140137,
                    4.931279182434082,
                    6.027060508728027,
                    7.122842311859131,
                    8.218624114990234,
                    9.31440544128418,
                    10.41018676757812,
                    11.50596809387207,
                    12.60175037384033,
                    13.69753170013428,
                    14.79331302642822,
                    15.88909530639648,
                    16.98487854003906,
                    18.08065986633301,
                    19.17644119262695,
                    20.2722225189209,
                    21.36800384521484,
                    22.46378517150879,
                    23.55956649780273,
                    24.65534782409668,
                    25.75112915039062,
                    26.84691047668457,
                    27.94269180297852,
                    29.03847312927246,
                    30.13425636291504,
                    31.23003578186035,
                    32.3258171081543,
                    33.42160034179688,
                    34.51737976074219,
                    35.6131591796875,
                    36.70894241333008,
                    37.80472564697266,
                    38.90050506591797,
                    39.99628829956055,
                    41.09206771850586,
                    42.18785095214844,
                    43.28363037109375
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    12,
                    29,
                    99,
                    409,
                    1089,
                    2435,
                    4466,
                    6737,
                    8286,
                    7982,
                    6428,
                    4584,
                    2888,
                    1855,
                    1176,
                    744,
                    439,
                    275,
                    149,
                    72,
                    52,
                    20,
                    9,
                    7,
                    3,
                    3,
                    1,
                    2,
                    0,
                    2,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.6790640354156494,
                    -0.6107392311096191,
                    -0.5424144268035889,
                    -0.4740895628929138,
                    -0.4057647585868835,
                    -0.3374399542808533,
                    -0.2691151201725006,
                    -0.2007902860641479,
                    -0.1324654817581177,
                    -0.0641406700015068,
                    0.004184134304523468,
                    0.07250899821519852,
                    0.1408337950706482,
                    0.2091585993766785,
                    0.2774834632873535,
                    0.3458082675933838,
                    0.4141330718994141,
                    0.4824578762054443,
                    0.5507826805114746,
                    0.6191074848175049,
                    0.6874324083328247,
                    0.755757212638855,
                    0.8240820169448853,
                    0.8924068212509155,
                    0.9607316255569458,
                    1.029056429862976,
                    1.097381234169006,
                    1.165706038475037,
                    1.234030842781067,
                    1.302355647087097,
                    1.370680570602417,
                    1.439005374908447,
                    1.507330179214478,
                    1.575654983520508,
                    1.643979787826538,
                    1.712304711341858,
                    1.780629515647888,
                    1.848954319953918,
                    1.917279124259949,
                    1.985603928565979
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clsy69xp17jn3kad1zulhzrzl",
                        "modelId": "gpt2-small",
                        "layer": "10-res-jb",
                        "index": "18881",
                        "description": "mentions of the word \"jew\" or \"jewelry.\"",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": null,
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 5.016091,
                        "umap_y": 6.8158827,
                        "umap_cluster": 1302,
                        "umap_log_feature_sparsity": -3.3263528,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-02-23T04:49:02.677Z",
                        "updatedAt": "2024-02-23T04:49:02.677Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clsifghx4agc4wf4r6vet9688",
                        "tokens": [
                            " advertisers",
                            " to",
                            " target",
                            " users",
                            " using",
                            " terms",
                            " like",
                            " \"",
                            "jew",
                            " h",
                            "ater",
                            "\"",
                            " in",
                            " its",
                            " education",
                            " and",
                            " employment"
                        ],
                        "dataIndex": null,
                        "index": "18881",
                        "layer": "10-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.83152389526367,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.83152389526367,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-12T04:21:44.291Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.156633377075195,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \"elled\", \"eled\", \"eller\", \"eling\"], \"v\": [10.87066650390625, 7.430367469787598, 6.457080841064453, 6.324709892272949, 5.1446027755737305]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" contin\", \" Reality\", \" Vietnam\", \" necessity\", \" evils\"], \"v\": [-8.733932495117188, -8.589649200439453, -8.447893142700195, -8.343544006347656, -8.088590621948242]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsifghx4agc5wf4rnf25tff8",
                        "tokens": [
                            "ans",
                            "acked",
                            " the",
                            " Victorian",
                            " property",
                            " in",
                            " Liverpool",
                            " for",
                            " jew",
                            "ellery",
                            ",",
                            " watches",
                            " and",
                            " clothes",
                            " amount",
                            "ing",
                            " to"
                        ],
                        "dataIndex": null,
                        "index": "18881",
                        "layer": "10-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.09199142456055,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.09199142456055,
                            5.72123384475708,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-12T04:21:44.291Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -0.1171223223209381,
                            0.07294082641601562,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \"elled\", \"eled\", \"eller\", \"els\"], \"v\": [0.11712232232093811, -3.066849708557129, -3.2445030212402344, -3.5897836685180664, -4.305105209350586]}, {\"t\": [\"ellery\", \"elled\", \"eller\", \"eled\", \"els\"], \"v\": [2.051614761352539, 1.5594902038574219, 1.4681358337402344, 1.4659175872802734, 1.2959270477294922]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" contin\", \" Allied\", \" Reality\", \" necessity\", \" Vietnam\"], \"v\": [-19.2052001953125, -18.846664428710938, -18.820354461669922, -18.53709602355957, -18.376144409179688]}, {\"t\": [\" contin\", \" Reality\", \" Vietnam\", \" Allied\", \" necessity\"], \"v\": [-0.7040348052978516, -0.6849365234375, -0.6207237243652344, -0.6170310974121094, -0.614715576171875]}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsifghx4agc6wf4ra6xbigwk",
                        "tokens": [
                            ".",
                            "<|endoftext|>",
                            " by",
                            " a",
                            " hood",
                            "ed",
                            " gang",
                            ".",
                            " Jew",
                            "ellery",
                            ",",
                            " watches",
                            " and",
                            " clothes",
                            " were",
                            " taken",
                            "\u010a"
                        ],
                        "dataIndex": null,
                        "index": "18881",
                        "layer": "10-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.91158294677734,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.91158294677734,
                            6.813690185546875,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-12T04:21:44.291Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -5.311007976531982,
                            0.2358312606811523,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \"elled\", \"eller\", \"eled\", \"eling\"], \"v\": [5.311007976531982, 1.8865361213684082, 1.0814776420593262, 0.9709792137145996, 0.2007436752319336]}, {\"t\": [\"ellery\", \"elled\", \"eled\", \"eller\", \"eling\"], \"v\": [2.1332216262817383, 1.5731964111328125, 1.4680137634277344, 1.45880126953125, 1.2777938842773438]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Reality\", \" contin\", \" Vietnam\", \" Allied\", \" Apostles\"], \"v\": [-13.26742935180664, -13.2601318359375, -12.848968505859375, -12.835416793823242, -12.763460159301758]}, {\"t\": [\" contin\", \" Reality\", \" Vietnam\", \" setbacks\", \" necessity\"], \"v\": [-0.9982948303222656, -0.9756832122802734, -0.8894863128662109, -0.8799114227294922, -0.8788089752197266]}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "2-res-jb",
            "index": "792",
            "description": "mentions of the term \"Jew\" with varying intensities",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 43.47324752807617,
            "frac_nonzero": 6.039937337239584e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "2-res-jb",
                "index": "792",
                "sourceSetName": "res-jb",
                "creatorId": null,
                "createdAt": "2024-02-09T23:24:10.571Z",
                "maxActApprox": 43.47324752807617,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    792,
                    18740,
                    1631,
                    13900,
                    17032,
                    6045,
                    15215,
                    9468,
                    15267,
                    3799,
                    871,
                    12778,
                    19630,
                    9734,
                    5879,
                    9811,
                    2040,
                    6427,
                    1682,
                    18862,
                    8146,
                    21001,
                    11405,
                    19728,
                    18394
                ],
                "topkCosSimValues": [
                    1,
                    0.6858,
                    0.5955,
                    0.4471,
                    0.4452,
                    0.4436,
                    0.4419,
                    0.423,
                    0.4215,
                    0.4054,
                    0.4011,
                    0.3854,
                    0.3852,
                    0.383,
                    0.3823,
                    0.3676,
                    0.364,
                    0.3602,
                    0.3595,
                    0.3552,
                    0.3539,
                    0.3509,
                    0.3503,
                    0.35,
                    0.3467
                ],
                "neuron_alignment_indices": [
                    526,
                    289,
                    0
                ],
                "neuron_alignment_values": [
                    0.1747378557920456,
                    0.1373535543680191,
                    0.1097589805722237
                ],
                "neuron_alignment_l1": [
                    0.008346280083060265,
                    0.006560634821653366,
                    0.005242591723799706
                ],
                "correlated_neurons_indices": [
                    289,
                    592,
                    202
                ],
                "correlated_neurons_pearson": [
                    0.01192672643810511,
                    0.01061419676989317,
                    0.009221168234944344
                ],
                "correlated_neurons_l1": [
                    0.009936568327248096,
                    0.01046580076217651,
                    0.00907581765204668
                ],
                "correlated_features_indices": [],
                "correlated_features_pearson": [],
                "correlated_features_l1": [],
                "neg_str": [
                    "ctory",
                    " Thai",
                    "\u00e9\u00be",
                    " ERA",
                    " Sask",
                    "LEASE",
                    "urate",
                    "ctica",
                    "likely",
                    "GAME"
                ],
                "neg_values": [
                    -0.681080162525177,
                    -0.6802264451980591,
                    -0.6722476482391357,
                    -0.655475914478302,
                    -0.6541232466697693,
                    -0.6504138708114624,
                    -0.6407849788665771,
                    -0.638842761516571,
                    -0.6349173784255981,
                    -0.625484824180603
                ],
                "pos_str": [
                    "ellery",
                    " Jew",
                    "Jew",
                    "eled",
                    "ry",
                    "eller",
                    "ard",
                    "bow",
                    "itsch",
                    "els"
                ],
                "pos_values": [
                    1.364835381507874,
                    1.063072204589844,
                    0.9831801652908325,
                    0.8936821818351746,
                    0.8925299048423767,
                    0.8374033570289612,
                    0.8373000621795654,
                    0.8229401111602783,
                    0.8190231323242188,
                    0.8067840933799744
                ],
                "frac_nonzero": 6.039937337239584e-05,
                "freq_hist_data_bar_heights": [
                    91,
                    41,
                    14,
                    10,
                    10,
                    2,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    2,
                    0,
                    0,
                    0,
                    0,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    5,
                    1,
                    2,
                    3,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.543617308139801,
                    1.630443453788757,
                    2.717269420623779,
                    3.80409574508667,
                    4.890921592712402,
                    5.977747917175293,
                    7.064573764801025,
                    8.151399612426758,
                    9.238225936889648,
                    10.32505226135254,
                    11.41187858581543,
                    12.498703956604,
                    13.58553028106689,
                    14.67235660552979,
                    15.75918197631836,
                    16.84600830078125,
                    17.93283462524414,
                    19.01966094970703,
                    20.10648727416992,
                    21.19331359863281,
                    22.28013801574707,
                    23.36696434020996,
                    24.45379066467285,
                    25.54061698913574,
                    26.62744331359863,
                    27.71426963806152,
                    28.80109596252441,
                    29.8879222869873,
                    30.9747486114502,
                    32.06157302856445,
                    33.14839935302734,
                    34.23522186279297,
                    35.32205200195312,
                    36.40887451171875,
                    37.49570083618164,
                    38.58252716064453,
                    39.66935348510742,
                    40.75617980957031,
                    41.8430061340332,
                    42.92983245849609
                ],
                "logits_hist_data_bar_heights": [
                    9,
                    8,
                    29,
                    62,
                    138,
                    328,
                    590,
                    1163,
                    2027,
                    3191,
                    4486,
                    5757,
                    6022,
                    6300,
                    5676,
                    4564,
                    3550,
                    2346,
                    1604,
                    978,
                    594,
                    380,
                    197,
                    113,
                    64,
                    31,
                    25,
                    11,
                    4,
                    5,
                    2,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.6555061936378479,
                    -0.6043583154678345,
                    -0.553210437297821,
                    -0.5020625591278076,
                    -0.4509146511554718,
                    -0.3997667729854584,
                    -0.3486188948154449,
                    -0.2974709868431091,
                    -0.2463231086730957,
                    -0.1951752305030823,
                    -0.1440273225307465,
                    -0.09287943691015244,
                    -0.04173155874013901,
                    0.009416317567229271,
                    0.06056425720453262,
                    0.1117121353745461,
                    0.1628600060939789,
                    0.2140078842639923,
                    0.2651557624340057,
                    0.3163037002086639,
                    0.3674515187740326,
                    0.418599396944046,
                    0.4697473347187042,
                    0.52089524269104,
                    0.5720431208610535,
                    0.6231909990310669,
                    0.6743388772010803,
                    0.7254868149757385,
                    0.776634693145752,
                    0.8277825713157654,
                    0.8789304494857788,
                    0.930078387260437,
                    0.9812262058258057,
                    1.032374143600464,
                    1.083522081375122,
                    1.134669899940491,
                    1.185817837715149,
                    1.236965656280518,
                    1.288113594055176,
                    1.339261412620544
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clsxs6wtf09lhenux3tj652k9",
                        "modelId": "gpt2-small",
                        "layer": "2-res-jb",
                        "index": "792",
                        "description": "mentions of the term \"Jew\" with varying intensities",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": null,
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 6.3126903,
                        "umap_y": 11.855283,
                        "umap_cluster": 421,
                        "umap_log_feature_sparsity": -4.262111,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-02-22T22:14:46.868Z",
                        "updatedAt": "2024-02-22T22:14:46.868Z"
                    },
                    {
                        "id": "clsmsl3n102ozjozp50cbbi9e",
                        "modelId": "gpt2-small",
                        "layer": "2-res-jb",
                        "index": "792",
                        "description": " the word \"Jew.\"",
                        "authorId": "cljj57d3c000076ei38vwnv35",
                        "triggeredByUserId": null,
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": null,
                        "umap_y": null,
                        "umap_cluster": null,
                        "umap_log_feature_sparsity": null,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4-turbo",
                        "createdAt": "2024-02-15T05:40:21.037Z",
                        "updatedAt": "2024-02-15T05:40:21.037Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clsf9y7mku3jlm2qvmr2a2rzn",
                        "tokens": [
                            ".",
                            "<|endoftext|>",
                            " by",
                            " a",
                            " hood",
                            "ed",
                            " gang",
                            ".",
                            " Jew",
                            "ellery",
                            ",",
                            " watches",
                            " and",
                            " clothes",
                            " were",
                            " taken",
                            "\u010a"
                        ],
                        "dataIndex": null,
                        "index": "792",
                        "layer": "2-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.47324752807617,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.47324752807617,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-09T23:24:15.552Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -12.00106620788574,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \"Jew\", \" Jew\", \"eled\", \"itsch\"], \"v\": [12.001066207885742, 6.036327362060547, 5.754977703094482, 4.691263198852539, 3.6955738067626953]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Thai\", \" Sask\", \"urate\", \" ERA\", \"ctory\"], \"v\": [-23.343774795532227, -22.606395721435547, -22.318073272705078, -22.31263542175293, -21.983867645263672]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsf9y7mku3jmm2qvt7rlt2in",
                        "tokens": [
                            " I",
                            " said",
                            ":",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " Jew",
                            " a",
                            "foot",
                            ".",
                            " Come",
                            " on",
                            " home",
                            " with",
                            " me"
                        ],
                        "dataIndex": null,
                        "index": "792",
                        "layer": "2-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.32301330566406,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.32301330566406,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-09T23:24:15.552Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            16.65147018432617,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"Jew\", \"itsch\", \"ry\"], \"v\": [8.725861549377441, 2.771871566772461, 2.6570515632629395, 2.152791976928711, 1.2980060577392578]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Thai\", \" Sask\", \" ERA\", \"urate\", \"likely\"], \"v\": [-24.908226013183594, -24.474342346191406, -24.325653076171875, -24.227937698364258, -23.923633575439453]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsf9y7mku3jnm2qvtxefm1z6",
                        "tokens": [
                            "eps",
                            " would",
                            " draw",
                            " a",
                            " big",
                            " difference",
                            " between",
                            " a",
                            " Jew",
                            " and",
                            " an",
                            " atheist",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\u010a",
                            "\u010a"
                        ],
                        "dataIndex": null,
                        "index": "792",
                        "layer": "2-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 41.37604522705078,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.37604522705078,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-09T23:24:15.552Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.387210845947266,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"Jew\", \"itsch\", \"eled\"], \"v\": [11.237591743469238, 4.5315351486206055, 4.451480388641357, 3.9826173782348633, 3.1300172805786133]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" ERA\", \" Thai\", \"urate\", \" Sask\", \"likely\"], \"v\": [-22.475589752197266, -22.443523406982422, -22.410728454589844, -22.15285873413086, -21.657955169677734]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "2-res-jb",
            "index": "792",
            "description": " the word \"Jew.\"",
            "explanationModelName": "gpt-4-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 43.47324752807617,
            "frac_nonzero": 6.039937337239584e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "2-res-jb",
                "index": "792",
                "sourceSetName": "res-jb",
                "creatorId": null,
                "createdAt": "2024-02-09T23:24:10.571Z",
                "maxActApprox": 43.47324752807617,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    792,
                    18740,
                    1631,
                    13900,
                    17032,
                    6045,
                    15215,
                    9468,
                    15267,
                    3799,
                    871,
                    12778,
                    19630,
                    9734,
                    5879,
                    9811,
                    2040,
                    6427,
                    1682,
                    18862,
                    8146,
                    21001,
                    11405,
                    19728,
                    18394
                ],
                "topkCosSimValues": [
                    1,
                    0.6858,
                    0.5955,
                    0.4471,
                    0.4452,
                    0.4436,
                    0.4419,
                    0.423,
                    0.4215,
                    0.4054,
                    0.4011,
                    0.3854,
                    0.3852,
                    0.383,
                    0.3823,
                    0.3676,
                    0.364,
                    0.3602,
                    0.3595,
                    0.3552,
                    0.3539,
                    0.3509,
                    0.3503,
                    0.35,
                    0.3467
                ],
                "neuron_alignment_indices": [
                    526,
                    289,
                    0
                ],
                "neuron_alignment_values": [
                    0.1747378557920456,
                    0.1373535543680191,
                    0.1097589805722237
                ],
                "neuron_alignment_l1": [
                    0.008346280083060265,
                    0.006560634821653366,
                    0.005242591723799706
                ],
                "correlated_neurons_indices": [
                    289,
                    592,
                    202
                ],
                "correlated_neurons_pearson": [
                    0.01192672643810511,
                    0.01061419676989317,
                    0.009221168234944344
                ],
                "correlated_neurons_l1": [
                    0.009936568327248096,
                    0.01046580076217651,
                    0.00907581765204668
                ],
                "correlated_features_indices": [],
                "correlated_features_pearson": [],
                "correlated_features_l1": [],
                "neg_str": [
                    "ctory",
                    " Thai",
                    "\u00e9\u00be",
                    " ERA",
                    " Sask",
                    "LEASE",
                    "urate",
                    "ctica",
                    "likely",
                    "GAME"
                ],
                "neg_values": [
                    -0.681080162525177,
                    -0.6802264451980591,
                    -0.6722476482391357,
                    -0.655475914478302,
                    -0.6541232466697693,
                    -0.6504138708114624,
                    -0.6407849788665771,
                    -0.638842761516571,
                    -0.6349173784255981,
                    -0.625484824180603
                ],
                "pos_str": [
                    "ellery",
                    " Jew",
                    "Jew",
                    "eled",
                    "ry",
                    "eller",
                    "ard",
                    "bow",
                    "itsch",
                    "els"
                ],
                "pos_values": [
                    1.364835381507874,
                    1.063072204589844,
                    0.9831801652908325,
                    0.8936821818351746,
                    0.8925299048423767,
                    0.8374033570289612,
                    0.8373000621795654,
                    0.8229401111602783,
                    0.8190231323242188,
                    0.8067840933799744
                ],
                "frac_nonzero": 6.039937337239584e-05,
                "freq_hist_data_bar_heights": [
                    91,
                    41,
                    14,
                    10,
                    10,
                    2,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    2,
                    0,
                    0,
                    0,
                    0,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    5,
                    1,
                    2,
                    3,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.543617308139801,
                    1.630443453788757,
                    2.717269420623779,
                    3.80409574508667,
                    4.890921592712402,
                    5.977747917175293,
                    7.064573764801025,
                    8.151399612426758,
                    9.238225936889648,
                    10.32505226135254,
                    11.41187858581543,
                    12.498703956604,
                    13.58553028106689,
                    14.67235660552979,
                    15.75918197631836,
                    16.84600830078125,
                    17.93283462524414,
                    19.01966094970703,
                    20.10648727416992,
                    21.19331359863281,
                    22.28013801574707,
                    23.36696434020996,
                    24.45379066467285,
                    25.54061698913574,
                    26.62744331359863,
                    27.71426963806152,
                    28.80109596252441,
                    29.8879222869873,
                    30.9747486114502,
                    32.06157302856445,
                    33.14839935302734,
                    34.23522186279297,
                    35.32205200195312,
                    36.40887451171875,
                    37.49570083618164,
                    38.58252716064453,
                    39.66935348510742,
                    40.75617980957031,
                    41.8430061340332,
                    42.92983245849609
                ],
                "logits_hist_data_bar_heights": [
                    9,
                    8,
                    29,
                    62,
                    138,
                    328,
                    590,
                    1163,
                    2027,
                    3191,
                    4486,
                    5757,
                    6022,
                    6300,
                    5676,
                    4564,
                    3550,
                    2346,
                    1604,
                    978,
                    594,
                    380,
                    197,
                    113,
                    64,
                    31,
                    25,
                    11,
                    4,
                    5,
                    2,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.6555061936378479,
                    -0.6043583154678345,
                    -0.553210437297821,
                    -0.5020625591278076,
                    -0.4509146511554718,
                    -0.3997667729854584,
                    -0.3486188948154449,
                    -0.2974709868431091,
                    -0.2463231086730957,
                    -0.1951752305030823,
                    -0.1440273225307465,
                    -0.09287943691015244,
                    -0.04173155874013901,
                    0.009416317567229271,
                    0.06056425720453262,
                    0.1117121353745461,
                    0.1628600060939789,
                    0.2140078842639923,
                    0.2651557624340057,
                    0.3163037002086639,
                    0.3674515187740326,
                    0.418599396944046,
                    0.4697473347187042,
                    0.52089524269104,
                    0.5720431208610535,
                    0.6231909990310669,
                    0.6743388772010803,
                    0.7254868149757385,
                    0.776634693145752,
                    0.8277825713157654,
                    0.8789304494857788,
                    0.930078387260437,
                    0.9812262058258057,
                    1.032374143600464,
                    1.083522081375122,
                    1.134669899940491,
                    1.185817837715149,
                    1.236965656280518,
                    1.288113594055176,
                    1.339261412620544
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clsxs6wtf09lhenux3tj652k9",
                        "modelId": "gpt2-small",
                        "layer": "2-res-jb",
                        "index": "792",
                        "description": "mentions of the term \"Jew\" with varying intensities",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": null,
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 6.3126903,
                        "umap_y": 11.855283,
                        "umap_cluster": 421,
                        "umap_log_feature_sparsity": -4.262111,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-02-22T22:14:46.868Z",
                        "updatedAt": "2024-02-22T22:14:46.868Z"
                    },
                    {
                        "id": "clsmsl3n102ozjozp50cbbi9e",
                        "modelId": "gpt2-small",
                        "layer": "2-res-jb",
                        "index": "792",
                        "description": " the word \"Jew.\"",
                        "authorId": "cljj57d3c000076ei38vwnv35",
                        "triggeredByUserId": null,
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": null,
                        "umap_y": null,
                        "umap_cluster": null,
                        "umap_log_feature_sparsity": null,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4-turbo",
                        "createdAt": "2024-02-15T05:40:21.037Z",
                        "updatedAt": "2024-02-15T05:40:21.037Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clsf9y7mku3jlm2qvmr2a2rzn",
                        "tokens": [
                            ".",
                            "<|endoftext|>",
                            " by",
                            " a",
                            " hood",
                            "ed",
                            " gang",
                            ".",
                            " Jew",
                            "ellery",
                            ",",
                            " watches",
                            " and",
                            " clothes",
                            " were",
                            " taken",
                            "\u010a"
                        ],
                        "dataIndex": null,
                        "index": "792",
                        "layer": "2-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.47324752807617,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.47324752807617,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-09T23:24:15.552Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -12.00106620788574,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \"Jew\", \" Jew\", \"eled\", \"itsch\"], \"v\": [12.001066207885742, 6.036327362060547, 5.754977703094482, 4.691263198852539, 3.6955738067626953]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Thai\", \" Sask\", \"urate\", \" ERA\", \"ctory\"], \"v\": [-23.343774795532227, -22.606395721435547, -22.318073272705078, -22.31263542175293, -21.983867645263672]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsf9y7mku3jmm2qvt7rlt2in",
                        "tokens": [
                            " I",
                            " said",
                            ":",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " Jew",
                            " a",
                            "foot",
                            ".",
                            " Come",
                            " on",
                            " home",
                            " with",
                            " me"
                        ],
                        "dataIndex": null,
                        "index": "792",
                        "layer": "2-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.32301330566406,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.32301330566406,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-09T23:24:15.552Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            16.65147018432617,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"Jew\", \"itsch\", \"ry\"], \"v\": [8.725861549377441, 2.771871566772461, 2.6570515632629395, 2.152791976928711, 1.2980060577392578]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Thai\", \" Sask\", \" ERA\", \"urate\", \"likely\"], \"v\": [-24.908226013183594, -24.474342346191406, -24.325653076171875, -24.227937698364258, -23.923633575439453]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsf9y7mku3jnm2qvtxefm1z6",
                        "tokens": [
                            "eps",
                            " would",
                            " draw",
                            " a",
                            " big",
                            " difference",
                            " between",
                            " a",
                            " Jew",
                            " and",
                            " an",
                            " atheist",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\u010a",
                            "\u010a"
                        ],
                        "dataIndex": null,
                        "index": "792",
                        "layer": "2-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 41.37604522705078,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.37604522705078,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-09T23:24:15.552Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.387210845947266,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"Jew\", \"itsch\", \"eled\"], \"v\": [11.237591743469238, 4.5315351486206055, 4.451480388641357, 3.9826173782348633, 3.1300172805786133]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" ERA\", \" Thai\", \"urate\", \" Sask\", \"likely\"], \"v\": [-22.475589752197266, -22.443523406982422, -22.410728454589844, -22.15285873413086, -21.657955169677734]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "2-res-jb",
            "index": "18740",
            "description": "mentions of the word \"Jews\" in various contexts",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 42.26984405517578,
            "frac_nonzero": 6.834665934244792e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "2-res-jb",
                "index": "18740",
                "sourceSetName": "res-jb",
                "creatorId": null,
                "createdAt": "2024-02-09T23:41:46.653Z",
                "maxActApprox": 42.26984405517578,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    18740,
                    1631,
                    792,
                    871,
                    17032,
                    20259,
                    3799,
                    9468,
                    19630,
                    15215,
                    6045,
                    22333,
                    8725,
                    5431,
                    15267,
                    8146,
                    9734,
                    5323,
                    19728,
                    13900,
                    12640,
                    10336,
                    21171,
                    17682,
                    12217
                ],
                "topkCosSimValues": [
                    1,
                    0.8152,
                    0.6858,
                    0.5919,
                    0.575,
                    0.5681,
                    0.5477,
                    0.544,
                    0.5424,
                    0.5231,
                    0.5198,
                    0.5144,
                    0.5103,
                    0.4979,
                    0.4924,
                    0.4911,
                    0.489,
                    0.4872,
                    0.4861,
                    0.4708,
                    0.4521,
                    0.4497,
                    0.4423,
                    0.442,
                    0.4344
                ],
                "neuron_alignment_indices": [
                    288,
                    289,
                    526
                ],
                "neuron_alignment_values": [
                    0.1447783410549164,
                    0.1410296857357025,
                    0.1314101815223694
                ],
                "neuron_alignment_l1": [
                    0.007029579021036625,
                    0.006847566459327936,
                    0.006380500271916389
                ],
                "correlated_neurons_indices": [
                    289,
                    592,
                    527
                ],
                "correlated_neurons_pearson": [
                    0.02041826769709587,
                    0.0200140718370676,
                    0.01767002046108246
                ],
                "correlated_neurons_l1": [
                    0.016985097900033,
                    0.01975519582629204,
                    0.01703321002423763
                ],
                "correlated_features_indices": [],
                "correlated_features_pearson": [],
                "correlated_features_l1": [],
                "neg_str": [
                    "inventoryQuantity",
                    "ctive",
                    "shown",
                    "tnc",
                    "cer",
                    "station",
                    "amina",
                    "aneously",
                    "nant",
                    "tten"
                ],
                "neg_values": [
                    -0.8506453633308411,
                    -0.784114420413971,
                    -0.7358006238937378,
                    -0.7213107347488403,
                    -0.7208688855171204,
                    -0.7117229700088501,
                    -0.6999852657318115,
                    -0.6954247355461121,
                    -0.6882948279380798,
                    -0.6789359450340271
                ],
                "pos_str": [
                    " Jews",
                    "ellery",
                    " Israelis",
                    "geist",
                    " Juda",
                    " Refugees",
                    "Semitism",
                    "esses",
                    " rabb",
                    "ophobia"
                ],
                "pos_values": [
                    0.914513885974884,
                    0.866271436214447,
                    0.8467645049095154,
                    0.8207748532295227,
                    0.7514067888259888,
                    0.7485530376434326,
                    0.7362693548202515,
                    0.7212926149368286,
                    0.7212154865264893,
                    0.7177457809448242
                ],
                "frac_nonzero": 6.834665934244792e-05,
                "freq_hist_data_bar_heights": [
                    53,
                    14,
                    13,
                    8,
                    11,
                    8,
                    5,
                    8,
                    7,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    2,
                    2,
                    6,
                    11,
                    27,
                    15,
                    17,
                    4,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.5338112115859985,
                    1.59041965007782,
                    2.647027969360352,
                    3.703636646270752,
                    4.760244846343994,
                    5.816853046417236,
                    6.873461723327637,
                    7.930070400238037,
                    8.986678123474121,
                    10.04328632354736,
                    11.09989452362061,
                    12.15650463104248,
                    13.21311283111572,
                    14.26972103118896,
                    15.32632923126221,
                    16.38293838500977,
                    17.43954658508301,
                    18.49615478515625,
                    19.55276298522949,
                    20.60937118530273,
                    21.66598129272461,
                    22.72258949279785,
                    23.77919769287109,
                    24.83580589294434,
                    25.89241409301758,
                    26.94902229309082,
                    28.00563049316406,
                    29.06224060058594,
                    30.11884689331055,
                    31.17545700073242,
                    32.23206329345703,
                    33.28867340087891,
                    34.34528350830078,
                    35.40188980102539,
                    36.45849990844727,
                    37.51510620117188,
                    38.57171630859375,
                    39.62832260131836,
                    40.68493270874023,
                    41.74153900146484
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    3,
                    6,
                    7,
                    20,
                    32,
                    54,
                    111,
                    227,
                    412,
                    689,
                    1061,
                    1573,
                    2366,
                    3107,
                    3907,
                    4749,
                    5157,
                    5330,
                    5143,
                    4502,
                    3702,
                    2832,
                    1978,
                    1340,
                    845,
                    469,
                    298,
                    130,
                    97,
                    58,
                    21,
                    13,
                    5,
                    5,
                    2,
                    1,
                    2,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.8285808563232422,
                    -0.7844519019126892,
                    -0.7403228878974915,
                    -0.6961939334869385,
                    -0.6520649194717407,
                    -0.6079359650611877,
                    -0.56380695104599,
                    -0.519677996635437,
                    -0.475549042224884,
                    -0.4314200580120087,
                    -0.3872910737991333,
                    -0.3431620895862579,
                    -0.299033135175705,
                    -0.2549041211605072,
                    -0.210775151848793,
                    -0.1666461378335953,
                    -0.1225171834230423,
                    -0.07838822901248932,
                    -0.03425921499729156,
                    0.009869737550616264,
                    0.05399875342845917,
                    0.09812776744365692,
                    0.1422567218542099,
                    0.1863857358694077,
                    0.2305146902799606,
                    0.2746436297893524,
                    0.3187726438045502,
                    0.3629015982151031,
                    0.4070306122303009,
                    0.4511595666408539,
                    0.4952885508537292,
                    0.539417564868927,
                    0.5835465788841248,
                    0.6276755332946777,
                    0.6718044877052307,
                    0.7159335017204285,
                    0.7600624561309814,
                    0.8041914701461792,
                    0.8483204245567322,
                    0.8924494385719299
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clsy3c8r15l45kad1xwusfuki",
                        "modelId": "gpt2-small",
                        "layer": "2-res-jb",
                        "index": "18740",
                        "description": "mentions of the word \"Jews\" in various contexts",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": null,
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 10.007071,
                        "umap_y": 10.022389,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": -4.0860205,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-02-23T03:26:51.470Z",
                        "updatedAt": "2024-02-23T03:26:51.470Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clsfakuj7js1dm2qvwz2pmbd9",
                        "tokens": [
                            " various",
                            " forms",
                            ":",
                            " dem",
                            "e",
                            "aning",
                            " remarks",
                            " about",
                            " Jews",
                            ",",
                            " abhor",
                            "rence",
                            " of",
                            " the",
                            " presence",
                            " of",
                            " Jews"
                        ],
                        "dataIndex": null,
                        "index": "18740",
                        "layer": "2-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.26984405517578,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.26984405517578,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.34230041503906
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-09T23:41:51.572Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.300997734069824,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jews\", \"geist\", \" Israelis\", \"hovah\"], \"v\": [9.539855003356934, 9.131073951721191, 9.003447532653809, 8.773391723632812, 7.483282089233398]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"cer\", \"ctive\", \"station\", \"inventoryQuantity\", \"nant\"], \"v\": [-18.019264221191406, -17.852100372314453, -17.35431671142578, -16.752769470214844, -16.279748916625977]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsfakuj8js1rm2qv91yg70r6",
                        "tokens": [
                            " Jews",
                            ",",
                            " abhor",
                            "rence",
                            " of",
                            " the",
                            " presence",
                            " of",
                            " Jews",
                            " or",
                            " so",
                            "-",
                            "called",
                            " \u00e2\u0122",
                            "\u013e",
                            "J",
                            "uda"
                        ],
                        "dataIndex": null,
                        "index": "18740",
                        "layer": "2-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.26984405517578,
                        "maxValueTokenIndex": 0,
                        "minValue": 0,
                        "values": [
                            42.26984405517578,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.34230041503906,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-09T23:41:51.572Z",
                        "lossValues": [
                            0,
                            2.300997734069824,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.298160552978516,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {\"t\": [\"ellery\", \" Jews\", \"geist\", \" Israelis\", \"hovah\"], \"v\": [9.539855003356934, 9.131073951721191, 9.003447532653809, 8.773391723632812, 7.483282089233398]}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jews\", \"geist\", \" Israelis\", \"hovah\"], \"v\": [10.838150024414062, 10.71605396270752, 10.358366012573242, 10.1764497756958, 8.60021686553955]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {\"t\": [\"cer\", \"ctive\", \"station\", \"inventoryQuantity\", \"nant\"], \"v\": [-18.019264221191406, -17.852100372314453, -17.35431671142578, -16.752769470214844, -16.279748916625977]}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ctive\", \"cer\", \"station\", \"inventoryQuantity\", \"nant\"], \"v\": [-16.35882568359375, -16.351364135742188, -16.236339569091797, -15.537254333496094, -15.371755599975586]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsfakuj7js1em2qvltgv8npt",
                        "tokens": [
                            " way",
                            "<|endoftext|>",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "F",
                            "ounded",
                            " by",
                            " Jews",
                            " in",
                            " 1989",
                            ",",
                            " JP",
                            "FO",
                            " initially",
                            " aimed",
                            " at"
                        ],
                        "dataIndex": null,
                        "index": "18740",
                        "layer": "2-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 41.6395149230957,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.6395149230957,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-09T23:41:51.572Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.774233818054199,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jews\", \"geist\", \" Israelis\", \"hovah\"], \"v\": [10.230405807495117, 9.661948204040527, 9.583158493041992, 9.352916717529297, 8.296360969543457]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"cer\", \"ctive\", \"station\", \"inventoryQuantity\", \"nant\"], \"v\": [-17.926959991455078, -17.560672760009766, -17.311241149902344, -16.67815399169922, -15.981451034545898]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "11-res-jb",
            "index": "22287",
            "description": "mentions of different religious and ethnic groups, particularly focusing on Jews and Hindus",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 34.87657165527344,
            "frac_nonzero": 0.001758893330891927,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "11-res-jb",
                "index": "22287",
                "sourceSetName": "res-jb",
                "creatorId": null,
                "createdAt": "2024-02-12T08:02:16.606Z",
                "maxActApprox": 34.87657165527344,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    22287,
                    15878,
                    19937,
                    23687,
                    884,
                    8764,
                    21619,
                    2689,
                    21845,
                    18565,
                    6378,
                    3227,
                    1431,
                    23048,
                    14311,
                    20165,
                    23613,
                    19789,
                    12218,
                    14133,
                    5591,
                    4001,
                    1095,
                    5730,
                    24247
                ],
                "topkCosSimValues": [
                    1,
                    0.5487,
                    0.5135,
                    0.4992,
                    0.454,
                    0.4513,
                    0.4337,
                    0.4156,
                    0.4109,
                    0.4034,
                    0.4015,
                    0.3989,
                    0.3878,
                    0.3782,
                    0.3661,
                    0.3645,
                    0.3579,
                    0.3572,
                    0.3528,
                    0.3515,
                    0.3496,
                    0.3425,
                    0.3422,
                    0.342,
                    0.3409
                ],
                "neuron_alignment_indices": [
                    224,
                    330,
                    507
                ],
                "neuron_alignment_values": [
                    0.1389313042163849,
                    0.1111380010843277,
                    0.08943168073892593
                ],
                "neuron_alignment_l1": [
                    0.006254804786294699,
                    0.00500352680683136,
                    0.004026290029287338
                ],
                "correlated_neurons_indices": [
                    224,
                    288,
                    330
                ],
                "correlated_neurons_pearson": [
                    0.051886186003685,
                    0.03913756087422371,
                    0.03884326666593552
                ],
                "correlated_neurons_l1": [
                    0.0557824969291687,
                    0.04795863106846809,
                    0.03939845785498619
                ],
                "correlated_features_indices": [],
                "correlated_features_pearson": [],
                "correlated_features_l1": [],
                "neg_str": [
                    "inventoryQuantity",
                    " increments",
                    "yrinth",
                    " srfAttach",
                    " Sunshine",
                    " Starship",
                    "\u00e6\u00a9\u0141",
                    " CMS",
                    "thumbnails",
                    "inery"
                ],
                "neg_values": [
                    -0.9372034072875977,
                    -0.7131914496421814,
                    -0.6601104140281677,
                    -0.6497434973716736,
                    -0.6340863108634949,
                    -0.6309471130371094,
                    -0.609867513179779,
                    -0.599994957447052,
                    -0.5834150910377502,
                    -0.5811131000518799
                ],
                "pos_str": [
                    "ervative",
                    "ervatives",
                    " living",
                    " residing",
                    " who",
                    "paces",
                    " fleeing",
                    "hip",
                    " everywhere",
                    " migrating"
                ],
                "pos_values": [
                    1.149841070175171,
                    1.147159576416016,
                    1.080159187316895,
                    1.055329561233521,
                    1.027230024337769,
                    1.023062229156494,
                    1.020908355712891,
                    1.016523480415344,
                    0.9540631175041199,
                    0.9399712681770325
                ],
                "frac_nonzero": 0.001758893330891927,
                "freq_hist_data_bar_heights": [
                    930,
                    649,
                    552,
                    467,
                    371,
                    312,
                    284,
                    216,
                    170,
                    152,
                    145,
                    133,
                    102,
                    108,
                    84,
                    83,
                    71,
                    65,
                    59,
                    72,
                    55,
                    57,
                    40,
                    57,
                    44,
                    56,
                    39,
                    38,
                    32,
                    25,
                    13,
                    11,
                    13,
                    9,
                    4,
                    3,
                    4,
                    4,
                    1,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.4360425174236298,
                    1.307954549789429,
                    2.179866790771484,
                    3.05177903175354,
                    3.923691034317017,
                    4.795602798461914,
                    5.667515277862549,
                    6.539427280426025,
                    7.411339282989502,
                    8.283251762390137,
                    9.155163764953613,
                    10.02707576751709,
                    10.89898872375488,
                    11.77090072631836,
                    12.64281272888184,
                    13.51472473144531,
                    14.38663673400879,
                    15.25854873657227,
                    16.13046073913574,
                    17.00237274169922,
                    17.87428665161133,
                    18.7461986541748,
                    19.61811065673828,
                    20.49002265930176,
                    21.36193466186523,
                    22.23384666442871,
                    23.10575866699219,
                    23.97767066955566,
                    24.84958267211914,
                    25.72149467468262,
                    26.59340858459473,
                    27.46531867980957,
                    28.33723258972168,
                    29.20914268493652,
                    30.08105659484863,
                    30.95296859741211,
                    31.82488059997559,
                    32.6967887878418,
                    33.56870269775391,
                    34.44061279296875
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    0,
                    1,
                    4,
                    8,
                    21,
                    78,
                    225,
                    432,
                    998,
                    1755,
                    2872,
                    3960,
                    5141,
                    5574,
                    5778,
                    5305,
                    4577,
                    3975,
                    2941,
                    2143,
                    1596,
                    1092,
                    666,
                    451,
                    270,
                    172,
                    87,
                    44,
                    37,
                    26,
                    9,
                    7,
                    2,
                    1,
                    4,
                    2,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.9111153483390808,
                    -0.8589392304420471,
                    -0.8067631125450134,
                    -0.7545869946479797,
                    -0.702410876750946,
                    -0.6502347588539124,
                    -0.5980587005615234,
                    -0.5458825826644897,
                    -0.4937064647674561,
                    -0.4415303468704224,
                    -0.3893542289733887,
                    -0.337178111076355,
                    -0.2850020527839661,
                    -0.2328259348869324,
                    -0.1806498169898987,
                    -0.128473699092865,
                    -0.0762975811958313,
                    -0.02412146702408791,
                    0.02805465087294579,
                    0.08023077249526978,
                    0.1324068903923035,
                    0.1845830082893372,
                    0.2367591261863708,
                    0.2889352440834045,
                    0.3411113619804382,
                    0.3932874798774719,
                    0.4454635977745056,
                    0.4976397156715393,
                    0.549815833568573,
                    0.6019918918609619,
                    0.6541680097579956,
                    0.7063441276550293,
                    0.758520245552063,
                    0.8106963634490967,
                    0.8628724813461304,
                    0.9150485396385193,
                    0.967224657535553,
                    1.019400715827942,
                    1.071576833724976,
                    1.123752951622009
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clsy913ze90mrkad17lsonpjl",
                        "modelId": "gpt2-small",
                        "layer": "11-res-jb",
                        "index": "22287",
                        "description": "mentions of different religious and ethnic groups, particularly focusing on Jews and Hindus",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": null,
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 5.820955,
                        "umap_y": 4.0919967,
                        "umap_cluster": 405,
                        "umap_log_feature_sparsity": -2.713525,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-02-23T06:06:09.770Z",
                        "updatedAt": "2024-02-23T06:06:09.770Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clsinc8uoqn8wwf4rrw25njdc",
                        "tokens": [
                            " edit",
                            " ]",
                            "\u010a",
                            "\u010a",
                            "Hal",
                            "ak",
                            "ha",
                            " forbids",
                            " Jews",
                            " from",
                            " doing",
                            " creative",
                            " work",
                            " on",
                            " the",
                            " Sh",
                            "abb"
                        ],
                        "dataIndex": null,
                        "index": "22287",
                        "layer": "11-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 34.87657165527344,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.87657165527344,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-12T08:02:23.612Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.5569580793380737,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ervative\", \"ervatives\", \"paces\", \" living\", \" fleeing\"], \"v\": [3.131925582885742, 3.1155052185058594, 2.4416284561157227, 2.3286590576171875, 2.279446601867676]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"inventoryQuantity\", \" increments\", \" Sunshine\", \" suites\", \" Starship\"], \"v\": [-5.26104736328125, -4.892644882202148, -4.412519454956055, -4.379936218261719, -4.362218856811523]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsinc8uoqn8xwf4rne7s33ic",
                        "tokens": [
                            "\u010a",
                            "When",
                            " Pakistan",
                            " was",
                            " created",
                            " in",
                            " 1947",
                            ",",
                            " Hindus",
                            " constituted",
                            " about",
                            " 16",
                            "%",
                            " of",
                            " the",
                            " population",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "22287",
                        "layer": "11-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 34.33447647094727,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.33447647094727,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-12T08:02:23.612Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.1033532619476318,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ervative\", \"ervatives\", \"paces\", \" living\", \" fleeing\"], \"v\": [3.3354759216308594, 3.2541427612304688, 2.6691932678222656, 2.6532297134399414, 2.5238609313964844]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"inventoryQuantity\", \" increments\", \"\\u00e6\\u00a9\\u0141\", \" CMS\", \" Starship\"], \"v\": [-4.4776153564453125, -3.9906158447265625, -3.6841392517089844, -3.676544189453125, -3.6697769165039062]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsinc8uoqn8ywf4r8tne249d",
                        "tokens": [
                            " home",
                            " for",
                            " the",
                            " Jewish",
                            " people",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " Jews",
                            ",",
                            " unless",
                            " they",
                            " were",
                            " anti",
                            "-",
                            "Z",
                            "ion"
                        ],
                        "dataIndex": null,
                        "index": "22287",
                        "layer": "11-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 34.1182746887207,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.1182746887207,
                            2.460098743438721,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-12T08:02:23.612Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.927555084228516,
                            0.004640579223632812,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ervative\", \"ervatives\", \"paces\", \" living\", \" fleeing\"], \"v\": [1.715585708618164, 1.684676170349121, 1.066237449645996, 0.9528317451477051, 0.8877782821655273]}, {\"t\": [\"ervative\", \"ervatives\", \" living\", \"paces\", \"hip\"], \"v\": [0.30400657653808594, 0.28775978088378906, 0.2634105682373047, 0.26338958740234375, 0.2569923400878906]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"inventoryQuantity\", \" increments\", \" Sunshine\", \" suites\", \" Starship\"], \"v\": [-6.072540283203125, -5.5939178466796875, -5.397756576538086, -5.322040557861328, -5.239156723022461]}, {\"t\": [\"inventoryQuantity\", \" increments\", \"yrinth\", \" Sunshine\", \" Starship\"], \"v\": [-0.33019256591796875, -0.2648754119873047, -0.24747848510742188, -0.2463703155517578, -0.24470138549804688]}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "86795",
            "description": "references to jewelry or the word \"Jew.\"",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 31.853,
            "frac_nonzero": 1e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "86795",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:16:55.256Z",
                "maxActApprox": 31.853,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    86795,
                    36896,
                    24636,
                    51431,
                    59581,
                    85294,
                    39819,
                    16216,
                    2177,
                    85962,
                    4266,
                    63225,
                    63187,
                    6018,
                    17834,
                    66819,
                    97950,
                    30879,
                    78785,
                    566,
                    59227,
                    32719,
                    40216,
                    69624,
                    33549
                ],
                "topkCosSimValues": [
                    1,
                    0.6955,
                    0.6017,
                    0.5173,
                    0.4971,
                    0.4221,
                    0.4146,
                    0.3794,
                    0.3653,
                    0.3635,
                    0.3554,
                    0.3418,
                    0.3412,
                    0.3381,
                    0.3377,
                    0.3348,
                    0.3326,
                    0.3303,
                    0.323,
                    0.3228,
                    0.3227,
                    0.3192,
                    0.317,
                    0.3169,
                    0.3141
                ],
                "neuron_alignment_indices": [
                    526,
                    247,
                    0
                ],
                "neuron_alignment_values": [
                    0.137,
                    0.127,
                    0.107
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    289,
                    0,
                    420
                ],
                "correlated_neurons_pearson": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_l1": [
                    0.003,
                    0.004,
                    0.004
                ],
                "correlated_features_indices": [
                    86684,
                    86717,
                    86795
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "\u00e9\u00be",
                    " NCT",
                    " recurring",
                    "ctory",
                    " Afric",
                    " Charter",
                    " Mobility",
                    "\u0143\u0136",
                    " scarce",
                    " simultane"
                ],
                "neg_values": [
                    -0.772,
                    -0.731,
                    -0.651,
                    -0.631,
                    -0.618,
                    -0.614,
                    -0.61,
                    -0.609,
                    -0.609,
                    -0.602
                ],
                "pos_str": [
                    "ellery",
                    "eled",
                    "elled",
                    "els",
                    "eller",
                    "ett",
                    "ell",
                    "el",
                    "eling",
                    "arre"
                ],
                "pos_values": [
                    1.638,
                    1.17,
                    1.143,
                    1.064,
                    1.045,
                    1.039,
                    1.03,
                    0.973,
                    0.955,
                    0.946
                ],
                "frac_nonzero": 1e-05,
                "freq_hist_data_bar_heights": [
                    5,
                    3,
                    3,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.425,
                    1.06,
                    1.695,
                    2.33,
                    2.965,
                    3.6,
                    4.235,
                    4.87,
                    5.505,
                    6.139,
                    6.774,
                    7.409,
                    8.044,
                    8.679,
                    9.314,
                    9.949,
                    10.584,
                    11.219,
                    11.854,
                    12.489,
                    13.123,
                    13.758,
                    14.393,
                    15.028,
                    15.663,
                    16.298,
                    16.933,
                    17.568,
                    18.203,
                    18.838,
                    19.472,
                    20.107,
                    20.742,
                    21.377,
                    22.012,
                    22.647,
                    23.282,
                    23.917,
                    24.552,
                    25.187,
                    25.822,
                    26.456,
                    27.091,
                    27.726,
                    28.361,
                    28.996,
                    29.631,
                    30.266,
                    30.901,
                    31.536
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    0,
                    2,
                    11,
                    19,
                    52,
                    124,
                    253,
                    548,
                    1067,
                    1785,
                    2921,
                    4038,
                    5093,
                    5530,
                    5579,
                    5314,
                    4380,
                    3456,
                    2726,
                    2134,
                    1539,
                    1131,
                    856,
                    568,
                    409,
                    284,
                    175,
                    100,
                    70,
                    36,
                    25,
                    6,
                    10,
                    3,
                    3,
                    1,
                    3,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.747,
                    -0.699,
                    -0.651,
                    -0.603,
                    -0.555,
                    -0.506,
                    -0.458,
                    -0.41,
                    -0.362,
                    -0.314,
                    -0.265,
                    -0.217,
                    -0.169,
                    -0.121,
                    -0.073,
                    -0.024,
                    0.024,
                    0.072,
                    0.12,
                    0.168,
                    0.217,
                    0.265,
                    0.313,
                    0.361,
                    0.409,
                    0.458,
                    0.506,
                    0.554,
                    0.602,
                    0.65,
                    0.698,
                    0.747,
                    0.795,
                    0.843,
                    0.891,
                    0.94,
                    0.988,
                    1.036,
                    1.084,
                    1.132,
                    1.18,
                    1.229,
                    1.277,
                    1.325,
                    1.373,
                    1.421,
                    1.47,
                    1.518,
                    1.566,
                    1.614
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clzddj9nk2oo7v3wqou4qn4po",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "86795",
                        "description": "references to jewelry or the word \"Jew.\"",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T00:07:02.048Z",
                        "updatedAt": "2024-08-03T00:07:02.048Z"
                    },
                    {
                        "id": "clzed229j4dfpv3wqh2yeugl9",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "86795",
                        "description": " references to Jewish identity or culture",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T16:41:25.495Z",
                        "updatedAt": "2024-08-03T16:41:25.495Z"
                    },
                    {
                        "id": "clzedzo484fsrv3wqafp97yid",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "86795",
                        "description": "references to Jewish identity or culture",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T17:07:33.375Z",
                        "updatedAt": "2024-08-03T17:07:33.375Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygirj9h53ry10exg416mkes",
                        "tokens": [
                            "above",
                            " energy",
                            " strategy",
                            " to",
                            " build",
                            " an",
                            " economy",
                            " fueled",
                            " by",
                            " homegrown",
                            " and",
                            " clean",
                            " energy",
                            " sources",
                            " produced",
                            " by",
                            " American",
                            " workers",
                            ".",
                            " With",
                            " the",
                            " help",
                            " of",
                            " the",
                            " Administration",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " unprecedented",
                            " investments",
                            " in",
                            " clean",
                            " energy",
                            ",",
                            " we",
                            " have",
                            " already",
                            " met",
                            " the",
                            " bold",
                            " goal",
                            " the",
                            " President",
                            " laid",
                            " out",
                            " in",
                            " 2008",
                            " to",
                            " double",
                            " renewable",
                            " energy",
                            " generation",
                            " in",
                            " this",
                            " country",
                            ".",
                            " Impro",
                            "ving",
                            " our",
                            " electrical",
                            " transmission",
                            " grid",
                            " will",
                            " make",
                            " electricity",
                            " more",
                            " reliable",
                            ",",
                            " save",
                            " consumers",
                            " money",
                            ",",
                            " improve",
                            " U",
                            ".",
                            "S",
                            ".",
                            " competitiveness",
                            ",",
                            " and",
                            " move",
                            " us",
                            " a",
                            " step",
                            " closer",
                            " to",
                            " achieving",
                            " the",
                            " President",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " goal",
                            " of",
                            " doubling",
                            " domestic",
                            " renewable",
                            " electricity",
                            " again",
                            " by",
                            " 2020",
                            ".",
                            "\n",
                            "\n",
                            "N",
                            "ancy",
                            " Sut",
                            "ley",
                            " is",
                            " Chair",
                            " of",
                            " the",
                            " Council",
                            " on",
                            " Environmental",
                            " Quality",
                            ".",
                            " Sally",
                            " Jew",
                            "ell",
                            " is",
                            " Secretary",
                            " of",
                            " the",
                            " U",
                            ".",
                            "S"
                        ],
                        "dataIndex": null,
                        "index": "86795",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 31.853,
                        "maxValueTokenIndex": 118,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            31.853,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:17:01.967Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 31.853,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygirj9j53si10exu5nzq11n",
                        "tokens": [
                            "above",
                            " energy",
                            " strategy",
                            " to",
                            " build",
                            " an",
                            " economy",
                            " fueled",
                            " by",
                            " homegrown",
                            " and",
                            " clean",
                            " energy",
                            " sources",
                            " produced",
                            " by",
                            " American",
                            " workers",
                            ".",
                            " With",
                            " the",
                            " help",
                            " of",
                            " the",
                            " Administration",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " unprecedented",
                            " investments",
                            " in",
                            " clean",
                            " energy",
                            ",",
                            " we",
                            " have",
                            " already",
                            " met",
                            " the",
                            " bold",
                            " goal",
                            " the",
                            " President",
                            " laid",
                            " out",
                            " in",
                            " 2008",
                            " to",
                            " double",
                            " renewable",
                            " energy",
                            " generation",
                            " in",
                            " this",
                            " country",
                            ".",
                            " Impro",
                            "ving",
                            " our",
                            " electrical",
                            " transmission",
                            " grid",
                            " will",
                            " make",
                            " electricity",
                            " more",
                            " reliable",
                            ",",
                            " save",
                            " consumers",
                            " money",
                            ",",
                            " improve",
                            " U",
                            ".",
                            "S",
                            ".",
                            " competitiveness",
                            ",",
                            " and",
                            " move",
                            " us",
                            " a",
                            " step",
                            " closer",
                            " to",
                            " achieving",
                            " the",
                            " President",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " goal",
                            " of",
                            " doubling",
                            " domestic",
                            " renewable",
                            " electricity",
                            " again",
                            " by",
                            " 2020",
                            ".",
                            "\n",
                            "\n",
                            "N",
                            "ancy",
                            " Sut",
                            "ley",
                            " is",
                            " Chair",
                            " of",
                            " the",
                            " Council",
                            " on",
                            " Environmental",
                            " Quality",
                            ".",
                            " Sally",
                            " Jew",
                            "ell",
                            " is",
                            " Secretary",
                            " of",
                            " the",
                            " U",
                            ".",
                            "S"
                        ],
                        "dataIndex": null,
                        "index": "86795",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 31.853,
                        "maxValueTokenIndex": 118,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            31.853,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:17:01.967Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 25.482,
                        "binMax": 31.853,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygirj9i53rz10exgniz6trq",
                        "tokens": [
                            " when",
                            " the",
                            " Brazilian",
                            " left",
                            " with",
                            " his",
                            " wife",
                            " and",
                            " two",
                            " children",
                            ".",
                            "\n",
                            "\n",
                            "They",
                            " r",
                            "ans",
                            "acked",
                            " the",
                            " Victorian",
                            " property",
                            " in",
                            " Liverpool",
                            " for",
                            " jew",
                            "ellery",
                            ",",
                            " watches",
                            " and",
                            " clothes",
                            " amount",
                            "ing",
                            " to",
                            " \u00c2\u00a3",
                            "70",
                            ",",
                            "000",
                            " before",
                            " leaving",
                            " on",
                            " foot",
                            ".",
                            "\n",
                            "\n",
                            "Rober",
                            "to",
                            " Fir",
                            "min",
                            "o",
                            " and",
                            " his",
                            " family",
                            " were",
                            " moved",
                            " to",
                            " a",
                            " hotel",
                            " over",
                            " Christmas",
                            " by",
                            " Liverpool",
                            " officials",
                            " after",
                            " his",
                            " home",
                            " was",
                            " raided",
                            " by",
                            " a",
                            " hood",
                            "ed",
                            " gang",
                            ".",
                            " Jew",
                            "ellery",
                            ",",
                            " watches",
                            " and",
                            " clothes",
                            " were",
                            " taken",
                            "\n",
                            "\n",
                            "F",
                            "ir",
                            "min",
                            "o",
                            " and",
                            " his",
                            " wife",
                            " Lar",
                            "issa",
                            " Pere",
                            "ira",
                            " were",
                            " said",
                            " to",
                            " have",
                            " been",
                            " left",
                            " shaken",
                            " by",
                            " the",
                            " burglary",
                            "\n",
                            "\n",
                            "It",
                            " is",
                            " believed",
                            " the",
                            " thieves",
                            " previously",
                            " targeted",
                            " the",
                            " property",
                            " but",
                            " were",
                            " disturbed",
                            " on",
                            " that",
                            " occasion",
                            ".",
                            "\n",
                            "\n",
                            "Liverpool",
                            " officials",
                            " moved",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "86795",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.704,
                        "maxValueTokenIndex": 72,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.118,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.704,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:17:01.967Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 31.853,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "2-res_scl-ajt",
            "index": "32160",
            "description": "mentions of the term \"Jew\" in various contexts",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 29.887,
            "frac_nonzero": 0.02836,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "2-res_scl-ajt",
                "index": "32160",
                "sourceSetName": "res_scl-ajt",
                "creatorId": null,
                "createdAt": "2024-04-24T20:52:08.144Z",
                "maxActApprox": 29.887,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [],
                "topkCosSimValues": [],
                "neuron_alignment_indices": [
                    526,
                    0,
                    285
                ],
                "neuron_alignment_values": [
                    0.095,
                    0.061,
                    0.055
                ],
                "neuron_alignment_l1": [
                    0.009,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    138,
                    447,
                    64
                ],
                "correlated_neurons_pearson": [
                    0.337,
                    0.293,
                    0.211
                ],
                "correlated_neurons_l1": [
                    0.344,
                    0.248,
                    -0.091
                ],
                "correlated_features_indices": [
                    32108,
                    32060,
                    32068
                ],
                "correlated_features_pearson": [
                    0.245,
                    0.244,
                    0.143
                ],
                "correlated_features_l1": [
                    0.258,
                    0.256,
                    0.172
                ],
                "neg_str": [
                    " \u00e8\u00a3\u0131",
                    " Thai",
                    " conflic",
                    "mberg",
                    " volunt",
                    "channelAvailability",
                    " Georgian",
                    " NDP",
                    " LAT",
                    "GAME"
                ],
                "neg_values": [
                    -0.339,
                    -0.337,
                    -0.333,
                    -0.325,
                    -0.317,
                    -0.317,
                    -0.315,
                    -0.314,
                    -0.312,
                    -0.312
                ],
                "pos_str": [
                    "ellery",
                    " Jew",
                    "eled",
                    "els",
                    "bow",
                    "ard",
                    "hart",
                    "Jew",
                    "ry",
                    "eller"
                ],
                "pos_values": [
                    0.716,
                    0.562,
                    0.55,
                    0.504,
                    0.496,
                    0.47,
                    0.468,
                    0.468,
                    0.461,
                    0.454
                ],
                "frac_nonzero": 0.02836,
                "freq_hist_data_bar_heights": [
                    17799,
                    19953,
                    4342,
                    1782,
                    499,
                    124,
                    54,
                    20,
                    8,
                    2,
                    0,
                    3,
                    1,
                    1,
                    0,
                    0,
                    0,
                    2,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    2,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    2,
                    0,
                    4,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.299,
                    0.897,
                    1.494,
                    2.092,
                    2.69,
                    3.288,
                    3.885,
                    4.483,
                    5.081,
                    5.679,
                    6.276,
                    6.874,
                    7.472,
                    8.069,
                    8.667,
                    9.265,
                    9.863,
                    10.46,
                    11.058,
                    11.656,
                    12.254,
                    12.851,
                    13.449,
                    14.047,
                    14.645,
                    15.242,
                    15.84,
                    16.438,
                    17.035,
                    17.633,
                    18.231,
                    18.829,
                    19.426,
                    20.024,
                    20.622,
                    21.22,
                    21.817,
                    22.415,
                    23.013,
                    23.611,
                    24.208,
                    24.806,
                    25.404,
                    26.002,
                    26.599,
                    27.197,
                    27.795,
                    28.392,
                    28.99,
                    29.588
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    13,
                    22,
                    45,
                    95,
                    169,
                    296,
                    520,
                    910,
                    1361,
                    2001,
                    2785,
                    3489,
                    4242,
                    4875,
                    5004,
                    4882,
                    4281,
                    3764,
                    3014,
                    2351,
                    1792,
                    1300,
                    962,
                    685,
                    462,
                    315,
                    210,
                    147,
                    98,
                    51,
                    42,
                    26,
                    15,
                    8,
                    7,
                    1,
                    5,
                    3,
                    2,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.329,
                    -0.308,
                    -0.287,
                    -0.266,
                    -0.244,
                    -0.223,
                    -0.202,
                    -0.181,
                    -0.16,
                    -0.139,
                    -0.118,
                    -0.097,
                    -0.076,
                    -0.054,
                    -0.033,
                    -0.012,
                    0.009,
                    0.03,
                    0.051,
                    0.072,
                    0.093,
                    0.115,
                    0.136,
                    0.157,
                    0.178,
                    0.199,
                    0.22,
                    0.241,
                    0.262,
                    0.284,
                    0.305,
                    0.326,
                    0.347,
                    0.368,
                    0.389,
                    0.41,
                    0.431,
                    0.452,
                    0.474,
                    0.495,
                    0.516,
                    0.537,
                    0.558,
                    0.579,
                    0.6,
                    0.621,
                    0.643,
                    0.664,
                    0.685,
                    0.706
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clvgi5nniebh2s89rt35wxds5",
                        "modelId": "gpt2-small",
                        "layer": "2-res_scl-ajt",
                        "index": "32160",
                        "description": "mentions of the term \"Jew\" in various contexts",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": null,
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 11.5964,
                        "umap_y": 0.7385,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-04-26T10:00:54.271Z",
                        "updatedAt": "2024-04-26T18:39:20.658Z"
                    },
                    {
                        "id": "xfrxagjmoq48nbn9obmtf9ima",
                        "modelId": "gpt2-small",
                        "layer": "2-res_scl-ajt",
                        "index": "32160",
                        "description": "references to Jewish identity and related terms",
                        "authorId": "cljgamm90000076zdchicy6zj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-26T02:09:25.614Z",
                        "updatedAt": "2024-08-26T02:09:25.614Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clveajjlvprl0k8mx7nw7l17t",
                        "tokens": [
                            "The",
                            " events",
                            " in",
                            " New",
                            " Orleans",
                            " received",
                            " national",
                            " coverage",
                            " and",
                            " had",
                            " ramifications",
                            " beyond",
                            " the",
                            " state",
                            ".",
                            " L",
                            "illian",
                            " Jew",
                            "ett",
                            ",",
                            " a",
                            " young",
                            " white",
                            " member",
                            " of",
                            " the",
                            " Anti",
                            "-",
                            "Lyn",
                            "ching",
                            " League",
                            ",",
                            " was",
                            " fundraising",
                            " at",
                            " a",
                            " Boston",
                            ",",
                            " Massachusetts",
                            " meeting",
                            " hours",
                            " after",
                            " Charles",
                            "'",
                            " death",
                            " to",
                            " raise",
                            " money",
                            " for",
                            " the",
                            " injured",
                            " in",
                            " New",
                            " Orleans",
                            ".",
                            " The",
                            " Louisiana",
                            " Times",
                            " Pic",
                            "ay",
                            "une",
                            " reported",
                            " \"",
                            "Ins",
                            "ane",
                            " Rav",
                            "ings",
                            " at",
                            " a",
                            " Boston",
                            " Meeting",
                            "\".",
                            " A",
                            " group",
                            " of",
                            " wealthy",
                            " young",
                            " white",
                            " men",
                            " from",
                            " New",
                            " Orleans",
                            " had",
                            " formed",
                            " the",
                            " Green",
                            " Turtles",
                            " the",
                            " previous",
                            " year",
                            ".",
                            " This",
                            " group",
                            " required",
                            " an",
                            " \"",
                            "o",
                            "ath",
                            " of",
                            " allegiance",
                            " to",
                            " white",
                            " supremacy",
                            " and",
                            " the",
                            " Democratic",
                            " Party",
                            ".\"",
                            " Because",
                            " of",
                            " this",
                            " group",
                            "'s",
                            " subsequent",
                            " threats",
                            " on",
                            " Jew",
                            "ett",
                            "'s",
                            " life",
                            ",",
                            " she",
                            " would",
                            " not",
                            " travel",
                            " further",
                            " South"
                        ],
                        "dataIndex": null,
                        "index": "32160",
                        "layer": "2-res_scl-ajt",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 29.887,
                        "maxValueTokenIndex": 17,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            29.887,
                            0,
                            0,
                            0,
                            0,
                            1.966,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.008,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.134,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.847,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.81,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            27.968,
                            0,
                            0,
                            0.412,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-04-24T20:52:11.976Z",
                        "lossValues": [
                            0.002,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -0.209,
                            0,
                            0,
                            0,
                            0,
                            -0.008,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -0.008,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -0.001,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.001,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.002,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{\"t\": [\"ellery\", \" Jew\", \"eled\", \"els\", \"bow\"], \"v\": [0.033, 0.026, 0.025, 0.023, 0.023]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"bow\", \"els\"], \"v\": [1.241, 0.837, 0.745, 0.601, 0.591]}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"els\", \"bow\"], \"v\": [0.095, 0.073, 0.073, 0.067, 0.066]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"els\", \"bow\"], \"v\": [0.001, 0.0, 0.0, 0.0, 0.0]}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"els\", \"bow\"], \"v\": [0.058, 0.042, 0.04, 0.035, 0.034]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"els\", \"bow\"], \"v\": [0.091, 0.071, 0.07, 0.065, 0.064]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"els\", \"bow\"], \"v\": [0.107, 0.084, 0.083, 0.077, 0.076]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"bow\", \"els\"], \"v\": [0.77, 0.465, 0.407, 0.32, 0.312]}, {}, {}, {\"t\": [\"ellery\", \"eled\", \" Jew\", \"els\", \"bow\"], \"v\": [0.015, 0.011, 0.011, 0.01, 0.009]}, {}, {}, {}, {}, {}, {}], \"neg\": [{\"t\": [\" \\u00e8\\u00a3\\u0131\", \" Thai\", \" conflic\", \"mberg\", \" volunt\"], \"v\": [-0.016, -0.016, -0.015, -0.015, -0.015]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"mberg\", \" \\u00e8\\u00a3\\u0131\", \" Thai\", \" NDP\", \" conflic\"], \"v\": [-1.829, -1.821, -1.818, -1.761, -1.749]}, {}, {}, {}, {}, {\"t\": [\" Thai\", \" \\u00e8\\u00a3\\u0131\", \" conflic\", \" Georgian\", \" volunt\"], \"v\": [-0.048, -0.047, -0.045, -0.045, -0.045]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Thai\", \" \\u00e8\\u00a3\\u0131\", \" conflic\", \" NDP\", \"channelAvailability\"], \"v\": [-0.0, -0.0, -0.0, -0.0, -0.0]}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Thai\", \" \\u00e8\\u00a3\\u0131\", \"mberg\", \" conflic\", \"ctory\"], \"v\": [-0.056, -0.056, -0.055, -0.055, -0.054]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Thai\", \" \\u00e8\\u00a3\\u0131\", \" conflic\", \"mberg\", \" Georgian\"], \"v\": [-0.036, -0.035, -0.034, -0.034, -0.034]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Thai\", \" \\u00e8\\u00a3\\u0131\", \" conflic\", \"mberg\", \" volunt\"], \"v\": [-0.04, -0.04, -0.038, -0.038, -0.038]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"mberg\", \" \\u00e8\\u00a3\\u0131\", \" Thai\", \"channelAvailability\", \"ctory\"], \"v\": [-1.434, -1.424, -1.419, -1.383, -1.383]}, {}, {}, {\"t\": [\" Thai\", \" \\u00e8\\u00a3\\u0131\", \" conflic\", \"mberg\", \" Georgian\"], \"v\": [-0.012, -0.012, -0.012, -0.012, -0.012]}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clveajjlvprl1k8mxps16ub3d",
                        "tokens": [
                            " to",
                            " practise",
                            " medicine",
                            ",",
                            " except",
                            " among",
                            " Jews",
                            ";",
                            " he",
                            " was",
                            " forbidden",
                            " the",
                            " handic",
                            "raft",
                            "s",
                            ".",
                            " Even",
                            " the",
                            " seats",
                            " of",
                            " learning",
                            " and",
                            " the",
                            " schools",
                            " of",
                            " science",
                            " had",
                            " to",
                            " be",
                            " closed",
                            " against",
                            " this",
                            " tremendous",
                            " antagonist",
                            ".",
                            " Still",
                            ",",
                            " almost",
                            " bere",
                            "ft",
                            " of",
                            " employ",
                            "ments",
                            ",",
                            " he",
                            " found",
                            " ways",
                            " to",
                            " make",
                            " money",
                            ",",
                            " even",
                            " ways",
                            " to",
                            " get",
                            " rich",
                            ".",
                            " Also",
                            " ways",
                            " to",
                            " invest",
                            " his",
                            " t",
                            "akings",
                            " well",
                            ",",
                            " for",
                            " us",
                            "ury",
                            " was",
                            " not",
                            " denied",
                            " him",
                            ".",
                            " In",
                            " the",
                            " hard",
                            " conditions",
                            " suggested",
                            ",",
                            " the",
                            " Jew",
                            " without",
                            " brains",
                            " could",
                            " not",
                            " survive",
                            ",",
                            " and",
                            " the",
                            " Jew",
                            " with",
                            " brains",
                            " had",
                            " to",
                            " keep",
                            " them",
                            " in",
                            " good",
                            " training",
                            " and",
                            " well",
                            " sharp",
                            "ened",
                            " up",
                            ",",
                            " or",
                            " starve",
                            ".",
                            " Ages",
                            " of",
                            " restriction",
                            " to",
                            " the",
                            " one",
                            " tool",
                            " which",
                            " the",
                            " law",
                            " was",
                            " not",
                            " able",
                            " to",
                            " take",
                            " from",
                            " him",
                            "--"
                        ],
                        "dataIndex": null,
                        "index": "32160",
                        "layer": "2-res_scl-ajt",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 29.005,
                        "maxValueTokenIndex": 81,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.748,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.306,
                            0,
                            0,
                            0,
                            1.145,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            29.005,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            26.316,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-04-24T20:52:11.976Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -0.007,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.001,
                            0,
                            0,
                            0,
                            -0.002,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -0.083,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{\"t\": [\"ellery\", \" Jew\", \"eled\", \"els\", \"bow\"], \"v\": [0.033, 0.026, 0.025, 0.023, 0.023]}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"els\", \"bow\"], \"v\": [0.167, 0.128, 0.127, 0.116, 0.115]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"els\", \"bow\"], \"v\": [0.012, 0.009, 0.009, 0.008, 0.008]}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"els\", \"bow\"], \"v\": [0.053, 0.041, 0.04, 0.037, 0.036]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"bow\", \"els\"], \"v\": [1.123, 0.872, 0.849, 0.788, 0.782]}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"els\", \"bow\"], \"v\": [0.925, 0.721, 0.707, 0.654, 0.649]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{\"t\": [\" \\u00e8\\u00a3\\u0131\", \" Thai\", \" conflic\", \"mberg\", \" volunt\"], \"v\": [-0.016, -0.016, -0.015, -0.015, -0.015]}, {}, {}, {}, {}, {}, {}, {\"t\": [\" \\u00e8\\u00a3\\u0131\", \" Thai\", \" conflic\", \"mberg\", \" volunt\"], \"v\": [-0.087, -0.087, -0.084, -0.083, -0.082]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Thai\", \" \\u00e8\\u00a3\\u0131\", \" conflic\", \"mberg\", \" volunt\"], \"v\": [-0.005, -0.005, -0.005, -0.005, -0.005]}, {}, {}, {}, {\"t\": [\" Thai\", \" \\u00e8\\u00a3\\u0131\", \" conflic\", \" volunt\", \"mberg\"], \"v\": [-0.028, -0.028, -0.027, -0.027, -0.026]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Thai\", \" \\u00e8\\u00a3\\u0131\", \"mberg\", \" volunt\", \" conflic\"], \"v\": [-0.528, -0.527, -0.51, -0.503, -0.499]}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" \\u00e8\\u00a3\\u0131\", \" Thai\", \"mberg\", \" volunt\", \" conflic\"], \"v\": [-0.406, -0.406, -0.388, -0.384, -0.38]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clveajjlvprl2k8mxzaecn50h",
                        "tokens": [
                            " touch",
                            " of",
                            " gl",
                            "itz",
                            ".",
                            " It",
                            " even",
                            " comes",
                            " in",
                            " a",
                            " little",
                            " gift",
                            " box",
                            "!",
                            "\n",
                            "\n",
                            "Now",
                            ",",
                            " this",
                            " is",
                            " one",
                            " blue",
                            " necklace",
                            " that",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " going",
                            " to",
                            " want",
                            " to",
                            " wear",
                            " all",
                            " the",
                            " time",
                            "!",
                            " Make",
                            " sure",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " always",
                            " got",
                            " luck",
                            " on",
                            " your",
                            " side",
                            " with",
                            " this",
                            " stunning",
                            " blue",
                            " four",
                            " leaf",
                            " cl",
                            "over",
                            " necklace",
                            " from",
                            " Dahl",
                            "ia",
                            " Jew",
                            "els",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " r",
                            "hod",
                            "ium",
                            " pl",
                            "ated",
                            " p",
                            "endant",
                            " is",
                            " a",
                            " four",
                            " leaf",
                            " cl",
                            "over",
                            " design",
                            ",",
                            " featuring",
                            " two",
                            " leaves",
                            " with",
                            " large",
                            " blue",
                            " Sw",
                            "arov",
                            "ski",
                            " Elements",
                            " crystals",
                            ",",
                            " one",
                            " leaf",
                            " that",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " enc",
                            "r",
                            "usted",
                            " with",
                            " little",
                            " blue",
                            " and",
                            " clear",
                            " Czech",
                            " crystals",
                            ",",
                            " and",
                            " the",
                            " fourth",
                            " leaf",
                            " that",
                            " is",
                            " just",
                            " the",
                            " r",
                            "hod",
                            "ium",
                            " pl",
                            "ated",
                            " metal",
                            ",",
                            " as"
                        ],
                        "dataIndex": null,
                        "index": "32160",
                        "layer": "2-res_scl-ajt",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.987,
                        "maxValueTokenIndex": 61,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.123,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.375,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.826,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.764,
                            0,
                            0,
                            0,
                            28.987,
                            1.112,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-04-24T20:52:11.976Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -0.001,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.02,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.012,
                            0,
                            0,
                            0,
                            0.206,
                            -0.002,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"els\", \"bow\"], \"v\": [0.005, 0.004, 0.004, 0.003, 0.003]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"els\", \"bow\"], \"v\": [0.106, 0.08, 0.078, 0.072, 0.069]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"els\", \"bow\"], \"v\": [0.035, 0.028, 0.027, 0.025, 0.024]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"els\", \"bow\"], \"v\": [0.107, 0.08, 0.079, 0.071, 0.069]}, {}, {}, {}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"bow\", \"els\"], \"v\": [0.372, 0.046, -0.05, -0.144, -0.206]}, {\"t\": [\"ellery\", \" Jew\", \"eled\", \"els\", \"bow\"], \"v\": [0.043, 0.033, 0.033, 0.03, 0.029]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Thai\", \" \\u00e8\\u00a3\\u0131\", \" conflic\", \"mberg\", \" volunt\"], \"v\": [-0.002, -0.002, -0.002, -0.002, -0.002]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Thai\", \" \\u00e8\\u00a3\\u0131\", \" conflic\", \"mberg\", \" Georgian\"], \"v\": [-0.069, -0.068, -0.066, -0.065, -0.065]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Thai\", \" \\u00e8\\u00a3\\u0131\", \" conflic\", \"mberg\", \" NDP\"], \"v\": [-0.015, -0.015, -0.014, -0.014, -0.014]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Thai\", \" \\u00e8\\u00a3\\u0131\", \" conflic\", \"mberg\", \" LAT\"], \"v\": [-0.077, -0.076, -0.074, -0.073, -0.072]}, {}, {}, {}, {\"t\": [\" Thai\", \" \\u00e8\\u00a3\\u0131\", \"mberg\", \" NDP\", \" Georgian\"], \"v\": [-2.409, -2.405, -2.393, -2.37, -2.367]}, {\"t\": [\" Thai\", \" \\u00e8\\u00a3\\u0131\", \" conflic\", \"mberg\", \" Georgian\"], \"v\": [-0.024, -0.024, -0.023, -0.023, -0.022]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "13903",
            "description": "references to different religious or ethnic groups, particularly Muslims, Jews, Hindus, Americans, and minorities",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 27.377,
            "frac_nonzero": 0.0005099999999999999,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "13903",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:23:22.689Z",
                "maxActApprox": 27.377,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    13903,
                    43543,
                    48639,
                    14487,
                    47036,
                    2138,
                    31647,
                    22445,
                    37939,
                    28131,
                    39822,
                    45077,
                    30928,
                    17438,
                    24599,
                    30103,
                    12504,
                    26570,
                    30291,
                    20678,
                    43593,
                    12383,
                    25206,
                    44866,
                    25592
                ],
                "topkCosSimValues": [
                    1,
                    0.717,
                    0.7095,
                    0.6799,
                    0.5906,
                    0.571,
                    0.5449,
                    0.5299,
                    0.5142,
                    0.5138,
                    0.5131,
                    0.51,
                    0.508,
                    0.4958,
                    0.4886,
                    0.4883,
                    0.4871,
                    0.4842,
                    0.4817,
                    0.4788,
                    0.4764,
                    0.4762,
                    0.4737,
                    0.4701,
                    0.4615
                ],
                "neuron_alignment_indices": [
                    447,
                    224,
                    481
                ],
                "neuron_alignment_values": [
                    0.177,
                    0.138,
                    0.118
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    224,
                    57,
                    537
                ],
                "correlated_neurons_pearson": [
                    0.036,
                    0.031,
                    0.028
                ],
                "correlated_neurons_l1": [
                    0.037,
                    0.028,
                    0.03
                ],
                "correlated_features_indices": [
                    13994,
                    13989,
                    13906
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.002,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "inventoryQuantity",
                    " increments",
                    "Owner",
                    "INAL",
                    "Products",
                    "Accessory",
                    "Delivery",
                    "TON",
                    "Attempts",
                    "Hur"
                ],
                "neg_values": [
                    -0.766,
                    -0.683,
                    -0.67,
                    -0.619,
                    -0.611,
                    -0.596,
                    -0.595,
                    -0.576,
                    -0.564,
                    -0.564
                ],
                "pos_str": [
                    "paces",
                    "aurus",
                    "ervative",
                    "ervatives",
                    "hip",
                    "pace",
                    " everywhere",
                    "']",
                    "folk",
                    "'"
                ],
                "pos_values": [
                    1.148,
                    1.122,
                    1.103,
                    1.08,
                    1.037,
                    1.006,
                    0.922,
                    0.918,
                    0.895,
                    0.887
                ],
                "frac_nonzero": 0.0005099999999999999,
                "freq_hist_data_bar_heights": [
                    190,
                    153,
                    123,
                    104,
                    87,
                    66,
                    73,
                    52,
                    41,
                    36,
                    40,
                    43,
                    40,
                    27,
                    31,
                    25,
                    18,
                    23,
                    28,
                    28,
                    14,
                    20,
                    21,
                    22,
                    16,
                    18,
                    13,
                    23,
                    17,
                    13,
                    20,
                    12,
                    17,
                    16,
                    15,
                    14,
                    13,
                    14,
                    8,
                    14,
                    6,
                    18,
                    11,
                    5,
                    10,
                    12,
                    3,
                    2,
                    2,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.275,
                    0.823,
                    1.37,
                    1.918,
                    2.465,
                    3.013,
                    3.56,
                    4.108,
                    4.655,
                    5.203,
                    5.75,
                    6.298,
                    6.845,
                    7.393,
                    7.94,
                    8.488,
                    9.035,
                    9.583,
                    10.13,
                    10.678,
                    11.225,
                    11.773,
                    12.321,
                    12.868,
                    13.416,
                    13.963,
                    14.511,
                    15.058,
                    15.606,
                    16.153,
                    16.701,
                    17.248,
                    17.796,
                    18.343,
                    18.891,
                    19.438,
                    19.986,
                    20.533,
                    21.081,
                    21.628,
                    22.176,
                    22.723,
                    23.271,
                    23.818,
                    24.366,
                    24.913,
                    25.461,
                    26.008,
                    26.556,
                    27.104
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    1,
                    4,
                    11,
                    30,
                    59,
                    150,
                    283,
                    498,
                    816,
                    1307,
                    1790,
                    2411,
                    3082,
                    3602,
                    4110,
                    4241,
                    4242,
                    4193,
                    3683,
                    3153,
                    2736,
                    2155,
                    1771,
                    1430,
                    1158,
                    924,
                    700,
                    504,
                    421,
                    265,
                    188,
                    122,
                    68,
                    44,
                    38,
                    22,
                    13,
                    8,
                    5,
                    5,
                    4,
                    1,
                    0,
                    1,
                    1,
                    2,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.747,
                    -0.709,
                    -0.671,
                    -0.632,
                    -0.594,
                    -0.556,
                    -0.517,
                    -0.479,
                    -0.441,
                    -0.403,
                    -0.364,
                    -0.326,
                    -0.288,
                    -0.249,
                    -0.211,
                    -0.173,
                    -0.134,
                    -0.096,
                    -0.058,
                    -0.02,
                    0.019,
                    0.057,
                    0.095,
                    0.134,
                    0.172,
                    0.21,
                    0.248,
                    0.287,
                    0.325,
                    0.363,
                    0.402,
                    0.44,
                    0.478,
                    0.516,
                    0.555,
                    0.593,
                    0.631,
                    0.67,
                    0.708,
                    0.746,
                    0.784,
                    0.823,
                    0.861,
                    0.899,
                    0.938,
                    0.976,
                    1.014,
                    1.052,
                    1.091,
                    1.129
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyv2mhye0vvvnba6hs0iul14",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs49152-jb",
                        "index": "13903",
                        "description": "references to different religious or ethnic groups, particularly Muslims, Jews, Hindus, Americans, and minorities",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-21T04:41:45.830Z",
                        "updatedAt": "2024-07-21T04:41:45.830Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk50grzoh0di666mxqospw7",
                        "tokens": [
                            " certain",
                            " minority",
                            " groups",
                            ".",
                            " Rec",
                            "alling",
                            " Lenin",
                            " here",
                            " may",
                            " not",
                            " actually",
                            " be",
                            " that",
                            " far",
                            "-",
                            "fetched",
                            ".",
                            " It",
                            " would",
                            " actually",
                            " push",
                            " a",
                            " society",
                            " that",
                            " is",
                            " more",
                            " inclusive",
                            " for",
                            " everyone",
                            ",",
                            " Muslims",
                            " included",
                            ".",
                            "\n",
                            "\n",
                            "Phot",
                            "ograph",
                            " courtesy",
                            " of",
                            " H",
                            "oss",
                            "am",
                            " el",
                            "-",
                            "Ham",
                            "al",
                            "aw",
                            "y",
                            ".",
                            " Published",
                            " under",
                            " a",
                            " Creative",
                            " Commons",
                            " License",
                            ".",
                            "<|endoftext|>",
                            "How",
                            " the",
                            " C",
                            "of",
                            "ound",
                            ".",
                            "it",
                            " Priority",
                            " Pass",
                            "\u00e2\u0126\u00a2",
                            " will",
                            " work",
                            " in",
                            " the",
                            " next",
                            " four",
                            " crowds",
                            "ales",
                            "\n",
                            "\n",
                            "Jan",
                            " Is",
                            "ak",
                            "ovic",
                            " Bl",
                            "ocked",
                            " Un",
                            "block",
                            " Follow",
                            " Following",
                            " Aug",
                            " 23",
                            ",",
                            " 2017",
                            "\n",
                            "\n",
                            "The",
                            " crowds",
                            "ales",
                            " of",
                            " the",
                            " next",
                            " four",
                            " C",
                            "of",
                            "ound",
                            ".",
                            "it",
                            " projects",
                            " are",
                            " just",
                            " around",
                            " the",
                            " corner",
                            ".",
                            " To",
                            " help",
                            " you",
                            " get",
                            " ready",
                            " to",
                            " contribute",
                            " in",
                            " the",
                            " pre",
                            "-",
                            "sale",
                            " as",
                            " a",
                            " C"
                        ],
                        "dataIndex": null,
                        "index": "13903",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 27.377,
                        "maxValueTokenIndex": 30,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            27.377,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:23:26.430Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 27.377,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk50grzoh0ei66626ug4c8i",
                        "tokens": [
                            ",",
                            " Sw",
                            "amy",
                            " said",
                            " he",
                            " had",
                            " spoken",
                            " to",
                            " All",
                            " India",
                            " Muslim",
                            " Personal",
                            " Law",
                            " Board",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Shah",
                            "ab",
                            "uddin",
                            " Ans",
                            "ari",
                            " and",
                            " A",
                            "IM",
                            "IM",
                            " leader",
                            " As",
                            "ad",
                            "uddin",
                            " O",
                            "wa",
                            "isi",
                            " and",
                            " they",
                            " are",
                            " ready",
                            " for",
                            " it",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "If",
                            " it",
                            " is",
                            " started",
                            ",",
                            " hearing",
                            " will",
                            " be",
                            " completed",
                            " within",
                            " a",
                            " month",
                            " and",
                            " decision",
                            " would",
                            " come",
                            ".",
                            " I",
                            " hope",
                            " the",
                            " Supreme",
                            " Court",
                            " will",
                            " go",
                            " by",
                            " the",
                            " All",
                            "ab",
                            "ah",
                            "ad",
                            " High",
                            " Court",
                            " decision",
                            ".",
                            " Former",
                            " PM",
                            " N",
                            "ars",
                            "im",
                            "ha",
                            " Rao",
                            " had",
                            " given",
                            " an",
                            " affidavit",
                            " that",
                            " if",
                            " it",
                            " is",
                            " proved",
                            " there",
                            " was",
                            " temple",
                            " on",
                            " the",
                            " disputed",
                            " site",
                            ",",
                            " it",
                            " would",
                            " be",
                            " given",
                            " to",
                            " Hindus",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Sw",
                            "amy",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " also",
                            " praised",
                            " HR",
                            "D",
                            " Minister",
                            " Sm",
                            "rit",
                            "i",
                            " Iran"
                        ],
                        "dataIndex": null,
                        "index": "13903",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 26.993,
                        "maxValueTokenIndex": 107,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            26.993,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:23:26.430Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 27.377,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk50gs0oh0fi666xobikuid",
                        "tokens": [
                            " of",
                            " Muslims",
                            " everywhere",
                            " poorer",
                            " and",
                            " more",
                            " insecure",
                            ".\"",
                            "\n",
                            "\n",
                            "\"",
                            "No",
                            " blasphemy",
                            " could",
                            " be",
                            " more",
                            " heinous",
                            " than",
                            " this",
                            " crime",
                            ",\"",
                            " Ans",
                            "ary",
                            " wrote",
                            " in",
                            " an",
                            " email",
                            ",",
                            " \"",
                            "no",
                            " matter",
                            " what",
                            " the",
                            " magazine",
                            " published",
                            " or",
                            " whom",
                            " it",
                            " offended",
                            ".",
                            " Judgment",
                            " belongs",
                            " to",
                            " God",
                            ".",
                            " Those",
                            " who",
                            " claim",
                            " to",
                            " defend",
                            " Islam",
                            " with",
                            " violence",
                            " and",
                            " horror",
                            " are",
                            " essentially",
                            " asserting",
                            " that",
                            " God",
                            " is",
                            " incapable",
                            " of",
                            " carrying",
                            " out",
                            " His",
                            " will",
                            " and",
                            " so",
                            " they",
                            " must",
                            " act",
                            " in",
                            " His",
                            " stead",
                            ":",
                            " that",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " blasphemy",
                            ".\"",
                            "\n",
                            "\n",
                            "There",
                            " is",
                            " a",
                            " tradition",
                            " of",
                            " avoiding",
                            " images",
                            " of",
                            " Prophet",
                            " Mohammed",
                            "\n",
                            "\n",
                            "The",
                            " degree",
                            " to",
                            " which",
                            " cartoons",
                            " like",
                            " those",
                            " in",
                            " Charlie",
                            " Hebdo",
                            " are",
                            " perceived",
                            " as",
                            " offensive",
                            " may",
                            " also",
                            " relate",
                            " to",
                            " Islam",
                            "'s",
                            " strong",
                            " religious",
                            " tradition",
                            " of",
                            " avoiding",
                            " images",
                            " of",
                            " the",
                            " prophet",
                            ".",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "13903",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 26.867,
                        "maxValueTokenIndex": 1,
                        "minValue": 0,
                        "values": [
                            0,
                            26.867,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:23:26.430Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 27.377,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "5-res-jb",
            "index": "3549",
            "description": "words related to religious and ethnic groups, specifically Arabs and Jews",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 22.24771881103516,
            "frac_nonzero": 0.0005000432332356771,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "5-res-jb",
                "index": "3549",
                "sourceSetName": "res-jb",
                "creatorId": null,
                "createdAt": "2024-02-11T23:40:17.047Z",
                "maxActApprox": 22.24771881103516,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    3549,
                    7589,
                    9449,
                    7982,
                    17316,
                    15153,
                    4327,
                    1182,
                    7723,
                    19736,
                    1754,
                    16186,
                    5317,
                    23960,
                    8174,
                    1731,
                    8114,
                    12708,
                    18151,
                    19177,
                    9092,
                    20536,
                    24451,
                    10703,
                    3312
                ],
                "topkCosSimValues": [
                    1,
                    0.7214,
                    0.7095,
                    0.7066,
                    0.6757,
                    0.6669,
                    0.6385,
                    0.6211,
                    0.6082,
                    0.5874,
                    0.576,
                    0.559,
                    0.5574,
                    0.5539,
                    0.5527,
                    0.5357,
                    0.5072,
                    0.4991,
                    0.4975,
                    0.4965,
                    0.4888,
                    0.4694,
                    0.4672,
                    0.4614,
                    0.4585
                ],
                "neuron_alignment_indices": [
                    447,
                    224,
                    218
                ],
                "neuron_alignment_values": [
                    0.1684985905885696,
                    0.1149594038724899,
                    0.1023546904325485
                ],
                "neuron_alignment_l1": [
                    0.007799576036632061,
                    0.005321318283677101,
                    0.004737862851470709
                ],
                "correlated_neurons_indices": [
                    57,
                    30,
                    224
                ],
                "correlated_neurons_pearson": [
                    0.03125045448541641,
                    0.02952765300869942,
                    0.02866001054644585
                ],
                "correlated_neurons_l1": [
                    0.02952103689312935,
                    0.02600658498704433,
                    0.02976930886507034
                ],
                "correlated_features_indices": [],
                "correlated_features_pearson": [],
                "correlated_features_l1": [],
                "neg_str": [
                    "inventoryQuantity",
                    "TI",
                    "Attempts",
                    "York",
                    "Weapons",
                    "Delivery",
                    "wise",
                    "yss",
                    "Chain",
                    "Hur"
                ],
                "neg_values": [
                    -0.7325084805488586,
                    -0.6566449403762817,
                    -0.6215665936470032,
                    -0.6125380992889404,
                    -0.6061524152755737,
                    -0.6034311056137085,
                    -0.5963742733001709,
                    -0.578515350818634,
                    -0.5779067277908325,
                    -0.5778180360794067
                ],
                "pos_str": [
                    "aurus",
                    "paces",
                    "ervative",
                    "ervatives",
                    "hip",
                    "pace",
                    "']",
                    "hips",
                    "'",
                    "cale"
                ],
                "pos_values": [
                    1.22991955280304,
                    1.212505102157593,
                    1.058987021446228,
                    1.034441232681274,
                    1.029233813285828,
                    0.9694327116012573,
                    0.9189167618751526,
                    0.9063204526901245,
                    0.8908570408821106,
                    0.8796495795249939
                ],
                "frac_nonzero": 0.0005000432332356771,
                "freq_hist_data_bar_heights": [
                    257,
                    176,
                    123,
                    123,
                    99,
                    67,
                    75,
                    59,
                    53,
                    44,
                    40,
                    32,
                    32,
                    28,
                    23,
                    22,
                    20,
                    15,
                    17,
                    11,
                    14,
                    15,
                    15,
                    17,
                    19,
                    23,
                    27,
                    32,
                    26,
                    20,
                    10,
                    13,
                    6,
                    6,
                    8,
                    2,
                    2,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.2828664183616638,
                    0.8389386534690857,
                    1.395010948181152,
                    1.951083183288574,
                    2.507155418395996,
                    3.063227653503418,
                    3.61929988861084,
                    4.175372123718262,
                    4.731444358825684,
                    5.287516593933105,
                    5.843588829040527,
                    6.399661064147949,
                    6.955733299255371,
                    7.511805534362793,
                    8.067877769470215,
                    8.623950004577637,
                    9.180022239685059,
                    9.73609447479248,
                    10.2921667098999,
                    10.84823894500732,
                    11.40431022644043,
                    11.96038246154785,
                    12.51645469665527,
                    13.0725269317627,
                    13.62859916687012,
                    14.18467140197754,
                    14.74074363708496,
                    15.29681587219238,
                    15.8528881072998,
                    16.40896034240723,
                    16.96503257751465,
                    17.52110481262207,
                    18.07717704772949,
                    18.63324928283691,
                    19.18932151794434,
                    19.74539375305176,
                    20.30146598815918,
                    20.8575382232666,
                    21.41361045837402,
                    21.96968269348145
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    5,
                    21,
                    46,
                    134,
                    265,
                    607,
                    1144,
                    1876,
                    2794,
                    3774,
                    4861,
                    5541,
                    5759,
                    5162,
                    4632,
                    3837,
                    2993,
                    2203,
                    1631,
                    1139,
                    708,
                    462,
                    275,
                    160,
                    108,
                    49,
                    28,
                    17,
                    2,
                    4,
                    9,
                    3,
                    1,
                    1,
                    2,
                    0,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.7079781293869019,
                    -0.6589174270629883,
                    -0.6098567247390747,
                    -0.5607960224151611,
                    -0.5117353200912476,
                    -0.462674617767334,
                    -0.4136139154434204,
                    -0.3645532131195068,
                    -0.3154925107955933,
                    -0.2664318084716797,
                    -0.2173711061477661,
                    -0.1683104038238525,
                    -0.119249701499939,
                    -0.07018899917602539,
                    -0.02112829685211182,
                    0.02793240547180176,
                    0.07699310779571533,
                    0.1260538101196289,
                    0.1751145124435425,
                    0.2241752147674561,
                    0.2732358574867249,
                    0.3222965598106384,
                    0.371357262134552,
                    0.4204179644584656,
                    0.4694786667823792,
                    0.5185393691062927,
                    0.5676000714302063,
                    0.6166607737541199,
                    0.6657214760780334,
                    0.714782178401947,
                    0.7638428807258606,
                    0.8129035830497742,
                    0.8619642853736877,
                    0.9110249876976013,
                    0.9600856900215149,
                    1.009146451950073,
                    1.058207035064697,
                    1.1072678565979,
                    1.156328439712524,
                    1.205389261245728
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clsxuhsz71rrnenuxxyalviuq",
                        "modelId": "gpt2-small",
                        "layer": "5-res-jb",
                        "index": "3549",
                        "description": "words related to religious and ethnic groups, specifically Arabs and Jews",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": null,
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 6.949279,
                        "umap_y": 10.271316,
                        "umap_cluster": 24,
                        "umap_log_feature_sparsity": -3.2763004,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-02-22T23:19:14.419Z",
                        "updatedAt": "2024-02-22T23:19:14.419Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clsi5eork85jpwf4rmq98jlkg",
                        "tokens": [
                            " affected",
                            " by",
                            " the",
                            " decades",
                            "-",
                            "long",
                            " violence",
                            " between",
                            " Arabs",
                            " and",
                            " Jews",
                            " in",
                            " Palestine",
                            ".",
                            "\u010a",
                            "\u010a",
                            "\""
                        ],
                        "dataIndex": null,
                        "index": "3549",
                        "layer": "5-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 22.24771881103516,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            22.24771881103516,
                            0,
                            16.71747398376465,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-11T23:40:23.578Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -1.144885063171387,
                            0,
                            0.4444828033447266,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aurus\", \"paces\", \"ervative\", \"ervatives\", \"hip\"], \"v\": [8.805166244506836, 8.45200252532959, 7.794309616088867, 7.656608581542969, 6.841233253479004]}, {}, {\"t\": [\"aurus\", \"paces\", \"ervatives\", \"ervative\", \"hip\"], \"v\": [5.225075721740723, 5.029094696044922, 4.345579147338867, 4.273924827575684, 4.089282035827637]}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"York\", \"Attempts\", \"TI\", \"wise\", \"Chain\"], \"v\": [-4.841020584106445, -4.636615753173828, -4.521768569946289, -4.520866394042969, -4.503292083740234]}, {}, {\"t\": [\"wise\", \" domain\", \"York\", \"TI\", \" significance\"], \"v\": [-5.580961227416992, -5.47821044921875, -5.382333755493164, -5.367258071899414, -5.300518035888672]}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsi5eork85jqwf4r3irkhw1v",
                        "tokens": [
                            " m",
                            "owing",
                            " down",
                            " scores",
                            " of",
                            " racially",
                            " stereotyp",
                            "ed",
                            " Arabs",
                            " in",
                            " some",
                            " fictional",
                            " Middle",
                            " Eastern",
                            " country",
                            ",",
                            " male"
                        ],
                        "dataIndex": null,
                        "index": "3549",
                        "layer": "5-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 20.86430168151855,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            20.86430168151855,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-11T23:40:23.578Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -0.7656803131103516,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"paces\", \"aurus\", \"ervatives\", \"ervative\", \"pace\"], \"v\": [6.996264457702637, 6.830334663391113, 6.500410079956055, 6.314105033874512, 5.283324241638184]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"TI\", \"York\", \" maneuvers\", \"wise\", \"Hur\"], \"v\": [-5.517360687255859, -5.363221168518066, -5.276415824890137, -5.21436882019043, -4.986356735229492]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsi5eork85jrwf4rth8dvjfi",
                        "tokens": [
                            " 82",
                            " percent",
                            "<|endoftext|>",
                            ",",
                            " 48",
                            " percent",
                            " of",
                            " Israeli",
                            " Arabs",
                            " and",
                            " 68",
                            " percent",
                            " of",
                            " Palestinians",
                            " agreed",
                            " with",
                            " this"
                        ],
                        "dataIndex": null,
                        "index": "3549",
                        "layer": "5-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 20.55595207214355,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            20.55595207214355,
                            0,
                            0,
                            0,
                            0,
                            15.94979667663574,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-11T23:40:23.578Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -0.8903083801269531,
                            0,
                            0,
                            0,
                            0,
                            -0.7701864242553711,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aurus\", \"paces\", \"ervatives\", \"ervative\", \"hip\"], \"v\": [7.41676139831543, 7.071534633636475, 6.485149383544922, 6.482025146484375, 5.36135721206665]}, {}, {}, {}, {}, {\"t\": [\"aurus\", \"paces\", \"hip\", \"ervative\", \"ervatives\"], \"v\": [6.616721153259277, 6.474382400512695, 5.855100631713867, 5.7850341796875, 5.78346061706543]}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"York\", \"TI\", \"Hur\", \"Products\", \"Attempts\"], \"v\": [-4.67800235748291, -4.583774566650391, -4.322376251220703, -4.312154769897461, -4.308162689208984]}, {}, {}, {}, {}, {\"t\": [\"TI\", \"wise\", \"TY\", \"York\", \"Attempts\"], \"v\": [-3.5892772674560547, -3.338693618774414, -3.206963539123535, -3.1336936950683594, -3.0964908599853516]}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "9-res-jb",
            "index": "9856",
            "description": "mentions of different groups of people in various contexts, such as researchers, voters, consumers, individuals, players, Jews, and liberals",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 22.05608367919922,
            "frac_nonzero": 0.002936045328776042,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "9-res-jb",
                "index": "9856",
                "sourceSetName": "res-jb",
                "creatorId": null,
                "createdAt": "2024-02-12T01:18:06.018Z",
                "maxActApprox": 22.05608367919922,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    9856,
                    13301,
                    15752,
                    8695,
                    23563,
                    16632,
                    19069,
                    13860,
                    929,
                    13082,
                    24523,
                    1992,
                    21206,
                    2600,
                    4672,
                    1811,
                    10470,
                    14806,
                    23758,
                    8663,
                    13812,
                    5633,
                    15602,
                    5915,
                    13230
                ],
                "topkCosSimValues": [
                    1,
                    0.6284,
                    0.6043,
                    0.579,
                    0.5742,
                    0.5701,
                    0.5685,
                    0.5558,
                    0.5504,
                    0.5404,
                    0.5379,
                    0.5285,
                    0.5134,
                    0.5118,
                    0.5115,
                    0.4849,
                    0.4808,
                    0.4741,
                    0.4683,
                    0.4511,
                    0.4443,
                    0.4396,
                    0.4312,
                    0.4273,
                    0.42
                ],
                "neuron_alignment_indices": [
                    447,
                    330,
                    496
                ],
                "neuron_alignment_values": [
                    0.1768439710140228,
                    0.13568976521492,
                    0.1356053352355957
                ],
                "neuron_alignment_l1": [
                    0.008161366917192936,
                    0.006262096110731363,
                    0.006258199457079172
                ],
                "correlated_neurons_indices": [
                    330,
                    32,
                    224
                ],
                "correlated_neurons_pearson": [
                    0.07783620804548264,
                    0.0632295161485672,
                    0.06196291744709015
                ],
                "correlated_neurons_l1": [
                    0.07958561182022095,
                    0.06907292455434799,
                    0.06619718670845032
                ],
                "correlated_features_indices": [],
                "correlated_features_pearson": [],
                "correlated_features_l1": [],
                "neg_str": [
                    "stars",
                    "ces",
                    " Shore",
                    "ILE",
                    "aughs",
                    "Aw",
                    "UV",
                    "DOWN",
                    "sie",
                    "shows"
                ],
                "neg_values": [
                    -0.6350551843643188,
                    -0.6105151176452637,
                    -0.6097295880317688,
                    -0.6088656783103943,
                    -0.6023644208908081,
                    -0.5991976261138916,
                    -0.5916523933410645,
                    -0.5798086524009705,
                    -0.5794059038162231,
                    -0.5751269459724426
                ],
                "pos_str": [
                    " are",
                    " aren",
                    " perceive",
                    " prefer",
                    " have",
                    " were",
                    " everywhere",
                    " crave",
                    " realize",
                    " weren"
                ],
                "pos_values": [
                    1.103465557098389,
                    1.034682393074036,
                    0.9773991703987122,
                    0.9718148708343506,
                    0.9690274000167847,
                    0.9514832496643066,
                    0.9352589845657349,
                    0.9349483251571655,
                    0.9084115624427795,
                    0.9077193737030029
                ],
                "frac_nonzero": 0.002936045328776042,
                "freq_hist_data_bar_heights": [
                    1110,
                    947,
                    788,
                    695,
                    603,
                    486,
                    426,
                    365,
                    368,
                    321,
                    285,
                    246,
                    243,
                    260,
                    207,
                    234,
                    237,
                    187,
                    148,
                    178,
                    172,
                    149,
                    117,
                    101,
                    83,
                    64,
                    58,
                    38,
                    30,
                    27,
                    16,
                    25,
                    11,
                    2,
                    1,
                    3,
                    1,
                    2,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.2757350206375122,
                    0.8271362781524658,
                    1.378537654876709,
                    1.929938793182373,
                    2.481339931488037,
                    3.032741069793701,
                    3.584142446517944,
                    4.135543823242188,
                    4.686944961547852,
                    5.238346099853516,
                    5.78974723815918,
                    6.341148853302002,
                    6.892549991607666,
                    7.44395112991333,
                    7.995352745056152,
                    8.546753883361816,
                    9.09815502166748,
                    9.649556159973145,
                    10.20095729827881,
                    10.75235843658447,
                    11.30375957489014,
                    11.8551607131958,
                    12.40656185150146,
                    12.95796298980713,
                    13.50936412811279,
                    14.06076526641846,
                    14.61216640472412,
                    15.16356754302979,
                    15.71496868133545,
                    16.26637077331543,
                    16.81777381896973,
                    17.36917304992676,
                    17.92057609558105,
                    18.47197532653809,
                    19.02337837219238,
                    19.57477951049805,
                    20.12618064880371,
                    20.67758178710938,
                    21.22898292541504,
                    21.7803840637207
                ],
                "logits_hist_data_bar_heights": [
                    7,
                    13,
                    32,
                    76,
                    137,
                    286,
                    495,
                    881,
                    1459,
                    2276,
                    3326,
                    4339,
                    5114,
                    5483,
                    5415,
                    4796,
                    3925,
                    3050,
                    2397,
                    1728,
                    1346,
                    971,
                    746,
                    532,
                    411,
                    277,
                    229,
                    154,
                    114,
                    90,
                    45,
                    31,
                    27,
                    27,
                    9,
                    5,
                    5,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.6133236885070801,
                    -0.5698606967926025,
                    -0.5263976454734802,
                    -0.4829346537590027,
                    -0.4394716024398804,
                    -0.3960086107254028,
                    -0.3525455892086029,
                    -0.309082567691803,
                    -0.2656195461750031,
                    -0.2221565097570419,
                    -0.178693488240242,
                    -0.1352304667234421,
                    -0.09176747500896454,
                    -0.04830442368984222,
                    -0.004841433838009834,
                    0.03862161934375763,
                    0.08208461105823517,
                    0.1255476027727127,
                    0.169010654091835,
                    0.2124736458063126,
                    0.2559366822242737,
                    0.299399733543396,
                    0.3428627252578735,
                    0.3863257765769958,
                    0.4297887682914734,
                    0.4732517600059509,
                    0.5167148113250732,
                    0.5601778030395508,
                    0.6036408543586731,
                    0.6471038460731506,
                    0.690566897392273,
                    0.7340298891067505,
                    0.777492880821228,
                    0.8209559321403503,
                    0.8644189834594727,
                    0.9078819751739502,
                    0.9513449668884277,
                    0.99480801820755,
                    1.038271069526672,
                    1.08173406124115
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clsxzwyf73aglkad1mrxmtnnz",
                        "modelId": "gpt2-small",
                        "layer": "9-res-jb",
                        "index": "9856",
                        "description": "mentions of different groups of people in various contexts, such as researchers, voters, consumers, individuals, players, Jews, and liberals",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": null,
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 6.5133142,
                        "umap_y": 6.3603773,
                        "umap_cluster": 1526,
                        "umap_log_feature_sparsity": -2.5045736,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-02-23T01:50:59.316Z",
                        "updatedAt": "2024-02-23T01:50:59.316Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clsi8wgqsjrffwf4rbn1z2kg7",
                        "tokens": [
                            " the",
                            " Internet",
                            " and",
                            " mobile",
                            " and",
                            " social",
                            " computing",
                            ",",
                            " people",
                            " are",
                            " starting",
                            " to",
                            " think",
                            ",",
                            " if",
                            " money",
                            " is"
                        ],
                        "dataIndex": null,
                        "index": "9856",
                        "layer": "9-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 22.05608367919922,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            22.05608367919922,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-12T01:18:13.208Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -2.51923656463623,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" are\", \" aren\", \"ometimes\", \" perceive\", \" crave\"], \"v\": [2.5192365646362305, 2.3631410598754883, 1.8947944641113281, 1.8302183151245117, 1.8243217468261719]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ces\", \"sie\", \"shows\", \"ties\", \"NING\"], \"v\": [-4.529552459716797, -4.466564178466797, -4.3449859619140625, -4.297389984130859, -4.164142608642578]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsi8wgqtjrfgwf4rup1f5xoq",
                        "tokens": [
                            " and",
                            " the",
                            " Holocaust",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " lesson",
                            " that",
                            " people",
                            " are",
                            " not",
                            " basically",
                            " good",
                            ".",
                            " Hal",
                            "akh",
                            "ic"
                        ],
                        "dataIndex": null,
                        "index": "9856",
                        "layer": "9-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 21.18416976928711,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            21.18416976928711,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-12T01:18:13.208Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -0.0007128664292395115,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" everywhere\", \" perceive\", \" prefer\", \" resorted\", \"hip\"], \"v\": [0.33623504638671875, 0.3352527618408203, 0.32588958740234375, 0.31464576721191406, 0.2848930358886719]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"sie\", \"Aw\", \"SPONSORED\", \"OTOS\", \"lies\"], \"v\": [-5.9505462646484375, -5.931297302246094, -5.928474426269531, -5.918188095092773, -5.838325500488281]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clsi8wgqtjrfhwf4r2vn90o3w",
                        "tokens": [
                            " as",
                            " Call",
                            " of",
                            " Duty",
                            " and",
                            " GTA",
                            " V",
                            ",",
                            " gamers",
                            " can",
                            " develop",
                            " an",
                            " understanding",
                            " of",
                            " the",
                            " fundamentals",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "9856",
                        "layer": "9-res-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 20.88326835632324,
                        "maxValueTokenIndex": 8,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            20.88326835632324,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "clkht01d40000jv08hvalcvly",
                        "createdAt": "2024-02-12T01:18:13.208Z",
                        "lossValues": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            -0.8210887908935547,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" are\", \" prefer\", \" aren\", \" underestimate\", \" hesitate\"], \"v\": [2.0935935974121094, 1.9829607009887695, 1.9486932754516602, 1.6764507293701172, 1.6697959899902344]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ces\", \"stars\", \"aughs\", \"cast\", \"casts\"], \"v\": [-4.6448516845703125, -4.630407333374023, -4.458257675170898, -4.425619125366211, -4.355706214904785]}, {}, {}, {}, {}, {}, {}, {}]}",
                        "binMin": null,
                        "binMax": null,
                        "binContains": null,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "0-tres-dc",
            "index": "20065",
            "description": "references to Jews and Jewish identity",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 18.609375,
            "frac_nonzero": 0.0001239013671875,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "0-tres-dc",
                "index": "20065",
                "sourceSetName": "tres-dc",
                "creatorId": null,
                "createdAt": "2024-05-05T07:59:59.202Z",
                "maxActApprox": 18.609375,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [],
                "topkCosSimValues": [],
                "neuron_alignment_indices": [],
                "neuron_alignment_values": [],
                "neuron_alignment_l1": [],
                "correlated_neurons_indices": [],
                "correlated_neurons_pearson": [],
                "correlated_neurons_l1": [],
                "correlated_features_indices": [],
                "correlated_features_pearson": [],
                "correlated_features_l1": [],
                "neg_str": [
                    "shown",
                    "ctive",
                    " McD",
                    "gain",
                    "ature",
                    "clip",
                    "currency",
                    ">>>",
                    "dB",
                    "lined"
                ],
                "neg_values": [
                    -0.7638909816741943,
                    -0.7155681252479553,
                    -0.6953537464141846,
                    -0.6756665706634521,
                    -0.6745589375495911,
                    -0.6575314998626709,
                    -0.6408237218856812,
                    -0.6383510231971741,
                    -0.6333310604095459,
                    -0.6307893991470337
                ],
                "pos_str": [
                    "ellery",
                    "odus",
                    "\u05d9\ufffd",
                    " Jews",
                    "anyahu",
                    "Semitism",
                    "ophobia",
                    "ettings",
                    " Sabbath",
                    "geist"
                ],
                "pos_values": [
                    0.7621411681175232,
                    0.7362611293792725,
                    0.7311986088752747,
                    0.7291879653930664,
                    0.7282294034957886,
                    0.7127469182014465,
                    0.6997500658035278,
                    0.6887431740760803,
                    0.6823519468307495,
                    0.6770918965339661
                ],
                "frac_nonzero": 0.0001239013671875,
                "freq_hist_data_bar_heights": [],
                "freq_hist_data_bar_values": [],
                "logits_hist_data_bar_heights": [],
                "logits_hist_data_bar_values": [],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "rhw3c6kwieohe559dtp4njon8",
                        "modelId": "gpt2-small",
                        "layer": "0-tres-dc",
                        "index": "20065",
                        "description": "references to Jews and Jewish identity",
                        "authorId": "cljgamm90000076zdchicy6zj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-25T01:43:31.087Z",
                        "updatedAt": "2024-08-25T01:43:31.087Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clvt8suz0903xzkyh3sdhrpp8",
                        "tokens": [
                            " had",
                            " released",
                            " six",
                            " separate",
                            " propaganda",
                            " videos",
                            ".",
                            " One",
                            " video",
                            ",",
                            " titled",
                            " \"",
                            "Return",
                            " Terror",
                            " to",
                            " the",
                            " Jews",
                            ",\"",
                            " features",
                            " a",
                            " masked",
                            " fighter",
                            " who",
                            " praises",
                            " Palestinians",
                            " who",
                            " attack",
                            " Jews",
                            ",",
                            " calling",
                            " them",
                            " \""
                        ],
                        "dataIndex": null,
                        "index": "20065",
                        "layer": "0-tres-dc",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.609375,
                        "maxValueTokenIndex": 16,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            18.609375,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            17.0625,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-05-05T08:00:00.770Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 14.8875,
                        "binMax": 18.609375,
                        "binContains": 4.0283203125e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clvt8suz0903wzkyh58rjxzwq",
                        "tokens": [
                            " had",
                            " released",
                            " six",
                            " separate",
                            " propaganda",
                            " videos",
                            ".",
                            " One",
                            " video",
                            ",",
                            " titled",
                            " \"",
                            "Return",
                            " Terror",
                            " to",
                            " the",
                            " Jews",
                            ",\"",
                            " features",
                            " a",
                            " masked",
                            " fighter",
                            " who",
                            " praises",
                            " Palestinians",
                            " who",
                            " attack",
                            " Jews",
                            ",",
                            " calling",
                            " them",
                            " \""
                        ],
                        "dataIndex": null,
                        "index": "20065",
                        "layer": "0-tres-dc",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.609375,
                        "maxValueTokenIndex": 16,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            18.609375,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            17.0625,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-05-05T08:00:00.770Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 18.609375,
                        "binMax": 22.33125,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clvt8suz1903yzkyh9ck3jh21",
                        "tokens": [
                            "<|endoftext|>",
                            " Two",
                            " people",
                            " can",
                            ",",
                            " and",
                            " should",
                            ",",
                            " sing",
                            " together",
                            ".",
                            " In",
                            " music",
                            ",",
                            " Jews",
                            " strive",
                            " for",
                            " harmony",
                            ".",
                            " And",
                            " harmony",
                            " cannot",
                            " exist",
                            " if",
                            " you",
                            " are",
                            " alone",
                            ".",
                            "\n",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "20065",
                        "layer": "0-tres-dc",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.234375,
                        "maxValueTokenIndex": 14,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            18.234375,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-05-05T08:00:00.770Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 14.8875,
                        "binMax": 18.609375,
                        "binContains": 4.0283203125e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "1-mlp_32k-oai",
            "index": "821",
            "description": " occurrences of the word \"Jew.\"",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 17.918,
            "frac_nonzero": 0.0009299999999999999,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "1-mlp_32k-oai",
                "index": "821",
                "sourceSetName": "mlp_32k-oai",
                "creatorId": "cljgamm90000076zdchicy6zj",
                "createdAt": "2024-07-22T17:33:16.189Z",
                "maxActApprox": 17.918,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    821,
                    30415,
                    21194,
                    1689,
                    9067,
                    9391,
                    26723,
                    20978,
                    25095,
                    26578,
                    9092,
                    30566,
                    19402,
                    5768,
                    6568,
                    8754,
                    13309,
                    28703,
                    23379,
                    29540,
                    11048,
                    17869,
                    18069,
                    31584,
                    12577
                ],
                "topkCosSimValues": [
                    1,
                    0.1982,
                    0.1677,
                    0.1611,
                    0.1597,
                    0.1566,
                    0.1531,
                    0.1529,
                    0.1523,
                    0.1491,
                    0.1491,
                    0.148,
                    0.1458,
                    0.1458,
                    0.145,
                    0.145,
                    0.1449,
                    0.1446,
                    0.1444,
                    0.144,
                    0.143,
                    0.1428,
                    0.1424,
                    0.1419,
                    0.1389
                ],
                "neuron_alignment_indices": [
                    430,
                    223,
                    267
                ],
                "neuron_alignment_values": [
                    0.126,
                    0.105,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    346,
                    418,
                    542
                ],
                "correlated_neurons_pearson": [
                    0.011,
                    0.01,
                    0.01
                ],
                "correlated_neurons_l1": [
                    0.01,
                    0.009,
                    0.01
                ],
                "correlated_features_indices": [
                    1398,
                    1394,
                    1127
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.005,
                    0.005
                ],
                "correlated_features_l1": [
                    0.008,
                    0.005,
                    0.005
                ],
                "neg_str": [
                    "senal",
                    " tiss",
                    "conom",
                    " accordingly",
                    " neighb",
                    " liter",
                    "iddles",
                    "MG",
                    "yrights",
                    "endas"
                ],
                "neg_values": [
                    -0.822,
                    -0.746,
                    -0.721,
                    -0.713,
                    -0.706,
                    -0.674,
                    -0.664,
                    -0.662,
                    -0.654,
                    -0.646
                ],
                "pos_str": [
                    " careg",
                    " offic",
                    "NULL",
                    " Samar",
                    "ascular",
                    "hide",
                    " ''",
                    "istically",
                    " Zeus",
                    "agher"
                ],
                "pos_values": [
                    0.643,
                    0.63,
                    0.626,
                    0.624,
                    0.62,
                    0.614,
                    0.587,
                    0.573,
                    0.572,
                    0.571
                ],
                "frac_nonzero": 0.0009299999999999999,
                "freq_hist_data_bar_heights": [
                    903,
                    343,
                    104,
                    42,
                    22,
                    8,
                    9,
                    3,
                    6,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    2,
                    2,
                    2,
                    0,
                    1,
                    0,
                    1,
                    0,
                    1,
                    2,
                    1,
                    0,
                    1,
                    0,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.18,
                    0.538,
                    0.896,
                    1.255,
                    1.613,
                    1.971,
                    2.33,
                    2.688,
                    3.046,
                    3.405,
                    3.763,
                    4.121,
                    4.48,
                    4.838,
                    5.197,
                    5.555,
                    5.913,
                    6.272,
                    6.63,
                    6.988,
                    7.347,
                    7.705,
                    8.063,
                    8.422,
                    8.78,
                    9.139,
                    9.497,
                    9.855,
                    10.214,
                    10.572,
                    10.93,
                    11.289,
                    11.647,
                    12.005,
                    12.364,
                    12.722,
                    13.08,
                    13.439,
                    13.797,
                    14.156,
                    14.514,
                    14.872,
                    15.231,
                    15.589,
                    15.947,
                    16.306,
                    16.664,
                    17.022,
                    17.381,
                    17.739
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    3,
                    0,
                    4,
                    12,
                    7,
                    27,
                    29,
                    52,
                    73,
                    127,
                    160,
                    226,
                    312,
                    434,
                    573,
                    817,
                    1062,
                    1379,
                    1713,
                    1985,
                    2424,
                    2833,
                    3209,
                    3496,
                    3623,
                    3627,
                    3579,
                    3309,
                    3037,
                    2665,
                    2237,
                    1843,
                    1558,
                    1131,
                    874,
                    605,
                    419,
                    280,
                    180,
                    146,
                    74,
                    50,
                    29,
                    16,
                    9,
                    1,
                    6
                ],
                "logits_hist_data_bar_values": [
                    -0.808,
                    -0.778,
                    -0.749,
                    -0.72,
                    -0.69,
                    -0.661,
                    -0.632,
                    -0.602,
                    -0.573,
                    -0.544,
                    -0.515,
                    -0.485,
                    -0.456,
                    -0.427,
                    -0.397,
                    -0.368,
                    -0.339,
                    -0.309,
                    -0.28,
                    -0.251,
                    -0.222,
                    -0.192,
                    -0.163,
                    -0.134,
                    -0.104,
                    -0.075,
                    -0.046,
                    -0.016,
                    0.013,
                    0.042,
                    0.071,
                    0.101,
                    0.13,
                    0.159,
                    0.189,
                    0.218,
                    0.247,
                    0.276,
                    0.306,
                    0.335,
                    0.364,
                    0.394,
                    0.423,
                    0.452,
                    0.482,
                    0.511,
                    0.54,
                    0.569,
                    0.599,
                    0.628
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "kyjoibudyqh8wd48p7tmqbuz4",
                        "modelId": "gpt2-small",
                        "layer": "1-mlp_32k-oai",
                        "index": "821",
                        "description": " occurrences of the word \"Jew.\"",
                        "authorId": "cljgamm90000076zdchicy6zj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-25T10:31:42.394Z",
                        "updatedAt": "2024-08-25T10:31:42.394Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clyx9mjlfytlydh763011b200",
                        "tokens": [
                            "\u00e2\u0122",
                            "\u013f",
                            " I",
                            " asked",
                            " him",
                            " how",
                            " this",
                            " came",
                            " about",
                            " and",
                            " what",
                            " he",
                            " was",
                            " referring",
                            " to",
                            ".",
                            " He",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "I",
                            " saw",
                            " a",
                            " man",
                            " walking",
                            ",",
                            " and",
                            " I",
                            " said",
                            ":",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " Jew",
                            " a",
                            "foot",
                            ".",
                            " Come",
                            " on",
                            " home",
                            " with",
                            " me",
                            " and",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " have",
                            " a",
                            " hot",
                            " drink",
                            ",",
                            " and",
                            " if",
                            " you",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " object"
                        ],
                        "dataIndex": null,
                        "index": "821",
                        "layer": "1-mlp_32k-oai",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.918,
                        "maxValueTokenIndex": 36,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            17.918,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-22T17:33:19.269Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 17.918,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyx9mjlfytmmdh7622pq9sah",
                        "tokens": [
                            "\u00e2\u0122",
                            "\u013f",
                            " I",
                            " asked",
                            " him",
                            " how",
                            " this",
                            " came",
                            " about",
                            " and",
                            " what",
                            " he",
                            " was",
                            " referring",
                            " to",
                            ".",
                            " He",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "I",
                            " saw",
                            " a",
                            " man",
                            " walking",
                            ",",
                            " and",
                            " I",
                            " said",
                            ":",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " Jew",
                            " a",
                            "foot",
                            ".",
                            " Come",
                            " on",
                            " home",
                            " with",
                            " me",
                            " and",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " have",
                            " a",
                            " hot",
                            " drink",
                            ",",
                            " and",
                            " if",
                            " you",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " object"
                        ],
                        "dataIndex": null,
                        "index": "821",
                        "layer": "1-mlp_32k-oai",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.918,
                        "maxValueTokenIndex": 36,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            17.918,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-22T17:33:19.269Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 14.335,
                        "binMax": 17.918,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyx9mjlfytlzdh76bf1e539a",
                        "tokens": [
                            "\u013f",
                            " Vel",
                            "vel",
                            " replied",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "Sil",
                            "ence",
                            ",",
                            " Reb",
                            " D",
                            "ov",
                            ",",
                            " silence",
                            ".",
                            " If",
                            " God",
                            " has",
                            " given",
                            " a",
                            " Jew",
                            " such",
                            " a",
                            " nice",
                            " singing",
                            " voice",
                            ",",
                            " all",
                            " of",
                            " Israel",
                            " should",
                            " rejoice",
                            " in",
                            " it",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "After",
                            " the",
                            " Grace",
                            " the",
                            " host",
                            "ess",
                            " brought",
                            " tea",
                            " and",
                            " jam",
                            ".",
                            " We",
                            " sat",
                            " drinking",
                            " and",
                            " talking",
                            " about",
                            " the",
                            " affairs",
                            " of",
                            " the",
                            " Land",
                            ","
                        ],
                        "dataIndex": null,
                        "index": "821",
                        "layer": "1-mlp_32k-oai",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.375,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            17.375,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-22T17:33:19.269Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 17.918,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}