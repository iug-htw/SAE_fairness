{
    "modelId": "gpt2-small",
    "layer": "5-res-jb",
    "index": "292",
    "sourceSetName": "res-jb",
    "creatorId": null,
    "createdAt": "2024-02-11T23:37:12.837Z",
    "maxActApprox": 48.27607345581055,
    "hasVector": false,
    "vector": [],
    "vectorLabel": null,
    "vectorDefaultSteerStrength": 10,
    "hookName": null,
    "topkCosSimIndices": [
        292,
        6367,
        9573,
        10965,
        3509,
        21980,
        18223,
        13649,
        15309,
        12061,
        1870,
        23496,
        21681,
        12883,
        14356,
        24506,
        52,
        21716,
        3983,
        2921,
        2683,
        19178,
        9853,
        19461,
        19827
    ],
    "topkCosSimValues": [
        1,
        0.6114,
        0.6005,
        0.5364,
        0.4746,
        0.4737,
        0.4703,
        0.4672,
        0.4633,
        0.446,
        0.4392,
        0.4373,
        0.4183,
        0.4149,
        0.4131,
        0.4123,
        0.4104,
        0.4083,
        0.4072,
        0.4005,
        0.4001,
        0.3982,
        0.3874,
        0.3818,
        0.3815
    ],
    "neuron_alignment_indices": [
        288,
        343,
        447
    ],
    "neuron_alignment_values": [
        0.1775582283735275,
        0.1191542148590088,
        0.1184330508112907
    ],
    "neuron_alignment_l1": [
        0.008305225521326065,
        0.005573397502303123,
        0.005539664998650551
    ],
    "correlated_neurons_indices": [
        384,
        461,
        343
    ],
    "correlated_neurons_pearson": [
        0.01236876379698515,
        0.01183729246258736,
        0.01177513599395752
    ],
    "correlated_neurons_l1": [
        0.01140482909977436,
        0.01160439383238554,
        0.01181225012987852
    ],
    "correlated_features_indices": [],
    "correlated_features_pearson": [],
    "correlated_features_l1": [],
    "neg_str": [
        "igating",
        "hof",
        "lying",
        " Arbor",
        "soType",
        "laus",
        "\u012a\u0134",
        "aer",
        "Bird",
        " Worcester"
    ],
    "neg_values": [
        -0.7778154015541077,
        -0.7640308737754822,
        -0.7288429141044617,
        -0.7262634038925171,
        -0.7143952250480652,
        -0.7128683924674988,
        -0.6997289657592773,
        -0.6991226077079773,
        -0.6963398456573486,
        -0.6758771538734436
    ],
    "pos_str": [
        " cocaine",
        " residue",
        " addiction",
        " addicts",
        " overdose",
        "stasy",
        " addict",
        " overdoses",
        " sulf",
        " traffickers"
    ],
    "pos_values": [
        1.153758406639099,
        1.085066676139832,
        0.9637422561645508,
        0.9505168199539185,
        0.941679060459137,
        0.90773606300354,
        0.9055854082107544,
        0.8929139375686646,
        0.8832375407218933,
        0.8454607129096985
    ],
    "frac_nonzero": 0.0001115798950195312,
    "freq_hist_data_bar_heights": [
        149,
        64,
        42,
        18,
        15,
        15,
        6,
        4,
        6,
        1,
        1,
        0,
        1,
        0,
        0,
        2,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        2,
        4,
        3,
        3,
        3,
        5,
        3,
        4
    ],
    "freq_hist_data_bar_values": [
        0.6126387119293213,
        1.836466789245605,
        3.060295104980469,
        4.284122943878174,
        5.507951259613037,
        6.7317795753479,
        7.955607414245605,
        9.179434776306152,
        10.40326309204102,
        11.62709140777588,
        12.85091972351074,
        14.07474708557129,
        15.29857540130615,
        16.52240371704102,
        17.74623107910156,
        18.97006034851074,
        20.19388771057129,
        21.41771507263184,
        22.64154434204102,
        23.86537170410156,
        25.08920097351074,
        26.31303024291992,
        27.53685760498047,
        28.76068687438965,
        29.9845142364502,
        31.20834159851074,
        32.43217086791992,
        33.65599822998047,
        34.87982940673828,
        36.10365676879883,
        37.32748413085938,
        38.55131149291992,
        39.77513885498047,
        40.99897003173828,
        42.22279739379883,
        43.44662475585938,
        44.67045211791992,
        45.89427947998047,
        47.11811065673828,
        48.34193801879883
    ],
    "logits_hist_data_bar_heights": [
        2,
        7,
        17,
        27,
        49,
        103,
        226,
        409,
        737,
        1254,
        1767,
        2562,
        3418,
        4250,
        4872,
        5253,
        5022,
        4917,
        4099,
        3476,
        2615,
        1890,
        1271,
        803,
        496,
        308,
        168,
        104,
        52,
        32,
        14,
        16,
        6,
        6,
        4,
        2,
        1,
        0,
        1,
        1
    ],
    "logits_hist_data_bar_values": [
        -0.7536707520484924,
        -0.7053813934326172,
        -0.6570920348167419,
        -0.6088026762008667,
        -0.5605133771896362,
        -0.512224018573761,
        -0.4639346301555634,
        -0.4156453013420105,
        -0.3673559427261353,
        -0.31906658411026,
        -0.2707772552967072,
        -0.2224878966808319,
        -0.1741985380649567,
        -0.1259091794490814,
        -0.07761988788843155,
        -0.0293305292725563,
        0.01895882934331894,
        0.06724818795919418,
        0.1155375465750694,
        0.1638268530368805,
        0.212116152048111,
        0.2604055106639862,
        0.3086948096752167,
        0.3569841682910919,
        0.4052735269069672,
        0.4535628855228424,
        0.5018522143363953,
        0.5501415133476257,
        0.598430871963501,
        0.6467202305793762,
        0.6950095891952515,
        0.7432988882064819,
        0.791588306427002,
        0.8398776054382324,
        0.8881669640541077,
        0.9364563226699829,
        0.9847456812858582,
        1.033035039901733,
        1.081324338912964,
        1.129613757133484
    ],
    "decoder_weights_dist": [],
    "umap_cluster": null,
    "umap_log_feature_sparsity": null,
    "umap_x": null,
    "umap_y": null,
    "model": {
        "id": "gpt2-small",
        "displayNameShort": "GPT2-SM",
        "displayName": "GPT2-Small",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "tlensId": null,
        "dimension": 768,
        "visibility": "PUBLIC",
        "inferenceEnabled": true,
        "instruct": false,
        "layers": 12,
        "neuronsPerLayer": 3072,
        "createdAt": "2023-07-06T00:01:44.843Z",
        "owner": "OpenAI",
        "updatedAt": "2023-07-06T00:01:44.843Z",
        "website": "https://openai.com"
    },
    "lists": [],
    "creator": null,
    "source": {
        "id": "5-res-jb",
        "modelId": "gpt2-small",
        "hasDashboards": true,
        "inferenceEnabled": true,
        "saelensConfig": {
            "lr": 0.0004,
            "d_in": 768,
            "seed": 42,
            "d_sae": 24576,
            "dtype": "torch.float32",
            "device": "mps",
            "run_name": "24576-L1-8e-05-LR-0.0004-Tokens-3.000e+08",
            "hook_point": "blocks.5.hook_resid_pre",
            "model_name": "gpt2-small",
            "prepend_bos": true,
            "architecture": "standard",
            "context_size": 128,
            "dataset_path": "Skylion007/openwebtext",
            "log_to_wandb": true,
            "wandb_entity": null,
            "n_checkpoints": 10,
            "wandb_project": "mats_sae_training_gpt2_small_resid_pre_5",
            "l1_coefficient": 8e-05,
            "neuronpedia_id": "gpt2-small/5-res-jb",
            "checkpoint_path": "checkpoints/65ufbyeo",
            "use_ghost_grads": false,
            "expansion_factor": 32,
            "hook_point_layer": 5,
            "lr_warm_up_steps": 5000,
            "resample_batches": 1028,
            "store_batch_size": 32,
            "train_batch_size": 4096,
            "activation_fn_str": "relu",
            "b_dec_init_method": "geometric_median",
            "lr_scheduler_name": null,
            "tokens_per_buffer": 67108864,
            "dead_feature_window": 5000,
            "n_batches_in_buffer": 128,
            "wandb_log_frequency": 100,
            "apply_b_dec_to_input": true,
            "feature_reinit_scale": 0.2,
            "from_pretrained_path": null,
            "is_dataset_tokenized": false,
            "hook_point_head_index": null,
            "normalize_activations": "none",
            "total_training_tokens": 300000000,
            "dead_feature_threshold": 1e-08,
            "use_cached_activations": false,
            "cached_activations_path": "activations/Skylion007_openwebtext/gpt2-small/blocks.5.hook_resid_pre",
            "feature_sampling_method": null,
            "feature_sampling_window": 1000,
            "dataset_trust_remote_code": true,
            "finetuning_scaling_factor": false,
            "sae_lens_training_version": null,
            "model_from_pretrained_kwargs": {
                "center_writing_weights": true
            },
            "dead_feature_estimation_method": "no_fire"
        },
        "saelensRelease": "gpt2-small-res-jb",
        "saelensSaeId": "blocks.5.hook_resid_pre",
        "hfRepoId": "jbloom/GPT2-Small-SAEs-Reformatted",
        "hfFolderId": "blocks.5.hook_resid_pre",
        "visibility": "PUBLIC",
        "setName": "res-jb",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "hasUmap": true,
        "hasUmapLogSparsity": true,
        "hasUmapClusters": true,
        "num_prompts": 24576,
        "num_tokens_in_prompt": 128,
        "dataset": "Skylion007/openwebtext",
        "notes": null,
        "createdAt": "2024-07-10T04:46:32.069Z"
    },
    "sourceSet": {
        "modelId": "gpt2-small",
        "name": "res-jb",
        "hasDashboards": true,
        "visibility": "PUBLIC",
        "description": "Open Source Sparse Autoencoders for all Residual Stream Layers of GPT2-Small",
        "type": "Residual Stream",
        "creatorName": "Joseph Bloom",
        "urls": [
            "https://www.lesswrong.com/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream",
            "https://huggingface.co/jbloom/GPT2-Small-SAEs/tree/main",
            "https://github.com/jbloomAus/mats_sae_training"
        ],
        "creatorEmail": null,
        "creatorId": "cljgamm90000076zdchicy6zj",
        "releaseName": "gpt2sm-res-jb",
        "defaultRange": 2,
        "defaultShowBreaks": true,
        "showDfa": false,
        "showCorrelated": false,
        "showHeadAttribution": false,
        "showUmap": true,
        "serverHost": "https://1ynud2kk7vnhjo-5002.proxy.runpod.net",
        "createdAt": "2024-07-10T04:46:32.075Z"
    },
    "activations": [
        {
            "id": "clsi5aqlk2cexwf4rf8iy73yo",
            "tokens": [
                " addiction",
                ",",
                " the",
                " study",
                " found",
                ".",
                " By",
                " giving",
                " cocaine",
                " to",
                " mice",
                " in",
                " the",
                " laboratory",
                ",",
                " the",
                " researchers"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 48.27607345581055,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                48.27607345581055,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.110553741455078,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" addiction\", \" overdose\", \"stasy\"], \"v\": [9.269879341125488, 8.368496894836426, 7.19167423248291, 6.741955757141113, 6.454291343688965]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"aer\", \"lying\", \" Arbor\", \"hof\"], \"v\": [-17.50265884399414, -16.918521881103516, -16.573991775512695, -16.491168975830078, -16.153413772583008]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlk2ceywf4rwke0emh9",
            "tokens": [
                " There",
                "'s",
                " a",
                " time",
                " and",
                " a",
                " place",
                " for",
                " cocaine",
                ",",
                " and",
                " that",
                " time",
                " is",
                " almost",
                " never",
                "\u00e2\u0122\u0136"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 47.83908843994141,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                47.83908843994141,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.260645389556885,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \"stasy\", \" addiction\", \" overdose\"], \"v\": [9.68049430847168, 8.3400239944458, 7.232978820800781, 6.323152542114258, 6.234829902648926]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \" Arbor\", \"lying\", \"Bird\", \"hof\"], \"v\": [-17.510223388671875, -17.36972999572754, -16.3011417388916, -16.059629440307617, -15.969223022460938]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlk2cezwf4rzmn69w0o",
            "tokens": [
                " than",
                " a",
                " bargain",
                ".",
                " (",
                "OK",
                ",",
                " maybe",
                " cocaine",
                ",",
                " but",
                " let",
                "'s",
                " not",
                " qu",
                "ibble",
                ".)"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 47.74395370483398,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                47.74395370483398,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.135435104370117,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \"stasy\", \" addiction\", \" overdose\"], \"v\": [9.94480037689209, 9.542903900146484, 6.821758270263672, 6.475342750549316, 6.36860466003418]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"lying\", \"hof\", \" Arbor\", \"laus\"], \"v\": [-17.692752838134766, -17.258583068847656, -17.107284545898438, -16.97933578491211, -16.89032745361328]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlk2cf0wf4ra90cbspv",
            "tokens": [
                "'s",
                " why",
                " an",
                " internet",
                " habit",
                ",",
                " like",
                " a",
                " cocaine",
                " habit",
                ",",
                " can",
                " reach",
                " dysfunctional",
                " levels",
                ".",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 47.18709564208984,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                47.18709564208984,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -1.632878303527832,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \"stasy\", \" addicts\", \" methamphetamine\"], \"v\": [11.002293586730957, 9.911754608154297, 8.165258407592773, 7.823786735534668, 7.336627960205078]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"hof\", \"lying\", \" Arbor\", \"Reviewer\"], \"v\": [-17.07266616821289, -16.101608276367188, -15.982826232910156, -15.893814086914062, -15.65032958984375]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlk2cf1wf4r46rin7rs",
            "tokens": [
                ",",
                " died",
                " after",
                " what",
                " the",
                " teen",
                " thought",
                " was",
                " cocaine",
                " turned",
                " out",
                " to",
                " be",
                " poison",
                ".",
                " Following",
                " this"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 46.81306838989258,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                46.81306838989258,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                9.647764205932617,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" residue\", \" cocaine\", \" sulf\", \" addicts\", \" residues\"], \"v\": [5.846738338470459, 4.745978832244873, 3.6674976348876953, 3.091768741607666, 2.7932968139648438]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"lying\", \" Arbor\", \"angering\", \"arily\"], \"v\": [-21.18844985961914, -19.809913635253906, -19.133220672607422, -19.00503921508789, -18.950660705566406]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlk2cf2wf4rk3606x8a",
            "tokens": [
                " like",
                " a",
                " pack",
                " of",
                " cigarettes",
                " or",
                " lots",
                " of",
                " cocaine",
                ",",
                " lets",
                " you",
                " just",
                " sit",
                " in",
                " a",
                " room"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 46.76111602783203,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                46.76111602783203,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.820239067077637,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" sulf\", \" overdose\", \" overdoses\"], \"v\": [7.805861949920654, 7.703690052032471, 5.157770156860352, 5.151431560516357, 4.845175266265869]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"hof\", \"lying\", \" Arbor\", \"rors\"], \"v\": [-19.728792190551758, -18.71057891845703, -18.105525970458984, -17.998693466186523, -17.821924209594727]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlk2cf3wf4rgt0n42qx",
            "tokens": [
                " credited",
                " with",
                " controlling",
                " much",
                " of",
                " the",
                " world",
                "'s",
                " cocaine",
                " trade",
                ".",
                "\u010a",
                "\u010a",
                "In",
                " May",
                ",",
                " 50"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 46.38810348510742,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                46.38810348510742,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.100444793701172,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" residue\", \" cocaine\", \"stasy\", \" sulf\", \" overdose\"], \"v\": [7.716142177581787, 7.666228771209717, 5.999022483825684, 5.661084175109863, 5.485764980316162]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"hof\", \" Arbor\", \"lying\", \"ament\"], \"v\": [-17.63027572631836, -17.060283660888672, -16.68657684326172, -16.437301635742188, -16.39297103881836]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlk2cf4wf4rdnbcfia7",
            "tokens": [
                " a",
                " public",
                " menace",
                " nearly",
                " eclips",
                "ing",
                " heroin",
                ",",
                " cocaine",
                ",",
                " amp",
                "het",
                "amines",
                " and",
                " club",
                " drugs",
                ","
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 46.14957809448242,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0.05323433876037598,
                0,
                46.14957809448242,
                0,
                0,
                0,
                3.620372772216797,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.00803375244140625,
                0,
                7.513514518737793,
                0,
                0,
                0,
                0.0894784927368164,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \"stasy\", \" residues\", \" sulf\"], \"v\": [0.005184650421142578, 0.0046291351318359375, 0.0026102066040039062, 0.00225067138671875, 0.0018329620361328125]}, {}, {\"t\": [\" cocaine\", \" residue\", \" overdose\", \" sulf\", \"stasy\"], \"v\": [9.02113151550293, 7.879093170166016, 6.325382232666016, 5.991427421569824, 5.827104568481445]}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" addiction\", \" methamphetamine\", \" addicts\"], \"v\": [1.1123847961425781, 1.0710735321044922, 0.8165502548217773, 0.8045473098754883, 0.8018093109130859]}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"Relations\", \" Arbor\", \" Forge\", \"ament\"], \"v\": [-0.019311904907226562, -0.019144058227539062, -0.019117355346679688, -0.018762588500976562, -0.018512725830078125]}, {}, {\"t\": [\"igating\", \" Forge\", \"hof\", \" Arbor\", \"lying\"], \"v\": [-19.7103271484375, -19.039093017578125, -19.029335021972656, -18.985158920288086, -18.71316909790039]}, {}, {}, {}, {\"t\": [\"igating\", \"hof\", \" Arbor\", \"rors\", \"laus\"], \"v\": [-1.1967639923095703, -1.1559181213378906, -1.0609359741210938, -1.0467243194580078, -1.0081405639648438]}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlk2cf5wf4rxeli2qzx",
            "tokens": [
                ".",
                " That",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " why",
                " a",
                " good",
                " cocaine",
                " habit",
                " can",
                " lower",
                " cholesterol",
                ".",
                " Chem",
                "otherapy",
                " can"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 45.92284393310547,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                45.92284393310547,
                0.1718345582485199,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -2.179224967956543,
                -0.007646560668945312,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" residue\", \" cocaine\", \"stasy\", \" residues\", \" traffickers\"], \"v\": [10.898422241210938, 10.804912567138672, 8.477920532226562, 8.410606384277344, 8.031167030334473]}, {\"t\": [\" cocaine\", \" residue\", \" addicts\", \" sulf\", \" overdose\"], \"v\": [0.06554412841796875, 0.06484127044677734, 0.05427360534667969, 0.05345916748046875, 0.05316352844238281]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Arbor\", \"igating\", \"hof\", \"Reviewer\", \"ait\"], \"v\": [-17.50985336303711, -16.785085678100586, -16.41791343688965, -16.407793045043945, -15.903046607971191]}, {\"t\": [\"igating\", \"hof\", \" Arbor\", \"laus\", \"lying\"], \"v\": [-0.04556083679199219, -0.04473876953125, -0.04393196105957031, -0.04245185852050781, -0.041439056396484375]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlk2cf6wf4rlgo3csyy",
            "tokens": [
                "<|endoftext|>",
                "ed",
                " with",
                " areas",
                " of",
                " high",
                "-",
                "volume",
                " cocaine",
                " trafficking",
                ".",
                " S",
                "es",
                "nie",
                "\u00e2\u0122",
                "\u013b",
                "s"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 45.8880500793457,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                45.8880500793457,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -2.647560119628906,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \"stasy\", \" addicts\", \" addiction\"], \"v\": [7.721661567687988, 6.575592994689941, 4.99623966217041, 4.848021507263184, 4.726291656494141]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \" Arbor\", \"hof\", \"aer\", \"lying\"], \"v\": [-17.392637252807617, -16.880258560180664, -16.834365844726562, -16.600067138671875, -16.587377548217773]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlk2cf7wf4rpieugfm7",
            "tokens": [
                " affordable",
                "<|endoftext|>",
                " wage",
                ",",
                " a",
                " small",
                " bag",
                " of",
                " cocaine",
                " costs",
                " like",
                " eight",
                " hours",
                "!",
                " And",
                " here",
                "'s"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 45.60016250610352,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                45.60016250610352,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.05587387084961,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \"stasy\", \" sulf\", \" addiction\"], \"v\": [7.212682723999023, 7.083217620849609, 4.989355564117432, 4.797695159912109, 4.536730766296387]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"lying\", \" Arbor\", \"hof\", \"aer\"], \"v\": [-17.76119041442871, -16.95343017578125, -16.91598129272461, -16.90216827392578, -16.352081298828125]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlk2cf8wf4rkzl82myi",
            "tokens": [
                " Sheila",
                " Steele",
                "\u010a",
                "\u010a",
                "-",
                "Ad",
                "ults",
                " use",
                " cocaine",
                " to",
                " stay",
                " up",
                " later",
                " than",
                " their",
                " day",
                " jobs"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 44.89813995361328,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                44.89813995361328,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.627331733703613,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" addiction\", \"stasy\", \" overdose\"], \"v\": [11.239948272705078, 9.735578536987305, 8.259637832641602, 8.174997329711914, 8.130531311035156]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"Reviewer\", \"hof\", \" Arbor\", \"aer\"], \"v\": [-15.194798469543457, -14.2564697265625, -14.171642303466797, -14.105426788330078, -13.796038627624512]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlk2cf9wf4rrnfxoohi",
            "tokens": [
                ",",
                " lost",
                " or",
                " delivered",
                ".",
                "\u010a",
                "\u010a",
                "Most",
                " cocaine",
                " production",
                " occurs",
                " in",
                " Peru",
                ",",
                " Bolivia",
                " and",
                " Colombia"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 44.7603645324707,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                44.7603645324707,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -1.777121543884277,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \"stasy\", \" overdose\", \" addiction\"], \"v\": [12.690727233886719, 10.829568862915039, 10.80080509185791, 9.530845642089844, 9.505630493164062]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \" Arbor\", \"aer\", \"Bird\", \"hof\"], \"v\": [-13.534910202026367, -12.712562561035156, -12.558855056762695, -12.477897644042969, -12.39912223815918]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlk2cfawf4rxsnss4sr",
            "tokens": [
                " A",
                " Mexican",
                " soldier",
                " stands",
                " by",
                " as",
                " piles",
                " of",
                " cocaine",
                " are",
                " burnt",
                "\u010a",
                "\u010a",
                "U",
                ".",
                "S",
                "."
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 44.41254425048828,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                44.41254425048828,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.521652221679688,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" overdose\", \"stasy\", \" overdoses\"], \"v\": [8.906888961791992, 8.1490478515625, 6.798316478729248, 6.707181453704834, 6.390153408050537]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"lying\", \" Arbor\", \"hof\", \" Forge\"], \"v\": [-16.263336181640625, -15.916471481323242, -15.247976303100586, -15.050460815429688, -14.464723587036133]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfbwf4rug6lmwdw",
            "tokens": [
                ".",
                " Te",
                "ens",
                " really",
                " have",
                " no",
                " business",
                " taking",
                " cocaine",
                ".",
                " For",
                " parents",
                " who",
                " want",
                " to",
                " talk",
                " to"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 43.56198883056641,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                43.56198883056641,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.290102481842041,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" residue\", \" cocaine\", \" addicts\", \" addiction\", \" overdose\"], \"v\": [9.204132080078125, 9.018756866455078, 6.646199703216553, 6.560135841369629, 6.375736713409424]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Arbor\", \"igating\", \" Forge\", \"hof\", \"lying\"], \"v\": [-16.429288864135742, -16.38599967956543, -15.166587829589844, -15.16463851928711, -15.131141662597656]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfcwf4r9rlwt4pq",
            "tokens": [
                "otics",
                " database",
                ",",
                " which",
                " quant",
                "ifies",
                " how",
                " much",
                " cocaine",
                " per",
                " year",
                " is",
                " being",
                " transported",
                " to",
                " certain",
                " countries"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 43.44115829467773,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                43.44115829467773,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                4.78692626953125,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \"stasy\", \" addicts\", \" overdose\"], \"v\": [9.519689559936523, 7.686256408691406, 7.504075050354004, 6.94838809967041, 6.938863754272461]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \" Arbor\", \"lying\", \" Forge\", \"aer\"], \"v\": [-14.359323501586914, -13.797401428222656, -13.686485290527344, -13.38771915435791, -13.356607437133789]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfdwf4rdulx48j7",
            "tokens": [
                " Rubio",
                " have",
                " where",
                " it",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " all",
                " cocaine",
                " and",
                " yelling",
                " about",
                " war",
                "locks",
                " until",
                " you",
                " wake"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 42.98469924926758,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                42.98469924926758,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.664887428283691,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" sulf\", \" overdose\", \" traffickers\"], \"v\": [7.527346134185791, 7.492887020111084, 5.224616050720215, 5.197421550750732, 5.056792259216309]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"hof\", \"ril\", \"lying\", \"ait\"], \"v\": [-18.234846115112305, -17.038175582885742, -16.781076431274414, -16.665714263916016, -16.564899444580078]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfewf4rt42ttzaq",
            "tokens": [
                " while",
                " fabric",
                "ating",
                " claims",
                " that",
                " Year",
                "wood",
                " possessed",
                " cocaine",
                ".",
                " Year",
                "wood",
                "'s",
                " lawsuit",
                " was",
                " dismissed",
                " this"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 42.75520706176758,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                42.75520706176758,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.078126907348633,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" addicts\", \" sulf\", \" addiction\"], \"v\": [6.3677167892456055, 5.968297004699707, 4.775850296020508, 4.220144271850586, 4.1901068687438965]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"lying\", \" Arbor\", \"angering\", \"aer\"], \"v\": [-16.853843688964844, -16.606725692749023, -15.5623779296875, -14.974960327148438, -14.887350082397461]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cffwf4rh4lkgvwd",
            "tokens": [
                " help",
                "fully",
                " compiled",
                " the",
                " following",
                " real",
                " facts",
                " behind",
                " cocaine",
                " use",
                ".",
                "\u010a",
                "\u010a",
                "The",
                " energy",
                " drink",
                " version"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 42.72116088867188,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                42.72116088867188,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.605768203735352,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \"stasy\", \" overdose\", \" addicts\"], \"v\": [10.131392478942871, 9.022740364074707, 7.942654609680176, 7.560356140136719, 7.303768157958984]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \" Arbor\", \"Reviewer\", \"hof\", \"lying\"], \"v\": [-15.218717575073242, -14.330503463745117, -13.733316421508789, -13.372264862060547, -13.301633834838867]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfgwf4rsx1ta1zi",
            "tokens": [
                " -",
                " more",
                " than",
                " the",
                " price",
                " of",
                " gold",
                " or",
                " cocaine",
                ".",
                "\u010a",
                "\u010a",
                "South",
                " Africa",
                " is",
                " home",
                " to"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 42.4297981262207,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                42.4297981262207,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.645715713500977,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" addiction\", \" overdose\", \" overdoses\"], \"v\": [9.382149696350098, 9.081631660461426, 7.168153285980225, 6.860615253448486, 6.8201823234558105]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"hof\", \" IEEE\", \" Arbor\", \"lying\"], \"v\": [-15.593582153320312, -15.514911651611328, -14.749432563781738, -14.73269271850586, -14.641559600830078]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlm2cgjwf4rzu22gu9n",
            "tokens": [
                " small",
                " amounts",
                " of",
                " marijuana",
                ",",
                " crack",
                " cocaine",
                " and",
                " methamphetamine",
                ",",
                " she",
                " said",
                ".",
                "\u010a",
                "\u010a",
                "Investigators",
                " released"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 41.47529983520508,
            "maxValueTokenIndex": 6,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                3.174279689788818,
                41.47529983520508,
                0,
                6.501777648925781,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                -0.6929945945739746,
                5.634080410003662,
                0,
                0.8390750885009766,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {\"t\": [\" residue\", \" sulf\", \" cocaine\", \" overdose\", \"stasy\"], \"v\": [0.8426036834716797, 0.6990928649902344, 0.6929945945739746, 0.6904087066650391, 0.6748275756835938]}, {\"t\": [\" cocaine\", \" residue\", \"stasy\", \" sulf\", \" overdose\"], \"v\": [7.718047142028809, 6.530123710632324, 5.237048149108887, 4.883133888244629, 4.7788848876953125]}, {}, {\"t\": [\" cocaine\", \" residue\", \"amide\", \" overdose\", \" morphine\"], \"v\": [1.085742473602295, 0.7824612855911255, 0.6564064025878906, 0.6052460670471191, 0.5397815704345703]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"lying\", \"ership\", \"\\u012a\\u0134\", \" Arbor\"], \"v\": [-1.157135009765625, -1.0690650939941406, -1.000295639038086, -0.9793605804443359, -0.9689464569091797]}, {\"t\": [\"igating\", \"lying\", \" Forge\", \"rors\", \"\\u012a\\u0134\"], \"v\": [-17.171348571777344, -17.163318634033203, -17.134136199951172, -16.47458839416504, -16.330583572387695]}, {}, {\"t\": [\"igating\", \"lying\", \"yll\", \"rors\", \"hof\"], \"v\": [-2.493276596069336, -2.3804378509521484, -2.3137435913085938, -2.310863494873047, -2.2878360748291016]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlm2cg8wf4rgknmxzfe",
            "tokens": [
                " armed",
                " guards",
                " in",
                " the",
                " house",
                " and",
                " steal",
                " the",
                " cocaine",
                ".",
                " Once",
                " the",
                " crew",
                " meets",
                " to",
                " prepare",
                " for"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 40.55965423583984,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                40.55965423583984,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.241560935974121,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" addicts\", \" overdoses\", \" sulf\"], \"v\": [9.619438171386719, 8.360628128051758, 7.407281398773193, 7.114612102508545, 7.079580307006836]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"lying\", \" Arbor\", \"hof\", \"Bird\"], \"v\": [-12.867698669433594, -12.766090393066406, -12.480813980102539, -12.257482528686523, -11.882165908813477]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlm2cg6wf4ryrt2jds7",
            "tokens": [
                " and",
                " Colombia",
                ",",
                " but",
                " 86",
                " percent",
                " of",
                " the",
                " cocaine",
                " that",
                " arrives",
                " in",
                " the",
                " US",
                " is",
                " currently",
                " transported"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 39.24897003173828,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                39.24897003173828,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.768365859985352,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \"stasy\", \" residue\", \" addiction\", \" addicts\"], \"v\": [10.51045036315918, 9.398115158081055, 9.050989151000977, 8.37318229675293, 8.310558319091797]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \" Arbor\", \"lying\", \"aer\", \"hof\"], \"v\": [-12.19798469543457, -11.492837905883789, -11.49266242980957, -11.306556701660156, -11.266407012939453]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlm2cgbwf4rluylhf7q",
            "tokens": [
                "\u013f",
                ",",
                " Op",
                "ium",
                ",",
                " Hero",
                "in",
                ",",
                " Coc",
                "aine",
                ",",
                " and",
                " Hash",
                "ish",
                ".",
                "\u010a",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 18.97171592712402,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                18.97171592712402,
                10.68910312652588,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -1.311023473739624,
                0.8843264579772949,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" addiction\", \" overdoses\", \" addicts\"], \"v\": [6.553654670715332, 6.125940322875977, 5.636645317077637, 5.590606689453125, 5.579008102416992]}, {\"t\": [\" cocaine\", \" residue\", \"stasy\", \" craving\", \" addiction\"], \"v\": [2.788693904876709, 2.594632625579834, 2.201730728149414, 2.04083251953125, 2.036400318145752]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"lying\", \"laus\", \"soType\", \"ament\"], \"v\": [-4.809934616088867, -4.701786041259766, -4.681781768798828, -4.567760467529297, -4.498027801513672]}, {\"t\": [\"hof\", \"igating\", \" Arbor\", \"\\u012a\\u0134\", \" Ded\"], \"v\": [-4.145021438598633, -4.0866546630859375, -3.9716835021972656, -3.786954879760742, -3.7561206817626953]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlm2cggwf4r74rxscr1",
            "tokens": [
                ",",
                " Op",
                "ium",
                ",",
                " Hero",
                "in",
                ",",
                " Coc",
                "aine",
                ",",
                " and",
                " Hash",
                "ish",
                ".",
                "\u010a",
                "\u010a",
                "According"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 18.97171592712402,
            "maxValueTokenIndex": 7,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                18.97171592712402,
                10.68910312652588,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -1.311023473739624,
                0.8843264579772949,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" addiction\", \" overdoses\", \" addicts\"], \"v\": [6.553654670715332, 6.125940322875977, 5.636645317077637, 5.590606689453125, 5.579008102416992]}, {\"t\": [\" cocaine\", \" residue\", \"stasy\", \" craving\", \" addiction\"], \"v\": [2.788693904876709, 2.594632625579834, 2.201730728149414, 2.04083251953125, 2.036400318145752]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"lying\", \"laus\", \"soType\", \"ament\"], \"v\": [-4.809934616088867, -4.701786041259766, -4.681781768798828, -4.567760467529297, -4.498027801513672]}, {\"t\": [\"hof\", \"igating\", \" Arbor\", \"\\u012a\\u0134\", \" Ded\"], \"v\": [-4.145021438598633, -4.0866546630859375, -3.9716835021972656, -3.786954879760742, -3.7561206817626953]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlm2cgcwf4rsf8iknd0",
            "tokens": [
                " person",
                ",",
                " and",
                " wasting",
                " money",
                " feels",
                " good",
                ".",
                " Coc",
                "aine",
                " activates",
                " the",
                " same",
                " pleasure",
                " centers",
                " in",
                " your"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 18.60702705383301,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                18.60702705383301,
                14.79197025299072,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.3569620847702026,
                1.756123542785645,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" overdose\", \" sulf\", \" addiction\"], \"v\": [5.612415313720703, 5.213227272033691, 4.500760078430176, 4.3913726806640625, 4.360401153564453]}, {\"t\": [\" cocaine\", \" residue\", \"stasy\", \" sulf\", \" addiction\"], \"v\": [2.5124945640563965, 2.114388942718506, 1.732193946838379, 1.5159473419189453, 1.3609089851379395]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"lying\", \"igating\", \"ament\", \" Arbor\", \"ril\"], \"v\": [-5.169078826904297, -5.137035369873047, -4.940242767333984, -4.852210998535156, -4.731353759765625]}, {\"t\": [\" Arbor\", \"igating\", \"hof\", \"lying\", \" Discuss\"], \"v\": [-5.802961349487305, -5.729686737060547, -5.46075439453125, -5.332670211791992, -5.309739112854004]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlm2cgdwf4rzulr1vm7",
            "tokens": [
                ",",
                " and",
                " wasting",
                " money",
                " feels",
                " good",
                ".",
                " Coc",
                "aine",
                " activates",
                " the",
                " same",
                " pleasure",
                " centers",
                " in",
                " your",
                " brain"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 18.60702705383301,
            "maxValueTokenIndex": 7,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                18.60702705383301,
                14.79197025299072,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.3569620847702026,
                1.756123542785645,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" overdose\", \" sulf\", \" addiction\"], \"v\": [5.612415313720703, 5.213227272033691, 4.500760078430176, 4.3913726806640625, 4.360401153564453]}, {\"t\": [\" cocaine\", \" residue\", \"stasy\", \" sulf\", \" addiction\"], \"v\": [2.5124945640563965, 2.114388942718506, 1.732193946838379, 1.5159473419189453, 1.3609089851379395]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"lying\", \"igating\", \"ament\", \" Arbor\", \"ril\"], \"v\": [-5.169078826904297, -5.137035369873047, -4.940242767333984, -4.852210998535156, -4.731353759765625]}, {\"t\": [\" Arbor\", \"igating\", \"hof\", \"lying\", \" Discuss\"], \"v\": [-5.802961349487305, -5.729686737060547, -5.46075439453125, -5.332670211791992, -5.309739112854004]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlm2cgiwf4rplbosyxb",
            "tokens": [
                "<|endoftext|>",
                " capt",
                "agon",
                " tablets",
                " contained",
                " amp",
                "hetamine",
                ",",
                " methamphetamine",
                ",",
                " ep",
                "hed",
                "rine",
                ",",
                " met",
                "ron",
                "id"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 11.27067279815674,
            "maxValueTokenIndex": 6,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                11.27067279815674,
                0,
                9.811307907104492,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.6011171340942383,
                0,
                1.463478088378906,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" addicts\", \" addiction\", \" cartels\"], \"v\": [2.5370731353759766, 2.1935768127441406, 1.748520851135254, 1.7466325759887695, 1.6558570861816406]}, {}, {\"t\": [\" cocaine\", \" residue\", \" overdose\", \"stasy\", \"amide\"], \"v\": [1.3873534202575684, 1.044818639755249, 0.7559599876403809, 0.7091422080993652, 0.6817407608032227]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"hof\", \"aer\", \"lying\", \"rors\"], \"v\": [-3.3078155517578125, -3.198925018310547, -3.1190567016601562, -3.112140655517578, -2.993724822998047]}, {}, {\"t\": [\"igating\", \"lying\", \"hof\", \"yll\", \"rors\"], \"v\": [-3.771089553833008, -3.691925048828125, -3.652189254760742, -3.5892200469970703, -3.519124984741211]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlm2cghwf4r48s5oy5y",
            "tokens": [
                " Lamb",
                " in",
                "<|endoftext|>",
                " capt",
                "agon",
                " tablets",
                " contained",
                " amp",
                "hetamine",
                ",",
                " methamphetamine",
                ",",
                " ep",
                "hed",
                "rine",
                ",",
                " met"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 11.27067279815674,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                11.27067279815674,
                0,
                9.811307907104492,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.6011171340942383,
                0,
                1.463478088378906,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" addicts\", \" addiction\", \" cartels\"], \"v\": [2.5370731353759766, 2.1935768127441406, 1.748520851135254, 1.7466325759887695, 1.6558570861816406]}, {}, {\"t\": [\" cocaine\", \" residue\", \" overdose\", \"stasy\", \"amide\"], \"v\": [1.3873534202575684, 1.044818639755249, 0.7559599876403809, 0.7091422080993652, 0.6817407608032227]}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"hof\", \"aer\", \"lying\", \"rors\"], \"v\": [-3.3078155517578125, -3.198925018310547, -3.1190567016601562, -3.112140655517578, -2.993724822998047]}, {}, {\"t\": [\"igating\", \"lying\", \"hof\", \"yll\", \"rors\"], \"v\": [-3.771089553833008, -3.691925048828125, -3.652189254760742, -3.5892200469970703, -3.519124984741211]}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlm2cgfwf4rl0ddzz6n",
            "tokens": [
                " ket",
                "amine",
                " (",
                "K",
                "et",
                ")",
                " and",
                " amp",
                "hetamine",
                " (",
                "Am",
                "ph",
                ")",
                " by",
                " drug",
                "-",
                "users"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 10.99629211425781,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                2.350606679916382,
                0,
                0,
                0,
                0,
                0,
                0,
                10.99629211425781,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0.1716294288635254,
                0,
                0,
                0,
                0,
                0,
                0,
                0.6917810440063477,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {\"t\": [\" cocaine\", \" residue\", \" addiction\", \" cartels\", \"stasy\"], \"v\": [0.5998940467834473, 0.5340571403503418, 0.42640256881713867, 0.42374229431152344, 0.41129112243652344]}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" addicts\", \" addiction\", \" trafficking\"], \"v\": [2.661595344543457, 2.3939743041992188, 1.9074745178222656, 1.8966798782348633, 1.7889480590820312]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {\"t\": [\"igating\", \"hof\", \"aer\", \"\\u012a\\u0134\", \"rors\"], \"v\": [-0.7821483612060547, -0.7682762145996094, -0.700714111328125, -0.6953010559082031, -0.6907558441162109]}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"hof\", \"lying\", \"aer\", \"rors\"], \"v\": [-3.18109130859375, -3.1461448669433594, -2.9896068572998047, -2.9720001220703125, -2.9368896484375]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlm2cgewf4rd2j2vtad",
            "tokens": [
                " the",
                " help",
                " of",
                " drugs",
                ",",
                " like",
                " MDMA",
                ",",
                " LSD",
                " and",
                " p",
                "sil",
                "ocy",
                "bin",
                ".",
                " After",
                " just"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 10.07769107818604,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                7.242860317230225,
                0,
                10.07769107818604,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.165995597839355,
                0,
                0.3993196487426758,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" craving\", \" addiction\", \" overdose\"], \"v\": [0.8700294494628906, 0.8055315017700195, 0.4837532043457031, 0.47032642364501953, 0.4683685302734375]}, {}, {\"t\": [\" cocaine\", \" residue\", \" addicts\", \" addiction\", \" overdose\"], \"v\": [2.547328472137451, 2.155223846435547, 1.9359984397888184, 1.9244446754455566, 1.8375191688537598]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {\"t\": [\"hof\", \"igating\", \"IGH\", \"LOC\", \"\\u012a\\u0134\"], \"v\": [-2.892505645751953, -2.886627197265625, -2.823160171508789, -2.6917285919189453, -2.6643848419189453]}, {}, {\"t\": [\"igating\", \"hof\", \"lich\", \"LOC\", \"IGH\"], \"v\": [-3.242450714111328, -3.043426513671875, -2.861959457397461, -2.8263206481933594, -2.793911933898926]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqln2cgnwf4rppkiecow",
            "tokens": [
                " 1",
                " narc",
                "otic",
                ",",
                " right",
                " up",
                " there",
                " with",
                " LSD",
                " and",
                " heroin",
                ".",
                " Purchase",
                " and",
                " K",
                "ren",
                "z"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 8.634666442871094,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.634666442871094,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.3370637893676758,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" addiction\", \" addicts\", \" craving\"], \"v\": [2.0877199172973633, 1.7849390506744385, 1.636092185974121, 1.613877296447754, 1.4855155944824219]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"hof\", \"laus\", \"LOC\", \"lich\"], \"v\": [-2.774190902709961, -2.4601058959960938, -2.4083995819091797, -2.3927364349365234, -2.377366065979004]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqln2cglwf4rc4rfq07h",
            "tokens": [
                " sniff",
                "ed",
                " out",
                " 75",
                " pounds",
                " of",
                " liquid",
                " crystal",
                " methamphetamine",
                ".",
                "\u010a",
                "\u010a",
                "Police",
                " officers",
                " had",
                " stopped",
                " her"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 7.839604377746582,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.839604377746582,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.185290336608887,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" addiction\", \" addicts\", \" morphine\"], \"v\": [1.0288130044937134, 0.8642172813415527, 0.5919308662414551, 0.5793166160583496, 0.5562515258789062]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"rors\", \"igating\", \"lying\", \"hof\", \"yll\"], \"v\": [-2.937654495239258, -2.8839054107666016, -2.861764907836914, -2.7954959869384766, -2.716747283935547]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqln2cgkwf4rx1ggynia",
            "tokens": [
                "br",
                "ano",
                "-",
                "Mont",
                "es",
                " was",
                " high",
                " on",
                " methamphetamine",
                ".",
                "\u010a",
                "\u010a",
                "Cell",
                "phone",
                " video",
                " showed",
                " the"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 6.87968635559082,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.87968635559082,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.866363525390625,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" addicts\", \" overdose\", \" addiction\"], \"v\": [0.7120428085327148, 0.7063751220703125, 0.4750394821166992, 0.4533729553222656, 0.4532785415649414]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"igating\", \"lying\", \" Arbor\", \"yll\", \"DEM\"], \"v\": [-2.3726940155029297, -2.2718353271484375, -2.151630401611328, -2.140890121459961, -2.1305065155029297]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqln2cgmwf4re50ofro3",
            "tokens": [
                " This",
                " is",
                ",",
                " however",
                ",",
                " the",
                " reality",
                " in",
                " Ivory",
                " Coast",
                " where",
                " a",
                " trader",
                " has",
                " to",
                " pay",
                " 10"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 6.140501499176025,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.140501499176025,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.04920974373817444,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" cocaine\", \" residue\", \" overdose\", \" addiction\", \"stasy\"], \"v\": [2.3709659576416016, 2.1899871826171875, 2.0881290435791016, 2.0228710174560547, 1.9971675872802734]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Arbor\", \"hof\", \"Bird\", \"aer\", \" Forge\"], \"v\": [-1.3014106750488281, -1.296295166015625, -1.2786369323730469, -1.2034263610839844, -1.1934089660644531]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfmwf4rdxw1cf8n",
            "tokens": [
                " months",
                " preparing",
                " for",
                " his",
                " presumed",
                " assignment",
                " in",
                " Afghanistan",
                ".",
                "\u010a",
                "\u010a",
                "Di",
                "plom",
                "at",
                " Cro",
                "cker",
                " seen"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfhwf4r97whzt5v",
            "tokens": [
                " troops",
                " in",
                " Afghanistan",
                "<|endoftext|>",
                " few",
                " months",
                " preparing",
                " for",
                " his",
                " presumed",
                " assignment",
                " in",
                " Afghanistan",
                ".",
                "\u010a",
                "\u010a",
                "Di"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfiwf4rl0apt027",
            "tokens": [
                " in",
                " Afghanistan",
                "<|endoftext|>",
                " few",
                " months",
                " preparing",
                " for",
                " his",
                " presumed",
                " assignment",
                " in",
                " Afghanistan",
                ".",
                "\u010a",
                "\u010a",
                "Di",
                "plom"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfjwf4r3jcuebhb",
            "tokens": [
                " Afghanistan",
                "<|endoftext|>",
                " few",
                " months",
                " preparing",
                " for",
                " his",
                " presumed",
                " assignment",
                " in",
                " Afghanistan",
                ".",
                "\u010a",
                "\u010a",
                "Di",
                "plom",
                "at"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfkwf4rp18yy1cf",
            "tokens": [
                "<|endoftext|>",
                " few",
                " months",
                " preparing",
                " for",
                " his",
                " presumed",
                " assignment",
                " in",
                " Afghanistan",
                ".",
                "\u010a",
                "\u010a",
                "Di",
                "plom",
                "at",
                " Cro"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cflwf4rphh8a3v0",
            "tokens": [
                " few",
                " months",
                " preparing",
                " for",
                " his",
                " presumed",
                " assignment",
                " in",
                " Afghanistan",
                ".",
                "\u010a",
                "\u010a",
                "Di",
                "plom",
                "at",
                " Cro",
                "cker"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqln2cgswf4rk5qis9zy",
            "tokens": [
                " 49",
                " (",
                " 6",
                " ):",
                " 8",
                "01",
                " \u00e2\u0122\u0135",
                " 8",
                "15",
                " .",
                "\u010a",
                "\u010a",
                "Da",
                "al",
                "der",
                " ,",
                " I"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqln2cgrwf4rqli84nxb",
            "tokens": [
                "agin",
                ",",
                " a",
                " neuro",
                "scient",
                "ist",
                " and",
                " first",
                " author",
                " of",
                " the",
                " study",
                ".",
                " \u00e2\u0122",
                "\u013e",
                "\u00e2\u0122",
                "\u013a"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqln2cgqwf4r6jumi146",
            "tokens": [
                " aged",
                " under",
                "<|endoftext|>",
                " children",
                " of",
                " prisoners",
                " struggle",
                " with",
                " anxiety",
                ",",
                " bullying",
                " at",
                " school",
                " and",
                " grief",
                " over",
                " losing"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlm2cg0wf4r8ca1blgd",
            "tokens": [
                " Cro",
                "cker",
                " seen",
                " as",
                " top",
                " pick",
                " for",
                " Afghan",
                " post",
                "\u010a",
                "\u010a",
                "The",
                " changes",
                " are",
                " expected",
                " to",
                " be"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlm2cfzwf4rkmydms2k",
            "tokens": [
                "at",
                " Cro",
                "cker",
                " seen",
                " as",
                " top",
                " pick",
                " for",
                " Afghan",
                " post",
                "\u010a",
                "\u010a",
                "The",
                " changes",
                " are",
                " expected",
                " to"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqlm2cfywf4rm1pzlq4n",
            "tokens": [
                "plom",
                "at",
                " Cro",
                "cker",
                " seen",
                " as",
                " top",
                " pick",
                " for",
                " Afghan",
                " post",
                "\u010a",
                "\u010a",
                "The",
                " changes",
                " are",
                " expected"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfwwf4rnv9a03wd",
            "tokens": [
                "\u010a",
                "Di",
                "plom",
                "at",
                " Cro",
                "cker",
                " seen",
                " as",
                " top",
                " pick",
                " for",
                " Afghan",
                " post",
                "\u010a",
                "\u010a",
                "The",
                " changes"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfvwf4rkvligmwq",
            "tokens": [
                "\u010a",
                "\u010a",
                "Di",
                "plom",
                "at",
                " Cro",
                "cker",
                " seen",
                " as",
                " top",
                " pick",
                " for",
                " Afghan",
                " post",
                "\u010a",
                "\u010a",
                "The"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfuwf4r84njcdz6",
            "tokens": [
                ".",
                "\u010a",
                "\u010a",
                "Di",
                "plom",
                "at",
                " Cro",
                "cker",
                " seen",
                " as",
                " top",
                " pick",
                " for",
                " Afghan",
                " post",
                "\u010a",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cftwf4rytj6bpuh",
            "tokens": [
                " Afghanistan",
                ".",
                "\u010a",
                "\u010a",
                "Di",
                "plom",
                "at",
                " Cro",
                "cker",
                " seen",
                " as",
                " top",
                " pick",
                " for",
                " Afghan",
                " post",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfswf4r34kb2v6f",
            "tokens": [
                " in",
                " Afghanistan",
                ".",
                "\u010a",
                "\u010a",
                "Di",
                "plom",
                "at",
                " Cro",
                "cker",
                " seen",
                " as",
                " top",
                " pick",
                " for",
                " Afghan",
                " post"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfxwf4rivbi9gv2",
            "tokens": [
                "Di",
                "plom",
                "at",
                " Cro",
                "cker",
                " seen",
                " as",
                " top",
                " pick",
                " for",
                " Afghan",
                " post",
                "\u010a",
                "\u010a",
                "The",
                " changes",
                " are"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfrwf4rjj018oqx",
            "tokens": [
                " assignment",
                " in",
                " Afghanistan",
                ".",
                "\u010a",
                "\u010a",
                "Di",
                "plom",
                "at",
                " Cro",
                "cker",
                " seen",
                " as",
                " top",
                " pick",
                " for",
                " Afghan"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfqwf4rba6w9kf2",
            "tokens": [
                " presumed",
                " assignment",
                " in",
                " Afghanistan",
                ".",
                "\u010a",
                "\u010a",
                "Di",
                "plom",
                "at",
                " Cro",
                "cker",
                " seen",
                " as",
                " top",
                " pick",
                " for"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqln2cgowf4r0ptoul4w",
            "tokens": [
                " the",
                " issue",
                " of",
                " the",
                " missing",
                " emails",
                " associated",
                " with",
                " former",
                " IRS",
                " official",
                " Lois",
                " Lerner",
                ",\"",
                " President",
                " of",
                " Judicial"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfnwf4r8ogniev3",
            "tokens": [
                " preparing",
                " for",
                " his",
                " presumed",
                " assignment",
                " in",
                " Afghanistan",
                ".",
                "\u010a",
                "\u010a",
                "Di",
                "plom",
                "at",
                " Cro",
                "cker",
                " seen",
                " as"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfpwf4rnqdnnto0",
            "tokens": [
                " his",
                " presumed",
                " assignment",
                " in",
                " Afghanistan",
                ".",
                "\u010a",
                "\u010a",
                "Di",
                "plom",
                "at",
                " Cro",
                "cker",
                " seen",
                " as",
                " top",
                " pick"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqll2cfowf4r5hj2bxnu",
            "tokens": [
                " for",
                " his",
                " presumed",
                " assignment",
                " in",
                " Afghanistan",
                ".",
                "\u010a",
                "\u010a",
                "Di",
                "plom",
                "at",
                " Cro",
                "cker",
                " seen",
                " as",
                " top"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi5aqln2cgpwf4re9uwa9l7",
            "tokens": [
                " shop",
                " dating",
                " back",
                " in",
                " 1906",
                ".",
                " Photo",
                " Credit",
                ":",
                " F",
                "oy",
                "les",
                " Archive",
                "\u010a",
                "\u010a",
                "It",
                " was"
            ],
            "dataIndex": null,
            "index": "292",
            "layer": "5-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-11T23:37:20.042Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        }
    ],
    "explanations": [
        {
            "id": "clsxrxsa90519enuxpig176ap",
            "modelId": "gpt2-small",
            "layer": "5-res-jb",
            "index": "292",
            "description": "mentions of the drug \"cocaine.\"",
            "authorId": "clsxqq2xd0000vvp2k5itlhqj",
            "triggeredByUserId": null,
            "notes": null,
            "scoreV1": 0,
            "scoreV2": null,
            "umap_x": 8.814639,
            "umap_y": 11.860011,
            "umap_cluster": 224,
            "umap_log_feature_sparsity": -3.8270302,
            "typeName": "oai_token-act-pair",
            "explanationModelName": "gpt-3.5-turbo",
            "createdAt": "2024-02-22T22:07:41.170Z",
            "updatedAt": "2024-02-22T22:07:41.170Z",
            "triggeredByUser": null,
            "scores": []
        }
    ]
}