{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "temple"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "30596",
            "description": " mentions of religious or spiritual places, specifically temples",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 56.172,
            "frac_nonzero": 5e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "30596",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:53:54.144Z",
                "maxActApprox": 56.172,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    30596,
                    14142,
                    19200,
                    1909,
                    47768,
                    25919,
                    36481,
                    42535,
                    13481,
                    40581,
                    20350,
                    22754,
                    31252,
                    14004,
                    18246,
                    30911,
                    30974,
                    15183,
                    5663,
                    45003,
                    24100,
                    28909,
                    44437,
                    25794,
                    47536
                ],
                "topkCosSimValues": [
                    1,
                    0.6849,
                    0.4524,
                    0.42,
                    0.4059,
                    0.3858,
                    0.3731,
                    0.3724,
                    0.3682,
                    0.3673,
                    0.3589,
                    0.3575,
                    0.3542,
                    0.3377,
                    0.3286,
                    0.3234,
                    0.3214,
                    0.3212,
                    0.3212,
                    0.3211,
                    0.3181,
                    0.3098,
                    0.3065,
                    0.3043,
                    0.3035
                ],
                "neuron_alignment_indices": [
                    288,
                    647,
                    207
                ],
                "neuron_alignment_values": [
                    0.11,
                    0.095,
                    0.09
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    325,
                    288,
                    224
                ],
                "correlated_neurons_pearson": [
                    0.007,
                    0.006,
                    0.006
                ],
                "correlated_neurons_l1": [
                    0.007,
                    0.007,
                    0.007
                ],
                "correlated_features_indices": [
                    30694,
                    30633,
                    30682
                ],
                "correlated_features_pearson": [
                    0.019,
                    0.002,
                    0.001
                ],
                "correlated_features_l1": [
                    0.019,
                    0.002,
                    0.002
                ],
                "neg_str": [
                    "iability",
                    "imil",
                    "hazard",
                    "ombie",
                    "ombies",
                    "Consumer",
                    "nesota",
                    "ial",
                    "agents",
                    "hops"
                ],
                "neg_values": [
                    -0.788,
                    -0.768,
                    -0.713,
                    -0.709,
                    -0.707,
                    -0.692,
                    -0.689,
                    -0.688,
                    -0.67,
                    -0.667
                ],
                "pos_str": [
                    "Stone",
                    " Mount",
                    "ton",
                    "keeper",
                    "keepers",
                    "inence",
                    " Garden",
                    "porary",
                    "plates",
                    "stein"
                ],
                "pos_values": [
                    0.801,
                    0.788,
                    0.783,
                    0.78,
                    0.771,
                    0.733,
                    0.723,
                    0.719,
                    0.715,
                    0.708
                ],
                "frac_nonzero": 5e-05,
                "freq_hist_data_bar_heights": [
                    40,
                    29,
                    14,
                    15,
                    9,
                    6,
                    2,
                    6,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    3,
                    5,
                    2,
                    1,
                    0,
                    0,
                    3,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.563,
                    1.686,
                    2.81,
                    3.933,
                    5.056,
                    6.18,
                    7.303,
                    8.427,
                    9.55,
                    10.673,
                    11.797,
                    12.92,
                    14.044,
                    15.167,
                    16.291,
                    17.414,
                    18.537,
                    19.661,
                    20.784,
                    21.908,
                    23.031,
                    24.155,
                    25.278,
                    26.401,
                    27.525,
                    28.648,
                    29.772,
                    30.895,
                    32.018,
                    33.142,
                    34.265,
                    35.389,
                    36.512,
                    37.636,
                    38.759,
                    39.882,
                    41.006,
                    42.129,
                    43.253,
                    44.376,
                    45.5,
                    46.623,
                    47.746,
                    48.87,
                    49.993,
                    51.117,
                    52.24,
                    53.363,
                    54.487,
                    55.61
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    0,
                    3,
                    5,
                    5,
                    10,
                    19,
                    27,
                    34,
                    60,
                    84,
                    143,
                    199,
                    281,
                    432,
                    639,
                    940,
                    1236,
                    1604,
                    2212,
                    2874,
                    3187,
                    3784,
                    4134,
                    4372,
                    4183,
                    3925,
                    3439,
                    2969,
                    2451,
                    1865,
                    1422,
                    1085,
                    745,
                    584,
                    410,
                    288,
                    207,
                    145,
                    88,
                    56,
                    38,
                    28,
                    5,
                    17,
                    5,
                    6,
                    5,
                    0,
                    5
                ],
                "logits_hist_data_bar_values": [
                    -0.772,
                    -0.74,
                    -0.708,
                    -0.677,
                    -0.645,
                    -0.613,
                    -0.581,
                    -0.55,
                    -0.518,
                    -0.486,
                    -0.454,
                    -0.422,
                    -0.391,
                    -0.359,
                    -0.327,
                    -0.295,
                    -0.264,
                    -0.232,
                    -0.2,
                    -0.168,
                    -0.136,
                    -0.105,
                    -0.073,
                    -0.041,
                    -0.009,
                    0.022,
                    0.054,
                    0.086,
                    0.118,
                    0.149,
                    0.181,
                    0.213,
                    0.245,
                    0.277,
                    0.308,
                    0.34,
                    0.372,
                    0.404,
                    0.435,
                    0.467,
                    0.499,
                    0.531,
                    0.562,
                    0.594,
                    0.626,
                    0.658,
                    0.69,
                    0.721,
                    0.753,
                    0.785
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyvgg11c1yfznba6gdp7dbwn",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs49152-jb",
                        "index": "30596",
                        "description": " mentions of religious or spiritual places, specifically temples",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-21T11:08:38.592Z",
                        "updatedAt": "2024-07-21T11:08:38.592Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk63pu23u5li666iann4bu6",
                        "tokens": [
                            "\u013e",
                            "ge",
                            "ek",
                            "y",
                            "\u00e2\u0122",
                            "\u013f",
                            " hybrid",
                            " hopes",
                            " to",
                            " contribute",
                            " to",
                            " the",
                            " burgeoning",
                            " Kens",
                            "ington",
                            " section",
                            " of",
                            " Philadelphia",
                            ".",
                            " Am",
                            "alg",
                            "am",
                            " hopes",
                            " to",
                            " build",
                            " community",
                            " around",
                            " comics",
                            ",",
                            " coffee",
                            ",",
                            " and",
                            " relaxing",
                            " with",
                            " friends",
                            ",",
                            " and",
                            " also",
                            " through",
                            " hosting",
                            " geek",
                            "y",
                            " and",
                            " diversity",
                            "-",
                            "themed",
                            " workshops",
                            ",",
                            " movie",
                            "/",
                            "TV",
                            " screenings",
                            ",",
                            " book",
                            " signings",
                            ",",
                            " and",
                            " BY",
                            "OB",
                            " nights",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "I",
                            " got",
                            " the",
                            " idea",
                            " for",
                            " the",
                            " shop",
                            " about",
                            " 12",
                            " years",
                            " ago",
                            ",",
                            " when",
                            " I",
                            " was",
                            " still",
                            " attending",
                            " Temple",
                            " University",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Am",
                            "alg",
                            "am",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " owner",
                            ",",
                            " Ari",
                            "ell",
                            " R",
                            ".",
                            " Johnson",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "My",
                            " favorite",
                            " coffee",
                            " shop",
                            " was",
                            " directly",
                            " across",
                            " the",
                            " street",
                            " from",
                            " my",
                            " comic",
                            " book",
                            " store",
                            " of",
                            " choice",
                            ".",
                            " So",
                            ",",
                            " each",
                            " Friday",
                            ",",
                            " I",
                            " would",
                            " buy"
                        ],
                        "dataIndex": null,
                        "index": "30596",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.172,
                        "maxValueTokenIndex": 80,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            56.172,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:53:57.444Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 44.938,
                        "binMax": 56.172,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk63pu03u50i6663mn1q9u9",
                        "tokens": [
                            "\u013e",
                            "ge",
                            "ek",
                            "y",
                            "\u00e2\u0122",
                            "\u013f",
                            " hybrid",
                            " hopes",
                            " to",
                            " contribute",
                            " to",
                            " the",
                            " burgeoning",
                            " Kens",
                            "ington",
                            " section",
                            " of",
                            " Philadelphia",
                            ".",
                            " Am",
                            "alg",
                            "am",
                            " hopes",
                            " to",
                            " build",
                            " community",
                            " around",
                            " comics",
                            ",",
                            " coffee",
                            ",",
                            " and",
                            " relaxing",
                            " with",
                            " friends",
                            ",",
                            " and",
                            " also",
                            " through",
                            " hosting",
                            " geek",
                            "y",
                            " and",
                            " diversity",
                            "-",
                            "themed",
                            " workshops",
                            ",",
                            " movie",
                            "/",
                            "TV",
                            " screenings",
                            ",",
                            " book",
                            " signings",
                            ",",
                            " and",
                            " BY",
                            "OB",
                            " nights",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "I",
                            " got",
                            " the",
                            " idea",
                            " for",
                            " the",
                            " shop",
                            " about",
                            " 12",
                            " years",
                            " ago",
                            ",",
                            " when",
                            " I",
                            " was",
                            " still",
                            " attending",
                            " Temple",
                            " University",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Am",
                            "alg",
                            "am",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " owner",
                            ",",
                            " Ari",
                            "ell",
                            " R",
                            ".",
                            " Johnson",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "My",
                            " favorite",
                            " coffee",
                            " shop",
                            " was",
                            " directly",
                            " across",
                            " the",
                            " street",
                            " from",
                            " my",
                            " comic",
                            " book",
                            " store",
                            " of",
                            " choice",
                            ".",
                            " So",
                            ",",
                            " each",
                            " Friday",
                            ",",
                            " I",
                            " would",
                            " buy"
                        ],
                        "dataIndex": null,
                        "index": "30596",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.172,
                        "maxValueTokenIndex": 80,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            56.172,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:53:57.444Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 56.172,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk63pu03u51i666zrfyvzge",
                        "tokens": [
                            ",",
                            " Dee",
                            " Ann",
                            " H",
                            "aney",
                            ",",
                            " was",
                            " involved",
                            " in",
                            " a",
                            " vehicle",
                            " accident",
                            " last",
                            " night",
                            " that",
                            " resulted",
                            " in",
                            " two",
                            " deaths",
                            ".",
                            " Our",
                            " deepest",
                            " condolences",
                            " go",
                            " to",
                            " the",
                            " families",
                            " of",
                            " those",
                            " who",
                            " lost",
                            " their",
                            " lives",
                            ".\"",
                            "North",
                            "bound",
                            " Gulf",
                            " Fre",
                            "eway",
                            " was",
                            " shut",
                            " down",
                            " heading",
                            " out",
                            " of",
                            " the",
                            " island",
                            " for",
                            " hours",
                            " during",
                            " the",
                            " investigation",
                            ".",
                            "<|endoftext|>",
                            "D",
                            "aryl",
                            " Hall",
                            " is",
                            " the",
                            " taller",
                            ",",
                            " more",
                            " visible",
                            " half",
                            " of",
                            " Hall",
                            " &",
                            " O",
                            "ates",
                            ",",
                            " one",
                            " of",
                            " the",
                            " best",
                            "-",
                            "selling",
                            " musical",
                            " du",
                            "os",
                            " of",
                            " all",
                            " time",
                            " who",
                            ",",
                            " despite",
                            " being",
                            " induct",
                            "ed",
                            " into",
                            " the",
                            " Rock",
                            " &",
                            " Roll",
                            " Hall",
                            " of",
                            " Fame",
                            ",",
                            " never",
                            " quite",
                            " got",
                            " the",
                            " sort",
                            " of",
                            " critical",
                            " love",
                            " that",
                            " many",
                            " other",
                            " induct",
                            "ees",
                            " have",
                            " generated",
                            ".",
                            " Hall",
                            " and",
                            " John",
                            " O",
                            "ates",
                            " met",
                            " while",
                            " attending",
                            " Temple",
                            " University",
                            " in",
                            " Philadelphia",
                            ",",
                            " a"
                        ],
                        "dataIndex": null,
                        "index": "30596",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 55.461,
                        "maxValueTokenIndex": 121,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            55.461,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:53:57.444Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 56.172,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "22506",
            "description": "references to places of worship, specifically temples",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 53.477,
            "frac_nonzero": 0.00019,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "22506",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:13:32.754Z",
                "maxActApprox": 53.477,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    22506,
                    14337,
                    13687,
                    11620,
                    2034,
                    579,
                    18301,
                    22661,
                    23403,
                    10270,
                    15674,
                    8043,
                    23507,
                    16032,
                    10321,
                    6581,
                    18993,
                    15955,
                    20936,
                    5777,
                    14316,
                    11561,
                    13438,
                    10300,
                    11568
                ],
                "topkCosSimValues": [
                    1,
                    0.5226,
                    0.4799,
                    0.4752,
                    0.4268,
                    0.4263,
                    0.4219,
                    0.4142,
                    0.4093,
                    0.4011,
                    0.388,
                    0.3786,
                    0.3752,
                    0.3711,
                    0.3659,
                    0.3626,
                    0.36,
                    0.3597,
                    0.3591,
                    0.3588,
                    0.3561,
                    0.3556,
                    0.349,
                    0.3439,
                    0.3336
                ],
                "neuron_alignment_indices": [
                    288,
                    447,
                    416
                ],
                "neuron_alignment_values": [
                    0.138,
                    0.106,
                    0.097
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    288,
                    325,
                    231
                ],
                "correlated_neurons_pearson": [
                    0.012,
                    0.011,
                    0.01
                ],
                "correlated_neurons_l1": [
                    0.013,
                    0.011,
                    0.01
                ],
                "correlated_features_indices": [
                    22433,
                    22492,
                    22424
                ],
                "correlated_features_pearson": [
                    0.01,
                    0.007,
                    0.002
                ],
                "correlated_features_l1": [
                    0.011,
                    0.007,
                    0.002
                ],
                "neg_str": [
                    "iability",
                    "\u00d1\u012e",
                    "leneck",
                    "20439",
                    "agher",
                    "ives",
                    "nesota",
                    "imil",
                    "sen",
                    "Consumer"
                ],
                "neg_values": [
                    -0.815,
                    -0.76,
                    -0.734,
                    -0.715,
                    -0.692,
                    -0.685,
                    -0.684,
                    -0.682,
                    -0.669,
                    -0.646
                ],
                "pos_str": [
                    " ceremonies",
                    " temple",
                    " temples",
                    "anus",
                    " procession",
                    "plates",
                    " ceremony",
                    " bells",
                    "keeper",
                    " rites"
                ],
                "pos_values": [
                    0.905,
                    0.868,
                    0.823,
                    0.805,
                    0.792,
                    0.792,
                    0.776,
                    0.769,
                    0.753,
                    0.751
                ],
                "frac_nonzero": 0.00019,
                "freq_hist_data_bar_heights": [
                    225,
                    144,
                    65,
                    46,
                    27,
                    16,
                    10,
                    5,
                    5,
                    3,
                    4,
                    2,
                    0,
                    2,
                    2,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    2,
                    4,
                    3,
                    0,
                    4,
                    2,
                    3,
                    4,
                    2,
                    2,
                    3,
                    6,
                    2,
                    4,
                    3,
                    3,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.537,
                    1.606,
                    2.676,
                    3.745,
                    4.815,
                    5.884,
                    6.954,
                    8.023,
                    9.093,
                    10.162,
                    11.232,
                    12.301,
                    13.371,
                    14.44,
                    15.51,
                    16.579,
                    17.649,
                    18.718,
                    19.788,
                    20.857,
                    21.927,
                    22.996,
                    24.066,
                    25.135,
                    26.205,
                    27.274,
                    28.344,
                    29.413,
                    30.483,
                    31.552,
                    32.622,
                    33.691,
                    34.761,
                    35.83,
                    36.9,
                    37.969,
                    39.039,
                    40.108,
                    41.178,
                    42.247,
                    43.317,
                    44.386,
                    45.456,
                    46.525,
                    47.595,
                    48.664,
                    49.734,
                    50.803,
                    51.873,
                    52.942
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    2,
                    4,
                    2,
                    2,
                    7,
                    19,
                    38,
                    67,
                    90,
                    167,
                    241,
                    407,
                    613,
                    905,
                    1249,
                    1726,
                    2268,
                    2749,
                    3435,
                    3978,
                    4413,
                    4397,
                    4347,
                    4109,
                    3481,
                    2908,
                    2282,
                    1853,
                    1307,
                    995,
                    688,
                    473,
                    337,
                    225,
                    167,
                    114,
                    53,
                    47,
                    32,
                    13,
                    11,
                    10,
                    10,
                    6,
                    4,
                    2,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.798,
                    -0.764,
                    -0.729,
                    -0.695,
                    -0.66,
                    -0.626,
                    -0.592,
                    -0.557,
                    -0.523,
                    -0.488,
                    -0.454,
                    -0.42,
                    -0.385,
                    -0.351,
                    -0.316,
                    -0.282,
                    -0.248,
                    -0.213,
                    -0.179,
                    -0.144,
                    -0.11,
                    -0.076,
                    -0.041,
                    -0.007,
                    0.028,
                    0.062,
                    0.096,
                    0.131,
                    0.165,
                    0.2,
                    0.234,
                    0.268,
                    0.303,
                    0.337,
                    0.372,
                    0.406,
                    0.441,
                    0.475,
                    0.509,
                    0.544,
                    0.578,
                    0.613,
                    0.647,
                    0.681,
                    0.716,
                    0.75,
                    0.785,
                    0.819,
                    0.853,
                    0.888
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clytpkvay01862ywtb1o8hcsf",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs24576-jb",
                        "index": "22506",
                        "description": "references to places of worship, specifically temples",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-20T05:48:48.635Z",
                        "updatedAt": "2024-07-20T05:48:48.635Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdn1ebale3wi6661tbglxp9",
                        "tokens": [
                            " our",
                            " land",
                            ",",
                            " those",
                            " that",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " belong",
                            " here",
                            ",",
                            " those",
                            " that",
                            " seek",
                            " to",
                            " destroy",
                            " and",
                            " replace",
                            " us",
                            ",",
                            " those",
                            " whose",
                            " Holy",
                            " book",
                            " pre",
                            "aches",
                            " hate",
                            " against",
                            " the",
                            " non",
                            "-",
                            "bel",
                            "iever",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            " matters",
                            " not",
                            " that",
                            " their",
                            " traditions",
                            " offend",
                            " us",
                            " in",
                            " our",
                            " own",
                            " land",
                            ",",
                            " it",
                            " matters",
                            " not",
                            " to",
                            " the",
                            " Liberals",
                            " that",
                            " the",
                            " foreigners",
                            " preach",
                            " hate",
                            " against",
                            " the",
                            " indigenous",
                            " people",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " of",
                            " this",
                            " fine",
                            " land",
                            ".",
                            "\n",
                            "\n",
                            "And",
                            " of",
                            " course",
                            ",",
                            " I",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " disagree",
                            " that",
                            " Christmas",
                            " is",
                            " a",
                            " money",
                            "-",
                            "making",
                            " racket",
                            " that",
                            " makes",
                            " millions",
                            " for",
                            " the",
                            " store",
                            " owners",
                            " and",
                            " traders",
                            ",",
                            " those",
                            " who",
                            " bay",
                            "ed",
                            " for",
                            " his",
                            " blood",
                            " at",
                            " the",
                            " Temple",
                            " have",
                            " made",
                            " a",
                            " fortune",
                            " out",
                            " of",
                            " his",
                            " name",
                            " ever",
                            " since",
                            "!",
                            "\n",
                            "\n",
                            "Christmas"
                        ],
                        "dataIndex": null,
                        "index": "22506",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 53.477,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            53.477,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:13:39.711Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 53.477,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn1ebble3xi666xt1vy64t",
                        "tokens": [
                            "\u013e",
                            "ge",
                            "ek",
                            "y",
                            "\u00e2\u0122",
                            "\u013f",
                            " hybrid",
                            " hopes",
                            " to",
                            " contribute",
                            " to",
                            " the",
                            " burgeoning",
                            " Kens",
                            "ington",
                            " section",
                            " of",
                            " Philadelphia",
                            ".",
                            " Am",
                            "alg",
                            "am",
                            " hopes",
                            " to",
                            " build",
                            " community",
                            " around",
                            " comics",
                            ",",
                            " coffee",
                            ",",
                            " and",
                            " relaxing",
                            " with",
                            " friends",
                            ",",
                            " and",
                            " also",
                            " through",
                            " hosting",
                            " geek",
                            "y",
                            " and",
                            " diversity",
                            "-",
                            "themed",
                            " workshops",
                            ",",
                            " movie",
                            "/",
                            "TV",
                            " screenings",
                            ",",
                            " book",
                            " signings",
                            ",",
                            " and",
                            " BY",
                            "OB",
                            " nights",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "I",
                            " got",
                            " the",
                            " idea",
                            " for",
                            " the",
                            " shop",
                            " about",
                            " 12",
                            " years",
                            " ago",
                            ",",
                            " when",
                            " I",
                            " was",
                            " still",
                            " attending",
                            " Temple",
                            " University",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Am",
                            "alg",
                            "am",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " owner",
                            ",",
                            " Ari",
                            "ell",
                            " R",
                            ".",
                            " Johnson",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "My",
                            " favorite",
                            " coffee",
                            " shop",
                            " was",
                            " directly",
                            " across",
                            " the",
                            " street",
                            " from",
                            " my",
                            " comic",
                            " book",
                            " store",
                            " of",
                            " choice",
                            ".",
                            " So",
                            ",",
                            " each",
                            " Friday",
                            ",",
                            " I",
                            " would",
                            " buy"
                        ],
                        "dataIndex": null,
                        "index": "22506",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.527,
                        "maxValueTokenIndex": 80,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.527,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:13:39.711Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 53.477,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn1ebble3yi666cgy8meds",
                        "tokens": [
                            " against",
                            " Temple",
                            " and",
                            " nearly",
                            " paid",
                            " a",
                            " steep",
                            " price",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "We",
                            " sent",
                            " an",
                            " email",
                            " design",
                            " concept",
                            " to",
                            " the",
                            " NCAA",
                            " football",
                            " rules",
                            " committee",
                            ",",
                            " got",
                            " a",
                            " curs",
                            "ory",
                            " response",
                            " which",
                            " says",
                            ",",
                            " '",
                            "It",
                            " looks",
                            " good",
                            " to",
                            " us",
                            ",'\"",
                            " Vanderbilt",
                            " athletics",
                            " department",
                            " spokesman",
                            " Rod",
                            " Williamson",
                            " said",
                            " via",
                            " David",
                            " Cl",
                            "imer",
                            " of",
                            " The",
                            " Tenn",
                            "esse",
                            "an",
                            ".",
                            " \"",
                            "We",
                            " thought",
                            " that",
                            " meant",
                            " every",
                            " piece",
                            " of",
                            " the",
                            " communication",
                            " was",
                            " fine",
                            ".\"",
                            "\n",
                            "\n",
                            "Initially",
                            ",",
                            " officials",
                            " working",
                            " the",
                            " game",
                            " announced",
                            " that",
                            " the",
                            " Comm",
                            "od",
                            "ores",
                            "'",
                            " uniform",
                            " violation",
                            " would",
                            " result",
                            " in",
                            " a",
                            " loss",
                            " of",
                            " a",
                            " timeout",
                            " for",
                            " each",
                            " quarter",
                            " those",
                            " jerseys",
                            " were",
                            " worn",
                            ".",
                            " That",
                            " ruling",
                            " was",
                            " quickly",
                            " overturned",
                            ",",
                            " though",
                            " it",
                            " didn",
                            "'t",
                            " help",
                            " V",
                            "andy",
                            " in",
                            " the",
                            " long",
                            " run",
                            ",",
                            " as",
                            " it",
                            " was",
                            " blown",
                            " out",
                            " 37"
                        ],
                        "dataIndex": null,
                        "index": "22506",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.797,
                        "maxValueTokenIndex": 1,
                        "minValue": 0,
                        "values": [
                            0,
                            46.797,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:13:39.711Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 53.477,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "14142",
            "description": "references to temples",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 50.438,
            "frac_nonzero": 7.000000000000001e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "14142",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:23:50.009Z",
                "maxActApprox": 50.438,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    14142,
                    30596,
                    47768,
                    18246,
                    36481,
                    20350,
                    22754,
                    14004,
                    25919,
                    25135,
                    30911,
                    5663,
                    13481,
                    19200,
                    30974,
                    13962,
                    12949,
                    38130,
                    45507,
                    39177,
                    44332,
                    28905,
                    29822,
                    33060,
                    47354
                ],
                "topkCosSimValues": [
                    1,
                    0.6849,
                    0.5858,
                    0.5357,
                    0.5324,
                    0.5012,
                    0.4881,
                    0.4783,
                    0.465,
                    0.4616,
                    0.4588,
                    0.4533,
                    0.453,
                    0.4516,
                    0.4472,
                    0.4438,
                    0.4362,
                    0.4221,
                    0.4164,
                    0.4161,
                    0.4157,
                    0.4146,
                    0.4043,
                    0.4001,
                    0.3938
                ],
                "neuron_alignment_indices": [
                    288,
                    447,
                    740
                ],
                "neuron_alignment_values": [
                    0.161,
                    0.131,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    288,
                    231,
                    416
                ],
                "correlated_neurons_pearson": [
                    0.011,
                    0.01,
                    0.009
                ],
                "correlated_neurons_l1": [
                    0.011,
                    0.01,
                    0.009
                ],
                "correlated_features_indices": [
                    14132,
                    14124,
                    14181
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.002,
                    0.002
                ],
                "correlated_features_l1": [
                    0.005,
                    0.002,
                    0.002
                ],
                "neg_str": [
                    "\u00d1\u012e",
                    "Leary",
                    "20439",
                    "leneck",
                    "OVER",
                    "DOS",
                    " Barkley",
                    "iability",
                    "nesota",
                    "Published"
                ],
                "neg_values": [
                    -0.8,
                    -0.74,
                    -0.735,
                    -0.721,
                    -0.686,
                    -0.678,
                    -0.673,
                    -0.671,
                    -0.665,
                    -0.655
                ],
                "pos_str": [
                    " ceremonies",
                    " temple",
                    " ceremony",
                    " altar",
                    " temples",
                    " rites",
                    " maiden",
                    " procession",
                    " rituals",
                    " complexes"
                ],
                "pos_values": [
                    1.025,
                    0.976,
                    0.961,
                    0.935,
                    0.919,
                    0.877,
                    0.864,
                    0.841,
                    0.84,
                    0.837
                ],
                "frac_nonzero": 7.000000000000001e-05,
                "freq_hist_data_bar_heights": [
                    70,
                    36,
                    17,
                    12,
                    4,
                    5,
                    6,
                    0,
                    2,
                    4,
                    4,
                    3,
                    1,
                    2,
                    2,
                    2,
                    1,
                    2,
                    2,
                    1,
                    1,
                    0,
                    0,
                    1,
                    0,
                    2,
                    1,
                    0,
                    1,
                    0,
                    0,
                    1,
                    2,
                    0,
                    1,
                    0,
                    1,
                    3,
                    1,
                    3,
                    3,
                    2,
                    3,
                    3,
                    2,
                    2,
                    3,
                    3,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.506,
                    1.515,
                    2.524,
                    3.533,
                    4.541,
                    5.55,
                    6.559,
                    7.568,
                    8.576,
                    9.585,
                    10.594,
                    11.602,
                    12.611,
                    13.62,
                    14.629,
                    15.637,
                    16.646,
                    17.655,
                    18.664,
                    19.672,
                    20.681,
                    21.69,
                    22.698,
                    23.707,
                    24.716,
                    25.725,
                    26.733,
                    27.742,
                    28.751,
                    29.76,
                    30.768,
                    31.777,
                    32.786,
                    33.794,
                    34.803,
                    35.812,
                    36.821,
                    37.829,
                    38.838,
                    39.847,
                    40.856,
                    41.864,
                    42.873,
                    43.882,
                    44.891,
                    45.899,
                    46.908,
                    47.917,
                    48.925,
                    49.934
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    1,
                    6,
                    9,
                    9,
                    26,
                    41,
                    67,
                    125,
                    265,
                    358,
                    558,
                    889,
                    1159,
                    1643,
                    2155,
                    2694,
                    3278,
                    3768,
                    4195,
                    4464,
                    4381,
                    4101,
                    3743,
                    3076,
                    2435,
                    1954,
                    1408,
                    1104,
                    727,
                    524,
                    369,
                    246,
                    153,
                    107,
                    66,
                    44,
                    38,
                    21,
                    15,
                    8,
                    5,
                    6,
                    6,
                    2,
                    0,
                    2,
                    2,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.782,
                    -0.745,
                    -0.709,
                    -0.672,
                    -0.636,
                    -0.599,
                    -0.563,
                    -0.526,
                    -0.49,
                    -0.453,
                    -0.417,
                    -0.38,
                    -0.344,
                    -0.307,
                    -0.271,
                    -0.234,
                    -0.198,
                    -0.161,
                    -0.125,
                    -0.088,
                    -0.052,
                    -0.015,
                    0.021,
                    0.058,
                    0.094,
                    0.131,
                    0.167,
                    0.204,
                    0.24,
                    0.277,
                    0.313,
                    0.35,
                    0.386,
                    0.423,
                    0.459,
                    0.496,
                    0.532,
                    0.569,
                    0.605,
                    0.642,
                    0.678,
                    0.715,
                    0.751,
                    0.788,
                    0.824,
                    0.861,
                    0.897,
                    0.934,
                    0.97,
                    1.007
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyv2tpa80wgcnba6b4dlsyze",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs49152-jb",
                        "index": "14142",
                        "description": "references to temples",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-21T04:47:21.920Z",
                        "updatedAt": "2024-07-21T04:47:21.920Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk511y1oowyi666mlptgg9o",
                        "tokens": [
                            " is",
                            " the",
                            " oldest",
                            " known",
                            " temple",
                            " in",
                            " the",
                            " world",
                            ".",
                            " Photo",
                            " source",
                            ":",
                            " Wikimedia",
                            "\n",
                            "\n",
                            "By",
                            " Robin",
                            " Whit",
                            "lock",
                            "<|endoftext|>",
                            "The",
                            " \u00e2\u0122",
                            "\u013a",
                            "non",
                            "-",
                            "religious",
                            "\u00e2\u0122",
                            "\u013b",
                            " are",
                            " the",
                            " largest",
                            " group",
                            " in",
                            " the",
                            " State",
                            " after",
                            " Catholics",
                            ",",
                            " according",
                            " to",
                            " the",
                            " last",
                            " census",
                            ".",
                            " They",
                            " range",
                            " from",
                            " active",
                            " atheists",
                            " lobbying",
                            " for",
                            " a",
                            " secular",
                            " Ireland",
                            " to",
                            " guilty",
                            " non",
                            "-",
                            "bel",
                            "ievers",
                            " who",
                            " still",
                            " observe",
                            " religious",
                            " rituals",
                            ",",
                            " writes",
                            " R",
                            "\u00c3",
                            "\u0135",
                            "IS",
                            "\u00c3\u012f",
                            "N",
                            " IN",
                            "G",
                            "LE",
                            "\n",
                            "\n",
                            "A",
                            " F",
                            "EW",
                            " W",
                            "EE",
                            "KS",
                            " ago",
                            " Brian",
                            " Whites",
                            "ide",
                            " of",
                            " the",
                            " Human",
                            "ist",
                            " Association",
                            " of",
                            " Ireland",
                            " addressed",
                            " a",
                            " gathering",
                            " that",
                            " included",
                            " Tao",
                            "ise",
                            "ach",
                            " End",
                            "a",
                            " Kenny",
                            ",",
                            " Minister",
                            " for",
                            " Justice",
                            " Alan",
                            " Sh",
                            "atter",
                            " as",
                            " well",
                            " as",
                            " various",
                            " religious",
                            " leaders",
                            ".",
                            " He",
                            " used",
                            " the",
                            " opportunity",
                            " to",
                            " raise",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "14142",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.438,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            50.438,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.564,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:23:53.790Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.439,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk511y1oowzi666do9v5i1x",
                        "tokens": [
                            " two",
                            " stayed",
                            " in",
                            " contact",
                            " through",
                            " social",
                            " media",
                            " and",
                            " texting",
                            ",",
                            " police",
                            " say",
                            ",",
                            " and",
                            " began",
                            " sending",
                            " \"",
                            "in",
                            "appropriate",
                            "\"",
                            " and",
                            " \"",
                            "dis",
                            "g",
                            "usting",
                            "\"",
                            " messages",
                            ".",
                            " The",
                            " boy",
                            " told",
                            " investigators",
                            " the",
                            " explicit",
                            " conversations",
                            " confused",
                            " him",
                            " but",
                            " that",
                            " he",
                            " looked",
                            " up",
                            " to",
                            " Cook",
                            " as",
                            " a",
                            " mentor",
                            ".",
                            "\n",
                            "\n",
                            "Shortly",
                            " after",
                            " the",
                            " boy",
                            " turned",
                            " 16",
                            ",",
                            " Cook",
                            " allegedly",
                            " met",
                            " with",
                            " him",
                            " at",
                            " the",
                            " LDS",
                            " temple",
                            " in",
                            " B",
                            "ount",
                            "iful",
                            " to",
                            " \"",
                            "catch",
                            " up",
                            "\"",
                            " and",
                            " then",
                            " went",
                            " to",
                            " a",
                            " nearby",
                            " park",
                            ".",
                            "\n",
                            "\n",
                            "\"(",
                            "Cook",
                            ")",
                            " made",
                            " advances",
                            " toward",
                            " the",
                            " minor",
                            " male",
                            " in",
                            " the",
                            " minor",
                            " male",
                            "'s",
                            " car",
                            ",\"",
                            " the",
                            " charges",
                            " state",
                            ".",
                            " \"",
                            "The",
                            " minor",
                            " male",
                            " stated",
                            " to",
                            " law",
                            " enforcement",
                            " that",
                            " the",
                            " defendant",
                            " persuaded",
                            " him",
                            " that",
                            " the",
                            " contact",
                            " they",
                            " had",
                            " was",
                            " acceptable",
                            " and",
                            " that"
                        ],
                        "dataIndex": null,
                        "index": "14142",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.451,
                        "maxValueTokenIndex": 65,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.451,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:23:53.790Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.439,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk511y1oox0i6664m9lp2ct",
                        "tokens": [
                            " where",
                            " he",
                            " would",
                            " later",
                            " pres",
                            "ide",
                            " over",
                            " a",
                            " branch",
                            " of",
                            " the",
                            " church",
                            ".",
                            " When",
                            " Missouri",
                            "ans",
                            " expelled",
                            " Mormons",
                            " from",
                            " the",
                            " area",
                            ",",
                            " Cor",
                            "rill",
                            " joined",
                            " in",
                            " petition",
                            "ing",
                            " the",
                            " governor",
                            " for",
                            " militia",
                            " assistance",
                            " and",
                            " settled",
                            " in",
                            " Clay",
                            " County",
                            " for",
                            " the",
                            " winter",
                            ".[",
                            "3",
                            "]",
                            "\n",
                            "\n",
                            "In",
                            " 18",
                            "34",
                            " he",
                            " was",
                            " called",
                            " back",
                            " to",
                            " K",
                            "irt",
                            "land",
                            " where",
                            " he",
                            " helped",
                            " build",
                            " the",
                            " temple",
                            " and",
                            " was",
                            " involved",
                            " with",
                            " approving",
                            " a",
                            " new",
                            " book",
                            " of",
                            " revelations",
                            " called",
                            " the",
                            " Doctrine",
                            " and",
                            " Co",
                            "venants",
                            ".",
                            " After",
                            " the",
                            " temple",
                            "'s",
                            " dedication",
                            " in",
                            " 18",
                            "36",
                            "[",
                            "6",
                            "]",
                            " he",
                            " returned",
                            " to",
                            " Missouri",
                            " and",
                            " was",
                            " one",
                            " of",
                            " the",
                            " founders",
                            " and",
                            " leaders",
                            " of",
                            " the",
                            " Mormon",
                            " settlement",
                            " of",
                            " Far",
                            " West",
                            ".[",
                            "3",
                            "][",
                            "7",
                            "]",
                            " During",
                            " this",
                            " time",
                            " the",
                            " residents",
                            " of",
                            " Clay",
                            " County",
                            " were",
                            " pushing",
                            " for",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "14142",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.467,
                        "maxValueTokenIndex": 82,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.106,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.467,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:23:53.790Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.439,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "7970",
            "description": "references to temples",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 47.104,
            "frac_nonzero": 6e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "7970",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:38:26.423Z",
                "maxActApprox": 47.104,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    7970,
                    12765,
                    92802,
                    64030,
                    19194,
                    96735,
                    5807,
                    1521,
                    80558,
                    89759,
                    3900,
                    4266,
                    75569,
                    9500,
                    71307,
                    26668,
                    54959,
                    60611,
                    36238,
                    97574,
                    19401,
                    16333,
                    11230,
                    82587,
                    22888
                ],
                "topkCosSimValues": [
                    1,
                    0.7186,
                    0.5892,
                    0.5739,
                    0.5223,
                    0.5142,
                    0.5095,
                    0.5067,
                    0.5009,
                    0.5008,
                    0.4957,
                    0.4918,
                    0.481,
                    0.4637,
                    0.4568,
                    0.4568,
                    0.4343,
                    0.4336,
                    0.4302,
                    0.4288,
                    0.4286,
                    0.4266,
                    0.4246,
                    0.4243,
                    0.4229
                ],
                "neuron_alignment_indices": [
                    288,
                    447,
                    231
                ],
                "neuron_alignment_values": [
                    0.185,
                    0.123,
                    0.11
                ],
                "neuron_alignment_l1": [
                    0.009,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    231,
                    288,
                    416
                ],
                "correlated_neurons_pearson": [
                    0.012,
                    0.011,
                    0.01
                ],
                "correlated_neurons_l1": [
                    0.012,
                    0.011,
                    0.01
                ],
                "correlated_features_indices": [
                    7957,
                    7988,
                    7893
                ],
                "correlated_features_pearson": [
                    0.01,
                    0.005,
                    0.003
                ],
                "correlated_features_l1": [
                    0.01,
                    0.005,
                    0.003
                ],
                "neg_str": [
                    "20439",
                    "\u00d1\u012e",
                    "Leary",
                    "agher",
                    "OVER",
                    "leneck",
                    "Roy",
                    "BAT",
                    "\u00ef\u00b8\u0131",
                    "Consumer"
                ],
                "neg_values": [
                    -0.828,
                    -0.753,
                    -0.73,
                    -0.725,
                    -0.691,
                    -0.673,
                    -0.658,
                    -0.657,
                    -0.652,
                    -0.642
                ],
                "pos_str": [
                    " temple",
                    " temples",
                    " ceremonies",
                    " complexes",
                    " ceremony",
                    " procession",
                    " altar",
                    " erected",
                    " gardens",
                    " maiden"
                ],
                "pos_values": [
                    0.995,
                    0.984,
                    0.976,
                    0.947,
                    0.906,
                    0.884,
                    0.849,
                    0.846,
                    0.837,
                    0.836
                ],
                "frac_nonzero": 6e-05,
                "freq_hist_data_bar_heights": [
                    41,
                    29,
                    17,
                    10,
                    9,
                    4,
                    1,
                    5,
                    1,
                    3,
                    3,
                    4,
                    1,
                    2,
                    3,
                    7,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    1,
                    0,
                    1,
                    2,
                    2,
                    2,
                    4,
                    4,
                    3,
                    5,
                    0,
                    6,
                    4,
                    2,
                    4,
                    0,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.475,
                    1.417,
                    2.359,
                    3.301,
                    4.243,
                    5.185,
                    6.127,
                    7.069,
                    8.011,
                    8.953,
                    9.895,
                    10.837,
                    11.779,
                    12.721,
                    13.663,
                    14.605,
                    15.547,
                    16.489,
                    17.431,
                    18.373,
                    19.315,
                    20.257,
                    21.199,
                    22.141,
                    23.083,
                    24.025,
                    24.967,
                    25.909,
                    26.851,
                    27.793,
                    28.735,
                    29.677,
                    30.619,
                    31.561,
                    32.503,
                    33.445,
                    34.387,
                    35.329,
                    36.271,
                    37.213,
                    38.155,
                    39.097,
                    40.039,
                    40.981,
                    41.923,
                    42.865,
                    43.807,
                    44.749,
                    45.691,
                    46.633
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    3,
                    1,
                    4,
                    12,
                    10,
                    34,
                    58,
                    74,
                    158,
                    267,
                    422,
                    628,
                    975,
                    1348,
                    1736,
                    2265,
                    2843,
                    3280,
                    3932,
                    4182,
                    4401,
                    4278,
                    3983,
                    3571,
                    2950,
                    2321,
                    1869,
                    1386,
                    1011,
                    695,
                    497,
                    345,
                    238,
                    157,
                    108,
                    71,
                    42,
                    30,
                    23,
                    16,
                    7,
                    9,
                    3,
                    7,
                    1,
                    1,
                    1,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.81,
                    -0.773,
                    -0.737,
                    -0.7,
                    -0.664,
                    -0.628,
                    -0.591,
                    -0.555,
                    -0.518,
                    -0.482,
                    -0.445,
                    -0.409,
                    -0.372,
                    -0.336,
                    -0.299,
                    -0.263,
                    -0.226,
                    -0.19,
                    -0.154,
                    -0.117,
                    -0.081,
                    -0.044,
                    -0.008,
                    0.029,
                    0.065,
                    0.102,
                    0.138,
                    0.175,
                    0.211,
                    0.247,
                    0.284,
                    0.32,
                    0.357,
                    0.393,
                    0.43,
                    0.466,
                    0.503,
                    0.539,
                    0.576,
                    0.612,
                    0.648,
                    0.685,
                    0.721,
                    0.758,
                    0.794,
                    0.831,
                    0.867,
                    0.904,
                    0.94,
                    0.977
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyzsftpm1xsp5q0z3cci6jfd",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "7970",
                        "description": "references to temples",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-24T11:55:29.111Z",
                        "updatedAt": "2024-07-24T11:55:29.111Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygf8vyxhcqw10ex1azvvvxv",
                        "tokens": [
                            " animals",
                            " including",
                            " fox",
                            "es",
                            ",",
                            " snakes",
                            ",",
                            " wild",
                            " bo",
                            "ars",
                            ",",
                            " cr",
                            "anes",
                            " and",
                            " ducks",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " archaeologists",
                            " believe",
                            " G\u00c3\u00b6",
                            "bek",
                            "lite",
                            "pe",
                            " was",
                            " used",
                            " as",
                            " a",
                            " religious",
                            " centre",
                            ".",
                            " Geo",
                            "-",
                            "rad",
                            "ar",
                            " work",
                            " has",
                            " revealed",
                            " evidence",
                            " of",
                            " 23",
                            " temple",
                            " structures",
                            " in",
                            " the",
                            " area",
                            ".",
                            " Two",
                            " of",
                            " the",
                            " ob",
                            "el",
                            "isks",
                            " in",
                            " the",
                            " city",
                            " were",
                            " constructed",
                            " in",
                            " the",
                            " form",
                            " of",
                            " a",
                            " letter",
                            " T",
                            " and",
                            " are",
                            " positioned",
                            " opposite",
                            " each",
                            " other",
                            " within",
                            " a",
                            " circle",
                            " of",
                            " smaller",
                            ",",
                            " round",
                            " ob",
                            "el",
                            "isks",
                            ".",
                            "\n",
                            "\n",
                            "Er",
                            "can",
                            " said",
                            " that",
                            " the",
                            " museum",
                            " at",
                            " \u00c5",
                            "\u0140",
                            "an",
                            "l",
                            "\u00c4\u00b1",
                            "ur",
                            "fa",
                            " contains",
                            " a",
                            " small",
                            " sculpture",
                            " of",
                            " a",
                            " pig",
                            " that",
                            " was",
                            " discovered",
                            " in",
                            " front",
                            " of",
                            " the",
                            " central",
                            " st",
                            "el",
                            "as",
                            " in",
                            " the",
                            " \u00e2\u0122",
                            "\u013a",
                            "C",
                            "\u00e2\u0122",
                            "\u013b",
                            " temple",
                            " at",
                            " G\u00c3\u00b6"
                        ],
                        "dataIndex": null,
                        "index": "7970",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 47.104,
                        "maxValueTokenIndex": 42,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            47.104,
                            0.902,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.508,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:38:33.133Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 47.104,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf8vyuhcqd10exbq02pedi",
                        "tokens": [
                            " animals",
                            " including",
                            " fox",
                            "es",
                            ",",
                            " snakes",
                            ",",
                            " wild",
                            " bo",
                            "ars",
                            ",",
                            " cr",
                            "anes",
                            " and",
                            " ducks",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " archaeologists",
                            " believe",
                            " G\u00c3\u00b6",
                            "bek",
                            "lite",
                            "pe",
                            " was",
                            " used",
                            " as",
                            " a",
                            " religious",
                            " centre",
                            ".",
                            " Geo",
                            "-",
                            "rad",
                            "ar",
                            " work",
                            " has",
                            " revealed",
                            " evidence",
                            " of",
                            " 23",
                            " temple",
                            " structures",
                            " in",
                            " the",
                            " area",
                            ".",
                            " Two",
                            " of",
                            " the",
                            " ob",
                            "el",
                            "isks",
                            " in",
                            " the",
                            " city",
                            " were",
                            " constructed",
                            " in",
                            " the",
                            " form",
                            " of",
                            " a",
                            " letter",
                            " T",
                            " and",
                            " are",
                            " positioned",
                            " opposite",
                            " each",
                            " other",
                            " within",
                            " a",
                            " circle",
                            " of",
                            " smaller",
                            ",",
                            " round",
                            " ob",
                            "el",
                            "isks",
                            ".",
                            "\n",
                            "\n",
                            "Er",
                            "can",
                            " said",
                            " that",
                            " the",
                            " museum",
                            " at",
                            " \u00c5",
                            "\u0140",
                            "an",
                            "l",
                            "\u00c4\u00b1",
                            "ur",
                            "fa",
                            " contains",
                            " a",
                            " small",
                            " sculpture",
                            " of",
                            " a",
                            " pig",
                            " that",
                            " was",
                            " discovered",
                            " in",
                            " front",
                            " of",
                            " the",
                            " central",
                            " st",
                            "el",
                            "as",
                            " in",
                            " the",
                            " \u00e2\u0122",
                            "\u013a",
                            "C",
                            "\u00e2\u0122",
                            "\u013b",
                            " temple",
                            " at",
                            " G\u00c3\u00b6"
                        ],
                        "dataIndex": null,
                        "index": "7970",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 47.104,
                        "maxValueTokenIndex": 42,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            47.104,
                            0.902,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.508,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:38:33.133Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 47.104,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf8vyxhcqy10exiaoxoqsm",
                        "tokens": [
                            " animals",
                            " including",
                            " fox",
                            "es",
                            ",",
                            " snakes",
                            ",",
                            " wild",
                            " bo",
                            "ars",
                            ",",
                            " cr",
                            "anes",
                            " and",
                            " ducks",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " archaeologists",
                            " believe",
                            " G\u00c3\u00b6",
                            "bek",
                            "lite",
                            "pe",
                            " was",
                            " used",
                            " as",
                            " a",
                            " religious",
                            " centre",
                            ".",
                            " Geo",
                            "-",
                            "rad",
                            "ar",
                            " work",
                            " has",
                            " revealed",
                            " evidence",
                            " of",
                            " 23",
                            " temple",
                            " structures",
                            " in",
                            " the",
                            " area",
                            ".",
                            " Two",
                            " of",
                            " the",
                            " ob",
                            "el",
                            "isks",
                            " in",
                            " the",
                            " city",
                            " were",
                            " constructed",
                            " in",
                            " the",
                            " form",
                            " of",
                            " a",
                            " letter",
                            " T",
                            " and",
                            " are",
                            " positioned",
                            " opposite",
                            " each",
                            " other",
                            " within",
                            " a",
                            " circle",
                            " of",
                            " smaller",
                            ",",
                            " round",
                            " ob",
                            "el",
                            "isks",
                            ".",
                            "\n",
                            "\n",
                            "Er",
                            "can",
                            " said",
                            " that",
                            " the",
                            " museum",
                            " at",
                            " \u00c5",
                            "\u0140",
                            "an",
                            "l",
                            "\u00c4\u00b1",
                            "ur",
                            "fa",
                            " contains",
                            " a",
                            " small",
                            " sculpture",
                            " of",
                            " a",
                            " pig",
                            " that",
                            " was",
                            " discovered",
                            " in",
                            " front",
                            " of",
                            " the",
                            " central",
                            " st",
                            "el",
                            "as",
                            " in",
                            " the",
                            " \u00e2\u0122",
                            "\u013a",
                            "C",
                            "\u00e2\u0122",
                            "\u013b",
                            " temple",
                            " at",
                            " G\u00c3\u00b6"
                        ],
                        "dataIndex": null,
                        "index": "7970",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 47.104,
                        "maxValueTokenIndex": 42,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            47.104,
                            0.902,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.508,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:38:33.133Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 37.683,
                        "binMax": 47.104,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "2731",
            "description": "references to specific locations, likely related to a concept or place called \"Temple\"",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 46.446,
            "frac_nonzero": 0.00109,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "2731",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:18:51.339Z",
                "maxActApprox": 46.446,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    2731,
                    7355,
                    9008,
                    1587,
                    6607,
                    3079,
                    1789,
                    7765,
                    2239,
                    4420,
                    1894,
                    4315,
                    10864,
                    8155,
                    5274,
                    7639,
                    9963,
                    8303,
                    6427,
                    3318,
                    11402,
                    3197,
                    1633,
                    7048,
                    1971
                ],
                "topkCosSimValues": [
                    1,
                    0.4358,
                    0.3902,
                    0.3713,
                    0.3623,
                    0.3597,
                    0.3511,
                    0.3302,
                    0.316,
                    0.3063,
                    0.3006,
                    0.3005,
                    0.2986,
                    0.2972,
                    0.296,
                    0.2913,
                    0.2887,
                    0.2885,
                    0.2877,
                    0.2859,
                    0.2832,
                    0.2815,
                    0.2728,
                    0.2718,
                    0.2717
                ],
                "neuron_alignment_indices": [
                    288,
                    231,
                    406
                ],
                "neuron_alignment_values": [
                    0.125,
                    0.114,
                    0.095
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    288,
                    325,
                    326
                ],
                "correlated_neurons_pearson": [
                    0.033,
                    0.023,
                    0.022
                ],
                "correlated_neurons_l1": [
                    0.036,
                    0.024,
                    0.023
                ],
                "correlated_features_indices": [
                    2808,
                    2746,
                    2771
                ],
                "correlated_features_pearson": [
                    0.015,
                    0.005,
                    0.004
                ],
                "correlated_features_l1": [
                    0.015,
                    0.006,
                    0.006
                ],
                "neg_str": [
                    "nesota",
                    "leneck",
                    "iability",
                    "agher",
                    "20439",
                    "\u00d1\u012e",
                    "Consumer",
                    "sen",
                    "ives",
                    "imil"
                ],
                "neg_values": [
                    -0.759,
                    -0.742,
                    -0.739,
                    -0.732,
                    -0.72,
                    -0.669,
                    -0.665,
                    -0.649,
                    -0.648,
                    -0.648
                ],
                "pos_str": [
                    " ceremonies",
                    "anus",
                    "plates",
                    "keeper",
                    "ifice",
                    "Stone",
                    " Ruins",
                    " temple",
                    "keepers",
                    " procession"
                ],
                "pos_values": [
                    0.868,
                    0.803,
                    0.797,
                    0.774,
                    0.771,
                    0.759,
                    0.759,
                    0.754,
                    0.745,
                    0.735
                ],
                "frac_nonzero": 0.00109,
                "freq_hist_data_bar_heights": [
                    1084,
                    727,
                    445,
                    303,
                    222,
                    160,
                    131,
                    96,
                    63,
                    35,
                    33,
                    23,
                    16,
                    8,
                    8,
                    5,
                    4,
                    0,
                    1,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1,
                    0,
                    2,
                    1,
                    2,
                    4,
                    3,
                    2,
                    7,
                    1,
                    3,
                    4,
                    3,
                    2,
                    1,
                    3,
                    1,
                    3,
                    0,
                    1,
                    0,
                    1,
                    2,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.465,
                    1.394,
                    2.322,
                    3.251,
                    4.18,
                    5.109,
                    6.038,
                    6.967,
                    7.896,
                    8.825,
                    9.754,
                    10.683,
                    11.612,
                    12.541,
                    13.47,
                    14.398,
                    15.327,
                    16.256,
                    17.185,
                    18.114,
                    19.043,
                    19.972,
                    20.901,
                    21.83,
                    22.759,
                    23.688,
                    24.616,
                    25.545,
                    26.474,
                    27.403,
                    28.332,
                    29.261,
                    30.19,
                    31.119,
                    32.048,
                    32.977,
                    33.906,
                    34.835,
                    35.764,
                    36.692,
                    37.621,
                    38.55,
                    39.479,
                    40.408,
                    41.337,
                    42.266,
                    43.195,
                    44.124,
                    45.053,
                    45.982
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    1,
                    2,
                    5,
                    3,
                    20,
                    22,
                    31,
                    64,
                    87,
                    143,
                    251,
                    350,
                    537,
                    780,
                    1151,
                    1448,
                    1881,
                    2478,
                    3024,
                    3538,
                    3931,
                    4274,
                    4236,
                    4048,
                    3648,
                    3317,
                    2703,
                    2245,
                    1709,
                    1314,
                    940,
                    600,
                    446,
                    330,
                    218,
                    157,
                    110,
                    69,
                    58,
                    34,
                    15,
                    5,
                    9,
                    5,
                    7,
                    4,
                    4,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.742,
                    -0.71,
                    -0.677,
                    -0.645,
                    -0.612,
                    -0.58,
                    -0.547,
                    -0.515,
                    -0.482,
                    -0.45,
                    -0.417,
                    -0.384,
                    -0.352,
                    -0.319,
                    -0.287,
                    -0.254,
                    -0.222,
                    -0.189,
                    -0.157,
                    -0.124,
                    -0.092,
                    -0.059,
                    -0.027,
                    0.006,
                    0.038,
                    0.071,
                    0.104,
                    0.136,
                    0.169,
                    0.201,
                    0.234,
                    0.266,
                    0.299,
                    0.331,
                    0.364,
                    0.396,
                    0.429,
                    0.461,
                    0.494,
                    0.526,
                    0.559,
                    0.592,
                    0.624,
                    0.657,
                    0.689,
                    0.722,
                    0.754,
                    0.787,
                    0.819,
                    0.852
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clymgiwwi0lz7j7a1hxgyd2n8",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs12288-jb",
                        "index": "2731",
                        "description": "references to specific locations, likely related to a concept or place called \"Temple\"",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-07-15T04:00:57.618Z",
                        "updatedAt": "2024-07-15T04:00:57.618Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtnmcz12tci666amuqdbvx",
                        "tokens": [
                            "\u013e",
                            "ge",
                            "ek",
                            "y",
                            "\u00e2\u0122",
                            "\u013f",
                            " hybrid",
                            " hopes",
                            " to",
                            " contribute",
                            " to",
                            " the",
                            " burgeoning",
                            " Kens",
                            "ington",
                            " section",
                            " of",
                            " Philadelphia",
                            ".",
                            " Am",
                            "alg",
                            "am",
                            " hopes",
                            " to",
                            " build",
                            " community",
                            " around",
                            " comics",
                            ",",
                            " coffee",
                            ",",
                            " and",
                            " relaxing",
                            " with",
                            " friends",
                            ",",
                            " and",
                            " also",
                            " through",
                            " hosting",
                            " geek",
                            "y",
                            " and",
                            " diversity",
                            "-",
                            "themed",
                            " workshops",
                            ",",
                            " movie",
                            "/",
                            "TV",
                            " screenings",
                            ",",
                            " book",
                            " signings",
                            ",",
                            " and",
                            " BY",
                            "OB",
                            " nights",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "I",
                            " got",
                            " the",
                            " idea",
                            " for",
                            " the",
                            " shop",
                            " about",
                            " 12",
                            " years",
                            " ago",
                            ",",
                            " when",
                            " I",
                            " was",
                            " still",
                            " attending",
                            " Temple",
                            " University",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Am",
                            "alg",
                            "am",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " owner",
                            ",",
                            " Ari",
                            "ell",
                            " R",
                            ".",
                            " Johnson",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "My",
                            " favorite",
                            " coffee",
                            " shop",
                            " was",
                            " directly",
                            " across",
                            " the",
                            " street",
                            " from",
                            " my",
                            " comic",
                            " book",
                            " store",
                            " of",
                            " choice",
                            ".",
                            " So",
                            ",",
                            " each",
                            " Friday",
                            ",",
                            " I",
                            " would",
                            " buy"
                        ],
                        "dataIndex": null,
                        "index": "2731",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.446,
                        "maxValueTokenIndex": 80,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.446,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:18:54.275Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 46.446,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtnmcz12tdi666obdwg1tw",
                        "tokens": [
                            ",",
                            " Dee",
                            " Ann",
                            " H",
                            "aney",
                            ",",
                            " was",
                            " involved",
                            " in",
                            " a",
                            " vehicle",
                            " accident",
                            " last",
                            " night",
                            " that",
                            " resulted",
                            " in",
                            " two",
                            " deaths",
                            ".",
                            " Our",
                            " deepest",
                            " condolences",
                            " go",
                            " to",
                            " the",
                            " families",
                            " of",
                            " those",
                            " who",
                            " lost",
                            " their",
                            " lives",
                            ".\"",
                            "North",
                            "bound",
                            " Gulf",
                            " Fre",
                            "eway",
                            " was",
                            " shut",
                            " down",
                            " heading",
                            " out",
                            " of",
                            " the",
                            " island",
                            " for",
                            " hours",
                            " during",
                            " the",
                            " investigation",
                            ".",
                            "<|endoftext|>",
                            "D",
                            "aryl",
                            " Hall",
                            " is",
                            " the",
                            " taller",
                            ",",
                            " more",
                            " visible",
                            " half",
                            " of",
                            " Hall",
                            " &",
                            " O",
                            "ates",
                            ",",
                            " one",
                            " of",
                            " the",
                            " best",
                            "-",
                            "selling",
                            " musical",
                            " du",
                            "os",
                            " of",
                            " all",
                            " time",
                            " who",
                            ",",
                            " despite",
                            " being",
                            " induct",
                            "ed",
                            " into",
                            " the",
                            " Rock",
                            " &",
                            " Roll",
                            " Hall",
                            " of",
                            " Fame",
                            ",",
                            " never",
                            " quite",
                            " got",
                            " the",
                            " sort",
                            " of",
                            " critical",
                            " love",
                            " that",
                            " many",
                            " other",
                            " induct",
                            "ees",
                            " have",
                            " generated",
                            ".",
                            " Hall",
                            " and",
                            " John",
                            " O",
                            "ates",
                            " met",
                            " while",
                            " attending",
                            " Temple",
                            " University",
                            " in",
                            " Philadelphia",
                            ",",
                            " a"
                        ],
                        "dataIndex": null,
                        "index": "2731",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.225,
                        "maxValueTokenIndex": 121,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.225,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:18:54.275Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 46.446,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtnmd112txi6666a8ciu2l",
                        "tokens": [
                            ",",
                            " Dee",
                            " Ann",
                            " H",
                            "aney",
                            ",",
                            " was",
                            " involved",
                            " in",
                            " a",
                            " vehicle",
                            " accident",
                            " last",
                            " night",
                            " that",
                            " resulted",
                            " in",
                            " two",
                            " deaths",
                            ".",
                            " Our",
                            " deepest",
                            " condolences",
                            " go",
                            " to",
                            " the",
                            " families",
                            " of",
                            " those",
                            " who",
                            " lost",
                            " their",
                            " lives",
                            ".\"",
                            "North",
                            "bound",
                            " Gulf",
                            " Fre",
                            "eway",
                            " was",
                            " shut",
                            " down",
                            " heading",
                            " out",
                            " of",
                            " the",
                            " island",
                            " for",
                            " hours",
                            " during",
                            " the",
                            " investigation",
                            ".",
                            "<|endoftext|>",
                            "D",
                            "aryl",
                            " Hall",
                            " is",
                            " the",
                            " taller",
                            ",",
                            " more",
                            " visible",
                            " half",
                            " of",
                            " Hall",
                            " &",
                            " O",
                            "ates",
                            ",",
                            " one",
                            " of",
                            " the",
                            " best",
                            "-",
                            "selling",
                            " musical",
                            " du",
                            "os",
                            " of",
                            " all",
                            " time",
                            " who",
                            ",",
                            " despite",
                            " being",
                            " induct",
                            "ed",
                            " into",
                            " the",
                            " Rock",
                            " &",
                            " Roll",
                            " Hall",
                            " of",
                            " Fame",
                            ",",
                            " never",
                            " quite",
                            " got",
                            " the",
                            " sort",
                            " of",
                            " critical",
                            " love",
                            " that",
                            " many",
                            " other",
                            " induct",
                            "ees",
                            " have",
                            " generated",
                            ".",
                            " Hall",
                            " and",
                            " John",
                            " O",
                            "ates",
                            " met",
                            " while",
                            " attending",
                            " Temple",
                            " University",
                            " in",
                            " Philadelphia",
                            ",",
                            " a"
                        ],
                        "dataIndex": null,
                        "index": "2731",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.225,
                        "maxValueTokenIndex": 121,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.225,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:18:54.275Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 37.157,
                        "binMax": 46.446,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "12765",
            "description": " references to \"Temple.\"",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 44.765,
            "frac_nonzero": 3e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "12765",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:44:02.350Z",
                "maxActApprox": 44.765,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    12765,
                    7970,
                    92802,
                    50890,
                    4266,
                    71307,
                    19194,
                    91208,
                    5807,
                    1521,
                    64030,
                    54959,
                    34716,
                    57996,
                    80558,
                    96735,
                    3900,
                    19401,
                    89759,
                    95122,
                    75569,
                    24972,
                    63326,
                    16333,
                    36238
                ],
                "topkCosSimValues": [
                    1,
                    0.7186,
                    0.493,
                    0.4703,
                    0.4589,
                    0.4425,
                    0.4362,
                    0.4327,
                    0.4231,
                    0.4185,
                    0.4172,
                    0.4111,
                    0.3964,
                    0.3954,
                    0.3933,
                    0.3878,
                    0.3824,
                    0.3805,
                    0.3785,
                    0.3637,
                    0.3619,
                    0.3614,
                    0.355,
                    0.3549,
                    0.3535
                ],
                "neuron_alignment_indices": [
                    288,
                    224,
                    326
                ],
                "neuron_alignment_values": [
                    0.15,
                    0.099,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    325,
                    683,
                    288
                ],
                "correlated_neurons_pearson": [
                    0.008,
                    0.008,
                    0.007
                ],
                "correlated_neurons_l1": [
                    0.008,
                    0.007,
                    0.008
                ],
                "correlated_features_indices": [
                    12769,
                    12666,
                    12784
                ],
                "correlated_features_pearson": [
                    0.001,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0.001,
                    0
                ],
                "neg_str": [
                    "imil",
                    "iability",
                    "nesota",
                    "hazard",
                    "ial",
                    "erry",
                    "ombie",
                    "ebin",
                    "leneck",
                    "iewicz"
                ],
                "neg_values": [
                    -0.77,
                    -0.764,
                    -0.702,
                    -0.696,
                    -0.694,
                    -0.681,
                    -0.672,
                    -0.655,
                    -0.647,
                    -0.647
                ],
                "pos_str": [
                    " Baal",
                    " Mount",
                    " Temple",
                    "Stone",
                    " Garden",
                    "keepers",
                    " Trials",
                    "keeper",
                    "tsky",
                    "anus"
                ],
                "pos_values": [
                    0.838,
                    0.83,
                    0.827,
                    0.808,
                    0.794,
                    0.774,
                    0.753,
                    0.751,
                    0.749,
                    0.745
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    25,
                    4,
                    7,
                    3,
                    4,
                    4,
                    5,
                    5,
                    4,
                    5,
                    3,
                    5,
                    4,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1,
                    1,
                    1,
                    1,
                    1,
                    4,
                    2,
                    1,
                    1,
                    3,
                    1,
                    1,
                    1,
                    0,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.461,
                    1.356,
                    2.251,
                    3.146,
                    4.041,
                    4.936,
                    5.831,
                    6.726,
                    7.621,
                    8.516,
                    9.411,
                    10.306,
                    11.201,
                    12.096,
                    12.991,
                    13.886,
                    14.781,
                    15.676,
                    16.571,
                    17.466,
                    18.362,
                    19.257,
                    20.152,
                    21.047,
                    21.942,
                    22.837,
                    23.732,
                    24.627,
                    25.522,
                    26.417,
                    27.312,
                    28.207,
                    29.102,
                    29.997,
                    30.892,
                    31.787,
                    32.682,
                    33.577,
                    34.472,
                    35.367,
                    36.262,
                    37.157,
                    38.052,
                    38.947,
                    39.842,
                    40.737,
                    41.632,
                    42.527,
                    43.422,
                    44.317
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    0,
                    4,
                    7,
                    10,
                    8,
                    25,
                    35,
                    47,
                    74,
                    137,
                    214,
                    324,
                    475,
                    647,
                    930,
                    1275,
                    1705,
                    2196,
                    2704,
                    3221,
                    3595,
                    3892,
                    4225,
                    4035,
                    3809,
                    3413,
                    3050,
                    2455,
                    1951,
                    1494,
                    1192,
                    891,
                    664,
                    466,
                    328,
                    233,
                    165,
                    116,
                    81,
                    66,
                    33,
                    22,
                    11,
                    7,
                    11,
                    2,
                    5,
                    1,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.754,
                    -0.722,
                    -0.69,
                    -0.658,
                    -0.625,
                    -0.593,
                    -0.561,
                    -0.529,
                    -0.497,
                    -0.465,
                    -0.432,
                    -0.4,
                    -0.368,
                    -0.336,
                    -0.304,
                    -0.272,
                    -0.239,
                    -0.207,
                    -0.175,
                    -0.143,
                    -0.111,
                    -0.079,
                    -0.046,
                    -0.014,
                    0.018,
                    0.05,
                    0.082,
                    0.114,
                    0.147,
                    0.179,
                    0.211,
                    0.243,
                    0.275,
                    0.307,
                    0.34,
                    0.372,
                    0.404,
                    0.436,
                    0.468,
                    0.5,
                    0.533,
                    0.565,
                    0.597,
                    0.629,
                    0.661,
                    0.693,
                    0.726,
                    0.758,
                    0.79,
                    0.822
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyzvf3vv20y65q0zfusonqbq",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "12765",
                        "description": " references to \"Temple.\"",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-24T13:18:54.571Z",
                        "updatedAt": "2024-07-24T13:18:54.571Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfg2w2kzm510exgcf3mc1a",
                        "tokens": [
                            " of",
                            " decay",
                            ".",
                            " The",
                            " only",
                            " human",
                            " institution",
                            " which",
                            " rejects",
                            " progress",
                            " is",
                            " the",
                            " cemetery",
                            ".",
                            " \u2013",
                            " Harold",
                            " Wilson",
                            "\n",
                            "\n",
                            "40",
                            ".",
                            " Change",
                            " before",
                            " you",
                            " have",
                            " to",
                            ".",
                            " \u2013",
                            " Jack",
                            " Welch",
                            "\n",
                            "\n",
                            "41",
                            ".",
                            " When",
                            " it",
                            " becomes",
                            " more",
                            " difficult",
                            " to",
                            " suffer",
                            " than",
                            " to",
                            " change",
                            "\u00e2\u0122\u00a6",
                            " you",
                            " will",
                            " change",
                            ".",
                            " \u2013",
                            " Robert",
                            " Anthony",
                            "\n",
                            "\n",
                            "42",
                            ".",
                            " People",
                            " are",
                            " always",
                            " looking",
                            " for",
                            " the",
                            " single",
                            " magic",
                            " bullet",
                            " that",
                            " will",
                            " totally",
                            " change",
                            " everything",
                            ".",
                            " There",
                            " is",
                            " no",
                            " single",
                            " magic",
                            " bullet",
                            ".",
                            " \u2013",
                            " Temple",
                            " Grand",
                            "in",
                            "\n",
                            "\n",
                            "43",
                            ".",
                            " Sometimes",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " the",
                            " smallest",
                            " decisions",
                            " that",
                            " can",
                            " change",
                            " your",
                            " life",
                            " forever",
                            ".",
                            " \u2013",
                            " Ker",
                            "i",
                            " Russell",
                            "\n",
                            "\n",
                            "44",
                            ".",
                            " He",
                            " that",
                            " will",
                            " not",
                            " apply",
                            " new",
                            " remedies",
                            " must",
                            " expect",
                            " new",
                            " evils",
                            ";",
                            " for",
                            " time",
                            " is",
                            " the",
                            " greatest",
                            " innov"
                        ],
                        "dataIndex": null,
                        "index": "12765",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.765,
                        "maxValueTokenIndex": 79,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.765,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:08.690Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 35.812,
                        "binMax": 44.765,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfg2w0kzli10ex9m9v55lz",
                        "tokens": [
                            " of",
                            " decay",
                            ".",
                            " The",
                            " only",
                            " human",
                            " institution",
                            " which",
                            " rejects",
                            " progress",
                            " is",
                            " the",
                            " cemetery",
                            ".",
                            " \u2013",
                            " Harold",
                            " Wilson",
                            "\n",
                            "\n",
                            "40",
                            ".",
                            " Change",
                            " before",
                            " you",
                            " have",
                            " to",
                            ".",
                            " \u2013",
                            " Jack",
                            " Welch",
                            "\n",
                            "\n",
                            "41",
                            ".",
                            " When",
                            " it",
                            " becomes",
                            " more",
                            " difficult",
                            " to",
                            " suffer",
                            " than",
                            " to",
                            " change",
                            "\u00e2\u0122\u00a6",
                            " you",
                            " will",
                            " change",
                            ".",
                            " \u2013",
                            " Robert",
                            " Anthony",
                            "\n",
                            "\n",
                            "42",
                            ".",
                            " People",
                            " are",
                            " always",
                            " looking",
                            " for",
                            " the",
                            " single",
                            " magic",
                            " bullet",
                            " that",
                            " will",
                            " totally",
                            " change",
                            " everything",
                            ".",
                            " There",
                            " is",
                            " no",
                            " single",
                            " magic",
                            " bullet",
                            ".",
                            " \u2013",
                            " Temple",
                            " Grand",
                            "in",
                            "\n",
                            "\n",
                            "43",
                            ".",
                            " Sometimes",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " the",
                            " smallest",
                            " decisions",
                            " that",
                            " can",
                            " change",
                            " your",
                            " life",
                            " forever",
                            ".",
                            " \u2013",
                            " Ker",
                            "i",
                            " Russell",
                            "\n",
                            "\n",
                            "44",
                            ".",
                            " He",
                            " that",
                            " will",
                            " not",
                            " apply",
                            " new",
                            " remedies",
                            " must",
                            " expect",
                            " new",
                            " evils",
                            ";",
                            " for",
                            " time",
                            " is",
                            " the",
                            " greatest",
                            " innov"
                        ],
                        "dataIndex": null,
                        "index": "12765",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.765,
                        "maxValueTokenIndex": 79,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.765,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:08.690Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.765,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfg2w0kzlj10exgabisc5n",
                        "tokens": [
                            " edit",
                            " ]",
                            "\n",
                            "\n",
                            "John",
                            " P",
                            "alf",
                            "rey",
                            ",",
                            " Harvard",
                            " Law",
                            " School",
                            " professor",
                            " and",
                            " Vice",
                            " Dean",
                            ",",
                            " and",
                            " Co",
                            "-",
                            "Director",
                            " of",
                            " the",
                            " Berk",
                            "man",
                            " Center",
                            " for",
                            " Internet",
                            " &",
                            " Society",
                            " cy",
                            "bers",
                            "pace",
                            " research",
                            " center",
                            ",",
                            " said",
                            ":",
                            " \"",
                            "If",
                            " the",
                            " facts",
                            " are",
                            " as",
                            " they",
                            " appear",
                            " to",
                            " be",
                            " in",
                            " the",
                            " claims",
                            " by",
                            " the",
                            " student",
                            ",",
                            " it",
                            "'s",
                            " shocking",
                            ".\"[",
                            "84",
                            "]",
                            " David",
                            " K",
                            "air",
                            "ys",
                            ",",
                            " a",
                            " Temple",
                            " University",
                            " Law",
                            " School",
                            " professor",
                            " who",
                            " specializes",
                            " in",
                            " civil",
                            " rights",
                            " and",
                            " constitutional",
                            " law",
                            " and",
                            " is",
                            " author",
                            " of",
                            " Philadelphia",
                            " Freedom",
                            ",",
                            " Mem",
                            "oir",
                            " of",
                            " a",
                            " Civil",
                            " Rights",
                            " Law",
                            "yer",
                            ",",
                            " described",
                            " the",
                            " school",
                            " district",
                            "'s",
                            " policy",
                            " as",
                            " \"",
                            "Or",
                            "well",
                            "ian",
                            "\".",
                            " He",
                            " said",
                            " that",
                            " it",
                            " appeared",
                            " to",
                            " be",
                            " a",
                            " \"",
                            "very",
                            " clear",
                            " civil",
                            "-",
                            "rights",
                            " violation",
                            "\",",
                            " continuing",
                            ":",
                            " \""
                        ],
                        "dataIndex": null,
                        "index": "12765",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.763,
                        "maxValueTokenIndex": 67,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.763,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:08.690Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.765,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "73144",
            "description": " terms related to replacement and superstition, as well as the concept of temples",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 40.912,
            "frac_nonzero": 3e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "73144",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:02:16.310Z",
                "maxActApprox": 40.912,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    73144,
                    9183,
                    67111,
                    46852,
                    92106,
                    80166,
                    59508,
                    25710,
                    50846,
                    98064,
                    92172,
                    57711,
                    88650,
                    40396,
                    65295,
                    42822,
                    97954,
                    12604,
                    76150,
                    89472,
                    61061,
                    15219,
                    24245,
                    21239,
                    61137
                ],
                "topkCosSimValues": [
                    1,
                    0.5864,
                    0.4574,
                    0.4079,
                    0.392,
                    0.3818,
                    0.3752,
                    0.3652,
                    0.3641,
                    0.3605,
                    0.3596,
                    0.3593,
                    0.3587,
                    0.3582,
                    0.3572,
                    0.353,
                    0.3519,
                    0.3514,
                    0.3489,
                    0.3482,
                    0.3481,
                    0.3478,
                    0.3459,
                    0.3458,
                    0.3452
                ],
                "neuron_alignment_indices": [
                    167,
                    288,
                    311
                ],
                "neuron_alignment_values": [
                    0.126,
                    0.119,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    167,
                    232,
                    311
                ],
                "correlated_neurons_pearson": [
                    0.006,
                    0.006,
                    0.006
                ],
                "correlated_neurons_l1": [
                    0.004,
                    0.006,
                    0.003
                ],
                "correlated_features_indices": [
                    73183,
                    73144,
                    73223
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "EStream",
                    "Spoiler",
                    "yip",
                    "IRO",
                    "chy",
                    "pheus",
                    "horn",
                    "STD",
                    "\u00e2\u0122\u00a2\u00e2\u0122\u00a2",
                    "Bloomberg"
                ],
                "neg_values": [
                    -0.924,
                    -0.862,
                    -0.816,
                    -0.755,
                    -0.733,
                    -0.712,
                    -0.691,
                    -0.689,
                    -0.688,
                    -0.687
                ],
                "pos_str": [
                    "ructure",
                    "itutional",
                    "itious",
                    "itution",
                    "itions",
                    "itute",
                    "ruct",
                    "raction",
                    "ract",
                    "itional"
                ],
                "pos_values": [
                    1.28,
                    1.142,
                    1.134,
                    1.093,
                    1.071,
                    1.062,
                    1.014,
                    1.011,
                    0.986,
                    0.969
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    40,
                    20,
                    9,
                    2,
                    2,
                    2,
                    3,
                    1,
                    1,
                    6,
                    2,
                    0,
                    0,
                    2,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    2,
                    1,
                    0,
                    0,
                    4,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.454,
                    1.271,
                    2.088,
                    2.906,
                    3.723,
                    4.541,
                    5.358,
                    6.175,
                    6.993,
                    7.81,
                    8.627,
                    9.445,
                    10.262,
                    11.079,
                    11.897,
                    12.714,
                    13.531,
                    14.349,
                    15.166,
                    15.983,
                    16.801,
                    17.618,
                    18.435,
                    19.253,
                    20.07,
                    20.887,
                    21.705,
                    22.522,
                    23.339,
                    24.157,
                    24.974,
                    25.791,
                    26.609,
                    27.426,
                    28.244,
                    29.061,
                    29.878,
                    30.696,
                    31.513,
                    32.33,
                    33.148,
                    33.965,
                    34.782,
                    35.6,
                    36.417,
                    37.234,
                    38.052,
                    38.869,
                    39.686,
                    40.504
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    1,
                    1,
                    2,
                    7,
                    8,
                    14,
                    30,
                    60,
                    127,
                    192,
                    420,
                    699,
                    1254,
                    2000,
                    2884,
                    3882,
                    4905,
                    5636,
                    5518,
                    4955,
                    4297,
                    3391,
                    2543,
                    1948,
                    1344,
                    1011,
                    759,
                    591,
                    481,
                    340,
                    292,
                    220,
                    144,
                    107,
                    61,
                    43,
                    27,
                    25,
                    10,
                    11,
                    6,
                    3,
                    0,
                    3,
                    2,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.902,
                    -0.858,
                    -0.814,
                    -0.77,
                    -0.726,
                    -0.681,
                    -0.637,
                    -0.593,
                    -0.549,
                    -0.505,
                    -0.461,
                    -0.417,
                    -0.373,
                    -0.329,
                    -0.285,
                    -0.241,
                    -0.197,
                    -0.152,
                    -0.108,
                    -0.064,
                    -0.02,
                    0.024,
                    0.068,
                    0.112,
                    0.156,
                    0.2,
                    0.244,
                    0.288,
                    0.332,
                    0.376,
                    0.421,
                    0.465,
                    0.509,
                    0.553,
                    0.597,
                    0.641,
                    0.685,
                    0.729,
                    0.773,
                    0.817,
                    0.861,
                    0.905,
                    0.95,
                    0.994,
                    1.038,
                    1.082,
                    1.126,
                    1.17,
                    1.214,
                    1.258
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clzdg0xds2w3hv3wq0mgy4ch7",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "73144",
                        "description": "words related to substances and structures",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T01:16:45.184Z",
                        "updatedAt": "2024-08-03T01:16:45.184Z"
                    },
                    {
                        "id": "clze5siw53pu0v3wqqom8kf2p",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "73144",
                        "description": "terms related to structural elements and substitutions",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T13:18:03.174Z",
                        "updatedAt": "2024-08-03T13:18:03.174Z"
                    },
                    {
                        "id": "clze7zth73s4gv3wqy62w5whm",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "73144",
                        "description": " terms related to replacement and superstition, as well as the concept of temples",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T14:19:42.715Z",
                        "updatedAt": "2024-08-03T14:19:42.715Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi8kdcurs910exq9qua4gu",
                        "tokens": [
                            "\n",
                            "\n",
                            "Large",
                            " amounts",
                            " of",
                            " fuel",
                            " oil",
                            " were",
                            " reportedly",
                            " stored",
                            " in",
                            " WTC",
                            "7",
                            ",",
                            " but",
                            " even",
                            " if",
                            " this",
                            " oil",
                            " was",
                            " burning",
                            " it",
                            " could",
                            " not",
                            " have",
                            " caused",
                            " the",
                            " simultaneous",
                            " structural",
                            " failure",
                            " of",
                            " all",
                            " the",
                            " support",
                            " columns",
                            " \u2014",
                            " or",
                            " any",
                            " of",
                            " them",
                            " for",
                            " that",
                            " matter",
                            ".",
                            " As",
                            " we",
                            " have",
                            " seen",
                            ",",
                            " open",
                            "-",
                            "air",
                            " hydro",
                            "carbon",
                            " fires",
                            " are",
                            " incapable",
                            " of",
                            " creating",
                            " enough",
                            " heat",
                            " at",
                            " a",
                            " high",
                            " enough",
                            " temperature",
                            " to",
                            " cause",
                            " the",
                            " failure",
                            " of",
                            " steel",
                            "-",
                            "frame",
                            " high",
                            "-",
                            "rise",
                            " structures",
                            ".",
                            " The",
                            " fact",
                            " that",
                            " WTC",
                            "7",
                            " was",
                            " built",
                            " over",
                            " a",
                            " pre",
                            "-",
                            "existing",
                            " three",
                            " story",
                            " subst",
                            "ation",
                            " also",
                            " does",
                            " not",
                            " explain",
                            " the",
                            " perfect",
                            " symmetry",
                            " of",
                            " the",
                            " collapse",
                            ",",
                            " or",
                            " the",
                            " collapse",
                            " itself",
                            ".",
                            "\n",
                            "\n",
                            "Official",
                            " investigators",
                            " and",
                            " \"",
                            "cons",
                            "piracy",
                            " theory",
                            " debunk",
                            "ers",
                            "\"",
                            " are",
                            " now",
                            " claiming",
                            " that"
                        ],
                        "dataIndex": null,
                        "index": "73144",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.912,
                        "maxValueTokenIndex": 93,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.912,
                            0.172,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:16.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 40.912,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi8kdeurst10exf381cbqj",
                        "tokens": [
                            "\n",
                            "\n",
                            "Large",
                            " amounts",
                            " of",
                            " fuel",
                            " oil",
                            " were",
                            " reportedly",
                            " stored",
                            " in",
                            " WTC",
                            "7",
                            ",",
                            " but",
                            " even",
                            " if",
                            " this",
                            " oil",
                            " was",
                            " burning",
                            " it",
                            " could",
                            " not",
                            " have",
                            " caused",
                            " the",
                            " simultaneous",
                            " structural",
                            " failure",
                            " of",
                            " all",
                            " the",
                            " support",
                            " columns",
                            " \u2014",
                            " or",
                            " any",
                            " of",
                            " them",
                            " for",
                            " that",
                            " matter",
                            ".",
                            " As",
                            " we",
                            " have",
                            " seen",
                            ",",
                            " open",
                            "-",
                            "air",
                            " hydro",
                            "carbon",
                            " fires",
                            " are",
                            " incapable",
                            " of",
                            " creating",
                            " enough",
                            " heat",
                            " at",
                            " a",
                            " high",
                            " enough",
                            " temperature",
                            " to",
                            " cause",
                            " the",
                            " failure",
                            " of",
                            " steel",
                            "-",
                            "frame",
                            " high",
                            "-",
                            "rise",
                            " structures",
                            ".",
                            " The",
                            " fact",
                            " that",
                            " WTC",
                            "7",
                            " was",
                            " built",
                            " over",
                            " a",
                            " pre",
                            "-",
                            "existing",
                            " three",
                            " story",
                            " subst",
                            "ation",
                            " also",
                            " does",
                            " not",
                            " explain",
                            " the",
                            " perfect",
                            " symmetry",
                            " of",
                            " the",
                            " collapse",
                            ",",
                            " or",
                            " the",
                            " collapse",
                            " itself",
                            ".",
                            "\n",
                            "\n",
                            "Official",
                            " investigators",
                            " and",
                            " \"",
                            "cons",
                            "piracy",
                            " theory",
                            " debunk",
                            "ers",
                            "\"",
                            " are",
                            " now",
                            " claiming",
                            " that"
                        ],
                        "dataIndex": null,
                        "index": "73144",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.912,
                        "maxValueTokenIndex": 93,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.912,
                            0.172,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:16.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 32.73,
                        "binMax": 40.912,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi8kdcursa10exelnp750c",
                        "tokens": [
                            "all",
                            " that",
                            " the",
                            " reson",
                            "ator",
                            " could",
                            " not",
                            " be",
                            " the",
                            " molecule",
                            " as",
                            " a",
                            " whole",
                            " unit",
                            ";",
                            " it",
                            " had",
                            " to",
                            " be",
                            " some",
                            " subst",
                            "ructure",
                            ",",
                            " because",
                            " otherwise",
                            " the",
                            " phot",
                            "ochemical",
                            " effect",
                            " would",
                            " be",
                            " impossible",
                            ".[",
                            "32",
                            "]",
                            " But",
                            " he",
                            " was",
                            " without",
                            " test",
                            "able",
                            " ideas",
                            " as",
                            " to",
                            " the",
                            " form",
                            " of",
                            " this",
                            " subst",
                            "ructure",
                            ",",
                            " and",
                            " did",
                            " not",
                            " partake",
                            " in",
                            " speculation",
                            " in",
                            " print",
                            ".",
                            " His",
                            " promotion",
                            " of",
                            " the",
                            " molecular",
                            " mindset",
                            ",",
                            " and",
                            " his",
                            " efforts",
                            " to",
                            " experiment",
                            "ally",
                            " expose",
                            " what",
                            " molecules",
                            " are",
                            ",",
                            " has",
                            " been",
                            " discussed",
                            " by",
                            " one",
                            " historian",
                            " under",
                            " the",
                            " title",
                            " \"",
                            "John",
                            " Ty",
                            "nd",
                            "all",
                            ",",
                            " The",
                            " R",
                            "het",
                            "or",
                            "ician",
                            " of",
                            " Molecular",
                            "ity",
                            "\".[",
                            "33",
                            "]",
                            "\n",
                            "\n",
                            "Al",
                            "pine",
                            " mount",
                            "aine",
                            "ering",
                            " and",
                            " glac",
                            "iology",
                            " [",
                            " edit",
                            " ]",
                            "\n",
                            "\n",
                            "Ty",
                            "nd",
                            "all",
                            " visited",
                            " the",
                            " Alps",
                            " mountains",
                            " in"
                        ],
                        "dataIndex": null,
                        "index": "73144",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.53,
                        "maxValueTokenIndex": 20,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.53,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            36.076,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:16.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 40.912,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "50890",
            "description": "references to specific educational institutions, particularly Temple University",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 25.37,
            "frac_nonzero": 0.00018,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "50890",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:38:05.526Z",
                "maxActApprox": 25.37,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    50890,
                    12765,
                    85425,
                    35284,
                    81514,
                    75079,
                    17211,
                    93604,
                    47940,
                    53040,
                    56289,
                    81682,
                    24769,
                    57996,
                    14447,
                    33306,
                    95819,
                    88570,
                    86401,
                    31802,
                    50161,
                    39312,
                    28331,
                    77336,
                    84263
                ],
                "topkCosSimValues": [
                    1,
                    0.4703,
                    0.4031,
                    0.3767,
                    0.3712,
                    0.325,
                    0.3243,
                    0.3228,
                    0.3167,
                    0.3095,
                    0.3058,
                    0.3026,
                    0.3004,
                    0.2987,
                    0.2964,
                    0.2924,
                    0.2916,
                    0.2908,
                    0.289,
                    0.2865,
                    0.2852,
                    0.2845,
                    0.2838,
                    0.2804,
                    0.2789
                ],
                "neuron_alignment_indices": [
                    199,
                    430,
                    683
                ],
                "neuron_alignment_values": [
                    0.104,
                    0.1,
                    0.087
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    288,
                    354,
                    683
                ],
                "correlated_neurons_pearson": [
                    0.013,
                    0.012,
                    0.011
                ],
                "correlated_neurons_l1": [
                    0.014,
                    0.012,
                    0.011
                ],
                "correlated_features_indices": [
                    50850,
                    50867,
                    50894
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.004,
                    0.002
                ],
                "correlated_features_l1": [
                    0.005,
                    0.004,
                    0.002
                ],
                "neg_str": [
                    " charism",
                    "iaries",
                    "orship",
                    "\u00e8\u0122\u0127",
                    " sinners",
                    " seiz",
                    "AMES",
                    "\u00e8\u00a6\u013c\u00e9\u0128\u0134",
                    " sanct",
                    "eatures"
                ],
                "neg_values": [
                    -0.744,
                    -0.731,
                    -0.671,
                    -0.66,
                    -0.649,
                    -0.644,
                    -0.638,
                    -0.637,
                    -0.63,
                    -0.629
                ],
                "pos_str": [
                    "ton",
                    "baugh",
                    "ley",
                    "hurst",
                    "beer",
                    "berger",
                    "plin",
                    "gren",
                    "llan",
                    "zyk"
                ],
                "pos_values": [
                    0.899,
                    0.852,
                    0.834,
                    0.818,
                    0.778,
                    0.774,
                    0.771,
                    0.767,
                    0.765,
                    0.755
                ],
                "frac_nonzero": 0.00018,
                "freq_hist_data_bar_heights": [
                    140,
                    101,
                    58,
                    53,
                    44,
                    20,
                    23,
                    11,
                    8,
                    6,
                    5,
                    6,
                    9,
                    18,
                    7,
                    3,
                    5,
                    3,
                    3,
                    3,
                    0,
                    2,
                    3,
                    3,
                    7,
                    4,
                    2,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    2,
                    0,
                    0,
                    2,
                    1,
                    0,
                    1,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.259,
                    0.767,
                    1.274,
                    1.781,
                    2.289,
                    2.796,
                    3.303,
                    3.81,
                    4.318,
                    4.825,
                    5.332,
                    5.84,
                    6.347,
                    6.854,
                    7.361,
                    7.869,
                    8.376,
                    8.883,
                    9.391,
                    9.898,
                    10.405,
                    10.912,
                    11.42,
                    11.927,
                    12.434,
                    12.942,
                    13.449,
                    13.956,
                    14.463,
                    14.971,
                    15.478,
                    15.985,
                    16.493,
                    17,
                    17.507,
                    18.014,
                    18.522,
                    19.029,
                    19.536,
                    20.044,
                    20.551,
                    21.058,
                    21.565,
                    22.073,
                    22.58,
                    23.087,
                    23.595,
                    24.102,
                    24.609,
                    25.116
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    0,
                    3,
                    9,
                    16,
                    16,
                    33,
                    65,
                    84,
                    155,
                    260,
                    362,
                    590,
                    840,
                    1172,
                    1577,
                    1990,
                    2473,
                    2926,
                    3278,
                    3620,
                    3799,
                    3857,
                    3782,
                    3530,
                    3172,
                    2670,
                    2316,
                    1776,
                    1445,
                    1106,
                    882,
                    682,
                    502,
                    353,
                    300,
                    184,
                    127,
                    99,
                    76,
                    45,
                    33,
                    21,
                    12,
                    5,
                    5,
                    3,
                    1,
                    2,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.728,
                    -0.695,
                    -0.662,
                    -0.629,
                    -0.596,
                    -0.563,
                    -0.531,
                    -0.498,
                    -0.465,
                    -0.432,
                    -0.399,
                    -0.366,
                    -0.333,
                    -0.3,
                    -0.268,
                    -0.235,
                    -0.202,
                    -0.169,
                    -0.136,
                    -0.103,
                    -0.07,
                    -0.038,
                    -0.005,
                    0.028,
                    0.061,
                    0.094,
                    0.127,
                    0.16,
                    0.193,
                    0.225,
                    0.258,
                    0.291,
                    0.324,
                    0.357,
                    0.39,
                    0.423,
                    0.456,
                    0.488,
                    0.521,
                    0.554,
                    0.587,
                    0.62,
                    0.653,
                    0.686,
                    0.718,
                    0.751,
                    0.784,
                    0.817,
                    0.85,
                    0.883
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clz1h3g1y2k6pweoxv5n3j695",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "50890",
                        "description": "references to the university Temple",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-25T16:13:28.119Z",
                        "updatedAt": "2024-07-25T16:13:28.119Z"
                    },
                    {
                        "id": "clze2lfrh3aytv3wq9v77gw29",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "50890",
                        "description": "references to specific educational institutions, particularly Temple University",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T11:48:33.678Z",
                        "updatedAt": "2024-08-03T11:48:33.678Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghdjradv4810exd8wf4iqr",
                        "tokens": [
                            " its",
                            " \"",
                            "An",
                            "ch",
                            "or",
                            " Down",
                            "\"",
                            " jerseys",
                            " for",
                            " the",
                            " season",
                            " opener",
                            " against",
                            " Temple",
                            " and",
                            " nearly",
                            " paid",
                            " a",
                            " steep",
                            " price",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "We",
                            " sent",
                            " an",
                            " email",
                            " design",
                            " concept",
                            " to",
                            " the",
                            " NCAA",
                            " football",
                            " rules",
                            " committee",
                            ",",
                            " got",
                            " a",
                            " curs",
                            "ory",
                            " response",
                            " which",
                            " says",
                            ",",
                            " '",
                            "It",
                            " looks",
                            " good",
                            " to",
                            " us",
                            ",'\"",
                            " Vanderbilt",
                            " athletics",
                            " department",
                            " spokesman",
                            " Rod",
                            " Williamson",
                            " said",
                            " via",
                            " David",
                            " Cl",
                            "imer",
                            " of",
                            " The",
                            " Tenn",
                            "esse",
                            "an",
                            ".",
                            " \"",
                            "We",
                            " thought",
                            " that",
                            " meant",
                            " every",
                            " piece",
                            " of",
                            " the",
                            " communication",
                            " was",
                            " fine",
                            ".\"",
                            "\n",
                            "\n",
                            "Initially",
                            ",",
                            " officials",
                            " working",
                            " the",
                            " game",
                            " announced",
                            " that",
                            " the",
                            " Comm",
                            "od",
                            "ores",
                            "'",
                            " uniform",
                            " violation",
                            " would",
                            " result",
                            " in",
                            " a",
                            " loss",
                            " of",
                            " a",
                            " timeout",
                            " for",
                            " each",
                            " quarter",
                            " those",
                            " jerseys",
                            " were",
                            " worn",
                            ".",
                            " That",
                            " ruling",
                            " was",
                            " quickly",
                            " overturned",
                            ",",
                            " though",
                            " it",
                            " didn",
                            "'t",
                            " help",
                            " V"
                        ],
                        "dataIndex": null,
                        "index": "50890",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.37,
                        "maxValueTokenIndex": 13,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.37,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:09.816Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 25.37,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghdjrcdv4w10exi54c42ub",
                        "tokens": [
                            " its",
                            " \"",
                            "An",
                            "ch",
                            "or",
                            " Down",
                            "\"",
                            " jerseys",
                            " for",
                            " the",
                            " season",
                            " opener",
                            " against",
                            " Temple",
                            " and",
                            " nearly",
                            " paid",
                            " a",
                            " steep",
                            " price",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "We",
                            " sent",
                            " an",
                            " email",
                            " design",
                            " concept",
                            " to",
                            " the",
                            " NCAA",
                            " football",
                            " rules",
                            " committee",
                            ",",
                            " got",
                            " a",
                            " curs",
                            "ory",
                            " response",
                            " which",
                            " says",
                            ",",
                            " '",
                            "It",
                            " looks",
                            " good",
                            " to",
                            " us",
                            ",'\"",
                            " Vanderbilt",
                            " athletics",
                            " department",
                            " spokesman",
                            " Rod",
                            " Williamson",
                            " said",
                            " via",
                            " David",
                            " Cl",
                            "imer",
                            " of",
                            " The",
                            " Tenn",
                            "esse",
                            "an",
                            ".",
                            " \"",
                            "We",
                            " thought",
                            " that",
                            " meant",
                            " every",
                            " piece",
                            " of",
                            " the",
                            " communication",
                            " was",
                            " fine",
                            ".\"",
                            "\n",
                            "\n",
                            "Initially",
                            ",",
                            " officials",
                            " working",
                            " the",
                            " game",
                            " announced",
                            " that",
                            " the",
                            " Comm",
                            "od",
                            "ores",
                            "'",
                            " uniform",
                            " violation",
                            " would",
                            " result",
                            " in",
                            " a",
                            " loss",
                            " of",
                            " a",
                            " timeout",
                            " for",
                            " each",
                            " quarter",
                            " those",
                            " jerseys",
                            " were",
                            " worn",
                            ".",
                            " That",
                            " ruling",
                            " was",
                            " quickly",
                            " overturned",
                            ",",
                            " though",
                            " it",
                            " didn",
                            "'t",
                            " help",
                            " V"
                        ],
                        "dataIndex": null,
                        "index": "50890",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.37,
                        "maxValueTokenIndex": 13,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.37,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:09.816Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 20.296,
                        "binMax": 25.37,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghdjradv4910exrlz4k3x6",
                        "tokens": [
                            " side",
                            ",",
                            " he",
                            " works",
                            " as",
                            " a",
                            " personal",
                            " trainer",
                            " to",
                            " fund",
                            " the",
                            " cost",
                            " of",
                            " his",
                            " travel",
                            " to",
                            " races",
                            ".",
                            "\n",
                            "\n",
                            "H",
                            "ud",
                            "gins",
                            " does",
                            " his",
                            " primary",
                            " run",
                            " around",
                            " 11",
                            " a",
                            ".",
                            "m",
                            ".,",
                            " and",
                            " a",
                            " second",
                            " run",
                            " when",
                            " he",
                            " gets",
                            " off",
                            " work",
                            ",",
                            " around",
                            " 11",
                            ":",
                            "30",
                            " p",
                            ".",
                            "m",
                            ".",
                            " Add",
                            " in",
                            " nine",
                            " hours",
                            " of",
                            " work",
                            " per",
                            " day",
                            ",",
                            " travel",
                            " time",
                            ",",
                            " weight",
                            "lifting",
                            ",",
                            " and",
                            " sleep",
                            ",",
                            " and",
                            " there",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " a",
                            " lot",
                            " of",
                            " time",
                            " left",
                            " over",
                            ".",
                            "\n",
                            "\n",
                            "Part",
                            "ially",
                            " because",
                            " of",
                            " his",
                            " unconventional",
                            " work",
                            " schedule",
                            ",",
                            " he",
                            " does",
                            " the",
                            " majority",
                            " of",
                            " his",
                            " 75",
                            "-",
                            "90",
                            " miles",
                            " per",
                            " week",
                            " alone",
                            ".",
                            " He",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " coached",
                            " remotely",
                            " by",
                            " Temple",
                            " University",
                            " coach",
                            " James",
                            " Snyder",
                            ",",
                            " who",
                            " was",
                            " one",
                            " of",
                            " Hud",
                            "gins",
                            "\u00e2\u0122"
                        ],
                        "dataIndex": null,
                        "index": "50890",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 23.979,
                        "maxValueTokenIndex": 114,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            23.979,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:09.816Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 25.37,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "50890",
            "description": "references to the university Temple",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 25.37,
            "frac_nonzero": 0.00018,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "50890",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:38:05.526Z",
                "maxActApprox": 25.37,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    50890,
                    12765,
                    85425,
                    35284,
                    81514,
                    75079,
                    17211,
                    93604,
                    47940,
                    53040,
                    56289,
                    81682,
                    24769,
                    57996,
                    14447,
                    33306,
                    95819,
                    88570,
                    86401,
                    31802,
                    50161,
                    39312,
                    28331,
                    77336,
                    84263
                ],
                "topkCosSimValues": [
                    1,
                    0.4703,
                    0.4031,
                    0.3767,
                    0.3712,
                    0.325,
                    0.3243,
                    0.3228,
                    0.3167,
                    0.3095,
                    0.3058,
                    0.3026,
                    0.3004,
                    0.2987,
                    0.2964,
                    0.2924,
                    0.2916,
                    0.2908,
                    0.289,
                    0.2865,
                    0.2852,
                    0.2845,
                    0.2838,
                    0.2804,
                    0.2789
                ],
                "neuron_alignment_indices": [
                    199,
                    430,
                    683
                ],
                "neuron_alignment_values": [
                    0.104,
                    0.1,
                    0.087
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    288,
                    354,
                    683
                ],
                "correlated_neurons_pearson": [
                    0.013,
                    0.012,
                    0.011
                ],
                "correlated_neurons_l1": [
                    0.014,
                    0.012,
                    0.011
                ],
                "correlated_features_indices": [
                    50850,
                    50867,
                    50894
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.004,
                    0.002
                ],
                "correlated_features_l1": [
                    0.005,
                    0.004,
                    0.002
                ],
                "neg_str": [
                    " charism",
                    "iaries",
                    "orship",
                    "\u00e8\u0122\u0127",
                    " sinners",
                    " seiz",
                    "AMES",
                    "\u00e8\u00a6\u013c\u00e9\u0128\u0134",
                    " sanct",
                    "eatures"
                ],
                "neg_values": [
                    -0.744,
                    -0.731,
                    -0.671,
                    -0.66,
                    -0.649,
                    -0.644,
                    -0.638,
                    -0.637,
                    -0.63,
                    -0.629
                ],
                "pos_str": [
                    "ton",
                    "baugh",
                    "ley",
                    "hurst",
                    "beer",
                    "berger",
                    "plin",
                    "gren",
                    "llan",
                    "zyk"
                ],
                "pos_values": [
                    0.899,
                    0.852,
                    0.834,
                    0.818,
                    0.778,
                    0.774,
                    0.771,
                    0.767,
                    0.765,
                    0.755
                ],
                "frac_nonzero": 0.00018,
                "freq_hist_data_bar_heights": [
                    140,
                    101,
                    58,
                    53,
                    44,
                    20,
                    23,
                    11,
                    8,
                    6,
                    5,
                    6,
                    9,
                    18,
                    7,
                    3,
                    5,
                    3,
                    3,
                    3,
                    0,
                    2,
                    3,
                    3,
                    7,
                    4,
                    2,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    2,
                    0,
                    0,
                    2,
                    1,
                    0,
                    1,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.259,
                    0.767,
                    1.274,
                    1.781,
                    2.289,
                    2.796,
                    3.303,
                    3.81,
                    4.318,
                    4.825,
                    5.332,
                    5.84,
                    6.347,
                    6.854,
                    7.361,
                    7.869,
                    8.376,
                    8.883,
                    9.391,
                    9.898,
                    10.405,
                    10.912,
                    11.42,
                    11.927,
                    12.434,
                    12.942,
                    13.449,
                    13.956,
                    14.463,
                    14.971,
                    15.478,
                    15.985,
                    16.493,
                    17,
                    17.507,
                    18.014,
                    18.522,
                    19.029,
                    19.536,
                    20.044,
                    20.551,
                    21.058,
                    21.565,
                    22.073,
                    22.58,
                    23.087,
                    23.595,
                    24.102,
                    24.609,
                    25.116
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    0,
                    3,
                    9,
                    16,
                    16,
                    33,
                    65,
                    84,
                    155,
                    260,
                    362,
                    590,
                    840,
                    1172,
                    1577,
                    1990,
                    2473,
                    2926,
                    3278,
                    3620,
                    3799,
                    3857,
                    3782,
                    3530,
                    3172,
                    2670,
                    2316,
                    1776,
                    1445,
                    1106,
                    882,
                    682,
                    502,
                    353,
                    300,
                    184,
                    127,
                    99,
                    76,
                    45,
                    33,
                    21,
                    12,
                    5,
                    5,
                    3,
                    1,
                    2,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.728,
                    -0.695,
                    -0.662,
                    -0.629,
                    -0.596,
                    -0.563,
                    -0.531,
                    -0.498,
                    -0.465,
                    -0.432,
                    -0.399,
                    -0.366,
                    -0.333,
                    -0.3,
                    -0.268,
                    -0.235,
                    -0.202,
                    -0.169,
                    -0.136,
                    -0.103,
                    -0.07,
                    -0.038,
                    -0.005,
                    0.028,
                    0.061,
                    0.094,
                    0.127,
                    0.16,
                    0.193,
                    0.225,
                    0.258,
                    0.291,
                    0.324,
                    0.357,
                    0.39,
                    0.423,
                    0.456,
                    0.488,
                    0.521,
                    0.554,
                    0.587,
                    0.62,
                    0.653,
                    0.686,
                    0.718,
                    0.751,
                    0.784,
                    0.817,
                    0.85,
                    0.883
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clz1h3g1y2k6pweoxv5n3j695",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "50890",
                        "description": "references to the university Temple",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-25T16:13:28.119Z",
                        "updatedAt": "2024-07-25T16:13:28.119Z"
                    },
                    {
                        "id": "clze2lfrh3aytv3wq9v77gw29",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "50890",
                        "description": "references to specific educational institutions, particularly Temple University",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T11:48:33.678Z",
                        "updatedAt": "2024-08-03T11:48:33.678Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghdjradv4810exd8wf4iqr",
                        "tokens": [
                            " its",
                            " \"",
                            "An",
                            "ch",
                            "or",
                            " Down",
                            "\"",
                            " jerseys",
                            " for",
                            " the",
                            " season",
                            " opener",
                            " against",
                            " Temple",
                            " and",
                            " nearly",
                            " paid",
                            " a",
                            " steep",
                            " price",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "We",
                            " sent",
                            " an",
                            " email",
                            " design",
                            " concept",
                            " to",
                            " the",
                            " NCAA",
                            " football",
                            " rules",
                            " committee",
                            ",",
                            " got",
                            " a",
                            " curs",
                            "ory",
                            " response",
                            " which",
                            " says",
                            ",",
                            " '",
                            "It",
                            " looks",
                            " good",
                            " to",
                            " us",
                            ",'\"",
                            " Vanderbilt",
                            " athletics",
                            " department",
                            " spokesman",
                            " Rod",
                            " Williamson",
                            " said",
                            " via",
                            " David",
                            " Cl",
                            "imer",
                            " of",
                            " The",
                            " Tenn",
                            "esse",
                            "an",
                            ".",
                            " \"",
                            "We",
                            " thought",
                            " that",
                            " meant",
                            " every",
                            " piece",
                            " of",
                            " the",
                            " communication",
                            " was",
                            " fine",
                            ".\"",
                            "\n",
                            "\n",
                            "Initially",
                            ",",
                            " officials",
                            " working",
                            " the",
                            " game",
                            " announced",
                            " that",
                            " the",
                            " Comm",
                            "od",
                            "ores",
                            "'",
                            " uniform",
                            " violation",
                            " would",
                            " result",
                            " in",
                            " a",
                            " loss",
                            " of",
                            " a",
                            " timeout",
                            " for",
                            " each",
                            " quarter",
                            " those",
                            " jerseys",
                            " were",
                            " worn",
                            ".",
                            " That",
                            " ruling",
                            " was",
                            " quickly",
                            " overturned",
                            ",",
                            " though",
                            " it",
                            " didn",
                            "'t",
                            " help",
                            " V"
                        ],
                        "dataIndex": null,
                        "index": "50890",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.37,
                        "maxValueTokenIndex": 13,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.37,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:09.816Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 25.37,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghdjrcdv4w10exi54c42ub",
                        "tokens": [
                            " its",
                            " \"",
                            "An",
                            "ch",
                            "or",
                            " Down",
                            "\"",
                            " jerseys",
                            " for",
                            " the",
                            " season",
                            " opener",
                            " against",
                            " Temple",
                            " and",
                            " nearly",
                            " paid",
                            " a",
                            " steep",
                            " price",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "We",
                            " sent",
                            " an",
                            " email",
                            " design",
                            " concept",
                            " to",
                            " the",
                            " NCAA",
                            " football",
                            " rules",
                            " committee",
                            ",",
                            " got",
                            " a",
                            " curs",
                            "ory",
                            " response",
                            " which",
                            " says",
                            ",",
                            " '",
                            "It",
                            " looks",
                            " good",
                            " to",
                            " us",
                            ",'\"",
                            " Vanderbilt",
                            " athletics",
                            " department",
                            " spokesman",
                            " Rod",
                            " Williamson",
                            " said",
                            " via",
                            " David",
                            " Cl",
                            "imer",
                            " of",
                            " The",
                            " Tenn",
                            "esse",
                            "an",
                            ".",
                            " \"",
                            "We",
                            " thought",
                            " that",
                            " meant",
                            " every",
                            " piece",
                            " of",
                            " the",
                            " communication",
                            " was",
                            " fine",
                            ".\"",
                            "\n",
                            "\n",
                            "Initially",
                            ",",
                            " officials",
                            " working",
                            " the",
                            " game",
                            " announced",
                            " that",
                            " the",
                            " Comm",
                            "od",
                            "ores",
                            "'",
                            " uniform",
                            " violation",
                            " would",
                            " result",
                            " in",
                            " a",
                            " loss",
                            " of",
                            " a",
                            " timeout",
                            " for",
                            " each",
                            " quarter",
                            " those",
                            " jerseys",
                            " were",
                            " worn",
                            ".",
                            " That",
                            " ruling",
                            " was",
                            " quickly",
                            " overturned",
                            ",",
                            " though",
                            " it",
                            " didn",
                            "'t",
                            " help",
                            " V"
                        ],
                        "dataIndex": null,
                        "index": "50890",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.37,
                        "maxValueTokenIndex": 13,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.37,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:09.816Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 20.296,
                        "binMax": 25.37,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghdjradv4910exrlz4k3x6",
                        "tokens": [
                            " side",
                            ",",
                            " he",
                            " works",
                            " as",
                            " a",
                            " personal",
                            " trainer",
                            " to",
                            " fund",
                            " the",
                            " cost",
                            " of",
                            " his",
                            " travel",
                            " to",
                            " races",
                            ".",
                            "\n",
                            "\n",
                            "H",
                            "ud",
                            "gins",
                            " does",
                            " his",
                            " primary",
                            " run",
                            " around",
                            " 11",
                            " a",
                            ".",
                            "m",
                            ".,",
                            " and",
                            " a",
                            " second",
                            " run",
                            " when",
                            " he",
                            " gets",
                            " off",
                            " work",
                            ",",
                            " around",
                            " 11",
                            ":",
                            "30",
                            " p",
                            ".",
                            "m",
                            ".",
                            " Add",
                            " in",
                            " nine",
                            " hours",
                            " of",
                            " work",
                            " per",
                            " day",
                            ",",
                            " travel",
                            " time",
                            ",",
                            " weight",
                            "lifting",
                            ",",
                            " and",
                            " sleep",
                            ",",
                            " and",
                            " there",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " a",
                            " lot",
                            " of",
                            " time",
                            " left",
                            " over",
                            ".",
                            "\n",
                            "\n",
                            "Part",
                            "ially",
                            " because",
                            " of",
                            " his",
                            " unconventional",
                            " work",
                            " schedule",
                            ",",
                            " he",
                            " does",
                            " the",
                            " majority",
                            " of",
                            " his",
                            " 75",
                            "-",
                            "90",
                            " miles",
                            " per",
                            " week",
                            " alone",
                            ".",
                            " He",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " coached",
                            " remotely",
                            " by",
                            " Temple",
                            " University",
                            " coach",
                            " James",
                            " Snyder",
                            ",",
                            " who",
                            " was",
                            " one",
                            " of",
                            " Hud",
                            "gins",
                            "\u00e2\u0122"
                        ],
                        "dataIndex": null,
                        "index": "50890",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 23.979,
                        "maxValueTokenIndex": 114,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            23.979,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:09.816Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 25.37,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 9,
    "hasMore": false
}