{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "cocaine"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "4478",
            "description": "words related to cocaine and other drugs",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 68.054,
            "frac_nonzero": 3e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "4478",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:05:55.715Z",
                "maxActApprox": 68.054,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    4478,
                    48085,
                    34627,
                    17266,
                    30639,
                    10368,
                    3869,
                    18722,
                    5080,
                    27650,
                    45150,
                    33396,
                    30496,
                    40950,
                    28078,
                    17880,
                    12080,
                    14729,
                    4495,
                    46327,
                    2029,
                    33972,
                    24319,
                    1026,
                    27687
                ],
                "topkCosSimValues": [
                    1,
                    0.5211,
                    0.4989,
                    0.4739,
                    0.4606,
                    0.4555,
                    0.4486,
                    0.433,
                    0.4296,
                    0.4278,
                    0.4227,
                    0.42,
                    0.4178,
                    0.4175,
                    0.4136,
                    0.4114,
                    0.4058,
                    0.3993,
                    0.3977,
                    0.3973,
                    0.3943,
                    0.3927,
                    0.3876,
                    0.3849,
                    0.381
                ],
                "neuron_alignment_indices": [
                    288,
                    746,
                    67
                ],
                "neuron_alignment_values": [
                    0.135,
                    0.116,
                    0.113
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    67,
                    746,
                    396
                ],
                "correlated_neurons_pearson": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_features_indices": [
                    4483,
                    4383,
                    4412
                ],
                "correlated_features_pearson": [
                    0.003,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0,
                    0
                ],
                "neg_str": [
                    "\u00e9\u0139\u013a",
                    " Barcl",
                    "\u00e8\u00a3\u0127",
                    " Fraz",
                    "\u012a\u0134",
                    "naires",
                    "\u00e3\u0125\u0126",
                    " GOODMAN",
                    "CLASS",
                    "Reviewer"
                ],
                "neg_values": [
                    -0.687,
                    -0.669,
                    -0.662,
                    -0.656,
                    -0.635,
                    -0.63,
                    -0.624,
                    -0.622,
                    -0.618,
                    -0.609
                ],
                "pos_str": [
                    "aine",
                    "leans",
                    "aleb",
                    "ilage",
                    "ulture",
                    "urrency",
                    "reated",
                    "ombs",
                    "urrencies",
                    "rary"
                ],
                "pos_values": [
                    1.07,
                    1.032,
                    0.995,
                    0.993,
                    0.983,
                    0.968,
                    0.956,
                    0.928,
                    0.926,
                    0.918
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    31,
                    17,
                    13,
                    7,
                    9,
                    4,
                    2,
                    1,
                    0,
                    2,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.7,
                    2.061,
                    3.422,
                    4.782,
                    6.143,
                    7.504,
                    8.864,
                    10.225,
                    11.586,
                    12.946,
                    14.307,
                    15.668,
                    17.028,
                    18.389,
                    19.75,
                    21.11,
                    22.471,
                    23.832,
                    25.192,
                    26.553,
                    27.914,
                    29.274,
                    30.635,
                    31.996,
                    33.356,
                    34.717,
                    36.078,
                    37.438,
                    38.799,
                    40.16,
                    41.52,
                    42.881,
                    44.242,
                    45.602,
                    46.963,
                    48.324,
                    49.684,
                    51.045,
                    52.406,
                    53.766,
                    55.127,
                    56.488,
                    57.848,
                    59.209,
                    60.57,
                    61.93,
                    63.291,
                    64.652,
                    66.012,
                    67.373
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    5,
                    4,
                    14,
                    20,
                    55,
                    99,
                    169,
                    269,
                    430,
                    695,
                    1104,
                    1554,
                    2075,
                    2682,
                    3277,
                    3774,
                    4260,
                    4365,
                    4135,
                    3902,
                    3345,
                    2815,
                    2342,
                    1933,
                    1517,
                    1171,
                    876,
                    721,
                    591,
                    438,
                    361,
                    289,
                    217,
                    199,
                    160,
                    115,
                    79,
                    49,
                    37,
                    29,
                    23,
                    29,
                    15,
                    2,
                    5,
                    1,
                    4,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.669,
                    -0.634,
                    -0.599,
                    -0.564,
                    -0.529,
                    -0.494,
                    -0.459,
                    -0.423,
                    -0.388,
                    -0.353,
                    -0.318,
                    -0.283,
                    -0.248,
                    -0.213,
                    -0.177,
                    -0.142,
                    -0.107,
                    -0.072,
                    -0.037,
                    -0.002,
                    0.033,
                    0.069,
                    0.104,
                    0.139,
                    0.174,
                    0.209,
                    0.244,
                    0.279,
                    0.315,
                    0.35,
                    0.385,
                    0.42,
                    0.455,
                    0.49,
                    0.525,
                    0.561,
                    0.596,
                    0.631,
                    0.666,
                    0.701,
                    0.736,
                    0.771,
                    0.807,
                    0.842,
                    0.877,
                    0.912,
                    0.947,
                    0.982,
                    1.017,
                    1.053
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyuuqf610a92nba6re6tj0z6",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs49152-jb",
                        "index": "4478",
                        "description": "words related to cocaine and other drugs",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-21T01:00:51.913Z",
                        "updatedAt": "2024-07-21T01:00:51.913Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4e4m4frqzi666r9tcxo6k",
                        "tokens": [
                            " of",
                            " 10",
                            "%",
                            " on",
                            " l",
                            "imes",
                            ",",
                            " bananas",
                            ",",
                            " mango",
                            "es",
                            ",",
                            " coc",
                            "on",
                            "uts",
                            ",",
                            " and",
                            " essentially",
                            " every",
                            " other",
                            " fruit",
                            " that",
                            " was",
                            " being",
                            " imported",
                            " to",
                            " the",
                            " US",
                            " at",
                            " the",
                            " time",
                            ".",
                            " Fruit",
                            " was",
                            " a",
                            " major",
                            " import",
                            " item",
                            ",",
                            " and",
                            " as",
                            " such",
                            ",",
                            " its",
                            " tariffs",
                            " constituted",
                            " a",
                            " considerable",
                            " portion",
                            " of",
                            " the",
                            " federal",
                            " budget",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " the",
                            " 18",
                            "72",
                            " revision",
                            ",",
                            " a",
                            " comma",
                            " was",
                            ",",
                            " for",
                            " some",
                            " inexplicable",
                            " reason",
                            ",",
                            " inserted",
                            " between",
                            " the",
                            " words",
                            " \u00e2\u0122",
                            "\u013e",
                            "fruit",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " \u00e2\u0122",
                            "\u013e",
                            "pl",
                            "ants",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " giving",
                            " fruit",
                            " imp",
                            "orters",
                            " the",
                            " means",
                            " of",
                            " evasion",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " been",
                            " looking",
                            " for",
                            ":",
                            "\n",
                            "\n",
                            "The",
                            " comma",
                            ",",
                            " intended",
                            " to",
                            " read",
                            " \u00e2\u0122",
                            "\u013e",
                            "fruit",
                            "-",
                            "pl",
                            "ants",
                            "\u00e2\u0122",
                            "\u013f",
                            " (",
                            "with",
                            " a",
                            " hyp",
                            "hen",
                            ",",
                            " not"
                        ],
                        "dataIndex": null,
                        "index": "4478",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 68.054,
                        "maxValueTokenIndex": 12,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            68.054,
                            6.279,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:06:03.910Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 68.053,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4e4m6frrki666ki7dzyqw",
                        "tokens": [
                            " of",
                            " 10",
                            "%",
                            " on",
                            " l",
                            "imes",
                            ",",
                            " bananas",
                            ",",
                            " mango",
                            "es",
                            ",",
                            " coc",
                            "on",
                            "uts",
                            ",",
                            " and",
                            " essentially",
                            " every",
                            " other",
                            " fruit",
                            " that",
                            " was",
                            " being",
                            " imported",
                            " to",
                            " the",
                            " US",
                            " at",
                            " the",
                            " time",
                            ".",
                            " Fruit",
                            " was",
                            " a",
                            " major",
                            " import",
                            " item",
                            ",",
                            " and",
                            " as",
                            " such",
                            ",",
                            " its",
                            " tariffs",
                            " constituted",
                            " a",
                            " considerable",
                            " portion",
                            " of",
                            " the",
                            " federal",
                            " budget",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " the",
                            " 18",
                            "72",
                            " revision",
                            ",",
                            " a",
                            " comma",
                            " was",
                            ",",
                            " for",
                            " some",
                            " inexplicable",
                            " reason",
                            ",",
                            " inserted",
                            " between",
                            " the",
                            " words",
                            " \u00e2\u0122",
                            "\u013e",
                            "fruit",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " \u00e2\u0122",
                            "\u013e",
                            "pl",
                            "ants",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " giving",
                            " fruit",
                            " imp",
                            "orters",
                            " the",
                            " means",
                            " of",
                            " evasion",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " been",
                            " looking",
                            " for",
                            ":",
                            "\n",
                            "\n",
                            "The",
                            " comma",
                            ",",
                            " intended",
                            " to",
                            " read",
                            " \u00e2\u0122",
                            "\u013e",
                            "fruit",
                            "-",
                            "pl",
                            "ants",
                            "\u00e2\u0122",
                            "\u013f",
                            " (",
                            "with",
                            " a",
                            " hyp",
                            "hen",
                            ",",
                            " not"
                        ],
                        "dataIndex": null,
                        "index": "4478",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 68.054,
                        "maxValueTokenIndex": 12,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            68.054,
                            6.279,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:06:03.910Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 54.443,
                        "binMax": 68.053,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4e4m4frr0i66662my2swp",
                        "tokens": [
                            " with",
                            " you",
                            ",",
                            " it",
                            "'s",
                            " fun",
                            " to",
                            " go",
                            " into",
                            " bar",
                            " bathrooms",
                            " with",
                            " another",
                            " person",
                            ",",
                            " and",
                            " wasting",
                            " money",
                            " feels",
                            " good",
                            ".",
                            " Coc",
                            "aine",
                            " activates",
                            " the",
                            " same",
                            " pleasure",
                            " centers",
                            " in",
                            " your",
                            " brain",
                            " as",
                            " breaking",
                            " champagne",
                            " glasses",
                            " or",
                            " taking",
                            " an",
                            " Uber",
                            ".",
                            " Te",
                            "ens",
                            " who",
                            " want",
                            " to",
                            " use",
                            " drugs",
                            " should",
                            " stick",
                            " with",
                            " pot",
                            " and",
                            " low",
                            "-",
                            "grade",
                            " psychedel",
                            "ics",
                            ",",
                            " drugs",
                            " that",
                            " coincide",
                            " with",
                            " their",
                            " unique",
                            " ability",
                            " to",
                            " identify",
                            " hypoc",
                            "rites",
                            " and",
                            " see",
                            " the",
                            " world",
                            " as",
                            " it",
                            " really",
                            " is",
                            ".",
                            " If",
                            " teens",
                            " want",
                            " to",
                            " feel",
                            " wired",
                            ",",
                            " they",
                            " should",
                            " use",
                            " energy",
                            " drinks",
                            " or",
                            " Ad",
                            "der",
                            "all",
                            ",",
                            " two",
                            " fairly",
                            " affordable",
                            " substances",
                            " that",
                            " they",
                            " already",
                            " have",
                            " easy",
                            " access",
                            " to",
                            ".",
                            " There",
                            "'s",
                            " a",
                            " time",
                            " and",
                            " a",
                            " place",
                            " for",
                            " cocaine",
                            ",",
                            " and",
                            " that",
                            " time",
                            " is",
                            " almost",
                            " never",
                            "\u2014",
                            "except",
                            " maybe",
                            " just"
                        ],
                        "dataIndex": null,
                        "index": "4478",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 55.244,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            55.244,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:06:03.910Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 68.053,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "59250",
            "description": "terms related to cocaine and addictive substances",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 64.474,
            "frac_nonzero": 3e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "59250",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:47:08.017Z",
                "maxActApprox": 64.474,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    59250,
                    15050,
                    84380,
                    31918,
                    60483,
                    89795,
                    46659,
                    51089,
                    58452,
                    96213,
                    13452,
                    34458,
                    5450,
                    66556,
                    37235,
                    20001,
                    56111,
                    86735,
                    64848,
                    47627,
                    13573,
                    46553,
                    68040,
                    5639,
                    38252
                ],
                "topkCosSimValues": [
                    1,
                    0.567,
                    0.5229,
                    0.5199,
                    0.509,
                    0.5043,
                    0.4949,
                    0.4874,
                    0.4476,
                    0.4393,
                    0.4369,
                    0.4324,
                    0.4318,
                    0.4268,
                    0.4234,
                    0.4189,
                    0.4133,
                    0.408,
                    0.4079,
                    0.4076,
                    0.3975,
                    0.3959,
                    0.3933,
                    0.3928,
                    0.3873
                ],
                "neuron_alignment_indices": [
                    288,
                    67,
                    746
                ],
                "neuron_alignment_values": [
                    0.149,
                    0.12,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    67,
                    746,
                    637
                ],
                "correlated_neurons_pearson": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_features_indices": [
                    59375,
                    59250,
                    59316
                ],
                "correlated_features_pearson": [
                    0.014,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.014,
                    0,
                    0
                ],
                "neg_str": [
                    "\u00e8\u00a3\u0127",
                    "journal",
                    "Reviewer",
                    "\u00e9\u0139\u013a",
                    " vest",
                    " publication",
                    " Bundes",
                    " modesty",
                    " detector",
                    "\u012a\u0134"
                ],
                "neg_values": [
                    -0.799,
                    -0.657,
                    -0.657,
                    -0.657,
                    -0.649,
                    -0.648,
                    -0.638,
                    -0.633,
                    -0.617,
                    -0.615
                ],
                "pos_str": [
                    "aine",
                    "aleb",
                    "urrencies",
                    "anut",
                    "ursor",
                    "keyes",
                    "urrency",
                    "keye",
                    "ilage",
                    "leans"
                ],
                "pos_values": [
                    1.191,
                    1.009,
                    0.995,
                    0.989,
                    0.978,
                    0.973,
                    0.97,
                    0.959,
                    0.927,
                    0.91
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    54,
                    16,
                    6,
                    3,
                    3,
                    4,
                    4,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    1,
                    0,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.647,
                    1.936,
                    3.226,
                    4.515,
                    5.805,
                    7.094,
                    8.383,
                    9.673,
                    10.962,
                    12.252,
                    13.541,
                    14.831,
                    16.12,
                    17.41,
                    18.699,
                    19.988,
                    21.278,
                    22.567,
                    23.857,
                    25.146,
                    26.436,
                    27.725,
                    29.015,
                    30.304,
                    31.593,
                    32.883,
                    34.172,
                    35.462,
                    36.751,
                    38.041,
                    39.33,
                    40.62,
                    41.909,
                    43.198,
                    44.488,
                    45.777,
                    47.067,
                    48.356,
                    49.646,
                    50.935,
                    52.225,
                    53.514,
                    54.803,
                    56.093,
                    57.382,
                    58.672,
                    59.961,
                    61.251,
                    62.54,
                    63.83
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    5,
                    8,
                    15,
                    25,
                    59,
                    100,
                    222,
                    375,
                    576,
                    1060,
                    1573,
                    2291,
                    2971,
                    3809,
                    4307,
                    4762,
                    4776,
                    4349,
                    3909,
                    3283,
                    2705,
                    2093,
                    1631,
                    1253,
                    934,
                    760,
                    586,
                    442,
                    346,
                    277,
                    229,
                    139,
                    119,
                    73,
                    57,
                    54,
                    32,
                    17,
                    18,
                    7,
                    1,
                    5,
                    2,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.779,
                    -0.739,
                    -0.7,
                    -0.66,
                    -0.62,
                    -0.58,
                    -0.54,
                    -0.501,
                    -0.461,
                    -0.421,
                    -0.381,
                    -0.341,
                    -0.302,
                    -0.262,
                    -0.222,
                    -0.182,
                    -0.142,
                    -0.103,
                    -0.063,
                    -0.023,
                    0.017,
                    0.057,
                    0.096,
                    0.136,
                    0.176,
                    0.216,
                    0.256,
                    0.295,
                    0.335,
                    0.375,
                    0.415,
                    0.455,
                    0.494,
                    0.534,
                    0.574,
                    0.614,
                    0.654,
                    0.693,
                    0.733,
                    0.773,
                    0.813,
                    0.852,
                    0.892,
                    0.932,
                    0.972,
                    1.012,
                    1.051,
                    1.091,
                    1.131,
                    1.171
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clzdaarpm2fnbv3wq4kboeaqf",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "59250",
                        "description": "terms related to cocaine and addictive substances",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-02T22:36:26.699Z",
                        "updatedAt": "2024-08-02T22:36:26.699Z"
                    },
                    {
                        "id": "clzehih2t4tujv3wq95mjzso8",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "59250",
                        "description": "terms related to cocaine and its derivatives",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T18:46:09.654Z",
                        "updatedAt": "2024-08-03T18:46:09.654Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghp3ihk70o10exv2s33yiy",
                        "tokens": [
                            " separate",
                            " canvas",
                            " contexts",
                            " for",
                            " each",
                            " view",
                            " that",
                            " then",
                            " get",
                            " compos",
                            "ited",
                            " back",
                            " together",
                            " at",
                            " the",
                            " final",
                            " step",
                            " in",
                            " rendering",
                            " using",
                            " draw",
                            "Image",
                            ".",
                            " This",
                            " style",
                            " is",
                            " akin",
                            " to",
                            " the",
                            " way",
                            " Core",
                            " Animation",
                            " works",
                            " in",
                            " Apple",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Coc",
                            "oa",
                            " framework",
                            ",",
                            " and",
                            " in",
                            " fact",
                            ",",
                            " GPU",
                            " accelerated",
                            " 3",
                            "D",
                            " transitions",
                            " are",
                            " possible",
                            " in",
                            " Blossom",
                            " as",
                            " well",
                            ".",
                            "\n",
                            "\n",
                            "Obviously",
                            ",",
                            " when",
                            " not",
                            " rendering",
                            " to",
                            " HTML",
                            " and",
                            " CSS",
                            ",",
                            " you",
                            " have",
                            " to",
                            " manage",
                            " everything",
                            " yourself",
                            ",",
                            " from",
                            " hit",
                            " testing",
                            " of",
                            " views",
                            ",",
                            " to",
                            " all",
                            " the",
                            " nuances",
                            " of",
                            " text",
                            " handling",
                            " including",
                            " all",
                            " the",
                            " platform",
                            " native",
                            " keyboard",
                            " shortcuts",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " the",
                            " first",
                            " time",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " an",
                            " attempt",
                            " to",
                            " create",
                            " an",
                            " entirely",
                            " canvas",
                            " based",
                            " view",
                            " pipeline",
                            ",",
                            " but",
                            " it",
                            " certainly"
                        ],
                        "dataIndex": null,
                        "index": "59250",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 64.474,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            64.474,
                            6.467,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:47:08.667Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 64.474,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghp3ijk71510ex8f724g7w",
                        "tokens": [
                            " separate",
                            " canvas",
                            " contexts",
                            " for",
                            " each",
                            " view",
                            " that",
                            " then",
                            " get",
                            " compos",
                            "ited",
                            " back",
                            " together",
                            " at",
                            " the",
                            " final",
                            " step",
                            " in",
                            " rendering",
                            " using",
                            " draw",
                            "Image",
                            ".",
                            " This",
                            " style",
                            " is",
                            " akin",
                            " to",
                            " the",
                            " way",
                            " Core",
                            " Animation",
                            " works",
                            " in",
                            " Apple",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Coc",
                            "oa",
                            " framework",
                            ",",
                            " and",
                            " in",
                            " fact",
                            ",",
                            " GPU",
                            " accelerated",
                            " 3",
                            "D",
                            " transitions",
                            " are",
                            " possible",
                            " in",
                            " Blossom",
                            " as",
                            " well",
                            ".",
                            "\n",
                            "\n",
                            "Obviously",
                            ",",
                            " when",
                            " not",
                            " rendering",
                            " to",
                            " HTML",
                            " and",
                            " CSS",
                            ",",
                            " you",
                            " have",
                            " to",
                            " manage",
                            " everything",
                            " yourself",
                            ",",
                            " from",
                            " hit",
                            " testing",
                            " of",
                            " views",
                            ",",
                            " to",
                            " all",
                            " the",
                            " nuances",
                            " of",
                            " text",
                            " handling",
                            " including",
                            " all",
                            " the",
                            " platform",
                            " native",
                            " keyboard",
                            " shortcuts",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " the",
                            " first",
                            " time",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " an",
                            " attempt",
                            " to",
                            " create",
                            " an",
                            " entirely",
                            " canvas",
                            " based",
                            " view",
                            " pipeline",
                            ",",
                            " but",
                            " it",
                            " certainly"
                        ],
                        "dataIndex": null,
                        "index": "59250",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 64.474,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            64.474,
                            6.467,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:47:08.667Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 64.474,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghp3ijk71910exzf65qpsr",
                        "tokens": [
                            " separate",
                            " canvas",
                            " contexts",
                            " for",
                            " each",
                            " view",
                            " that",
                            " then",
                            " get",
                            " compos",
                            "ited",
                            " back",
                            " together",
                            " at",
                            " the",
                            " final",
                            " step",
                            " in",
                            " rendering",
                            " using",
                            " draw",
                            "Image",
                            ".",
                            " This",
                            " style",
                            " is",
                            " akin",
                            " to",
                            " the",
                            " way",
                            " Core",
                            " Animation",
                            " works",
                            " in",
                            " Apple",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Coc",
                            "oa",
                            " framework",
                            ",",
                            " and",
                            " in",
                            " fact",
                            ",",
                            " GPU",
                            " accelerated",
                            " 3",
                            "D",
                            " transitions",
                            " are",
                            " possible",
                            " in",
                            " Blossom",
                            " as",
                            " well",
                            ".",
                            "\n",
                            "\n",
                            "Obviously",
                            ",",
                            " when",
                            " not",
                            " rendering",
                            " to",
                            " HTML",
                            " and",
                            " CSS",
                            ",",
                            " you",
                            " have",
                            " to",
                            " manage",
                            " everything",
                            " yourself",
                            ",",
                            " from",
                            " hit",
                            " testing",
                            " of",
                            " views",
                            ",",
                            " to",
                            " all",
                            " the",
                            " nuances",
                            " of",
                            " text",
                            " handling",
                            " including",
                            " all",
                            " the",
                            " platform",
                            " native",
                            " keyboard",
                            " shortcuts",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " the",
                            " first",
                            " time",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " an",
                            " attempt",
                            " to",
                            " create",
                            " an",
                            " entirely",
                            " canvas",
                            " based",
                            " view",
                            " pipeline",
                            ",",
                            " but",
                            " it",
                            " certainly"
                        ],
                        "dataIndex": null,
                        "index": "59250",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 64.474,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            64.474,
                            6.467,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:47:08.667Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 51.579,
                        "binMax": 64.474,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "59250",
            "description": "terms related to cocaine and its derivatives",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 64.474,
            "frac_nonzero": 3e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "59250",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:47:08.017Z",
                "maxActApprox": 64.474,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    59250,
                    15050,
                    84380,
                    31918,
                    60483,
                    89795,
                    46659,
                    51089,
                    58452,
                    96213,
                    13452,
                    34458,
                    5450,
                    66556,
                    37235,
                    20001,
                    56111,
                    86735,
                    64848,
                    47627,
                    13573,
                    46553,
                    68040,
                    5639,
                    38252
                ],
                "topkCosSimValues": [
                    1,
                    0.567,
                    0.5229,
                    0.5199,
                    0.509,
                    0.5043,
                    0.4949,
                    0.4874,
                    0.4476,
                    0.4393,
                    0.4369,
                    0.4324,
                    0.4318,
                    0.4268,
                    0.4234,
                    0.4189,
                    0.4133,
                    0.408,
                    0.4079,
                    0.4076,
                    0.3975,
                    0.3959,
                    0.3933,
                    0.3928,
                    0.3873
                ],
                "neuron_alignment_indices": [
                    288,
                    67,
                    746
                ],
                "neuron_alignment_values": [
                    0.149,
                    0.12,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    67,
                    746,
                    637
                ],
                "correlated_neurons_pearson": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_features_indices": [
                    59375,
                    59250,
                    59316
                ],
                "correlated_features_pearson": [
                    0.014,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.014,
                    0,
                    0
                ],
                "neg_str": [
                    "\u00e8\u00a3\u0127",
                    "journal",
                    "Reviewer",
                    "\u00e9\u0139\u013a",
                    " vest",
                    " publication",
                    " Bundes",
                    " modesty",
                    " detector",
                    "\u012a\u0134"
                ],
                "neg_values": [
                    -0.799,
                    -0.657,
                    -0.657,
                    -0.657,
                    -0.649,
                    -0.648,
                    -0.638,
                    -0.633,
                    -0.617,
                    -0.615
                ],
                "pos_str": [
                    "aine",
                    "aleb",
                    "urrencies",
                    "anut",
                    "ursor",
                    "keyes",
                    "urrency",
                    "keye",
                    "ilage",
                    "leans"
                ],
                "pos_values": [
                    1.191,
                    1.009,
                    0.995,
                    0.989,
                    0.978,
                    0.973,
                    0.97,
                    0.959,
                    0.927,
                    0.91
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    54,
                    16,
                    6,
                    3,
                    3,
                    4,
                    4,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    1,
                    0,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.647,
                    1.936,
                    3.226,
                    4.515,
                    5.805,
                    7.094,
                    8.383,
                    9.673,
                    10.962,
                    12.252,
                    13.541,
                    14.831,
                    16.12,
                    17.41,
                    18.699,
                    19.988,
                    21.278,
                    22.567,
                    23.857,
                    25.146,
                    26.436,
                    27.725,
                    29.015,
                    30.304,
                    31.593,
                    32.883,
                    34.172,
                    35.462,
                    36.751,
                    38.041,
                    39.33,
                    40.62,
                    41.909,
                    43.198,
                    44.488,
                    45.777,
                    47.067,
                    48.356,
                    49.646,
                    50.935,
                    52.225,
                    53.514,
                    54.803,
                    56.093,
                    57.382,
                    58.672,
                    59.961,
                    61.251,
                    62.54,
                    63.83
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    5,
                    8,
                    15,
                    25,
                    59,
                    100,
                    222,
                    375,
                    576,
                    1060,
                    1573,
                    2291,
                    2971,
                    3809,
                    4307,
                    4762,
                    4776,
                    4349,
                    3909,
                    3283,
                    2705,
                    2093,
                    1631,
                    1253,
                    934,
                    760,
                    586,
                    442,
                    346,
                    277,
                    229,
                    139,
                    119,
                    73,
                    57,
                    54,
                    32,
                    17,
                    18,
                    7,
                    1,
                    5,
                    2,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.779,
                    -0.739,
                    -0.7,
                    -0.66,
                    -0.62,
                    -0.58,
                    -0.54,
                    -0.501,
                    -0.461,
                    -0.421,
                    -0.381,
                    -0.341,
                    -0.302,
                    -0.262,
                    -0.222,
                    -0.182,
                    -0.142,
                    -0.103,
                    -0.063,
                    -0.023,
                    0.017,
                    0.057,
                    0.096,
                    0.136,
                    0.176,
                    0.216,
                    0.256,
                    0.295,
                    0.335,
                    0.375,
                    0.415,
                    0.455,
                    0.494,
                    0.534,
                    0.574,
                    0.614,
                    0.654,
                    0.693,
                    0.733,
                    0.773,
                    0.813,
                    0.852,
                    0.892,
                    0.932,
                    0.972,
                    1.012,
                    1.051,
                    1.091,
                    1.131,
                    1.171
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clzdaarpm2fnbv3wq4kboeaqf",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "59250",
                        "description": "terms related to cocaine and addictive substances",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-02T22:36:26.699Z",
                        "updatedAt": "2024-08-02T22:36:26.699Z"
                    },
                    {
                        "id": "clzehih2t4tujv3wq95mjzso8",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "59250",
                        "description": "terms related to cocaine and its derivatives",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T18:46:09.654Z",
                        "updatedAt": "2024-08-03T18:46:09.654Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghp3ihk70o10exv2s33yiy",
                        "tokens": [
                            " separate",
                            " canvas",
                            " contexts",
                            " for",
                            " each",
                            " view",
                            " that",
                            " then",
                            " get",
                            " compos",
                            "ited",
                            " back",
                            " together",
                            " at",
                            " the",
                            " final",
                            " step",
                            " in",
                            " rendering",
                            " using",
                            " draw",
                            "Image",
                            ".",
                            " This",
                            " style",
                            " is",
                            " akin",
                            " to",
                            " the",
                            " way",
                            " Core",
                            " Animation",
                            " works",
                            " in",
                            " Apple",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Coc",
                            "oa",
                            " framework",
                            ",",
                            " and",
                            " in",
                            " fact",
                            ",",
                            " GPU",
                            " accelerated",
                            " 3",
                            "D",
                            " transitions",
                            " are",
                            " possible",
                            " in",
                            " Blossom",
                            " as",
                            " well",
                            ".",
                            "\n",
                            "\n",
                            "Obviously",
                            ",",
                            " when",
                            " not",
                            " rendering",
                            " to",
                            " HTML",
                            " and",
                            " CSS",
                            ",",
                            " you",
                            " have",
                            " to",
                            " manage",
                            " everything",
                            " yourself",
                            ",",
                            " from",
                            " hit",
                            " testing",
                            " of",
                            " views",
                            ",",
                            " to",
                            " all",
                            " the",
                            " nuances",
                            " of",
                            " text",
                            " handling",
                            " including",
                            " all",
                            " the",
                            " platform",
                            " native",
                            " keyboard",
                            " shortcuts",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " the",
                            " first",
                            " time",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " an",
                            " attempt",
                            " to",
                            " create",
                            " an",
                            " entirely",
                            " canvas",
                            " based",
                            " view",
                            " pipeline",
                            ",",
                            " but",
                            " it",
                            " certainly"
                        ],
                        "dataIndex": null,
                        "index": "59250",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 64.474,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            64.474,
                            6.467,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:47:08.667Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 64.474,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghp3ijk71510ex8f724g7w",
                        "tokens": [
                            " separate",
                            " canvas",
                            " contexts",
                            " for",
                            " each",
                            " view",
                            " that",
                            " then",
                            " get",
                            " compos",
                            "ited",
                            " back",
                            " together",
                            " at",
                            " the",
                            " final",
                            " step",
                            " in",
                            " rendering",
                            " using",
                            " draw",
                            "Image",
                            ".",
                            " This",
                            " style",
                            " is",
                            " akin",
                            " to",
                            " the",
                            " way",
                            " Core",
                            " Animation",
                            " works",
                            " in",
                            " Apple",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Coc",
                            "oa",
                            " framework",
                            ",",
                            " and",
                            " in",
                            " fact",
                            ",",
                            " GPU",
                            " accelerated",
                            " 3",
                            "D",
                            " transitions",
                            " are",
                            " possible",
                            " in",
                            " Blossom",
                            " as",
                            " well",
                            ".",
                            "\n",
                            "\n",
                            "Obviously",
                            ",",
                            " when",
                            " not",
                            " rendering",
                            " to",
                            " HTML",
                            " and",
                            " CSS",
                            ",",
                            " you",
                            " have",
                            " to",
                            " manage",
                            " everything",
                            " yourself",
                            ",",
                            " from",
                            " hit",
                            " testing",
                            " of",
                            " views",
                            ",",
                            " to",
                            " all",
                            " the",
                            " nuances",
                            " of",
                            " text",
                            " handling",
                            " including",
                            " all",
                            " the",
                            " platform",
                            " native",
                            " keyboard",
                            " shortcuts",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " the",
                            " first",
                            " time",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " an",
                            " attempt",
                            " to",
                            " create",
                            " an",
                            " entirely",
                            " canvas",
                            " based",
                            " view",
                            " pipeline",
                            ",",
                            " but",
                            " it",
                            " certainly"
                        ],
                        "dataIndex": null,
                        "index": "59250",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 64.474,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            64.474,
                            6.467,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:47:08.667Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 64.474,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghp3ijk71910exzf65qpsr",
                        "tokens": [
                            " separate",
                            " canvas",
                            " contexts",
                            " for",
                            " each",
                            " view",
                            " that",
                            " then",
                            " get",
                            " compos",
                            "ited",
                            " back",
                            " together",
                            " at",
                            " the",
                            " final",
                            " step",
                            " in",
                            " rendering",
                            " using",
                            " draw",
                            "Image",
                            ".",
                            " This",
                            " style",
                            " is",
                            " akin",
                            " to",
                            " the",
                            " way",
                            " Core",
                            " Animation",
                            " works",
                            " in",
                            " Apple",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Coc",
                            "oa",
                            " framework",
                            ",",
                            " and",
                            " in",
                            " fact",
                            ",",
                            " GPU",
                            " accelerated",
                            " 3",
                            "D",
                            " transitions",
                            " are",
                            " possible",
                            " in",
                            " Blossom",
                            " as",
                            " well",
                            ".",
                            "\n",
                            "\n",
                            "Obviously",
                            ",",
                            " when",
                            " not",
                            " rendering",
                            " to",
                            " HTML",
                            " and",
                            " CSS",
                            ",",
                            " you",
                            " have",
                            " to",
                            " manage",
                            " everything",
                            " yourself",
                            ",",
                            " from",
                            " hit",
                            " testing",
                            " of",
                            " views",
                            ",",
                            " to",
                            " all",
                            " the",
                            " nuances",
                            " of",
                            " text",
                            " handling",
                            " including",
                            " all",
                            " the",
                            " platform",
                            " native",
                            " keyboard",
                            " shortcuts",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " the",
                            " first",
                            " time",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " an",
                            " attempt",
                            " to",
                            " create",
                            " an",
                            " entirely",
                            " canvas",
                            " based",
                            " view",
                            " pipeline",
                            ",",
                            " but",
                            " it",
                            " certainly"
                        ],
                        "dataIndex": null,
                        "index": "59250",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 64.474,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            64.474,
                            6.467,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:47:08.667Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 51.579,
                        "binMax": 64.474,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "30639",
            "description": "references to cocaine and related substances",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 60.762,
            "frac_nonzero": 8.999999999999999e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "30639",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:53:54.144Z",
                "maxActApprox": 60.762,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    30639,
                    32046,
                    36761,
                    47759,
                    47962,
                    22479,
                    13385,
                    37288,
                    27285,
                    1849,
                    6388,
                    4478,
                    46260,
                    32573,
                    26614,
                    9844,
                    37692,
                    5364,
                    2522,
                    45361,
                    29808,
                    25100,
                    23753,
                    12971,
                    14632
                ],
                "topkCosSimValues": [
                    1,
                    0.7064,
                    0.6306,
                    0.6096,
                    0.5965,
                    0.5213,
                    0.5164,
                    0.5096,
                    0.4945,
                    0.4846,
                    0.4759,
                    0.4606,
                    0.4447,
                    0.4392,
                    0.4384,
                    0.4383,
                    0.4367,
                    0.4308,
                    0.427,
                    0.4269,
                    0.4255,
                    0.4244,
                    0.424,
                    0.4194,
                    0.4147
                ],
                "neuron_alignment_indices": [
                    481,
                    288,
                    447
                ],
                "neuron_alignment_values": [
                    0.164,
                    0.134,
                    0.123
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.006,
                    0.006
                ],
                "correlated_neurons_indices": [
                    698,
                    461,
                    384
                ],
                "correlated_neurons_pearson": [
                    0.012,
                    0.011,
                    0.01
                ],
                "correlated_neurons_l1": [
                    0.012,
                    0.01,
                    0.009
                ],
                "correlated_features_indices": [
                    30707,
                    30636,
                    30682
                ],
                "correlated_features_pearson": [
                    0.006,
                    0.002,
                    0.001
                ],
                "correlated_features_l1": [
                    0.006,
                    0.002,
                    0.001
                ],
                "neg_str": [
                    "laus",
                    "hof",
                    "\u012a\u0134",
                    "DEM",
                    "Reviewer",
                    "soType",
                    "Madison",
                    "aer",
                    " Koen",
                    " Brach"
                ],
                "neg_values": [
                    -0.775,
                    -0.768,
                    -0.73,
                    -0.718,
                    -0.691,
                    -0.69,
                    -0.688,
                    -0.685,
                    -0.683,
                    -0.677
                ],
                "pos_str": [
                    " cocaine",
                    " residue",
                    " addict",
                    " addicts",
                    " addiction",
                    " overdose",
                    " overdoses",
                    " poisoning",
                    " methamphetamine",
                    " cartels"
                ],
                "pos_values": [
                    1.239,
                    1.076,
                    1.065,
                    1.053,
                    1.047,
                    1.035,
                    1.023,
                    0.967,
                    0.967,
                    0.948
                ],
                "frac_nonzero": 8.999999999999999e-05,
                "freq_hist_data_bar_heights": [
                    95,
                    44,
                    28,
                    18,
                    13,
                    6,
                    7,
                    8,
                    3,
                    5,
                    2,
                    6,
                    3,
                    4,
                    3,
                    1,
                    0,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    2,
                    1,
                    0,
                    0,
                    5,
                    5,
                    8,
                    6,
                    0,
                    2,
                    3,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.647,
                    1.861,
                    3.076,
                    4.29,
                    5.504,
                    6.719,
                    7.933,
                    9.148,
                    10.362,
                    11.577,
                    12.791,
                    14.006,
                    15.22,
                    16.434,
                    17.649,
                    18.863,
                    20.078,
                    21.292,
                    22.507,
                    23.721,
                    24.936,
                    26.15,
                    27.364,
                    28.579,
                    29.793,
                    31.008,
                    32.222,
                    33.437,
                    34.651,
                    35.866,
                    37.08,
                    38.294,
                    39.509,
                    40.723,
                    41.938,
                    43.152,
                    44.367,
                    45.581,
                    46.796,
                    48.01,
                    49.224,
                    50.439,
                    51.653,
                    52.868,
                    54.082,
                    55.297,
                    56.511,
                    57.726,
                    58.94,
                    60.154
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    2,
                    16,
                    13,
                    39,
                    52,
                    129,
                    201,
                    318,
                    471,
                    774,
                    1102,
                    1573,
                    2101,
                    2587,
                    3252,
                    3735,
                    4001,
                    4241,
                    4310,
                    4008,
                    3676,
                    3172,
                    2595,
                    2145,
                    1675,
                    1169,
                    873,
                    622,
                    446,
                    281,
                    213,
                    148,
                    102,
                    66,
                    47,
                    26,
                    25,
                    10,
                    12,
                    7,
                    7,
                    4,
                    2,
                    2,
                    4,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.755,
                    -0.715,
                    -0.674,
                    -0.634,
                    -0.594,
                    -0.553,
                    -0.513,
                    -0.473,
                    -0.433,
                    -0.392,
                    -0.352,
                    -0.312,
                    -0.272,
                    -0.231,
                    -0.191,
                    -0.151,
                    -0.11,
                    -0.07,
                    -0.03,
                    0.01,
                    0.051,
                    0.091,
                    0.131,
                    0.172,
                    0.212,
                    0.252,
                    0.292,
                    0.333,
                    0.373,
                    0.413,
                    0.453,
                    0.494,
                    0.534,
                    0.574,
                    0.615,
                    0.655,
                    0.695,
                    0.735,
                    0.776,
                    0.816,
                    0.856,
                    0.897,
                    0.937,
                    0.977,
                    1.017,
                    1.058,
                    1.098,
                    1.138,
                    1.178,
                    1.219
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyvgh8a01yjlnba6xyc4kjoo",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs49152-jb",
                        "index": "30639",
                        "description": "references to cocaine and related substances",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-21T11:09:34.633Z",
                        "updatedAt": "2024-07-21T11:09:34.633Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk63su13vk0i666y89f2cvr",
                        "tokens": [
                            ",",
                            " said",
                            " senior",
                            " author",
                            " Don",
                            " Cooper",
                            ",",
                            " assistant",
                            " professor",
                            " of",
                            " psychiatry",
                            " at",
                            " the",
                            " University",
                            " of",
                            " Texas",
                            " South",
                            "western",
                            " Medical",
                            " Center",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " idea",
                            ",",
                            " that",
                            " an",
                            " individual",
                            " nerve",
                            " cell",
                            " can",
                            " hold",
                            " a",
                            " trace",
                            " memory",
                            ",",
                            " is",
                            " also",
                            " related",
                            " to",
                            " drug",
                            " addiction",
                            ",",
                            " the",
                            " study",
                            " found",
                            ".",
                            " By",
                            " giving",
                            " cocaine",
                            " to",
                            " mice",
                            " in",
                            " the",
                            " laboratory",
                            ",",
                            " the",
                            " researchers",
                            " explained",
                            " why",
                            " the",
                            " drug",
                            " imp",
                            "airs",
                            " short",
                            " term",
                            " memory",
                            ":",
                            " Coc",
                            "aine",
                            " causes",
                            " a",
                            " buildup",
                            " of",
                            " dopamine",
                            ",",
                            " a",
                            " brain",
                            " chemical",
                            " that",
                            " decreases",
                            " the",
                            " individual",
                            " nerve",
                            " cells",
                            "'",
                            " ability",
                            " to",
                            " hold",
                            " moment",
                            "-",
                            "to",
                            "-",
                            "mom",
                            "ent",
                            " information",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " study",
                            " is",
                            " an",
                            " important",
                            " contribution",
                            " to",
                            " the",
                            " field",
                            " of",
                            " working",
                            " memory",
                            " because",
                            " it",
                            " shows",
                            " the",
                            " molecular",
                            " mechanisms",
                            " involved",
                            " in",
                            " the",
                            " process",
                            ",",
                            " said",
                            " Michael",
                            " Kuh",
                            "ar"
                        ],
                        "dataIndex": null,
                        "index": "30639",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 60.762,
                        "maxValueTokenIndex": 50,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.155,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            60.762,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.201,
                            20.7,
                            0,
                            0,
                            0,
                            0,
                            8.172,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:54:01.192Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 60.762,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk63su13vk1i666whq7bvot",
                        "tokens": [
                            " dollars",
                            " worth",
                            " of",
                            " cocaine",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " ATF",
                            " agent",
                            " explains",
                            " that",
                            " he",
                            " needs",
                            " a",
                            " robbery",
                            " crew",
                            " to",
                            " help",
                            " him",
                            " overtake",
                            " armed",
                            " guards",
                            " in",
                            " the",
                            " house",
                            " and",
                            " steal",
                            " the",
                            " cocaine",
                            ".",
                            " Once",
                            " the",
                            " crew",
                            " meets",
                            " to",
                            " prepare",
                            " for",
                            " the",
                            " armed",
                            " robbery",
                            ",",
                            " federal",
                            " authorities",
                            " bust",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "Several",
                            " of",
                            " the",
                            " bust",
                            "s",
                            " have",
                            " lead",
                            " to",
                            " the",
                            " deaths",
                            " of",
                            " suspects",
                            " who",
                            " shot",
                            " at",
                            " or",
                            " tried",
                            " to",
                            " run",
                            " down",
                            " agents",
                            " in",
                            " an",
                            " attempt",
                            " to",
                            " flee",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            "form",
                            "ants",
                            " are",
                            " paid",
                            " by",
                            " the",
                            " ATF",
                            " to",
                            " pressure",
                            " people",
                            " to",
                            " join",
                            " the",
                            " fake",
                            " robberies",
                            ".",
                            " Individuals",
                            " may",
                            " be",
                            " targeted",
                            " simply",
                            " because",
                            " the",
                            " informants",
                            " know",
                            " them",
                            " through",
                            " work",
                            " or",
                            " a",
                            " personal",
                            " connection",
                            ",",
                            " just",
                            " like",
                            " a",
                            " r",
                            "affle",
                            " ticket",
                            " sale",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " preparation",
                            " for",
                            " the",
                            " fake"
                        ],
                        "dataIndex": null,
                        "index": "30639",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 60.716,
                        "maxValueTokenIndex": 3,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            60.716,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            51.546,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:54:01.192Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 60.762,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk63su43vkmi6660ns383u1",
                        "tokens": [
                            " dollars",
                            " worth",
                            " of",
                            " cocaine",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " ATF",
                            " agent",
                            " explains",
                            " that",
                            " he",
                            " needs",
                            " a",
                            " robbery",
                            " crew",
                            " to",
                            " help",
                            " him",
                            " overtake",
                            " armed",
                            " guards",
                            " in",
                            " the",
                            " house",
                            " and",
                            " steal",
                            " the",
                            " cocaine",
                            ".",
                            " Once",
                            " the",
                            " crew",
                            " meets",
                            " to",
                            " prepare",
                            " for",
                            " the",
                            " armed",
                            " robbery",
                            ",",
                            " federal",
                            " authorities",
                            " bust",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "Several",
                            " of",
                            " the",
                            " bust",
                            "s",
                            " have",
                            " lead",
                            " to",
                            " the",
                            " deaths",
                            " of",
                            " suspects",
                            " who",
                            " shot",
                            " at",
                            " or",
                            " tried",
                            " to",
                            " run",
                            " down",
                            " agents",
                            " in",
                            " an",
                            " attempt",
                            " to",
                            " flee",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            "form",
                            "ants",
                            " are",
                            " paid",
                            " by",
                            " the",
                            " ATF",
                            " to",
                            " pressure",
                            " people",
                            " to",
                            " join",
                            " the",
                            " fake",
                            " robberies",
                            ".",
                            " Individuals",
                            " may",
                            " be",
                            " targeted",
                            " simply",
                            " because",
                            " the",
                            " informants",
                            " know",
                            " them",
                            " through",
                            " work",
                            " or",
                            " a",
                            " personal",
                            " connection",
                            ",",
                            " just",
                            " like",
                            " a",
                            " r",
                            "affle",
                            " ticket",
                            " sale",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " preparation",
                            " for",
                            " the",
                            " fake"
                        ],
                        "dataIndex": null,
                        "index": "30639",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 60.716,
                        "maxValueTokenIndex": 3,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            60.716,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            51.546,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:54:01.192Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 48.609,
                        "binMax": 60.762,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "15050",
            "description": "words related to cocaine or its derivatives",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 59.167,
            "frac_nonzero": 1e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "15050",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:46:40.099Z",
                "maxActApprox": 59.167,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    15050,
                    59250,
                    46659,
                    96213,
                    35384,
                    20001,
                    53894,
                    61758,
                    97812,
                    54916,
                    89659,
                    59995,
                    63306,
                    89795,
                    43230,
                    51089,
                    56061,
                    27167,
                    13573,
                    22878,
                    10082,
                    77583,
                    13452,
                    81902,
                    59394
                ],
                "topkCosSimValues": [
                    1,
                    0.567,
                    0.4435,
                    0.4428,
                    0.4062,
                    0.4002,
                    0.3993,
                    0.3906,
                    0.3899,
                    0.3875,
                    0.3873,
                    0.3867,
                    0.3848,
                    0.38,
                    0.3789,
                    0.3775,
                    0.3761,
                    0.3754,
                    0.3736,
                    0.3703,
                    0.3694,
                    0.3664,
                    0.3635,
                    0.3619,
                    0.3614
                ],
                "neuron_alignment_indices": [
                    288,
                    549,
                    545
                ],
                "neuron_alignment_values": [
                    0.127,
                    0.114,
                    0.108
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    746,
                    67,
                    545
                ],
                "correlated_neurons_pearson": [
                    0.004,
                    0.004,
                    0.003
                ],
                "correlated_neurons_l1": [
                    0.003,
                    0.004,
                    0.003
                ],
                "correlated_features_indices": [
                    15014,
                    15057,
                    15077
                ],
                "correlated_features_pearson": [
                    0.002,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0,
                    0
                ],
                "neg_str": [
                    " Barcl",
                    " GOODMAN",
                    "\u012a\u0134",
                    "\u00e9\u0139\u013a",
                    "CLASS",
                    " Wembley",
                    " Turk",
                    " Prompt",
                    "\u00e3\u0124\u00b6",
                    "DragonMagazine"
                ],
                "neg_values": [
                    -0.826,
                    -0.719,
                    -0.682,
                    -0.651,
                    -0.649,
                    -0.634,
                    -0.61,
                    -0.602,
                    -0.601,
                    -0.597
                ],
                "pos_str": [
                    " coc",
                    "ulture",
                    "anus",
                    "leans",
                    "reated",
                    "roach",
                    "ombs",
                    "overed",
                    "ategor",
                    "ached"
                ],
                "pos_values": [
                    1.031,
                    0.994,
                    0.951,
                    0.939,
                    0.886,
                    0.886,
                    0.858,
                    0.852,
                    0.851,
                    0.845
                ],
                "frac_nonzero": 1e-05,
                "freq_hist_data_bar_heights": [
                    17,
                    3,
                    1,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.612,
                    1.795,
                    2.978,
                    4.161,
                    5.344,
                    6.527,
                    7.709,
                    8.892,
                    10.075,
                    11.258,
                    12.441,
                    13.624,
                    14.807,
                    15.99,
                    17.173,
                    18.356,
                    19.539,
                    20.722,
                    21.905,
                    23.088,
                    24.27,
                    25.453,
                    26.636,
                    27.819,
                    29.002,
                    30.185,
                    31.368,
                    32.551,
                    33.734,
                    34.917,
                    36.1,
                    37.283,
                    38.466,
                    39.648,
                    40.831,
                    42.014,
                    43.197,
                    44.38,
                    45.563,
                    46.746,
                    47.929,
                    49.112,
                    50.295,
                    51.478,
                    52.661,
                    53.844,
                    55.027,
                    56.209,
                    57.392,
                    58.575
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    1,
                    2,
                    2,
                    14,
                    19,
                    39,
                    77,
                    146,
                    279,
                    474,
                    706,
                    1033,
                    1548,
                    2120,
                    2744,
                    3392,
                    3971,
                    4313,
                    4430,
                    4395,
                    3999,
                    3619,
                    2957,
                    2377,
                    1861,
                    1462,
                    1075,
                    830,
                    616,
                    495,
                    336,
                    262,
                    207,
                    154,
                    106,
                    67,
                    45,
                    33,
                    13,
                    15,
                    9,
                    3,
                    3,
                    2,
                    2,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.808,
                    -0.77,
                    -0.733,
                    -0.696,
                    -0.659,
                    -0.622,
                    -0.585,
                    -0.548,
                    -0.51,
                    -0.473,
                    -0.436,
                    -0.399,
                    -0.362,
                    -0.325,
                    -0.288,
                    -0.25,
                    -0.213,
                    -0.176,
                    -0.139,
                    -0.102,
                    -0.065,
                    -0.027,
                    0.01,
                    0.047,
                    0.084,
                    0.121,
                    0.158,
                    0.195,
                    0.233,
                    0.27,
                    0.307,
                    0.344,
                    0.381,
                    0.418,
                    0.456,
                    0.493,
                    0.53,
                    0.567,
                    0.604,
                    0.641,
                    0.678,
                    0.716,
                    0.753,
                    0.79,
                    0.827,
                    0.864,
                    0.901,
                    0.938,
                    0.976,
                    1.013
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyzwu4u822ft5q0zee2tyktc",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "15050",
                        "description": "words related to cocaine or its derivatives",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-24T13:58:35.264Z",
                        "updatedAt": "2024-07-24T13:58:35.264Z"
                    },
                    {
                        "id": "clzeao1hy43dbv3wqlhwfdll0",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "15050",
                        "description": "references to cocaine",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T15:34:32.087Z",
                        "updatedAt": "2024-08-03T15:34:32.087Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfji3cmpco10exk98lwyr5",
                        "tokens": [
                            "Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " statement",
                            " calling",
                            " President",
                            " Trump",
                            " \u00e2\u0122",
                            "\u013e",
                            "ment",
                            "ally",
                            " der",
                            "anged",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " promising",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "highest",
                            "-",
                            "level",
                            " of",
                            " the",
                            " hard",
                            "line",
                            " counter",
                            "measures",
                            "\u00e2\u0122",
                            "\u013f",
                            " shows",
                            " that",
                            " he",
                            " has",
                            " taken",
                            " ownership",
                            " of",
                            " this",
                            " showdown",
                            " and",
                            " that",
                            " he",
                            " alone",
                            "\u2014",
                            "as",
                            " the",
                            " leader",
                            " of",
                            " North",
                            " Korea",
                            "\u2014",
                            "will",
                            " defend",
                            " the",
                            " country",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " survival",
                            ",",
                            " as",
                            " well",
                            " as",
                            " its",
                            " dignity",
                            ".",
                            " Kim",
                            " also",
                            " has",
                            " a",
                            " bias",
                            " for",
                            " action",
                            " and",
                            " he",
                            " wants",
                            " to",
                            " win",
                            ",",
                            " as",
                            " the",
                            " Kim",
                            " family",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " former",
                            " sushi",
                            " chef",
                            " recalled",
                            ",",
                            " and",
                            " as",
                            " Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " recent",
                            " behavior",
                            " has",
                            " shown",
                            ".",
                            " Not",
                            " only",
                            " has",
                            " Kim",
                            " Jong",
                            "-",
                            "un",
                            " grown",
                            " up",
                            " in",
                            " a",
                            " coc",
                            "oon",
                            " of",
                            " indul",
                            "gence",
                            " and",
                            " privilege",
                            ",",
                            " he",
                            " has",
                            " inherited",
                            " advanced"
                        ],
                        "dataIndex": null,
                        "index": "15050",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.167,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.167,
                            7.314,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:48.361Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 59.167,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfji3cmpcs10exyu8nva2a",
                        "tokens": [
                            "Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " statement",
                            " calling",
                            " President",
                            " Trump",
                            " \u00e2\u0122",
                            "\u013e",
                            "ment",
                            "ally",
                            " der",
                            "anged",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " promising",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "highest",
                            "-",
                            "level",
                            " of",
                            " the",
                            " hard",
                            "line",
                            " counter",
                            "measures",
                            "\u00e2\u0122",
                            "\u013f",
                            " shows",
                            " that",
                            " he",
                            " has",
                            " taken",
                            " ownership",
                            " of",
                            " this",
                            " showdown",
                            " and",
                            " that",
                            " he",
                            " alone",
                            "\u2014",
                            "as",
                            " the",
                            " leader",
                            " of",
                            " North",
                            " Korea",
                            "\u2014",
                            "will",
                            " defend",
                            " the",
                            " country",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " survival",
                            ",",
                            " as",
                            " well",
                            " as",
                            " its",
                            " dignity",
                            ".",
                            " Kim",
                            " also",
                            " has",
                            " a",
                            " bias",
                            " for",
                            " action",
                            " and",
                            " he",
                            " wants",
                            " to",
                            " win",
                            ",",
                            " as",
                            " the",
                            " Kim",
                            " family",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " former",
                            " sushi",
                            " chef",
                            " recalled",
                            ",",
                            " and",
                            " as",
                            " Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " recent",
                            " behavior",
                            " has",
                            " shown",
                            ".",
                            " Not",
                            " only",
                            " has",
                            " Kim",
                            " Jong",
                            "-",
                            "un",
                            " grown",
                            " up",
                            " in",
                            " a",
                            " coc",
                            "oon",
                            " of",
                            " indul",
                            "gence",
                            " and",
                            " privilege",
                            ",",
                            " he",
                            " has",
                            " inherited",
                            " advanced"
                        ],
                        "dataIndex": null,
                        "index": "15050",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.167,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.167,
                            7.314,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:48.361Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 59.167,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfji3empda10exp8io8tig",
                        "tokens": [
                            "Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " statement",
                            " calling",
                            " President",
                            " Trump",
                            " \u00e2\u0122",
                            "\u013e",
                            "ment",
                            "ally",
                            " der",
                            "anged",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " promising",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "highest",
                            "-",
                            "level",
                            " of",
                            " the",
                            " hard",
                            "line",
                            " counter",
                            "measures",
                            "\u00e2\u0122",
                            "\u013f",
                            " shows",
                            " that",
                            " he",
                            " has",
                            " taken",
                            " ownership",
                            " of",
                            " this",
                            " showdown",
                            " and",
                            " that",
                            " he",
                            " alone",
                            "\u2014",
                            "as",
                            " the",
                            " leader",
                            " of",
                            " North",
                            " Korea",
                            "\u2014",
                            "will",
                            " defend",
                            " the",
                            " country",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " survival",
                            ",",
                            " as",
                            " well",
                            " as",
                            " its",
                            " dignity",
                            ".",
                            " Kim",
                            " also",
                            " has",
                            " a",
                            " bias",
                            " for",
                            " action",
                            " and",
                            " he",
                            " wants",
                            " to",
                            " win",
                            ",",
                            " as",
                            " the",
                            " Kim",
                            " family",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " former",
                            " sushi",
                            " chef",
                            " recalled",
                            ",",
                            " and",
                            " as",
                            " Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " recent",
                            " behavior",
                            " has",
                            " shown",
                            ".",
                            " Not",
                            " only",
                            " has",
                            " Kim",
                            " Jong",
                            "-",
                            "un",
                            " grown",
                            " up",
                            " in",
                            " a",
                            " coc",
                            "oon",
                            " of",
                            " indul",
                            "gence",
                            " and",
                            " privilege",
                            ",",
                            " he",
                            " has",
                            " inherited",
                            " advanced"
                        ],
                        "dataIndex": null,
                        "index": "15050",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.167,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.167,
                            7.314,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:48.361Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 47.333,
                        "binMax": 59.167,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "15050",
            "description": "references to cocaine",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 59.167,
            "frac_nonzero": 1e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "15050",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:46:40.099Z",
                "maxActApprox": 59.167,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    15050,
                    59250,
                    46659,
                    96213,
                    35384,
                    20001,
                    53894,
                    61758,
                    97812,
                    54916,
                    89659,
                    59995,
                    63306,
                    89795,
                    43230,
                    51089,
                    56061,
                    27167,
                    13573,
                    22878,
                    10082,
                    77583,
                    13452,
                    81902,
                    59394
                ],
                "topkCosSimValues": [
                    1,
                    0.567,
                    0.4435,
                    0.4428,
                    0.4062,
                    0.4002,
                    0.3993,
                    0.3906,
                    0.3899,
                    0.3875,
                    0.3873,
                    0.3867,
                    0.3848,
                    0.38,
                    0.3789,
                    0.3775,
                    0.3761,
                    0.3754,
                    0.3736,
                    0.3703,
                    0.3694,
                    0.3664,
                    0.3635,
                    0.3619,
                    0.3614
                ],
                "neuron_alignment_indices": [
                    288,
                    549,
                    545
                ],
                "neuron_alignment_values": [
                    0.127,
                    0.114,
                    0.108
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    746,
                    67,
                    545
                ],
                "correlated_neurons_pearson": [
                    0.004,
                    0.004,
                    0.003
                ],
                "correlated_neurons_l1": [
                    0.003,
                    0.004,
                    0.003
                ],
                "correlated_features_indices": [
                    15014,
                    15057,
                    15077
                ],
                "correlated_features_pearson": [
                    0.002,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0,
                    0
                ],
                "neg_str": [
                    " Barcl",
                    " GOODMAN",
                    "\u012a\u0134",
                    "\u00e9\u0139\u013a",
                    "CLASS",
                    " Wembley",
                    " Turk",
                    " Prompt",
                    "\u00e3\u0124\u00b6",
                    "DragonMagazine"
                ],
                "neg_values": [
                    -0.826,
                    -0.719,
                    -0.682,
                    -0.651,
                    -0.649,
                    -0.634,
                    -0.61,
                    -0.602,
                    -0.601,
                    -0.597
                ],
                "pos_str": [
                    " coc",
                    "ulture",
                    "anus",
                    "leans",
                    "reated",
                    "roach",
                    "ombs",
                    "overed",
                    "ategor",
                    "ached"
                ],
                "pos_values": [
                    1.031,
                    0.994,
                    0.951,
                    0.939,
                    0.886,
                    0.886,
                    0.858,
                    0.852,
                    0.851,
                    0.845
                ],
                "frac_nonzero": 1e-05,
                "freq_hist_data_bar_heights": [
                    17,
                    3,
                    1,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.612,
                    1.795,
                    2.978,
                    4.161,
                    5.344,
                    6.527,
                    7.709,
                    8.892,
                    10.075,
                    11.258,
                    12.441,
                    13.624,
                    14.807,
                    15.99,
                    17.173,
                    18.356,
                    19.539,
                    20.722,
                    21.905,
                    23.088,
                    24.27,
                    25.453,
                    26.636,
                    27.819,
                    29.002,
                    30.185,
                    31.368,
                    32.551,
                    33.734,
                    34.917,
                    36.1,
                    37.283,
                    38.466,
                    39.648,
                    40.831,
                    42.014,
                    43.197,
                    44.38,
                    45.563,
                    46.746,
                    47.929,
                    49.112,
                    50.295,
                    51.478,
                    52.661,
                    53.844,
                    55.027,
                    56.209,
                    57.392,
                    58.575
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    1,
                    2,
                    2,
                    14,
                    19,
                    39,
                    77,
                    146,
                    279,
                    474,
                    706,
                    1033,
                    1548,
                    2120,
                    2744,
                    3392,
                    3971,
                    4313,
                    4430,
                    4395,
                    3999,
                    3619,
                    2957,
                    2377,
                    1861,
                    1462,
                    1075,
                    830,
                    616,
                    495,
                    336,
                    262,
                    207,
                    154,
                    106,
                    67,
                    45,
                    33,
                    13,
                    15,
                    9,
                    3,
                    3,
                    2,
                    2,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.808,
                    -0.77,
                    -0.733,
                    -0.696,
                    -0.659,
                    -0.622,
                    -0.585,
                    -0.548,
                    -0.51,
                    -0.473,
                    -0.436,
                    -0.399,
                    -0.362,
                    -0.325,
                    -0.288,
                    -0.25,
                    -0.213,
                    -0.176,
                    -0.139,
                    -0.102,
                    -0.065,
                    -0.027,
                    0.01,
                    0.047,
                    0.084,
                    0.121,
                    0.158,
                    0.195,
                    0.233,
                    0.27,
                    0.307,
                    0.344,
                    0.381,
                    0.418,
                    0.456,
                    0.493,
                    0.53,
                    0.567,
                    0.604,
                    0.641,
                    0.678,
                    0.716,
                    0.753,
                    0.79,
                    0.827,
                    0.864,
                    0.901,
                    0.938,
                    0.976,
                    1.013
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyzwu4u822ft5q0zee2tyktc",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "15050",
                        "description": "words related to cocaine or its derivatives",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-24T13:58:35.264Z",
                        "updatedAt": "2024-07-24T13:58:35.264Z"
                    },
                    {
                        "id": "clzeao1hy43dbv3wqlhwfdll0",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "15050",
                        "description": "references to cocaine",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T15:34:32.087Z",
                        "updatedAt": "2024-08-03T15:34:32.087Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfji3cmpco10exk98lwyr5",
                        "tokens": [
                            "Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " statement",
                            " calling",
                            " President",
                            " Trump",
                            " \u00e2\u0122",
                            "\u013e",
                            "ment",
                            "ally",
                            " der",
                            "anged",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " promising",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "highest",
                            "-",
                            "level",
                            " of",
                            " the",
                            " hard",
                            "line",
                            " counter",
                            "measures",
                            "\u00e2\u0122",
                            "\u013f",
                            " shows",
                            " that",
                            " he",
                            " has",
                            " taken",
                            " ownership",
                            " of",
                            " this",
                            " showdown",
                            " and",
                            " that",
                            " he",
                            " alone",
                            "\u2014",
                            "as",
                            " the",
                            " leader",
                            " of",
                            " North",
                            " Korea",
                            "\u2014",
                            "will",
                            " defend",
                            " the",
                            " country",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " survival",
                            ",",
                            " as",
                            " well",
                            " as",
                            " its",
                            " dignity",
                            ".",
                            " Kim",
                            " also",
                            " has",
                            " a",
                            " bias",
                            " for",
                            " action",
                            " and",
                            " he",
                            " wants",
                            " to",
                            " win",
                            ",",
                            " as",
                            " the",
                            " Kim",
                            " family",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " former",
                            " sushi",
                            " chef",
                            " recalled",
                            ",",
                            " and",
                            " as",
                            " Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " recent",
                            " behavior",
                            " has",
                            " shown",
                            ".",
                            " Not",
                            " only",
                            " has",
                            " Kim",
                            " Jong",
                            "-",
                            "un",
                            " grown",
                            " up",
                            " in",
                            " a",
                            " coc",
                            "oon",
                            " of",
                            " indul",
                            "gence",
                            " and",
                            " privilege",
                            ",",
                            " he",
                            " has",
                            " inherited",
                            " advanced"
                        ],
                        "dataIndex": null,
                        "index": "15050",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.167,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.167,
                            7.314,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:48.361Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 59.167,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfji3cmpcs10exyu8nva2a",
                        "tokens": [
                            "Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " statement",
                            " calling",
                            " President",
                            " Trump",
                            " \u00e2\u0122",
                            "\u013e",
                            "ment",
                            "ally",
                            " der",
                            "anged",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " promising",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "highest",
                            "-",
                            "level",
                            " of",
                            " the",
                            " hard",
                            "line",
                            " counter",
                            "measures",
                            "\u00e2\u0122",
                            "\u013f",
                            " shows",
                            " that",
                            " he",
                            " has",
                            " taken",
                            " ownership",
                            " of",
                            " this",
                            " showdown",
                            " and",
                            " that",
                            " he",
                            " alone",
                            "\u2014",
                            "as",
                            " the",
                            " leader",
                            " of",
                            " North",
                            " Korea",
                            "\u2014",
                            "will",
                            " defend",
                            " the",
                            " country",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " survival",
                            ",",
                            " as",
                            " well",
                            " as",
                            " its",
                            " dignity",
                            ".",
                            " Kim",
                            " also",
                            " has",
                            " a",
                            " bias",
                            " for",
                            " action",
                            " and",
                            " he",
                            " wants",
                            " to",
                            " win",
                            ",",
                            " as",
                            " the",
                            " Kim",
                            " family",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " former",
                            " sushi",
                            " chef",
                            " recalled",
                            ",",
                            " and",
                            " as",
                            " Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " recent",
                            " behavior",
                            " has",
                            " shown",
                            ".",
                            " Not",
                            " only",
                            " has",
                            " Kim",
                            " Jong",
                            "-",
                            "un",
                            " grown",
                            " up",
                            " in",
                            " a",
                            " coc",
                            "oon",
                            " of",
                            " indul",
                            "gence",
                            " and",
                            " privilege",
                            ",",
                            " he",
                            " has",
                            " inherited",
                            " advanced"
                        ],
                        "dataIndex": null,
                        "index": "15050",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.167,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.167,
                            7.314,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:48.361Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 59.167,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfji3empda10exp8io8tig",
                        "tokens": [
                            "Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " statement",
                            " calling",
                            " President",
                            " Trump",
                            " \u00e2\u0122",
                            "\u013e",
                            "ment",
                            "ally",
                            " der",
                            "anged",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " promising",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "highest",
                            "-",
                            "level",
                            " of",
                            " the",
                            " hard",
                            "line",
                            " counter",
                            "measures",
                            "\u00e2\u0122",
                            "\u013f",
                            " shows",
                            " that",
                            " he",
                            " has",
                            " taken",
                            " ownership",
                            " of",
                            " this",
                            " showdown",
                            " and",
                            " that",
                            " he",
                            " alone",
                            "\u2014",
                            "as",
                            " the",
                            " leader",
                            " of",
                            " North",
                            " Korea",
                            "\u2014",
                            "will",
                            " defend",
                            " the",
                            " country",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " survival",
                            ",",
                            " as",
                            " well",
                            " as",
                            " its",
                            " dignity",
                            ".",
                            " Kim",
                            " also",
                            " has",
                            " a",
                            " bias",
                            " for",
                            " action",
                            " and",
                            " he",
                            " wants",
                            " to",
                            " win",
                            ",",
                            " as",
                            " the",
                            " Kim",
                            " family",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " former",
                            " sushi",
                            " chef",
                            " recalled",
                            ",",
                            " and",
                            " as",
                            " Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " recent",
                            " behavior",
                            " has",
                            " shown",
                            ".",
                            " Not",
                            " only",
                            " has",
                            " Kim",
                            " Jong",
                            "-",
                            "un",
                            " grown",
                            " up",
                            " in",
                            " a",
                            " coc",
                            "oon",
                            " of",
                            " indul",
                            "gence",
                            " and",
                            " privilege",
                            ",",
                            " he",
                            " has",
                            " inherited",
                            " advanced"
                        ],
                        "dataIndex": null,
                        "index": "15050",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.167,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.167,
                            7.314,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:48.361Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 47.333,
                        "binMax": 59.167,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "74706",
            "description": "references to \"crack\" related to drugs or crack-cocaine",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 57.362,
            "frac_nonzero": 4e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "74706",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:03:53.021Z",
                "maxActApprox": 57.362,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    74706,
                    11446,
                    39006,
                    9625,
                    4773,
                    54142,
                    3058,
                    73523,
                    56218,
                    87455,
                    96973,
                    54621,
                    21788,
                    66724,
                    86509,
                    26663,
                    89055,
                    85177,
                    72215,
                    26103,
                    78835,
                    26830,
                    68391,
                    35753,
                    58556
                ],
                "topkCosSimValues": [
                    1,
                    0.7501,
                    0.7019,
                    0.4432,
                    0.4201,
                    0.403,
                    0.3962,
                    0.3899,
                    0.3856,
                    0.3854,
                    0.3781,
                    0.376,
                    0.374,
                    0.3725,
                    0.3681,
                    0.3617,
                    0.3602,
                    0.3557,
                    0.3506,
                    0.3491,
                    0.3483,
                    0.3468,
                    0.3459,
                    0.344,
                    0.3382
                ],
                "neuron_alignment_indices": [
                    35,
                    156,
                    211
                ],
                "neuron_alignment_values": [
                    0.116,
                    0.106,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    211,
                    35,
                    156
                ],
                "correlated_neurons_pearson": [
                    0.015,
                    0.014,
                    0.013
                ],
                "correlated_neurons_l1": [
                    0.011,
                    0.013,
                    0.012
                ],
                "correlated_features_indices": [
                    74724,
                    74706,
                    74652
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "ikk",
                    "istic",
                    " obser",
                    " Leth",
                    " traged",
                    "omorphic",
                    "velength",
                    "folk",
                    "isted",
                    " nomine"
                ],
                "neg_values": [
                    -0.778,
                    -0.735,
                    -0.731,
                    -0.71,
                    -0.709,
                    -0.706,
                    -0.7,
                    -0.679,
                    -0.679,
                    -0.678
                ],
                "pos_str": [
                    "Berry",
                    "pots",
                    "pot",
                    "lings",
                    "ible",
                    " cocaine",
                    "ling",
                    "buster",
                    "downs",
                    "down"
                ],
                "pos_values": [
                    1.149,
                    1.132,
                    1.053,
                    1.031,
                    1.022,
                    0.989,
                    0.969,
                    0.952,
                    0.924,
                    0.913
                ],
                "frac_nonzero": 4e-05,
                "freq_hist_data_bar_heights": [
                    16,
                    5,
                    5,
                    5,
                    3,
                    5,
                    2,
                    3,
                    0,
                    5,
                    0,
                    2,
                    4,
                    4,
                    1,
                    2,
                    5,
                    5,
                    0,
                    1,
                    7,
                    1,
                    1,
                    2,
                    0,
                    1,
                    1,
                    2,
                    1,
                    2,
                    2,
                    0,
                    2,
                    0,
                    0,
                    0,
                    2,
                    1,
                    1,
                    4,
                    5,
                    4,
                    0,
                    3,
                    3,
                    0,
                    1,
                    1,
                    0,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.605,
                    1.752,
                    2.899,
                    4.045,
                    5.192,
                    6.338,
                    7.485,
                    8.632,
                    9.778,
                    10.925,
                    12.071,
                    13.218,
                    14.365,
                    15.511,
                    16.658,
                    17.804,
                    18.951,
                    20.098,
                    21.244,
                    22.391,
                    23.537,
                    24.684,
                    25.831,
                    26.977,
                    28.124,
                    29.27,
                    30.417,
                    31.564,
                    32.71,
                    33.857,
                    35.003,
                    36.15,
                    37.297,
                    38.443,
                    39.59,
                    40.737,
                    41.883,
                    43.03,
                    44.176,
                    45.323,
                    46.47,
                    47.616,
                    48.763,
                    49.909,
                    51.056,
                    52.203,
                    53.349,
                    54.496,
                    55.642,
                    56.789
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    5,
                    7,
                    3,
                    7,
                    8,
                    28,
                    46,
                    101,
                    165,
                    326,
                    466,
                    825,
                    1272,
                    1854,
                    2521,
                    3263,
                    4222,
                    4823,
                    5063,
                    5162,
                    4669,
                    3893,
                    3146,
                    2426,
                    1627,
                    1262,
                    903,
                    634,
                    470,
                    325,
                    217,
                    149,
                    121,
                    80,
                    65,
                    28,
                    28,
                    9,
                    15,
                    6,
                    2,
                    2,
                    3,
                    2,
                    2,
                    2,
                    1,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.759,
                    -0.72,
                    -0.682,
                    -0.643,
                    -0.605,
                    -0.566,
                    -0.528,
                    -0.489,
                    -0.45,
                    -0.412,
                    -0.373,
                    -0.335,
                    -0.296,
                    -0.258,
                    -0.219,
                    -0.181,
                    -0.142,
                    -0.104,
                    -0.065,
                    -0.026,
                    0.012,
                    0.051,
                    0.089,
                    0.128,
                    0.166,
                    0.205,
                    0.243,
                    0.282,
                    0.32,
                    0.359,
                    0.398,
                    0.436,
                    0.475,
                    0.513,
                    0.552,
                    0.59,
                    0.629,
                    0.667,
                    0.706,
                    0.745,
                    0.783,
                    0.822,
                    0.86,
                    0.899,
                    0.937,
                    0.976,
                    1.014,
                    1.053,
                    1.091,
                    1.13
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clzdidjx633efv3wqslahrisn",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "74706",
                        "description": "references to \"crack\" related to drugs or crack-cocaine",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T02:22:33.498Z",
                        "updatedAt": "2024-08-03T02:22:33.498Z"
                    },
                    {
                        "id": "clzea7isz41czv3wqycexttb3",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "74706",
                        "description": " references to crack cocaine",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T15:21:41.363Z",
                        "updatedAt": "2024-08-03T15:21:41.363Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygiapvhvywi10exy0gmg0mq",
                        "tokens": [
                            " or",
                            " to",
                            " drink",
                            " than",
                            " those",
                            " ten",
                            " years",
                            " older",
                            " were",
                            " at",
                            " their",
                            " age",
                            ",",
                            " and",
                            " the",
                            " same",
                            " is",
                            " true",
                            " in",
                            " most",
                            " European",
                            " countries",
                            ".",
                            " In",
                            " most",
                            " countries",
                            " wife",
                            "-",
                            "be",
                            "ating",
                            " has",
                            " become",
                            " more",
                            " stigmat",
                            "ised",
                            " and",
                            " less",
                            " common",
                            ":",
                            " since",
                            " 1994",
                            ",",
                            " self",
                            "-",
                            "reported",
                            " domestic",
                            " violence",
                            " has",
                            " fallen",
                            " by",
                            " three",
                            "-",
                            "quarters",
                            " in",
                            " Britain",
                            " and",
                            " two",
                            "-",
                            "thirds",
                            " in",
                            " America",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " America",
                            ",",
                            " the",
                            " end",
                            " of",
                            " the",
                            " crack",
                            "-",
                            "c",
                            "oc",
                            "aine",
                            " epidemic",
                            " in",
                            " the",
                            " 1990",
                            "s",
                            " is",
                            " widely",
                            " credited",
                            " with",
                            " reducing",
                            " crime",
                            ".",
                            " In",
                            " Europe",
                            ",",
                            " the",
                            " explosion",
                            " in",
                            " heroin",
                            " use",
                            " that",
                            " accompanied",
                            " the",
                            " high",
                            " unemployment",
                            " of",
                            " the",
                            " 1980",
                            "s",
                            " has",
                            " largely",
                            " rec",
                            "eded",
                            ",",
                            " even",
                            " though",
                            " hard",
                            " economic",
                            " times",
                            " are",
                            " back",
                            ".",
                            " Junk",
                            "ies",
                            " are",
                            " older",
                            " and",
                            " fewer",
                            ";",
                            " in",
                            " Rot"
                        ],
                        "dataIndex": null,
                        "index": "74706",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 57.362,
                        "maxValueTokenIndex": 71,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            57.362,
                            6.479,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:03:57.398Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 57.362,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiapvjvyx310ex9q2coicm",
                        "tokens": [
                            " or",
                            " to",
                            " drink",
                            " than",
                            " those",
                            " ten",
                            " years",
                            " older",
                            " were",
                            " at",
                            " their",
                            " age",
                            ",",
                            " and",
                            " the",
                            " same",
                            " is",
                            " true",
                            " in",
                            " most",
                            " European",
                            " countries",
                            ".",
                            " In",
                            " most",
                            " countries",
                            " wife",
                            "-",
                            "be",
                            "ating",
                            " has",
                            " become",
                            " more",
                            " stigmat",
                            "ised",
                            " and",
                            " less",
                            " common",
                            ":",
                            " since",
                            " 1994",
                            ",",
                            " self",
                            "-",
                            "reported",
                            " domestic",
                            " violence",
                            " has",
                            " fallen",
                            " by",
                            " three",
                            "-",
                            "quarters",
                            " in",
                            " Britain",
                            " and",
                            " two",
                            "-",
                            "thirds",
                            " in",
                            " America",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " America",
                            ",",
                            " the",
                            " end",
                            " of",
                            " the",
                            " crack",
                            "-",
                            "c",
                            "oc",
                            "aine",
                            " epidemic",
                            " in",
                            " the",
                            " 1990",
                            "s",
                            " is",
                            " widely",
                            " credited",
                            " with",
                            " reducing",
                            " crime",
                            ".",
                            " In",
                            " Europe",
                            ",",
                            " the",
                            " explosion",
                            " in",
                            " heroin",
                            " use",
                            " that",
                            " accompanied",
                            " the",
                            " high",
                            " unemployment",
                            " of",
                            " the",
                            " 1980",
                            "s",
                            " has",
                            " largely",
                            " rec",
                            "eded",
                            ",",
                            " even",
                            " though",
                            " hard",
                            " economic",
                            " times",
                            " are",
                            " back",
                            ".",
                            " Junk",
                            "ies",
                            " are",
                            " older",
                            " and",
                            " fewer",
                            ";",
                            " in",
                            " Rot"
                        ],
                        "dataIndex": null,
                        "index": "74706",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 57.362,
                        "maxValueTokenIndex": 71,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            57.362,
                            6.479,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:03:57.398Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 45.89,
                        "binMax": 57.362,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiapvhvywj10exnsqapebv",
                        "tokens": [
                            " per",
                            " cent",
                            " of",
                            " people",
                            " between",
                            " 15",
                            " and",
                            " 65",
                            " years",
                            " old",
                            " reported",
                            " they",
                            " had",
                            " smoked",
                            " marijuana",
                            " at",
                            " least",
                            " once",
                            " and",
                            " about",
                            " 5",
                            " per",
                            " cent",
                            " of",
                            " respondents",
                            " were",
                            " habitual",
                            " users",
                            ".",
                            "\n",
                            "\n",
                            "A",
                            " government",
                            " survey",
                            " puts",
                            " the",
                            " percentage",
                            " of",
                            " the",
                            " population",
                            " that",
                            " consumed",
                            " marijuana",
                            " over",
                            " the",
                            " last",
                            " year",
                            " at",
                            " 8",
                            ".",
                            "3",
                            " per",
                            " cent",
                            ",",
                            " compared",
                            " to",
                            " one",
                            " per",
                            " cent",
                            " who",
                            " consumed",
                            " cocaine",
                            " in",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " proposal",
                            " to",
                            " legal",
                            "ise",
                            " the",
                            " marijuana",
                            " market",
                            " is",
                            " one",
                            " of",
                            " 15",
                            " crime",
                            "-",
                            "fighting",
                            " measures",
                            " that",
                            " include",
                            " tougher",
                            " penalties",
                            " for",
                            " police",
                            " corruption",
                            ",",
                            " crack",
                            "-",
                            "c",
                            "oc",
                            "aine",
                            " trafficking",
                            " and",
                            " juvenile",
                            " offenders",
                            ".",
                            "<|endoftext|>",
                            "CLOSE",
                            " An",
                            "he",
                            "user",
                            "-",
                            "Bus",
                            "ch",
                            " In",
                            "B",
                            "ev",
                            " sealed",
                            " a",
                            " deal",
                            " months",
                            " in",
                            " the",
                            " making",
                            " to",
                            " acquire",
                            " its",
                            " biggest",
                            " rival",
                            ","
                        ],
                        "dataIndex": null,
                        "index": "74706",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 57.215,
                        "maxValueTokenIndex": 93,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            57.215,
                            6.272,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:03:57.398Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 57.362,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "74706",
            "description": " references to crack cocaine",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 57.362,
            "frac_nonzero": 4e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "74706",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:03:53.021Z",
                "maxActApprox": 57.362,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    74706,
                    11446,
                    39006,
                    9625,
                    4773,
                    54142,
                    3058,
                    73523,
                    56218,
                    87455,
                    96973,
                    54621,
                    21788,
                    66724,
                    86509,
                    26663,
                    89055,
                    85177,
                    72215,
                    26103,
                    78835,
                    26830,
                    68391,
                    35753,
                    58556
                ],
                "topkCosSimValues": [
                    1,
                    0.7501,
                    0.7019,
                    0.4432,
                    0.4201,
                    0.403,
                    0.3962,
                    0.3899,
                    0.3856,
                    0.3854,
                    0.3781,
                    0.376,
                    0.374,
                    0.3725,
                    0.3681,
                    0.3617,
                    0.3602,
                    0.3557,
                    0.3506,
                    0.3491,
                    0.3483,
                    0.3468,
                    0.3459,
                    0.344,
                    0.3382
                ],
                "neuron_alignment_indices": [
                    35,
                    156,
                    211
                ],
                "neuron_alignment_values": [
                    0.116,
                    0.106,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    211,
                    35,
                    156
                ],
                "correlated_neurons_pearson": [
                    0.015,
                    0.014,
                    0.013
                ],
                "correlated_neurons_l1": [
                    0.011,
                    0.013,
                    0.012
                ],
                "correlated_features_indices": [
                    74724,
                    74706,
                    74652
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "ikk",
                    "istic",
                    " obser",
                    " Leth",
                    " traged",
                    "omorphic",
                    "velength",
                    "folk",
                    "isted",
                    " nomine"
                ],
                "neg_values": [
                    -0.778,
                    -0.735,
                    -0.731,
                    -0.71,
                    -0.709,
                    -0.706,
                    -0.7,
                    -0.679,
                    -0.679,
                    -0.678
                ],
                "pos_str": [
                    "Berry",
                    "pots",
                    "pot",
                    "lings",
                    "ible",
                    " cocaine",
                    "ling",
                    "buster",
                    "downs",
                    "down"
                ],
                "pos_values": [
                    1.149,
                    1.132,
                    1.053,
                    1.031,
                    1.022,
                    0.989,
                    0.969,
                    0.952,
                    0.924,
                    0.913
                ],
                "frac_nonzero": 4e-05,
                "freq_hist_data_bar_heights": [
                    16,
                    5,
                    5,
                    5,
                    3,
                    5,
                    2,
                    3,
                    0,
                    5,
                    0,
                    2,
                    4,
                    4,
                    1,
                    2,
                    5,
                    5,
                    0,
                    1,
                    7,
                    1,
                    1,
                    2,
                    0,
                    1,
                    1,
                    2,
                    1,
                    2,
                    2,
                    0,
                    2,
                    0,
                    0,
                    0,
                    2,
                    1,
                    1,
                    4,
                    5,
                    4,
                    0,
                    3,
                    3,
                    0,
                    1,
                    1,
                    0,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.605,
                    1.752,
                    2.899,
                    4.045,
                    5.192,
                    6.338,
                    7.485,
                    8.632,
                    9.778,
                    10.925,
                    12.071,
                    13.218,
                    14.365,
                    15.511,
                    16.658,
                    17.804,
                    18.951,
                    20.098,
                    21.244,
                    22.391,
                    23.537,
                    24.684,
                    25.831,
                    26.977,
                    28.124,
                    29.27,
                    30.417,
                    31.564,
                    32.71,
                    33.857,
                    35.003,
                    36.15,
                    37.297,
                    38.443,
                    39.59,
                    40.737,
                    41.883,
                    43.03,
                    44.176,
                    45.323,
                    46.47,
                    47.616,
                    48.763,
                    49.909,
                    51.056,
                    52.203,
                    53.349,
                    54.496,
                    55.642,
                    56.789
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    5,
                    7,
                    3,
                    7,
                    8,
                    28,
                    46,
                    101,
                    165,
                    326,
                    466,
                    825,
                    1272,
                    1854,
                    2521,
                    3263,
                    4222,
                    4823,
                    5063,
                    5162,
                    4669,
                    3893,
                    3146,
                    2426,
                    1627,
                    1262,
                    903,
                    634,
                    470,
                    325,
                    217,
                    149,
                    121,
                    80,
                    65,
                    28,
                    28,
                    9,
                    15,
                    6,
                    2,
                    2,
                    3,
                    2,
                    2,
                    2,
                    1,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.759,
                    -0.72,
                    -0.682,
                    -0.643,
                    -0.605,
                    -0.566,
                    -0.528,
                    -0.489,
                    -0.45,
                    -0.412,
                    -0.373,
                    -0.335,
                    -0.296,
                    -0.258,
                    -0.219,
                    -0.181,
                    -0.142,
                    -0.104,
                    -0.065,
                    -0.026,
                    0.012,
                    0.051,
                    0.089,
                    0.128,
                    0.166,
                    0.205,
                    0.243,
                    0.282,
                    0.32,
                    0.359,
                    0.398,
                    0.436,
                    0.475,
                    0.513,
                    0.552,
                    0.59,
                    0.629,
                    0.667,
                    0.706,
                    0.745,
                    0.783,
                    0.822,
                    0.86,
                    0.899,
                    0.937,
                    0.976,
                    1.014,
                    1.053,
                    1.091,
                    1.13
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clzdidjx633efv3wqslahrisn",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "74706",
                        "description": "references to \"crack\" related to drugs or crack-cocaine",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T02:22:33.498Z",
                        "updatedAt": "2024-08-03T02:22:33.498Z"
                    },
                    {
                        "id": "clzea7isz41czv3wqycexttb3",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "74706",
                        "description": " references to crack cocaine",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T15:21:41.363Z",
                        "updatedAt": "2024-08-03T15:21:41.363Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygiapvhvywi10exy0gmg0mq",
                        "tokens": [
                            " or",
                            " to",
                            " drink",
                            " than",
                            " those",
                            " ten",
                            " years",
                            " older",
                            " were",
                            " at",
                            " their",
                            " age",
                            ",",
                            " and",
                            " the",
                            " same",
                            " is",
                            " true",
                            " in",
                            " most",
                            " European",
                            " countries",
                            ".",
                            " In",
                            " most",
                            " countries",
                            " wife",
                            "-",
                            "be",
                            "ating",
                            " has",
                            " become",
                            " more",
                            " stigmat",
                            "ised",
                            " and",
                            " less",
                            " common",
                            ":",
                            " since",
                            " 1994",
                            ",",
                            " self",
                            "-",
                            "reported",
                            " domestic",
                            " violence",
                            " has",
                            " fallen",
                            " by",
                            " three",
                            "-",
                            "quarters",
                            " in",
                            " Britain",
                            " and",
                            " two",
                            "-",
                            "thirds",
                            " in",
                            " America",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " America",
                            ",",
                            " the",
                            " end",
                            " of",
                            " the",
                            " crack",
                            "-",
                            "c",
                            "oc",
                            "aine",
                            " epidemic",
                            " in",
                            " the",
                            " 1990",
                            "s",
                            " is",
                            " widely",
                            " credited",
                            " with",
                            " reducing",
                            " crime",
                            ".",
                            " In",
                            " Europe",
                            ",",
                            " the",
                            " explosion",
                            " in",
                            " heroin",
                            " use",
                            " that",
                            " accompanied",
                            " the",
                            " high",
                            " unemployment",
                            " of",
                            " the",
                            " 1980",
                            "s",
                            " has",
                            " largely",
                            " rec",
                            "eded",
                            ",",
                            " even",
                            " though",
                            " hard",
                            " economic",
                            " times",
                            " are",
                            " back",
                            ".",
                            " Junk",
                            "ies",
                            " are",
                            " older",
                            " and",
                            " fewer",
                            ";",
                            " in",
                            " Rot"
                        ],
                        "dataIndex": null,
                        "index": "74706",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 57.362,
                        "maxValueTokenIndex": 71,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            57.362,
                            6.479,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:03:57.398Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 57.362,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiapvjvyx310ex9q2coicm",
                        "tokens": [
                            " or",
                            " to",
                            " drink",
                            " than",
                            " those",
                            " ten",
                            " years",
                            " older",
                            " were",
                            " at",
                            " their",
                            " age",
                            ",",
                            " and",
                            " the",
                            " same",
                            " is",
                            " true",
                            " in",
                            " most",
                            " European",
                            " countries",
                            ".",
                            " In",
                            " most",
                            " countries",
                            " wife",
                            "-",
                            "be",
                            "ating",
                            " has",
                            " become",
                            " more",
                            " stigmat",
                            "ised",
                            " and",
                            " less",
                            " common",
                            ":",
                            " since",
                            " 1994",
                            ",",
                            " self",
                            "-",
                            "reported",
                            " domestic",
                            " violence",
                            " has",
                            " fallen",
                            " by",
                            " three",
                            "-",
                            "quarters",
                            " in",
                            " Britain",
                            " and",
                            " two",
                            "-",
                            "thirds",
                            " in",
                            " America",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " America",
                            ",",
                            " the",
                            " end",
                            " of",
                            " the",
                            " crack",
                            "-",
                            "c",
                            "oc",
                            "aine",
                            " epidemic",
                            " in",
                            " the",
                            " 1990",
                            "s",
                            " is",
                            " widely",
                            " credited",
                            " with",
                            " reducing",
                            " crime",
                            ".",
                            " In",
                            " Europe",
                            ",",
                            " the",
                            " explosion",
                            " in",
                            " heroin",
                            " use",
                            " that",
                            " accompanied",
                            " the",
                            " high",
                            " unemployment",
                            " of",
                            " the",
                            " 1980",
                            "s",
                            " has",
                            " largely",
                            " rec",
                            "eded",
                            ",",
                            " even",
                            " though",
                            " hard",
                            " economic",
                            " times",
                            " are",
                            " back",
                            ".",
                            " Junk",
                            "ies",
                            " are",
                            " older",
                            " and",
                            " fewer",
                            ";",
                            " in",
                            " Rot"
                        ],
                        "dataIndex": null,
                        "index": "74706",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 57.362,
                        "maxValueTokenIndex": 71,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            57.362,
                            6.479,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:03:57.398Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 45.89,
                        "binMax": 57.362,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiapvhvywj10exnsqapebv",
                        "tokens": [
                            " per",
                            " cent",
                            " of",
                            " people",
                            " between",
                            " 15",
                            " and",
                            " 65",
                            " years",
                            " old",
                            " reported",
                            " they",
                            " had",
                            " smoked",
                            " marijuana",
                            " at",
                            " least",
                            " once",
                            " and",
                            " about",
                            " 5",
                            " per",
                            " cent",
                            " of",
                            " respondents",
                            " were",
                            " habitual",
                            " users",
                            ".",
                            "\n",
                            "\n",
                            "A",
                            " government",
                            " survey",
                            " puts",
                            " the",
                            " percentage",
                            " of",
                            " the",
                            " population",
                            " that",
                            " consumed",
                            " marijuana",
                            " over",
                            " the",
                            " last",
                            " year",
                            " at",
                            " 8",
                            ".",
                            "3",
                            " per",
                            " cent",
                            ",",
                            " compared",
                            " to",
                            " one",
                            " per",
                            " cent",
                            " who",
                            " consumed",
                            " cocaine",
                            " in",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " proposal",
                            " to",
                            " legal",
                            "ise",
                            " the",
                            " marijuana",
                            " market",
                            " is",
                            " one",
                            " of",
                            " 15",
                            " crime",
                            "-",
                            "fighting",
                            " measures",
                            " that",
                            " include",
                            " tougher",
                            " penalties",
                            " for",
                            " police",
                            " corruption",
                            ",",
                            " crack",
                            "-",
                            "c",
                            "oc",
                            "aine",
                            " trafficking",
                            " and",
                            " juvenile",
                            " offenders",
                            ".",
                            "<|endoftext|>",
                            "CLOSE",
                            " An",
                            "he",
                            "user",
                            "-",
                            "Bus",
                            "ch",
                            " In",
                            "B",
                            "ev",
                            " sealed",
                            " a",
                            " deal",
                            " months",
                            " in",
                            " the",
                            " making",
                            " to",
                            " acquire",
                            " its",
                            " biggest",
                            " rival",
                            ","
                        ],
                        "dataIndex": null,
                        "index": "74706",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 57.215,
                        "maxValueTokenIndex": 93,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            57.215,
                            6.272,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:03:57.398Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 57.362,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "51089",
            "description": "references to cocaine and its associated terminology",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 56.244,
            "frac_nonzero": 2e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "51089",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:38:14.891Z",
                "maxActApprox": 56.244,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    51089,
                    66264,
                    93834,
                    95121,
                    83933,
                    13775,
                    22346,
                    19646,
                    93178,
                    36800,
                    39003,
                    15729,
                    3570,
                    60483,
                    6468,
                    59250,
                    59791,
                    55695,
                    15939,
                    5551,
                    40091,
                    81344,
                    90520,
                    62292,
                    16740
                ],
                "topkCosSimValues": [
                    1,
                    0.6526,
                    0.5893,
                    0.5828,
                    0.572,
                    0.5636,
                    0.5472,
                    0.5471,
                    0.5395,
                    0.5342,
                    0.5319,
                    0.5126,
                    0.5039,
                    0.4956,
                    0.4949,
                    0.4874,
                    0.4798,
                    0.4723,
                    0.4587,
                    0.4467,
                    0.4452,
                    0.4434,
                    0.4431,
                    0.4395,
                    0.4364
                ],
                "neuron_alignment_indices": [
                    288,
                    481,
                    384
                ],
                "neuron_alignment_values": [
                    0.146,
                    0.146,
                    0.115
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.007,
                    0.005
                ],
                "correlated_neurons_indices": [
                    698,
                    461,
                    384
                ],
                "correlated_neurons_pearson": [
                    0.009,
                    0.008,
                    0.008
                ],
                "correlated_neurons_l1": [
                    0.009,
                    0.008,
                    0.007
                ],
                "correlated_features_indices": [
                    51116,
                    50975,
                    51089
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.002,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0.002,
                    0
                ],
                "neg_str": [
                    "hof",
                    "\u012a\u0134",
                    "lying",
                    "laus",
                    "edIn",
                    "DEM",
                    "aer",
                    "Madison",
                    " Canterbury",
                    "\u0143\u0136"
                ],
                "neg_values": [
                    -0.817,
                    -0.766,
                    -0.737,
                    -0.724,
                    -0.721,
                    -0.71,
                    -0.709,
                    -0.695,
                    -0.695,
                    -0.686
                ],
                "pos_str": [
                    " cocaine",
                    " addict",
                    " addicts",
                    " residue",
                    " addiction",
                    " overdose",
                    " cartels",
                    " overdoses",
                    " traffickers",
                    " sulf"
                ],
                "pos_values": [
                    1.148,
                    1.01,
                    1.007,
                    1.005,
                    0.97,
                    0.948,
                    0.924,
                    0.903,
                    0.902,
                    0.876
                ],
                "frac_nonzero": 2e-05,
                "freq_hist_data_bar_heights": [
                    15,
                    6,
                    3,
                    1,
                    1,
                    1,
                    5,
                    1,
                    1,
                    4,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    2,
                    3,
                    0,
                    3,
                    1,
                    1,
                    1,
                    5,
                    2,
                    1,
                    2,
                    1,
                    2,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.604,
                    1.728,
                    2.852,
                    3.976,
                    5.101,
                    6.225,
                    7.349,
                    8.473,
                    9.597,
                    10.721,
                    11.845,
                    12.969,
                    14.093,
                    15.217,
                    16.341,
                    17.465,
                    18.589,
                    19.713,
                    20.837,
                    21.961,
                    23.085,
                    24.209,
                    25.333,
                    26.457,
                    27.581,
                    28.705,
                    29.829,
                    30.953,
                    32.077,
                    33.201,
                    34.325,
                    35.449,
                    36.573,
                    37.697,
                    38.821,
                    39.945,
                    41.069,
                    42.193,
                    43.317,
                    44.441,
                    45.565,
                    46.69,
                    47.814,
                    48.938,
                    50.062,
                    51.186,
                    52.31,
                    53.434,
                    54.558,
                    55.682
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    5,
                    12,
                    11,
                    22,
                    53,
                    100,
                    169,
                    248,
                    410,
                    563,
                    914,
                    1331,
                    1677,
                    2248,
                    2822,
                    3379,
                    3888,
                    4077,
                    4284,
                    4224,
                    4146,
                    3596,
                    2993,
                    2474,
                    1870,
                    1454,
                    1027,
                    719,
                    505,
                    340,
                    224,
                    171,
                    108,
                    53,
                    42,
                    32,
                    24,
                    10,
                    7,
                    7,
                    6,
                    3,
                    2,
                    1,
                    3,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.797,
                    -0.758,
                    -0.718,
                    -0.679,
                    -0.64,
                    -0.601,
                    -0.561,
                    -0.522,
                    -0.483,
                    -0.443,
                    -0.404,
                    -0.365,
                    -0.325,
                    -0.286,
                    -0.247,
                    -0.208,
                    -0.168,
                    -0.129,
                    -0.09,
                    -0.05,
                    -0.011,
                    0.028,
                    0.068,
                    0.107,
                    0.146,
                    0.185,
                    0.225,
                    0.264,
                    0.303,
                    0.343,
                    0.382,
                    0.421,
                    0.46,
                    0.5,
                    0.539,
                    0.578,
                    0.618,
                    0.657,
                    0.696,
                    0.736,
                    0.775,
                    0.814,
                    0.853,
                    0.893,
                    0.932,
                    0.971,
                    1.011,
                    1.05,
                    1.089,
                    1.129
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clz1h7qzh2kb8weox18nlgtfm",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "51089",
                        "description": "references to cocaine and its associated terminology",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-25T16:16:48.912Z",
                        "updatedAt": "2024-07-25T16:16:48.912Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghdsshe0c510explmcpwjg",
                        "tokens": [
                            " an",
                            " individual",
                            " nerve",
                            " cell",
                            " can",
                            " hold",
                            " a",
                            " trace",
                            " memory",
                            ",",
                            " is",
                            " also",
                            " related",
                            " to",
                            " drug",
                            " addiction",
                            ",",
                            " the",
                            " study",
                            " found",
                            ".",
                            " By",
                            " giving",
                            " cocaine",
                            " to",
                            " mice",
                            " in",
                            " the",
                            " laboratory",
                            ",",
                            " the",
                            " researchers",
                            " explained",
                            " why",
                            " the",
                            " drug",
                            " imp",
                            "airs",
                            " short",
                            " term",
                            " memory",
                            ":",
                            " Coc",
                            "aine",
                            " causes",
                            " a",
                            " buildup",
                            " of",
                            " dopamine",
                            ",",
                            " a",
                            " brain",
                            " chemical",
                            " that",
                            " decreases",
                            " the",
                            " individual",
                            " nerve",
                            " cells",
                            "'",
                            " ability",
                            " to",
                            " hold",
                            " moment",
                            "-",
                            "to",
                            "-",
                            "mom",
                            "ent",
                            " information",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " study",
                            " is",
                            " an",
                            " important",
                            " contribution",
                            " to",
                            " the",
                            " field",
                            " of",
                            " working",
                            " memory",
                            " because",
                            " it",
                            " shows",
                            " the",
                            " molecular",
                            " mechanisms",
                            " involved",
                            " in",
                            " the",
                            " process",
                            ",",
                            " said",
                            " Michael",
                            " Kuh",
                            "ar",
                            ",",
                            " professor",
                            " of",
                            " neuro",
                            "ph",
                            "armac",
                            "ology",
                            " at",
                            " Em",
                            "ory",
                            " University",
                            ",",
                            " who",
                            " was",
                            " not",
                            " involved",
                            " with",
                            " the",
                            " research",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " distant",
                            " but",
                            " possible",
                            " implication"
                        ],
                        "dataIndex": null,
                        "index": "51089",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.244,
                        "maxValueTokenIndex": 23,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            56.244,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.564,
                            18.952,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:21.523Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 11.249,
                        "binMax": 22.497,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghdssee0ba10ex8wgvf3u2",
                        "tokens": [
                            " an",
                            " individual",
                            " nerve",
                            " cell",
                            " can",
                            " hold",
                            " a",
                            " trace",
                            " memory",
                            ",",
                            " is",
                            " also",
                            " related",
                            " to",
                            " drug",
                            " addiction",
                            ",",
                            " the",
                            " study",
                            " found",
                            ".",
                            " By",
                            " giving",
                            " cocaine",
                            " to",
                            " mice",
                            " in",
                            " the",
                            " laboratory",
                            ",",
                            " the",
                            " researchers",
                            " explained",
                            " why",
                            " the",
                            " drug",
                            " imp",
                            "airs",
                            " short",
                            " term",
                            " memory",
                            ":",
                            " Coc",
                            "aine",
                            " causes",
                            " a",
                            " buildup",
                            " of",
                            " dopamine",
                            ",",
                            " a",
                            " brain",
                            " chemical",
                            " that",
                            " decreases",
                            " the",
                            " individual",
                            " nerve",
                            " cells",
                            "'",
                            " ability",
                            " to",
                            " hold",
                            " moment",
                            "-",
                            "to",
                            "-",
                            "mom",
                            "ent",
                            " information",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " study",
                            " is",
                            " an",
                            " important",
                            " contribution",
                            " to",
                            " the",
                            " field",
                            " of",
                            " working",
                            " memory",
                            " because",
                            " it",
                            " shows",
                            " the",
                            " molecular",
                            " mechanisms",
                            " involved",
                            " in",
                            " the",
                            " process",
                            ",",
                            " said",
                            " Michael",
                            " Kuh",
                            "ar",
                            ",",
                            " professor",
                            " of",
                            " neuro",
                            "ph",
                            "armac",
                            "ology",
                            " at",
                            " Em",
                            "ory",
                            " University",
                            ",",
                            " who",
                            " was",
                            " not",
                            " involved",
                            " with",
                            " the",
                            " research",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " distant",
                            " but",
                            " possible",
                            " implication"
                        ],
                        "dataIndex": null,
                        "index": "51089",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.244,
                        "maxValueTokenIndex": 23,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            56.244,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.564,
                            18.952,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:21.523Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 56.244,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghdsshe0c610ex60x7xi4b",
                        "tokens": [
                            " an",
                            " individual",
                            " nerve",
                            " cell",
                            " can",
                            " hold",
                            " a",
                            " trace",
                            " memory",
                            ",",
                            " is",
                            " also",
                            " related",
                            " to",
                            " drug",
                            " addiction",
                            ",",
                            " the",
                            " study",
                            " found",
                            ".",
                            " By",
                            " giving",
                            " cocaine",
                            " to",
                            " mice",
                            " in",
                            " the",
                            " laboratory",
                            ",",
                            " the",
                            " researchers",
                            " explained",
                            " why",
                            " the",
                            " drug",
                            " imp",
                            "airs",
                            " short",
                            " term",
                            " memory",
                            ":",
                            " Coc",
                            "aine",
                            " causes",
                            " a",
                            " buildup",
                            " of",
                            " dopamine",
                            ",",
                            " a",
                            " brain",
                            " chemical",
                            " that",
                            " decreases",
                            " the",
                            " individual",
                            " nerve",
                            " cells",
                            "'",
                            " ability",
                            " to",
                            " hold",
                            " moment",
                            "-",
                            "to",
                            "-",
                            "mom",
                            "ent",
                            " information",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " study",
                            " is",
                            " an",
                            " important",
                            " contribution",
                            " to",
                            " the",
                            " field",
                            " of",
                            " working",
                            " memory",
                            " because",
                            " it",
                            " shows",
                            " the",
                            " molecular",
                            " mechanisms",
                            " involved",
                            " in",
                            " the",
                            " process",
                            ",",
                            " said",
                            " Michael",
                            " Kuh",
                            "ar",
                            ",",
                            " professor",
                            " of",
                            " neuro",
                            "ph",
                            "armac",
                            "ology",
                            " at",
                            " Em",
                            "ory",
                            " University",
                            ",",
                            " who",
                            " was",
                            " not",
                            " involved",
                            " with",
                            " the",
                            " research",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " distant",
                            " but",
                            " possible",
                            " implication"
                        ],
                        "dataIndex": null,
                        "index": "51089",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.244,
                        "maxValueTokenIndex": 23,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            56.244,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.564,
                            18.952,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:38:21.523Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 11.249,
                        "binMax": 22.497,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "568",
            "description": "words related to illegal activities or substances, particularly contrasting internet addiction with traditional substances like cigarettes and cocaine, and also discussing counterfeit activities",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 55.219,
            "frac_nonzero": 0.00066,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "568",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:15:23.896Z",
                "maxActApprox": 55.219,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    568,
                    9444,
                    8741,
                    11391,
                    8524,
                    11090,
                    6984,
                    5084,
                    1065,
                    589,
                    6571,
                    12062,
                    6123,
                    8911,
                    3615,
                    395,
                    1793,
                    8193,
                    10001,
                    8611,
                    6503,
                    3200,
                    7317,
                    10698,
                    10395
                ],
                "topkCosSimValues": [
                    1,
                    0.5723,
                    0.4712,
                    0.4113,
                    0.4022,
                    0.3484,
                    0.3291,
                    0.3224,
                    0.3176,
                    0.3122,
                    0.3077,
                    0.3045,
                    0.2995,
                    0.2948,
                    0.2939,
                    0.2902,
                    0.286,
                    0.2859,
                    0.2831,
                    0.2755,
                    0.2714,
                    0.2705,
                    0.2699,
                    0.2661,
                    0.2658
                ],
                "neuron_alignment_indices": [
                    376,
                    314,
                    121
                ],
                "neuron_alignment_values": [
                    0.099,
                    0.099,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    106,
                    326,
                    31
                ],
                "correlated_neurons_pearson": [
                    0.019,
                    0.018,
                    0.016
                ],
                "correlated_neurons_l1": [
                    0.021,
                    0.017,
                    0.018
                ],
                "correlated_features_indices": [
                    589,
                    544,
                    566
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.004,
                    0.004
                ],
                "correlated_features_l1": [
                    0.009,
                    0.006,
                    0.005
                ],
                "neg_str": [
                    "nesota",
                    "Downloadha",
                    "DonaldTrump",
                    " livest",
                    "sembly",
                    "phasis",
                    " Rosenthal",
                    " Cald",
                    " Khe",
                    " Bie"
                ],
                "neg_values": [
                    -0.733,
                    -0.708,
                    -0.705,
                    -0.65,
                    -0.642,
                    -0.638,
                    -0.617,
                    -0.616,
                    -0.61,
                    -0.6
                ],
                "pos_str": [
                    "aging",
                    "ages",
                    "erness",
                    "agers",
                    "pack",
                    "rats",
                    "aged",
                    "raft",
                    "arding",
                    "ager"
                ],
                "pos_values": [
                    1.165,
                    1.131,
                    1.056,
                    1.031,
                    1.007,
                    0.894,
                    0.89,
                    0.882,
                    0.881,
                    0.854
                ],
                "frac_nonzero": 0.00066,
                "freq_hist_data_bar_heights": [
                    686,
                    447,
                    255,
                    165,
                    110,
                    54,
                    37,
                    30,
                    13,
                    16,
                    5,
                    8,
                    2,
                    5,
                    7,
                    10,
                    4,
                    3,
                    2,
                    6,
                    8,
                    12,
                    10,
                    14,
                    7,
                    9,
                    11,
                    9,
                    13,
                    8,
                    9,
                    8,
                    3,
                    11,
                    9,
                    11,
                    7,
                    12,
                    3,
                    7,
                    7,
                    5,
                    2,
                    4,
                    1,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.553,
                    1.658,
                    2.762,
                    3.866,
                    4.971,
                    6.075,
                    7.18,
                    8.284,
                    9.388,
                    10.493,
                    11.597,
                    12.701,
                    13.806,
                    14.91,
                    16.014,
                    17.119,
                    18.223,
                    19.328,
                    20.432,
                    21.536,
                    22.641,
                    23.745,
                    24.849,
                    25.954,
                    27.058,
                    28.162,
                    29.267,
                    30.371,
                    31.476,
                    32.58,
                    33.684,
                    34.789,
                    35.893,
                    36.997,
                    38.102,
                    39.206,
                    40.31,
                    41.415,
                    42.519,
                    43.624,
                    44.728,
                    45.832,
                    46.937,
                    48.041,
                    49.145,
                    50.25,
                    51.354,
                    52.458,
                    53.563,
                    54.667
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    0,
                    3,
                    9,
                    19,
                    29,
                    43,
                    83,
                    141,
                    257,
                    460,
                    756,
                    1205,
                    1797,
                    2510,
                    3241,
                    4033,
                    4641,
                    4970,
                    5165,
                    4650,
                    4018,
                    3378,
                    2599,
                    1927,
                    1347,
                    960,
                    640,
                    423,
                    290,
                    205,
                    146,
                    107,
                    62,
                    42,
                    30,
                    21,
                    10,
                    10,
                    7,
                    7,
                    4,
                    4,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.714,
                    -0.676,
                    -0.638,
                    -0.6,
                    -0.562,
                    -0.524,
                    -0.486,
                    -0.448,
                    -0.41,
                    -0.372,
                    -0.334,
                    -0.296,
                    -0.258,
                    -0.22,
                    -0.182,
                    -0.145,
                    -0.107,
                    -0.069,
                    -0.031,
                    0.007,
                    0.045,
                    0.083,
                    0.121,
                    0.159,
                    0.197,
                    0.235,
                    0.273,
                    0.311,
                    0.349,
                    0.387,
                    0.425,
                    0.463,
                    0.501,
                    0.539,
                    0.577,
                    0.615,
                    0.653,
                    0.69,
                    0.728,
                    0.766,
                    0.804,
                    0.842,
                    0.88,
                    0.918,
                    0.956,
                    0.994,
                    1.032,
                    1.07,
                    1.108,
                    1.146
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clymebo680in1j7a14b3oc46q",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs12288-jb",
                        "index": "568",
                        "description": "words related to illegal activities or substances, particularly contrasting internet addiction with traditional substances like cigarettes and cocaine, and also discussing counterfeit activities",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-07-15T02:59:20.480Z",
                        "updatedAt": "2024-07-15T02:59:20.480Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtj6u6z036i6667tlxm0xm",
                        "tokens": [
                            ":",
                            " the",
                            " internet",
                            ",",
                            " like",
                            " a",
                            " pack",
                            " of",
                            " cigarettes",
                            " or",
                            " lots",
                            " of",
                            " cocaine",
                            ",",
                            " lets",
                            " you",
                            " just",
                            " sit",
                            " in",
                            " a",
                            " room",
                            " and",
                            " repeatedly",
                            " trigger",
                            " reward",
                            " chemicals",
                            " that",
                            ",",
                            " back",
                            " in",
                            " the",
                            " environment",
                            " of",
                            " our",
                            " evolution",
                            ",",
                            " you",
                            " could",
                            " trigger",
                            " only",
                            " with",
                            " more",
                            " work",
                            " and",
                            " only",
                            " less",
                            " frequently",
                            ".",
                            " That",
                            "'s",
                            " why",
                            " an",
                            " internet",
                            " habit",
                            ",",
                            " like",
                            " a",
                            " cocaine",
                            " habit",
                            ",",
                            " can",
                            " reach",
                            " dysfunctional",
                            " levels",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " above",
                            "-",
                            "listed",
                            " forms",
                            " of",
                            " internet",
                            " dependence",
                            " --",
                            " porn",
                            ",",
                            " Facebook",
                            ",",
                            " TMZ",
                            ",",
                            " Twitter",
                            ",",
                            " YouTube",
                            " --",
                            " are",
                            " just",
                            " a",
                            " few",
                            " of",
                            " the",
                            " possible",
                            " ingredients",
                            " of",
                            " any",
                            " one",
                            " case",
                            " of",
                            " internet",
                            " \"",
                            "add",
                            "iction",
                            ".\"",
                            " And",
                            " each",
                            " of",
                            " these",
                            " ingredients",
                            " itself",
                            " involves",
                            " God",
                            "-",
                            "kn",
                            "ows",
                            "-",
                            "which",
                            " neurotrans",
                            "mit",
                            "ters",
                            " and",
                            " neuronal",
                            " receptors",
                            " and",
                            ",",
                            " by",
                            " extension"
                        ],
                        "dataIndex": null,
                        "index": "568",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 55.219,
                        "maxValueTokenIndex": 6,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            55.219,
                            0,
                            1.336,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:15:27.529Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 55.219,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtj6u9z03ui666tuy7hdpy",
                        "tokens": [
                            ":",
                            " the",
                            " internet",
                            ",",
                            " like",
                            " a",
                            " pack",
                            " of",
                            " cigarettes",
                            " or",
                            " lots",
                            " of",
                            " cocaine",
                            ",",
                            " lets",
                            " you",
                            " just",
                            " sit",
                            " in",
                            " a",
                            " room",
                            " and",
                            " repeatedly",
                            " trigger",
                            " reward",
                            " chemicals",
                            " that",
                            ",",
                            " back",
                            " in",
                            " the",
                            " environment",
                            " of",
                            " our",
                            " evolution",
                            ",",
                            " you",
                            " could",
                            " trigger",
                            " only",
                            " with",
                            " more",
                            " work",
                            " and",
                            " only",
                            " less",
                            " frequently",
                            ".",
                            " That",
                            "'s",
                            " why",
                            " an",
                            " internet",
                            " habit",
                            ",",
                            " like",
                            " a",
                            " cocaine",
                            " habit",
                            ",",
                            " can",
                            " reach",
                            " dysfunctional",
                            " levels",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " above",
                            "-",
                            "listed",
                            " forms",
                            " of",
                            " internet",
                            " dependence",
                            " --",
                            " porn",
                            ",",
                            " Facebook",
                            ",",
                            " TMZ",
                            ",",
                            " Twitter",
                            ",",
                            " YouTube",
                            " --",
                            " are",
                            " just",
                            " a",
                            " few",
                            " of",
                            " the",
                            " possible",
                            " ingredients",
                            " of",
                            " any",
                            " one",
                            " case",
                            " of",
                            " internet",
                            " \"",
                            "add",
                            "iction",
                            ".\"",
                            " And",
                            " each",
                            " of",
                            " these",
                            " ingredients",
                            " itself",
                            " involves",
                            " God",
                            "-",
                            "kn",
                            "ows",
                            "-",
                            "which",
                            " neurotrans",
                            "mit",
                            "ters",
                            " and",
                            " neuronal",
                            " receptors",
                            " and",
                            ",",
                            " by",
                            " extension"
                        ],
                        "dataIndex": null,
                        "index": "568",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 55.219,
                        "maxValueTokenIndex": 6,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            55.219,
                            0,
                            1.336,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:15:27.529Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 44.175,
                        "binMax": 55.219,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtj6u6z037i666t57cnzyh",
                        "tokens": [
                            "Truth",
                            " in",
                            " Pack",
                            "aging",
                            " time",
                            "\u00e2\u0122\u00a6",
                            "\n",
                            "\n",
                            "School",
                            " systems",
                            " consume",
                            " huge",
                            " amounts",
                            " of",
                            " tax",
                            " revenue",
                            ",",
                            " and",
                            " spend",
                            " much",
                            " of",
                            " that",
                            " money",
                            ",",
                            " via",
                            " the",
                            " time",
                            " and",
                            " resources",
                            " it",
                            " pays",
                            "-",
                            "for",
                            ",",
                            " forcing",
                            " boys",
                            " to",
                            " act",
                            " like",
                            " girls",
                            ".",
                            " They",
                            " waste",
                            " the",
                            " time",
                            " of",
                            " bright",
                            " children",
                            ",",
                            " especially",
                            " of",
                            " bright",
                            " boys",
                            ",",
                            " by",
                            " forcing",
                            " them",
                            " to",
                            " sit",
                            " still",
                            " and",
                            " wait",
                            " for",
                            " dull",
                            "er",
                            " pupils",
                            " to",
                            " learn",
                            " lessons",
                            " they",
                            " have",
                            " already",
                            " \u00e2\u0122",
                            "\u013e",
                            "got",
                            "\u00e2\u0122",
                            "\u013f",
                            ".",
                            "\n",
                            "\n",
                            "K",
                            "lein",
                            "feld",
                            " (",
                            "2009",
                            ")",
                            " reported",
                            ":",
                            "\n",
                            "\n",
                            "middle",
                            " class",
                            " parents",
                            " \u00e2\u0122\u00a6",
                            " were",
                            " worried",
                            " that",
                            " so",
                            " many",
                            " of",
                            " their",
                            " sons",
                            " had",
                            " been",
                            " diagnosed",
                            " with",
                            " Attention",
                            " Def",
                            "icit",
                            " Hyper",
                            "activity",
                            " Disorder",
                            " (",
                            "AD",
                            "HD",
                            ")",
                            " and",
                            " prescribed",
                            " drugs",
                            " such",
                            " as",
                            " R",
                            "ital",
                            "in",
                            " which",
                            " might",
                            " damage"
                        ],
                        "dataIndex": null,
                        "index": "568",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.965,
                        "maxValueTokenIndex": 2,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            50.965,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:15:27.529Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 55.219,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "10491",
            "description": "mentions of illegal drugs, particularly cocaine",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 50.507,
            "frac_nonzero": 0.00062,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "10491",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:58:04.713Z",
                "maxActApprox": 50.507,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    10491,
                    13178,
                    18400,
                    471,
                    17907,
                    23285,
                    9704,
                    10346,
                    190,
                    18076,
                    5953,
                    14086,
                    8640,
                    11055,
                    833,
                    6461,
                    5714,
                    21688,
                    9433,
                    14380,
                    7906,
                    4709,
                    11906,
                    599,
                    22564
                ],
                "topkCosSimValues": [
                    1,
                    0.6492,
                    0.5822,
                    0.5709,
                    0.5369,
                    0.4759,
                    0.4598,
                    0.4567,
                    0.4544,
                    0.4498,
                    0.4383,
                    0.4306,
                    0.4271,
                    0.4263,
                    0.4202,
                    0.4061,
                    0.4019,
                    0.397,
                    0.3792,
                    0.3782,
                    0.3776,
                    0.3756,
                    0.3742,
                    0.3738,
                    0.3717
                ],
                "neuron_alignment_indices": [
                    481,
                    447,
                    288
                ],
                "neuron_alignment_values": [
                    0.162,
                    0.109,
                    0.107
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    461,
                    35,
                    288
                ],
                "correlated_neurons_pearson": [
                    0.025,
                    0.025,
                    0.024
                ],
                "correlated_neurons_l1": [
                    0.023,
                    0.023,
                    0.027
                ],
                "correlated_features_indices": [
                    10428,
                    10486,
                    10382
                ],
                "correlated_features_pearson": [
                    0.013,
                    0.013,
                    0.005
                ],
                "correlated_features_l1": [
                    0.014,
                    0.014,
                    0.006
                ],
                "neg_str": [
                    "soType",
                    "Reviewer",
                    " Eag",
                    " Canterbury",
                    "Struct",
                    "arching",
                    "tnc",
                    "semble",
                    "Pont",
                    "earth"
                ],
                "neg_values": [
                    -0.727,
                    -0.727,
                    -0.716,
                    -0.69,
                    -0.688,
                    -0.687,
                    -0.687,
                    -0.682,
                    -0.68,
                    -0.68
                ],
                "pos_str": [
                    " cocaine",
                    " methamphetamine",
                    " overdose",
                    " addiction",
                    " addict",
                    " overdoses",
                    " addicts",
                    " drugs",
                    " intoxication",
                    " heroin"
                ],
                "pos_values": [
                    1.423,
                    1.22,
                    1.219,
                    1.21,
                    1.208,
                    1.201,
                    1.177,
                    1.174,
                    1.162,
                    1.094
                ],
                "frac_nonzero": 0.00062,
                "freq_hist_data_bar_heights": [
                    491,
                    318,
                    227,
                    191,
                    128,
                    102,
                    79,
                    69,
                    52,
                    39,
                    42,
                    31,
                    15,
                    22,
                    11,
                    9,
                    12,
                    5,
                    7,
                    8,
                    6,
                    5,
                    6,
                    3,
                    7,
                    8,
                    5,
                    9,
                    3,
                    2,
                    5,
                    2,
                    0,
                    1,
                    1,
                    1,
                    0,
                    3,
                    4,
                    1,
                    4,
                    3,
                    3,
                    4,
                    4,
                    2,
                    0,
                    2,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.506,
                    1.516,
                    2.526,
                    3.537,
                    4.547,
                    5.557,
                    6.567,
                    7.577,
                    8.587,
                    9.597,
                    10.607,
                    11.618,
                    12.628,
                    13.638,
                    14.648,
                    15.658,
                    16.668,
                    17.678,
                    18.688,
                    19.699,
                    20.709,
                    21.719,
                    22.729,
                    23.739,
                    24.749,
                    25.759,
                    26.769,
                    27.78,
                    28.79,
                    29.8,
                    30.81,
                    31.82,
                    32.83,
                    33.84,
                    34.85,
                    35.86,
                    36.871,
                    37.881,
                    38.891,
                    39.901,
                    40.911,
                    41.921,
                    42.931,
                    43.941,
                    44.952,
                    45.962,
                    46.972,
                    47.982,
                    48.992,
                    50.002
                ],
                "logits_hist_data_bar_heights": [
                    7,
                    16,
                    25,
                    53,
                    100,
                    165,
                    292,
                    423,
                    719,
                    1081,
                    1570,
                    2325,
                    2875,
                    3534,
                    4086,
                    4449,
                    4659,
                    4550,
                    4142,
                    3556,
                    2946,
                    2368,
                    1751,
                    1359,
                    1009,
                    657,
                    442,
                    316,
                    233,
                    171,
                    90,
                    77,
                    51,
                    40,
                    31,
                    25,
                    14,
                    10,
                    12,
                    12,
                    3,
                    3,
                    1,
                    1,
                    3,
                    4,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.705,
                    -0.662,
                    -0.619,
                    -0.576,
                    -0.533,
                    -0.49,
                    -0.447,
                    -0.404,
                    -0.361,
                    -0.318,
                    -0.275,
                    -0.232,
                    -0.189,
                    -0.146,
                    -0.103,
                    -0.06,
                    -0.017,
                    0.026,
                    0.069,
                    0.112,
                    0.155,
                    0.198,
                    0.241,
                    0.284,
                    0.327,
                    0.37,
                    0.413,
                    0.456,
                    0.499,
                    0.542,
                    0.585,
                    0.627,
                    0.67,
                    0.713,
                    0.756,
                    0.799,
                    0.842,
                    0.885,
                    0.928,
                    0.971,
                    1.014,
                    1.057,
                    1.1,
                    1.143,
                    1.186,
                    1.229,
                    1.272,
                    1.315,
                    1.358,
                    1.401
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clynprw3pfzkhj7a1a5kyzagu",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs24576-jb",
                        "index": "10491",
                        "description": "mentions of illegal drugs, particularly cocaine",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-07-16T01:07:39.205Z",
                        "updatedAt": "2024-07-16T01:07:39.205Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmhj5v9yw7i666gkdx00ig",
                        "tokens": [
                            " Kw",
                            "iat",
                            "kowski",
                            ",",
                            " was",
                            " fired",
                            " after",
                            " being",
                            " found",
                            " un",
                            "responsive",
                            " in",
                            " a",
                            " men",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " locker",
                            " room",
                            " with",
                            " sy",
                            "ring",
                            "es",
                            " and",
                            " needles",
                            ";",
                            " tests",
                            " found",
                            " cocaine",
                            " and",
                            " marijuana",
                            " in",
                            " his",
                            " system",
                            ",",
                            " said",
                            " the",
                            " official",
                            ",",
                            " Monica",
                            " Bowman",
                            ",",
                            " chief",
                            " executive",
                            " of",
                            " Arizona",
                            " Heart",
                            " Hospital",
                            ".",
                            " Mr",
                            ".",
                            " Kw",
                            "iat",
                            "kowski",
                            ",",
                            " 33",
                            ",",
                            " is",
                            " accused",
                            " of",
                            " stealing",
                            " an",
                            "esthetic",
                            " drugs",
                            " from",
                            " Ex",
                            "eter",
                            " Hospital",
                            " in",
                            " New",
                            " Hampshire",
                            " and",
                            " contamin",
                            "ating",
                            " sy",
                            "ring",
                            "es",
                            ".",
                            " His",
                            " strain",
                            " of",
                            " hepatitis",
                            " C",
                            " has",
                            " been",
                            " diagnosed",
                            " in",
                            " 30",
                            " patients",
                            ",",
                            " and",
                            " testing",
                            " has",
                            " been",
                            " recommended",
                            " for",
                            " about",
                            " 4",
                            ",",
                            "700",
                            " people",
                            " in",
                            " New",
                            " Hampshire",
                            " alone",
                            ".",
                            " Officials",
                            " are",
                            " still",
                            " determining",
                            " who",
                            " should",
                            " be",
                            " tested",
                            " elsewhere",
                            ".",
                            " They",
                            " have",
                            " confirmed",
                            " that",
                            " Mr",
                            ".",
                            " Kw",
                            "iat",
                            "kowski",
                            " also",
                            " worked"
                        ],
                        "dataIndex": null,
                        "index": "10491",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.507,
                        "maxValueTokenIndex": 28,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.507,
                            8.233,
                            18.399,
                            6.012,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.437,
                            0.75,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:58:12.908Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.507,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmhj5x9ywri666eu4veuxv",
                        "tokens": [
                            " Kw",
                            "iat",
                            "kowski",
                            ",",
                            " was",
                            " fired",
                            " after",
                            " being",
                            " found",
                            " un",
                            "responsive",
                            " in",
                            " a",
                            " men",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " locker",
                            " room",
                            " with",
                            " sy",
                            "ring",
                            "es",
                            " and",
                            " needles",
                            ";",
                            " tests",
                            " found",
                            " cocaine",
                            " and",
                            " marijuana",
                            " in",
                            " his",
                            " system",
                            ",",
                            " said",
                            " the",
                            " official",
                            ",",
                            " Monica",
                            " Bowman",
                            ",",
                            " chief",
                            " executive",
                            " of",
                            " Arizona",
                            " Heart",
                            " Hospital",
                            ".",
                            " Mr",
                            ".",
                            " Kw",
                            "iat",
                            "kowski",
                            ",",
                            " 33",
                            ",",
                            " is",
                            " accused",
                            " of",
                            " stealing",
                            " an",
                            "esthetic",
                            " drugs",
                            " from",
                            " Ex",
                            "eter",
                            " Hospital",
                            " in",
                            " New",
                            " Hampshire",
                            " and",
                            " contamin",
                            "ating",
                            " sy",
                            "ring",
                            "es",
                            ".",
                            " His",
                            " strain",
                            " of",
                            " hepatitis",
                            " C",
                            " has",
                            " been",
                            " diagnosed",
                            " in",
                            " 30",
                            " patients",
                            ",",
                            " and",
                            " testing",
                            " has",
                            " been",
                            " recommended",
                            " for",
                            " about",
                            " 4",
                            ",",
                            "700",
                            " people",
                            " in",
                            " New",
                            " Hampshire",
                            " alone",
                            ".",
                            " Officials",
                            " are",
                            " still",
                            " determining",
                            " who",
                            " should",
                            " be",
                            " tested",
                            " elsewhere",
                            ".",
                            " They",
                            " have",
                            " confirmed",
                            " that",
                            " Mr",
                            ".",
                            " Kw",
                            "iat",
                            "kowski",
                            " also",
                            " worked"
                        ],
                        "dataIndex": null,
                        "index": "10491",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.507,
                        "maxValueTokenIndex": 28,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.507,
                            8.233,
                            18.399,
                            6.012,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.437,
                            0.75,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:58:12.908Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 40.406,
                        "binMax": 50.507,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmhj5v9yw8i6669ryi3ta0",
                        "tokens": [
                            " dollars",
                            " worth",
                            " of",
                            " cocaine",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " ATF",
                            " agent",
                            " explains",
                            " that",
                            " he",
                            " needs",
                            " a",
                            " robbery",
                            " crew",
                            " to",
                            " help",
                            " him",
                            " overtake",
                            " armed",
                            " guards",
                            " in",
                            " the",
                            " house",
                            " and",
                            " steal",
                            " the",
                            " cocaine",
                            ".",
                            " Once",
                            " the",
                            " crew",
                            " meets",
                            " to",
                            " prepare",
                            " for",
                            " the",
                            " armed",
                            " robbery",
                            ",",
                            " federal",
                            " authorities",
                            " bust",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "Several",
                            " of",
                            " the",
                            " bust",
                            "s",
                            " have",
                            " lead",
                            " to",
                            " the",
                            " deaths",
                            " of",
                            " suspects",
                            " who",
                            " shot",
                            " at",
                            " or",
                            " tried",
                            " to",
                            " run",
                            " down",
                            " agents",
                            " in",
                            " an",
                            " attempt",
                            " to",
                            " flee",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            "form",
                            "ants",
                            " are",
                            " paid",
                            " by",
                            " the",
                            " ATF",
                            " to",
                            " pressure",
                            " people",
                            " to",
                            " join",
                            " the",
                            " fake",
                            " robberies",
                            ".",
                            " Individuals",
                            " may",
                            " be",
                            " targeted",
                            " simply",
                            " because",
                            " the",
                            " informants",
                            " know",
                            " them",
                            " through",
                            " work",
                            " or",
                            " a",
                            " personal",
                            " connection",
                            ",",
                            " just",
                            " like",
                            " a",
                            " r",
                            "affle",
                            " ticket",
                            " sale",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " preparation",
                            " for",
                            " the",
                            " fake"
                        ],
                        "dataIndex": null,
                        "index": "10491",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.329,
                        "maxValueTokenIndex": 3,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            48.329,
                            2.09,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            38.422,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:58:12.908Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.507,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "7195",
            "description": "mentions of drugs, particularly cocaine",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 42.266,
            "frac_nonzero": 0.00022,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "7195",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:53:54.469Z",
                "maxActApprox": 42.266,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    7195,
                    11791,
                    3975,
                    14575,
                    24546,
                    2976,
                    13735,
                    15094,
                    5746,
                    4905,
                    5189,
                    4562,
                    17717,
                    8878,
                    19655,
                    12331,
                    13404,
                    973,
                    13930,
                    18220,
                    17323,
                    11867,
                    23084,
                    6393,
                    17399
                ],
                "topkCosSimValues": [
                    1,
                    0.4575,
                    0.4478,
                    0.402,
                    0.3996,
                    0.3987,
                    0.3714,
                    0.3645,
                    0.3639,
                    0.3529,
                    0.3514,
                    0.3446,
                    0.3415,
                    0.3388,
                    0.3376,
                    0.3333,
                    0.3311,
                    0.3233,
                    0.321,
                    0.32,
                    0.3191,
                    0.3177,
                    0.3146,
                    0.3141,
                    0.3124
                ],
                "neuron_alignment_indices": [
                    746,
                    67,
                    99
                ],
                "neuron_alignment_values": [
                    0.119,
                    0.112,
                    0.104
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    67,
                    326,
                    343
                ],
                "correlated_neurons_pearson": [
                    0.017,
                    0.015,
                    0.015
                ],
                "correlated_neurons_l1": [
                    0.018,
                    0.013,
                    0.014
                ],
                "correlated_features_indices": [
                    7178,
                    7224,
                    7183
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.002,
                    0.002
                ],
                "correlated_features_l1": [
                    0.006,
                    0.003,
                    0.002
                ],
                "neg_str": [
                    "holes",
                    " \u00e3\u0124\u00b5\u00e3\u0125\u00bc\u00e3\u0125\u0128\u00e3\u0124\u00a3\u00e3\u0125\u00af\u00e3\u0125\u00b3",
                    "\u012a\u0134",
                    " Supplemental",
                    " Duchess",
                    "\u00e3\u0122\u0132",
                    "hole",
                    " Shutterstock",
                    " Burgess",
                    " roar"
                ],
                "neg_values": [
                    -0.691,
                    -0.688,
                    -0.685,
                    -0.64,
                    -0.597,
                    -0.594,
                    -0.587,
                    -0.581,
                    -0.572,
                    -0.559
                ],
                "pos_str": [
                    "keyes",
                    "keye",
                    "kefeller",
                    "kered",
                    "hester",
                    "ombs",
                    "ody",
                    "aine",
                    "het",
                    "ursor"
                ],
                "pos_values": [
                    1.091,
                    1.085,
                    1.078,
                    1.037,
                    1.015,
                    0.968,
                    0.963,
                    0.956,
                    0.95,
                    0.895
                ],
                "frac_nonzero": 0.00022,
                "freq_hist_data_bar_heights": [
                    150,
                    123,
                    88,
                    74,
                    44,
                    48,
                    32,
                    22,
                    15,
                    18,
                    16,
                    13,
                    10,
                    7,
                    4,
                    5,
                    3,
                    3,
                    3,
                    0,
                    0,
                    1,
                    0,
                    0,
                    2,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.424,
                    1.269,
                    2.115,
                    2.96,
                    3.805,
                    4.651,
                    5.496,
                    6.341,
                    7.186,
                    8.032,
                    8.877,
                    9.722,
                    10.568,
                    11.413,
                    12.258,
                    13.103,
                    13.949,
                    14.794,
                    15.639,
                    16.485,
                    17.33,
                    18.175,
                    19.02,
                    19.866,
                    20.711,
                    21.556,
                    22.402,
                    23.247,
                    24.092,
                    24.937,
                    25.783,
                    26.628,
                    27.473,
                    28.319,
                    29.164,
                    30.009,
                    30.855,
                    31.7,
                    32.545,
                    33.39,
                    34.236,
                    35.081,
                    35.926,
                    36.772,
                    37.617,
                    38.462,
                    39.307,
                    40.153,
                    40.998,
                    41.843
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    1,
                    3,
                    6,
                    17,
                    52,
                    74,
                    133,
                    236,
                    384,
                    630,
                    946,
                    1515,
                    1961,
                    2737,
                    3316,
                    3917,
                    4350,
                    4565,
                    4324,
                    4225,
                    3610,
                    2957,
                    2457,
                    1964,
                    1479,
                    1080,
                    831,
                    624,
                    468,
                    353,
                    254,
                    214,
                    145,
                    124,
                    77,
                    69,
                    43,
                    32,
                    26,
                    14,
                    12,
                    9,
                    10,
                    1,
                    0,
                    4,
                    1,
                    1,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.673,
                    -0.638,
                    -0.602,
                    -0.566,
                    -0.531,
                    -0.495,
                    -0.46,
                    -0.424,
                    -0.388,
                    -0.353,
                    -0.317,
                    -0.281,
                    -0.246,
                    -0.21,
                    -0.174,
                    -0.139,
                    -0.103,
                    -0.068,
                    -0.032,
                    0.004,
                    0.039,
                    0.075,
                    0.111,
                    0.146,
                    0.182,
                    0.218,
                    0.253,
                    0.289,
                    0.325,
                    0.36,
                    0.396,
                    0.431,
                    0.467,
                    0.503,
                    0.538,
                    0.574,
                    0.61,
                    0.645,
                    0.681,
                    0.717,
                    0.752,
                    0.788,
                    0.823,
                    0.859,
                    0.895,
                    0.93,
                    0.966,
                    1.002,
                    1.037,
                    1.073
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clynlmxtrfuhdj7a14h56geux",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs24576-jb",
                        "index": "7195",
                        "description": "mentions of drugs, particularly cocaine",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-07-15T23:11:49.695Z",
                        "updatedAt": "2024-07-15T23:11:49.695Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmc1h06u2ji666f25rqgxi",
                        "tokens": [
                            " with",
                            " you",
                            ",",
                            " it",
                            "'s",
                            " fun",
                            " to",
                            " go",
                            " into",
                            " bar",
                            " bathrooms",
                            " with",
                            " another",
                            " person",
                            ",",
                            " and",
                            " wasting",
                            " money",
                            " feels",
                            " good",
                            ".",
                            " Coc",
                            "aine",
                            " activates",
                            " the",
                            " same",
                            " pleasure",
                            " centers",
                            " in",
                            " your",
                            " brain",
                            " as",
                            " breaking",
                            " champagne",
                            " glasses",
                            " or",
                            " taking",
                            " an",
                            " Uber",
                            ".",
                            " Te",
                            "ens",
                            " who",
                            " want",
                            " to",
                            " use",
                            " drugs",
                            " should",
                            " stick",
                            " with",
                            " pot",
                            " and",
                            " low",
                            "-",
                            "grade",
                            " psychedel",
                            "ics",
                            ",",
                            " drugs",
                            " that",
                            " coincide",
                            " with",
                            " their",
                            " unique",
                            " ability",
                            " to",
                            " identify",
                            " hypoc",
                            "rites",
                            " and",
                            " see",
                            " the",
                            " world",
                            " as",
                            " it",
                            " really",
                            " is",
                            ".",
                            " If",
                            " teens",
                            " want",
                            " to",
                            " feel",
                            " wired",
                            ",",
                            " they",
                            " should",
                            " use",
                            " energy",
                            " drinks",
                            " or",
                            " Ad",
                            "der",
                            "all",
                            ",",
                            " two",
                            " fairly",
                            " affordable",
                            " substances",
                            " that",
                            " they",
                            " already",
                            " have",
                            " easy",
                            " access",
                            " to",
                            ".",
                            " There",
                            "'s",
                            " a",
                            " time",
                            " and",
                            " a",
                            " place",
                            " for",
                            " cocaine",
                            ",",
                            " and",
                            " that",
                            " time",
                            " is",
                            " almost",
                            " never",
                            "\u2014",
                            "except",
                            " maybe",
                            " just"
                        ],
                        "dataIndex": null,
                        "index": "7195",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.266,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.266,
                            0.327,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.434,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:53:56.694Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 42.266,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmc1h26u33i666wo34gk3w",
                        "tokens": [
                            " with",
                            " you",
                            ",",
                            " it",
                            "'s",
                            " fun",
                            " to",
                            " go",
                            " into",
                            " bar",
                            " bathrooms",
                            " with",
                            " another",
                            " person",
                            ",",
                            " and",
                            " wasting",
                            " money",
                            " feels",
                            " good",
                            ".",
                            " Coc",
                            "aine",
                            " activates",
                            " the",
                            " same",
                            " pleasure",
                            " centers",
                            " in",
                            " your",
                            " brain",
                            " as",
                            " breaking",
                            " champagne",
                            " glasses",
                            " or",
                            " taking",
                            " an",
                            " Uber",
                            ".",
                            " Te",
                            "ens",
                            " who",
                            " want",
                            " to",
                            " use",
                            " drugs",
                            " should",
                            " stick",
                            " with",
                            " pot",
                            " and",
                            " low",
                            "-",
                            "grade",
                            " psychedel",
                            "ics",
                            ",",
                            " drugs",
                            " that",
                            " coincide",
                            " with",
                            " their",
                            " unique",
                            " ability",
                            " to",
                            " identify",
                            " hypoc",
                            "rites",
                            " and",
                            " see",
                            " the",
                            " world",
                            " as",
                            " it",
                            " really",
                            " is",
                            ".",
                            " If",
                            " teens",
                            " want",
                            " to",
                            " feel",
                            " wired",
                            ",",
                            " they",
                            " should",
                            " use",
                            " energy",
                            " drinks",
                            " or",
                            " Ad",
                            "der",
                            "all",
                            ",",
                            " two",
                            " fairly",
                            " affordable",
                            " substances",
                            " that",
                            " they",
                            " already",
                            " have",
                            " easy",
                            " access",
                            " to",
                            ".",
                            " There",
                            "'s",
                            " a",
                            " time",
                            " and",
                            " a",
                            " place",
                            " for",
                            " cocaine",
                            ",",
                            " and",
                            " that",
                            " time",
                            " is",
                            " almost",
                            " never",
                            "\u2014",
                            "except",
                            " maybe",
                            " just"
                        ],
                        "dataIndex": null,
                        "index": "7195",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.266,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.266,
                            0.327,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.434,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:53:56.694Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 33.813,
                        "binMax": 42.266,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmc1h06u2ki666yc8ef96p",
                        "tokens": [
                            "amine",
                            ",",
                            " proc",
                            "aine",
                            ",",
                            " trim",
                            "eth",
                            "op",
                            "rim",
                            ",",
                            " chlor",
                            "oqu",
                            "ine",
                            ",",
                            " and",
                            " qu",
                            "in",
                            "ine",
                            ".",
                            " In",
                            " short",
                            ",",
                            " a",
                            " drug",
                            " cocktail",
                            " far",
                            " more",
                            " potent",
                            " than",
                            " the",
                            " original",
                            " name",
                            " brand",
                            " version",
                            ".",
                            "\n",
                            "\n",
                            "Indeed",
                            ",",
                            " reports",
                            " suggest",
                            " that",
                            " Syrian",
                            " insurgent",
                            " groups",
                            " ingest",
                            " a",
                            " far",
                            " ranging",
                            " and",
                            " prod",
                            "igious",
                            " amount",
                            " of",
                            " potent",
                            " drugs",
                            " including",
                            " \u00e2\u0122",
                            "\u013e",
                            "Balt",
                            "con",
                            "\u00e2\u0122",
                            "\u013f",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "Af",
                            "oun",
                            "\u00e2\u0122",
                            "\u013f",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            "Z",
                            "ol",
                            "m",
                            "\u00e2\u0122",
                            "\u013f",
                            ",",
                            " Op",
                            "ium",
                            ",",
                            " Hero",
                            "in",
                            ",",
                            " Coc",
                            "aine",
                            ",",
                            " and",
                            " Hash",
                            "ish",
                            ".",
                            "\n",
                            "\n",
                            "According",
                            " to",
                            " Frank",
                            " Lamb",
                            " in",
                            " Counter",
                            "P",
                            "unch",
                            ":",
                            " \u00e2\u0122",
                            "\u013e",
                            "J",
                            "ihad",
                            "ists",
                            " high",
                            " on",
                            " drugs",
                            " apparently",
                            " feel",
                            " invincible",
                            " and",
                            " hostile",
                            " and",
                            " do",
                            " not",
                            " fear",
                            " death",
                            ".",
                            " Many",
                            " are",
                            " indeed",
                            " ferocious",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "7195",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.513,
                        "maxValueTokenIndex": 85,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            5.555,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.513,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:53:56.694Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 42.266,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 12,
    "hasMore": false
}