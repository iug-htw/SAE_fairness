{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "professor"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "39715",
            "description": "mentions of university professors and their roles or actions",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 76.434,
            "frac_nonzero": 4e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "39715",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:10:05.166Z",
                "maxActApprox": 76.434,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    39715,
                    15773,
                    8712,
                    37264,
                    17330,
                    38723,
                    45750,
                    2786,
                    25164,
                    48794,
                    9169,
                    21281,
                    8684,
                    25525,
                    17841,
                    26078,
                    23180,
                    33986,
                    7797,
                    14257,
                    6935,
                    8681,
                    38492,
                    38907,
                    4961
                ],
                "topkCosSimValues": [
                    1,
                    0.6815,
                    0.6726,
                    0.6723,
                    0.6209,
                    0.5683,
                    0.5471,
                    0.5226,
                    0.51,
                    0.4834,
                    0.4721,
                    0.4545,
                    0.454,
                    0.4435,
                    0.4343,
                    0.4259,
                    0.4192,
                    0.415,
                    0.4116,
                    0.4069,
                    0.3986,
                    0.3838,
                    0.3814,
                    0.3771,
                    0.3769
                ],
                "neuron_alignment_indices": [
                    679,
                    631,
                    430
                ],
                "neuron_alignment_values": [
                    0.123,
                    0.102,
                    0.096
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    631,
                    462,
                    60
                ],
                "correlated_neurons_pearson": [
                    0.012,
                    0.011,
                    0.011
                ],
                "correlated_neurons_l1": [
                    0.012,
                    0.011,
                    0.01
                ],
                "correlated_features_indices": [
                    39761,
                    39782,
                    39715
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    " cruc",
                    " ashore",
                    " setback",
                    " handc",
                    " leash",
                    "MENTS",
                    " routed",
                    " ranger",
                    "boat",
                    " cramped"
                ],
                "neg_values": [
                    -0.711,
                    -0.702,
                    -0.687,
                    -0.686,
                    -0.686,
                    -0.677,
                    -0.674,
                    -0.659,
                    -0.656,
                    -0.649
                ],
                "pos_str": [
                    "essors",
                    "iles",
                    "iciency",
                    "icient",
                    "essor",
                    "ession",
                    "umo",
                    "ound",
                    "edes",
                    "illing"
                ],
                "pos_values": [
                    1.629,
                    1.232,
                    1.195,
                    1.159,
                    1.132,
                    1.066,
                    1.022,
                    0.999,
                    0.953,
                    0.94
                ],
                "frac_nonzero": 4e-05,
                "freq_hist_data_bar_heights": [
                    38,
                    14,
                    8,
                    2,
                    6,
                    8,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    2,
                    1,
                    2,
                    0,
                    3,
                    1,
                    1,
                    1,
                    0,
                    1,
                    2,
                    1,
                    3,
                    4,
                    1,
                    0,
                    5,
                    2,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.838,
                    2.365,
                    3.893,
                    5.42,
                    6.947,
                    8.474,
                    10.001,
                    11.529,
                    13.056,
                    14.583,
                    16.11,
                    17.637,
                    19.165,
                    20.692,
                    22.219,
                    23.746,
                    25.273,
                    26.801,
                    28.328,
                    29.855,
                    31.382,
                    32.909,
                    34.437,
                    35.964,
                    37.491,
                    39.018,
                    40.545,
                    42.073,
                    43.6,
                    45.127,
                    46.654,
                    48.181,
                    49.709,
                    51.236,
                    52.763,
                    54.29,
                    55.817,
                    57.344,
                    58.872,
                    60.399,
                    61.926,
                    63.453,
                    64.98,
                    66.508,
                    68.035,
                    69.562,
                    71.089,
                    72.616,
                    74.144,
                    75.671
                ],
                "logits_hist_data_bar_heights": [
                    7,
                    10,
                    24,
                    38,
                    107,
                    245,
                    463,
                    868,
                    1453,
                    2145,
                    3010,
                    3774,
                    4379,
                    4698,
                    4688,
                    4313,
                    4017,
                    3515,
                    2976,
                    2434,
                    1967,
                    1606,
                    1122,
                    843,
                    556,
                    398,
                    228,
                    171,
                    85,
                    48,
                    31,
                    10,
                    10,
                    4,
                    4,
                    2,
                    1,
                    2,
                    0,
                    2,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.687,
                    -0.64,
                    -0.594,
                    -0.547,
                    -0.5,
                    -0.453,
                    -0.406,
                    -0.36,
                    -0.313,
                    -0.266,
                    -0.219,
                    -0.172,
                    -0.126,
                    -0.079,
                    -0.032,
                    0.015,
                    0.062,
                    0.108,
                    0.155,
                    0.202,
                    0.249,
                    0.295,
                    0.342,
                    0.389,
                    0.436,
                    0.483,
                    0.529,
                    0.576,
                    0.623,
                    0.67,
                    0.717,
                    0.763,
                    0.81,
                    0.857,
                    0.904,
                    0.951,
                    0.997,
                    1.044,
                    1.091,
                    1.138,
                    1.184,
                    1.231,
                    1.278,
                    1.325,
                    1.372,
                    1.418,
                    1.465,
                    1.512,
                    1.559,
                    1.606
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyvp7i1e2evwnba6ydlq7icy",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs49152-jb",
                        "index": "39715",
                        "description": "mentions of university professors and their roles or actions",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-21T15:13:57.266Z",
                        "updatedAt": "2024-07-21T15:13:57.266Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk6ohl3c8z5i66636nh63h4",
                        "tokens": [
                            " Rao",
                            " Pod",
                            "ile",
                            " for",
                            " using",
                            " force",
                            " to",
                            " suppress",
                            " the",
                            " students",
                            "\u00e2\u0122",
                            "\u013b",
                            " voice",
                            ",",
                            " Dr",
                            " Hugo",
                            " Gor",
                            "ringe",
                            ",",
                            " senior",
                            " lecturer",
                            " of",
                            " sociology",
                            " from",
                            " the",
                            " University",
                            " of",
                            " Edinburgh",
                            ",",
                            " Scotland",
                            ",",
                            " in",
                            " a",
                            " letter",
                            " to",
                            " the",
                            " U",
                            "o",
                            "H",
                            ",",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "At",
                            " present",
                            ",",
                            " the",
                            " U",
                            "o",
                            "H",
                            " in",
                            " no",
                            " way",
                            " resembles",
                            " an",
                            " institution",
                            " of",
                            " higher",
                            " education",
                            " and",
                            " er",
                            "ud",
                            "ition",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " added",
                            ".",
                            "\n",
                            "\n",
                            "Dr",
                            " Gor",
                            "ringe",
                            ",",
                            " a",
                            " scholar",
                            " in",
                            " the",
                            " area",
                            " of",
                            " social",
                            " and",
                            " political",
                            " movements",
                            " both",
                            " in",
                            " South",
                            " India",
                            " and",
                            " Scotland",
                            ",",
                            " has",
                            " appealed",
                            " to",
                            " Prof",
                            ".",
                            " App",
                            "a",
                            " Rao",
                            " to",
                            " listen",
                            " to",
                            " the",
                            " students",
                            " instead",
                            " of",
                            " using",
                            " the",
                            " police",
                            " to",
                            " silence",
                            " dissent",
                            ".",
                            "\n",
                            "\n",
                            "Dr",
                            " Gor",
                            "ringe",
                            ",",
                            " who",
                            " was",
                            " one",
                            " of",
                            " the",
                            " many"
                        ],
                        "dataIndex": null,
                        "index": "39715",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 76.434,
                        "maxValueTokenIndex": 96,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            76.434,
                            7.409,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:10:06.719Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 76.434,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6ohl3c8z6i666m2hqicqx",
                        "tokens": [
                            "Dr",
                            " Gor",
                            "ringe",
                            ",",
                            " a",
                            " faculty",
                            " in",
                            " the",
                            " School",
                            " of",
                            " Social",
                            " and",
                            " Political",
                            " Science",
                            ",",
                            " has",
                            " slammed",
                            " Prof",
                            ".",
                            " App",
                            "a",
                            " Rao",
                            " for",
                            " using",
                            " force",
                            " to",
                            " suppress",
                            " the",
                            " students",
                            "\u00e2\u0122",
                            "\u013b",
                            " voice",
                            ".",
                            "\n",
                            "\n",
                            "Hy",
                            "der",
                            "abad",
                            ":",
                            " Dr",
                            " Hugo",
                            " Gor",
                            "ringe",
                            ",",
                            " senior",
                            " lecturer",
                            " of",
                            " sociology",
                            " from",
                            " the",
                            " University",
                            " of",
                            " Edinburgh",
                            ",",
                            " Scotland",
                            ",",
                            " has",
                            " written",
                            " an",
                            " open",
                            " letter",
                            " to",
                            " U",
                            "o",
                            "H",
                            " vice",
                            "-",
                            "chance",
                            "llor",
                            " Prof",
                            ".",
                            " App",
                            "a",
                            " Rao",
                            " Pod",
                            "ile",
                            " saying",
                            " that",
                            " he",
                            " and",
                            " other",
                            " members",
                            " of",
                            " the",
                            " global",
                            " community",
                            " of",
                            " scholars",
                            " are",
                            " reconsider",
                            "ing",
                            " continuation",
                            " of",
                            " research",
                            " links",
                            " and",
                            " ties",
                            " with",
                            " the",
                            " university",
                            " in",
                            " view",
                            " of",
                            " its",
                            " \u00e2\u0122",
                            "\u013e",
                            "high",
                            "-",
                            "handed",
                            "ness",
                            "\u00e2\u0122",
                            "\u013f",
                            " with",
                            " students",
                            ".",
                            "\n",
                            "\n",
                            "Dr",
                            " Gor",
                            "ringe",
                            ",",
                            " a",
                            " faculty",
                            " in",
                            " the",
                            " School",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "39715",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 71.053,
                        "maxValueTokenIndex": 17,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            71.053,
                            8.484,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.044,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            69.598,
                            8.321,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:10:06.719Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 76.434,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6ohl3c8z9i666bd6lx0se",
                        "tokens": [
                            "Dr",
                            " Gor",
                            "ringe",
                            ",",
                            " a",
                            " faculty",
                            " in",
                            " the",
                            " School",
                            " of",
                            " Social",
                            " and",
                            " Political",
                            " Science",
                            ",",
                            " has",
                            " slammed",
                            " Prof",
                            ".",
                            " App",
                            "a",
                            " Rao",
                            " for",
                            " using",
                            " force",
                            " to",
                            " suppress",
                            " the",
                            " students",
                            "\u00e2\u0122",
                            "\u013b",
                            " voice",
                            ".",
                            "\n",
                            "\n",
                            "Hy",
                            "der",
                            "abad",
                            ":",
                            " Dr",
                            " Hugo",
                            " Gor",
                            "ringe",
                            ",",
                            " senior",
                            " lecturer",
                            " of",
                            " sociology",
                            " from",
                            " the",
                            " University",
                            " of",
                            " Edinburgh",
                            ",",
                            " Scotland",
                            ",",
                            " has",
                            " written",
                            " an",
                            " open",
                            " letter",
                            " to",
                            " U",
                            "o",
                            "H",
                            " vice",
                            "-",
                            "chance",
                            "llor",
                            " Prof",
                            ".",
                            " App",
                            "a",
                            " Rao",
                            " Pod",
                            "ile",
                            " saying",
                            " that",
                            " he",
                            " and",
                            " other",
                            " members",
                            " of",
                            " the",
                            " global",
                            " community",
                            " of",
                            " scholars",
                            " are",
                            " reconsider",
                            "ing",
                            " continuation",
                            " of",
                            " research",
                            " links",
                            " and",
                            " ties",
                            " with",
                            " the",
                            " university",
                            " in",
                            " view",
                            " of",
                            " its",
                            " \u00e2\u0122",
                            "\u013e",
                            "high",
                            "-",
                            "handed",
                            "ness",
                            "\u00e2\u0122",
                            "\u013f",
                            " with",
                            " students",
                            ".",
                            "\n",
                            "\n",
                            "Dr",
                            " Gor",
                            "ringe",
                            ",",
                            " a",
                            " faculty",
                            " in",
                            " the",
                            " School",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "39715",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 71.053,
                        "maxValueTokenIndex": 17,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            71.053,
                            8.484,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.044,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            69.598,
                            8.321,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:10:06.719Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 76.434,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "44",
            "description": "references to professors or academic professionals",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 69.065,
            "frac_nonzero": 3e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "44",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:28:31.021Z",
                "maxActApprox": 69.065,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    44,
                    97409,
                    68007,
                    73248,
                    6218,
                    12928,
                    78071,
                    10517,
                    36642,
                    57268,
                    86544,
                    24175,
                    38945,
                    46751,
                    16944,
                    64654,
                    54842,
                    80673,
                    89731,
                    4411,
                    91451,
                    13602,
                    30381,
                    37952,
                    61929
                ],
                "topkCosSimValues": [
                    1,
                    0.682,
                    0.6665,
                    0.6403,
                    0.6203,
                    0.5641,
                    0.5467,
                    0.5436,
                    0.5101,
                    0.5068,
                    0.4948,
                    0.4865,
                    0.4824,
                    0.4778,
                    0.466,
                    0.4496,
                    0.4487,
                    0.4411,
                    0.4342,
                    0.4323,
                    0.4296,
                    0.4259,
                    0.4254,
                    0.4248,
                    0.4224
                ],
                "neuron_alignment_indices": [
                    679,
                    631,
                    288
                ],
                "neuron_alignment_values": [
                    0.119,
                    0.105,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    631,
                    60,
                    462
                ],
                "correlated_neurons_pearson": [
                    0.012,
                    0.012,
                    0.011
                ],
                "correlated_neurons_l1": [
                    0.012,
                    0.011,
                    0.01
                ],
                "correlated_features_indices": [
                    143,
                    119,
                    44
                ],
                "correlated_features_pearson": [
                    0.003,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0,
                    0
                ],
                "neg_str": [
                    " ashore",
                    " cruc",
                    " routed",
                    " handc",
                    " leash",
                    " setback",
                    " cramped",
                    "boat",
                    " ranger",
                    " overboard"
                ],
                "neg_values": [
                    -0.724,
                    -0.695,
                    -0.693,
                    -0.692,
                    -0.686,
                    -0.673,
                    -0.658,
                    -0.649,
                    -0.642,
                    -0.637
                ],
                "pos_str": [
                    "essors",
                    "iles",
                    "iciency",
                    "icient",
                    "ession",
                    "essor",
                    "umo",
                    "ound",
                    "edes",
                    "illing"
                ],
                "pos_values": [
                    1.594,
                    1.219,
                    1.163,
                    1.116,
                    1.079,
                    1.079,
                    1.004,
                    0.952,
                    0.947,
                    0.934
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    18,
                    7,
                    3,
                    2,
                    5,
                    3,
                    1,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    3,
                    2,
                    1,
                    0,
                    1,
                    2,
                    0,
                    3,
                    1,
                    1,
                    2,
                    2,
                    1,
                    2,
                    3,
                    0,
                    2,
                    0,
                    3,
                    3,
                    4,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.814,
                    2.193,
                    3.572,
                    4.951,
                    6.329,
                    7.708,
                    9.087,
                    10.466,
                    11.845,
                    13.223,
                    14.602,
                    15.981,
                    17.36,
                    18.739,
                    20.117,
                    21.496,
                    22.875,
                    24.254,
                    25.633,
                    27.011,
                    28.39,
                    29.769,
                    31.148,
                    32.527,
                    33.906,
                    35.284,
                    36.663,
                    38.042,
                    39.421,
                    40.8,
                    42.178,
                    43.557,
                    44.936,
                    46.315,
                    47.694,
                    49.072,
                    50.451,
                    51.83,
                    53.209,
                    54.588,
                    55.966,
                    57.345,
                    58.724,
                    60.103,
                    61.482,
                    62.861,
                    64.239,
                    65.618,
                    66.997,
                    68.376
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    6,
                    14,
                    42,
                    75,
                    191,
                    371,
                    768,
                    1215,
                    1887,
                    2745,
                    3433,
                    4077,
                    4512,
                    4550,
                    4539,
                    3938,
                    3641,
                    3162,
                    2725,
                    2201,
                    1796,
                    1387,
                    996,
                    711,
                    448,
                    332,
                    191,
                    134,
                    71,
                    40,
                    20,
                    13,
                    4,
                    4,
                    4,
                    2,
                    1,
                    2,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.701,
                    -0.655,
                    -0.608,
                    -0.562,
                    -0.516,
                    -0.469,
                    -0.423,
                    -0.377,
                    -0.33,
                    -0.284,
                    -0.237,
                    -0.191,
                    -0.145,
                    -0.098,
                    -0.052,
                    -0.006,
                    0.041,
                    0.087,
                    0.134,
                    0.18,
                    0.226,
                    0.273,
                    0.319,
                    0.365,
                    0.412,
                    0.458,
                    0.504,
                    0.551,
                    0.597,
                    0.644,
                    0.69,
                    0.736,
                    0.783,
                    0.829,
                    0.875,
                    0.922,
                    0.968,
                    1.015,
                    1.061,
                    1.107,
                    1.154,
                    1.2,
                    1.246,
                    1.293,
                    1.339,
                    1.386,
                    1.432,
                    1.478,
                    1.525,
                    1.571
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyznkknu1sm15q0zxwb6i1xb",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "44",
                        "description": "references to professors or academic professionals",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-24T09:39:12.588Z",
                        "updatedAt": "2024-07-24T09:39:12.588Z"
                    },
                    {
                        "id": "clze1cark35b5v3wq23jqs2jk",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "44",
                        "description": "mentions of academic professionals, specifically professors",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T11:13:27.680Z",
                        "updatedAt": "2024-08-03T11:13:27.680Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygew2cxbdb010exx12lsn1d",
                        "tokens": [
                            " to",
                            " this",
                            " idea",
                            " was",
                            " outlined",
                            " in",
                            " a",
                            " 2013",
                            " post",
                            ",",
                            " Challenges",
                            " of",
                            " Passive",
                            " Funding",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " shift",
                            " led",
                            " to",
                            " a",
                            " noticeable",
                            " improvement",
                            " in",
                            " our",
                            " ability",
                            " to",
                            " source",
                            " tangible",
                            " giving",
                            " opportunities",
                            ".",
                            "\n",
                            "\n",
                            "Examples",
                            " of",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "giving",
                            " to",
                            " learn",
                            "\u00e2\u0122",
                            "\u013f",
                            " dynamic",
                            "\n",
                            "\n",
                            "The",
                            " first",
                            " cause",
                            " we",
                            " chose",
                            " for",
                            " a",
                            " relatively",
                            " deep",
                            " investigation",
                            " \u2013",
                            " including",
                            " some",
                            " grants",
                            " \u2013",
                            " was",
                            " criminal",
                            " justice",
                            " reform",
                            " .",
                            " Of",
                            " the",
                            " causes",
                            " we",
                            " were",
                            " interested",
                            " in",
                            ",",
                            " it",
                            " seemed",
                            " to",
                            " offer",
                            " the",
                            " best",
                            " odds",
                            " of",
                            " quickly",
                            " finding",
                            " \u00e2\u0122",
                            "\u013e",
                            "sh",
                            "o",
                            "vel",
                            "-",
                            "ready",
                            "\u00e2\u0122",
                            "\u013f",
                            " giving",
                            " opportunities",
                            ",",
                            " based",
                            " on",
                            " the",
                            " comments",
                            " of",
                            " Steven",
                            " Tel",
                            "es",
                            " .",
                            " We",
                            " told",
                            " Prof",
                            ".",
                            " Tel",
                            "es",
                            " that",
                            " we",
                            " were",
                            " interested",
                            " in",
                            " making",
                            " some",
                            " initial",
                            " grants",
                            " in",
                            " this",
                            " cause",
                            ",",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "44",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 69.065,
                        "maxValueTokenIndex": 109,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            69.065,
                            8.569,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:34.412Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 69.065,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew2czbdbo10exhcif3be5",
                        "tokens": [
                            " to",
                            " this",
                            " idea",
                            " was",
                            " outlined",
                            " in",
                            " a",
                            " 2013",
                            " post",
                            ",",
                            " Challenges",
                            " of",
                            " Passive",
                            " Funding",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " shift",
                            " led",
                            " to",
                            " a",
                            " noticeable",
                            " improvement",
                            " in",
                            " our",
                            " ability",
                            " to",
                            " source",
                            " tangible",
                            " giving",
                            " opportunities",
                            ".",
                            "\n",
                            "\n",
                            "Examples",
                            " of",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "giving",
                            " to",
                            " learn",
                            "\u00e2\u0122",
                            "\u013f",
                            " dynamic",
                            "\n",
                            "\n",
                            "The",
                            " first",
                            " cause",
                            " we",
                            " chose",
                            " for",
                            " a",
                            " relatively",
                            " deep",
                            " investigation",
                            " \u2013",
                            " including",
                            " some",
                            " grants",
                            " \u2013",
                            " was",
                            " criminal",
                            " justice",
                            " reform",
                            " .",
                            " Of",
                            " the",
                            " causes",
                            " we",
                            " were",
                            " interested",
                            " in",
                            ",",
                            " it",
                            " seemed",
                            " to",
                            " offer",
                            " the",
                            " best",
                            " odds",
                            " of",
                            " quickly",
                            " finding",
                            " \u00e2\u0122",
                            "\u013e",
                            "sh",
                            "o",
                            "vel",
                            "-",
                            "ready",
                            "\u00e2\u0122",
                            "\u013f",
                            " giving",
                            " opportunities",
                            ",",
                            " based",
                            " on",
                            " the",
                            " comments",
                            " of",
                            " Steven",
                            " Tel",
                            "es",
                            " .",
                            " We",
                            " told",
                            " Prof",
                            ".",
                            " Tel",
                            "es",
                            " that",
                            " we",
                            " were",
                            " interested",
                            " in",
                            " making",
                            " some",
                            " initial",
                            " grants",
                            " in",
                            " this",
                            " cause",
                            ",",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "44",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 69.065,
                        "maxValueTokenIndex": 109,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            69.065,
                            8.569,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:34.412Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 55.252,
                        "binMax": 69.065,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew2cxbdb110exlmqmddh2",
                        "tokens": [
                            " to",
                            " state",
                            " schools",
                            ",",
                            " not",
                            " private",
                            " schools",
                            ".",
                            " Acad",
                            "emies",
                            " and",
                            " free",
                            " schools",
                            " can",
                            " also",
                            " choose",
                            " not",
                            " to",
                            " follow",
                            " it",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " an",
                            " interview",
                            " with",
                            " the",
                            " Times",
                            " Educational",
                            " Supplement",
                            " (",
                            "T",
                            "ES",
                            "),",
                            " Prof",
                            " Roberts",
                            ",",
                            " who",
                            " has",
                            " presented",
                            " a",
                            " number",
                            " of",
                            " BBC",
                            " programmes",
                            " including",
                            " The",
                            " Incredible",
                            " Human",
                            " Journey",
                            " and",
                            " Origins",
                            " of",
                            " Us",
                            ",",
                            " said",
                            ":",
                            " \u00e2\u0122",
                            "\u013e",
                            "There",
                            " should",
                            " be",
                            " regulation",
                            " that",
                            " prevents",
                            " all",
                            " schools",
                            ",",
                            " not",
                            " just",
                            " state",
                            " schools",
                            ",",
                            " from",
                            " teaching",
                            " creation",
                            "ism",
                            " because",
                            " it",
                            " is",
                            " indoctr",
                            "ination",
                            ",",
                            " it",
                            " is",
                            " planting",
                            " ideas",
                            " into",
                            " children",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " heads",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "We",
                            " should",
                            " be",
                            " teaching",
                            " children",
                            " to",
                            " be",
                            " much",
                            " more",
                            " open",
                            "-",
                            "minded",
                            ".",
                            " People",
                            " who",
                            " believe",
                            " in",
                            " creation",
                            "ism",
                            " say",
                            " that",
                            " by",
                            " teaching",
                            " evolution",
                            " you",
                            " are",
                            " indoctr",
                            "inating"
                        ],
                        "dataIndex": null,
                        "index": "44",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 65.873,
                        "maxValueTokenIndex": 35,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            65.873,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:34.412Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 69.065,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "44",
            "description": "mentions of academic professionals, specifically professors",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 69.065,
            "frac_nonzero": 3e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "44",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:28:31.021Z",
                "maxActApprox": 69.065,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    44,
                    97409,
                    68007,
                    73248,
                    6218,
                    12928,
                    78071,
                    10517,
                    36642,
                    57268,
                    86544,
                    24175,
                    38945,
                    46751,
                    16944,
                    64654,
                    54842,
                    80673,
                    89731,
                    4411,
                    91451,
                    13602,
                    30381,
                    37952,
                    61929
                ],
                "topkCosSimValues": [
                    1,
                    0.682,
                    0.6665,
                    0.6403,
                    0.6203,
                    0.5641,
                    0.5467,
                    0.5436,
                    0.5101,
                    0.5068,
                    0.4948,
                    0.4865,
                    0.4824,
                    0.4778,
                    0.466,
                    0.4496,
                    0.4487,
                    0.4411,
                    0.4342,
                    0.4323,
                    0.4296,
                    0.4259,
                    0.4254,
                    0.4248,
                    0.4224
                ],
                "neuron_alignment_indices": [
                    679,
                    631,
                    288
                ],
                "neuron_alignment_values": [
                    0.119,
                    0.105,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    631,
                    60,
                    462
                ],
                "correlated_neurons_pearson": [
                    0.012,
                    0.012,
                    0.011
                ],
                "correlated_neurons_l1": [
                    0.012,
                    0.011,
                    0.01
                ],
                "correlated_features_indices": [
                    143,
                    119,
                    44
                ],
                "correlated_features_pearson": [
                    0.003,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0,
                    0
                ],
                "neg_str": [
                    " ashore",
                    " cruc",
                    " routed",
                    " handc",
                    " leash",
                    " setback",
                    " cramped",
                    "boat",
                    " ranger",
                    " overboard"
                ],
                "neg_values": [
                    -0.724,
                    -0.695,
                    -0.693,
                    -0.692,
                    -0.686,
                    -0.673,
                    -0.658,
                    -0.649,
                    -0.642,
                    -0.637
                ],
                "pos_str": [
                    "essors",
                    "iles",
                    "iciency",
                    "icient",
                    "ession",
                    "essor",
                    "umo",
                    "ound",
                    "edes",
                    "illing"
                ],
                "pos_values": [
                    1.594,
                    1.219,
                    1.163,
                    1.116,
                    1.079,
                    1.079,
                    1.004,
                    0.952,
                    0.947,
                    0.934
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    18,
                    7,
                    3,
                    2,
                    5,
                    3,
                    1,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    3,
                    2,
                    1,
                    0,
                    1,
                    2,
                    0,
                    3,
                    1,
                    1,
                    2,
                    2,
                    1,
                    2,
                    3,
                    0,
                    2,
                    0,
                    3,
                    3,
                    4,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.814,
                    2.193,
                    3.572,
                    4.951,
                    6.329,
                    7.708,
                    9.087,
                    10.466,
                    11.845,
                    13.223,
                    14.602,
                    15.981,
                    17.36,
                    18.739,
                    20.117,
                    21.496,
                    22.875,
                    24.254,
                    25.633,
                    27.011,
                    28.39,
                    29.769,
                    31.148,
                    32.527,
                    33.906,
                    35.284,
                    36.663,
                    38.042,
                    39.421,
                    40.8,
                    42.178,
                    43.557,
                    44.936,
                    46.315,
                    47.694,
                    49.072,
                    50.451,
                    51.83,
                    53.209,
                    54.588,
                    55.966,
                    57.345,
                    58.724,
                    60.103,
                    61.482,
                    62.861,
                    64.239,
                    65.618,
                    66.997,
                    68.376
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    6,
                    14,
                    42,
                    75,
                    191,
                    371,
                    768,
                    1215,
                    1887,
                    2745,
                    3433,
                    4077,
                    4512,
                    4550,
                    4539,
                    3938,
                    3641,
                    3162,
                    2725,
                    2201,
                    1796,
                    1387,
                    996,
                    711,
                    448,
                    332,
                    191,
                    134,
                    71,
                    40,
                    20,
                    13,
                    4,
                    4,
                    4,
                    2,
                    1,
                    2,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.701,
                    -0.655,
                    -0.608,
                    -0.562,
                    -0.516,
                    -0.469,
                    -0.423,
                    -0.377,
                    -0.33,
                    -0.284,
                    -0.237,
                    -0.191,
                    -0.145,
                    -0.098,
                    -0.052,
                    -0.006,
                    0.041,
                    0.087,
                    0.134,
                    0.18,
                    0.226,
                    0.273,
                    0.319,
                    0.365,
                    0.412,
                    0.458,
                    0.504,
                    0.551,
                    0.597,
                    0.644,
                    0.69,
                    0.736,
                    0.783,
                    0.829,
                    0.875,
                    0.922,
                    0.968,
                    1.015,
                    1.061,
                    1.107,
                    1.154,
                    1.2,
                    1.246,
                    1.293,
                    1.339,
                    1.386,
                    1.432,
                    1.478,
                    1.525,
                    1.571
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyznkknu1sm15q0zxwb6i1xb",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "44",
                        "description": "references to professors or academic professionals",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-24T09:39:12.588Z",
                        "updatedAt": "2024-07-24T09:39:12.588Z"
                    },
                    {
                        "id": "clze1cark35b5v3wq23jqs2jk",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "44",
                        "description": "mentions of academic professionals, specifically professors",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T11:13:27.680Z",
                        "updatedAt": "2024-08-03T11:13:27.680Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygew2cxbdb010exx12lsn1d",
                        "tokens": [
                            " to",
                            " this",
                            " idea",
                            " was",
                            " outlined",
                            " in",
                            " a",
                            " 2013",
                            " post",
                            ",",
                            " Challenges",
                            " of",
                            " Passive",
                            " Funding",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " shift",
                            " led",
                            " to",
                            " a",
                            " noticeable",
                            " improvement",
                            " in",
                            " our",
                            " ability",
                            " to",
                            " source",
                            " tangible",
                            " giving",
                            " opportunities",
                            ".",
                            "\n",
                            "\n",
                            "Examples",
                            " of",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "giving",
                            " to",
                            " learn",
                            "\u00e2\u0122",
                            "\u013f",
                            " dynamic",
                            "\n",
                            "\n",
                            "The",
                            " first",
                            " cause",
                            " we",
                            " chose",
                            " for",
                            " a",
                            " relatively",
                            " deep",
                            " investigation",
                            " \u2013",
                            " including",
                            " some",
                            " grants",
                            " \u2013",
                            " was",
                            " criminal",
                            " justice",
                            " reform",
                            " .",
                            " Of",
                            " the",
                            " causes",
                            " we",
                            " were",
                            " interested",
                            " in",
                            ",",
                            " it",
                            " seemed",
                            " to",
                            " offer",
                            " the",
                            " best",
                            " odds",
                            " of",
                            " quickly",
                            " finding",
                            " \u00e2\u0122",
                            "\u013e",
                            "sh",
                            "o",
                            "vel",
                            "-",
                            "ready",
                            "\u00e2\u0122",
                            "\u013f",
                            " giving",
                            " opportunities",
                            ",",
                            " based",
                            " on",
                            " the",
                            " comments",
                            " of",
                            " Steven",
                            " Tel",
                            "es",
                            " .",
                            " We",
                            " told",
                            " Prof",
                            ".",
                            " Tel",
                            "es",
                            " that",
                            " we",
                            " were",
                            " interested",
                            " in",
                            " making",
                            " some",
                            " initial",
                            " grants",
                            " in",
                            " this",
                            " cause",
                            ",",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "44",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 69.065,
                        "maxValueTokenIndex": 109,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            69.065,
                            8.569,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:34.412Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 69.065,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew2czbdbo10exhcif3be5",
                        "tokens": [
                            " to",
                            " this",
                            " idea",
                            " was",
                            " outlined",
                            " in",
                            " a",
                            " 2013",
                            " post",
                            ",",
                            " Challenges",
                            " of",
                            " Passive",
                            " Funding",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " shift",
                            " led",
                            " to",
                            " a",
                            " noticeable",
                            " improvement",
                            " in",
                            " our",
                            " ability",
                            " to",
                            " source",
                            " tangible",
                            " giving",
                            " opportunities",
                            ".",
                            "\n",
                            "\n",
                            "Examples",
                            " of",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "giving",
                            " to",
                            " learn",
                            "\u00e2\u0122",
                            "\u013f",
                            " dynamic",
                            "\n",
                            "\n",
                            "The",
                            " first",
                            " cause",
                            " we",
                            " chose",
                            " for",
                            " a",
                            " relatively",
                            " deep",
                            " investigation",
                            " \u2013",
                            " including",
                            " some",
                            " grants",
                            " \u2013",
                            " was",
                            " criminal",
                            " justice",
                            " reform",
                            " .",
                            " Of",
                            " the",
                            " causes",
                            " we",
                            " were",
                            " interested",
                            " in",
                            ",",
                            " it",
                            " seemed",
                            " to",
                            " offer",
                            " the",
                            " best",
                            " odds",
                            " of",
                            " quickly",
                            " finding",
                            " \u00e2\u0122",
                            "\u013e",
                            "sh",
                            "o",
                            "vel",
                            "-",
                            "ready",
                            "\u00e2\u0122",
                            "\u013f",
                            " giving",
                            " opportunities",
                            ",",
                            " based",
                            " on",
                            " the",
                            " comments",
                            " of",
                            " Steven",
                            " Tel",
                            "es",
                            " .",
                            " We",
                            " told",
                            " Prof",
                            ".",
                            " Tel",
                            "es",
                            " that",
                            " we",
                            " were",
                            " interested",
                            " in",
                            " making",
                            " some",
                            " initial",
                            " grants",
                            " in",
                            " this",
                            " cause",
                            ",",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "44",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 69.065,
                        "maxValueTokenIndex": 109,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            69.065,
                            8.569,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:34.412Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 55.252,
                        "binMax": 69.065,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew2cxbdb110exlmqmddh2",
                        "tokens": [
                            " to",
                            " state",
                            " schools",
                            ",",
                            " not",
                            " private",
                            " schools",
                            ".",
                            " Acad",
                            "emies",
                            " and",
                            " free",
                            " schools",
                            " can",
                            " also",
                            " choose",
                            " not",
                            " to",
                            " follow",
                            " it",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " an",
                            " interview",
                            " with",
                            " the",
                            " Times",
                            " Educational",
                            " Supplement",
                            " (",
                            "T",
                            "ES",
                            "),",
                            " Prof",
                            " Roberts",
                            ",",
                            " who",
                            " has",
                            " presented",
                            " a",
                            " number",
                            " of",
                            " BBC",
                            " programmes",
                            " including",
                            " The",
                            " Incredible",
                            " Human",
                            " Journey",
                            " and",
                            " Origins",
                            " of",
                            " Us",
                            ",",
                            " said",
                            ":",
                            " \u00e2\u0122",
                            "\u013e",
                            "There",
                            " should",
                            " be",
                            " regulation",
                            " that",
                            " prevents",
                            " all",
                            " schools",
                            ",",
                            " not",
                            " just",
                            " state",
                            " schools",
                            ",",
                            " from",
                            " teaching",
                            " creation",
                            "ism",
                            " because",
                            " it",
                            " is",
                            " indoctr",
                            "ination",
                            ",",
                            " it",
                            " is",
                            " planting",
                            " ideas",
                            " into",
                            " children",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " heads",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "We",
                            " should",
                            " be",
                            " teaching",
                            " children",
                            " to",
                            " be",
                            " much",
                            " more",
                            " open",
                            "-",
                            "minded",
                            ".",
                            " People",
                            " who",
                            " believe",
                            " in",
                            " creation",
                            "ism",
                            " say",
                            " that",
                            " by",
                            " teaching",
                            " evolution",
                            " you",
                            " are",
                            " indoctr",
                            "inating"
                        ],
                        "dataIndex": null,
                        "index": "44",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 65.873,
                        "maxValueTokenIndex": 35,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            65.873,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:34.412Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 69.065,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "37264",
            "description": "references to professors or academic titles",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 66.666,
            "frac_nonzero": 3e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "37264",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:05:54.689Z",
                "maxActApprox": 66.666,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    37264,
                    17330,
                    39715,
                    11796,
                    48794,
                    39782,
                    30557,
                    24511,
                    25826,
                    30100,
                    38723,
                    39060,
                    15773,
                    36712,
                    11521,
                    38952,
                    19725,
                    21149,
                    28263,
                    40312,
                    36846,
                    4531,
                    18527,
                    47105,
                    36694
                ],
                "topkCosSimValues": [
                    1,
                    0.7674,
                    0.6723,
                    0.4632,
                    0.3805,
                    0.379,
                    0.3714,
                    0.3691,
                    0.3643,
                    0.362,
                    0.3583,
                    0.3525,
                    0.3511,
                    0.3486,
                    0.3483,
                    0.3478,
                    0.3463,
                    0.3455,
                    0.3412,
                    0.3408,
                    0.3407,
                    0.3398,
                    0.3392,
                    0.338,
                    0.3363
                ],
                "neuron_alignment_indices": [
                    288,
                    575,
                    90
                ],
                "neuron_alignment_values": [
                    0.125,
                    0.116,
                    0.114
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    90,
                    462,
                    60
                ],
                "correlated_neurons_pearson": [
                    0.01,
                    0.009,
                    0.009
                ],
                "correlated_neurons_l1": [
                    0.01,
                    0.009,
                    0.009
                ],
                "correlated_features_indices": [
                    37375,
                    37309,
                    37274
                ],
                "correlated_features_pearson": [
                    0.002,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0,
                    0
                ],
                "neg_str": [
                    "MENTS",
                    "doors",
                    " Nebula",
                    " halfway",
                    "MENT",
                    " Mali",
                    " Blazers",
                    "wolves",
                    "boat",
                    " PAL"
                ],
                "neg_values": [
                    -0.795,
                    -0.738,
                    -0.683,
                    -0.645,
                    -0.633,
                    -0.63,
                    -0.63,
                    -0.621,
                    -0.618,
                    -0.614
                ],
                "pos_str": [
                    "essor",
                    "iciency",
                    "ession",
                    "iles",
                    "essors",
                    "ound",
                    "icient",
                    "essed",
                    "iling",
                    "iled"
                ],
                "pos_values": [
                    1.703,
                    1.46,
                    1.395,
                    1.352,
                    1.336,
                    1.3,
                    1.262,
                    1.16,
                    1.145,
                    1.12
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    25,
                    19,
                    9,
                    6,
                    5,
                    3,
                    1,
                    3,
                    0,
                    2,
                    3,
                    4,
                    0,
                    0,
                    0,
                    2,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    2,
                    0,
                    0,
                    0,
                    1,
                    2,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    1,
                    0,
                    0,
                    2,
                    1,
                    2,
                    2,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.675,
                    2.009,
                    3.342,
                    4.675,
                    6.008,
                    7.341,
                    8.674,
                    10.007,
                    11.341,
                    12.674,
                    14.007,
                    15.34,
                    16.673,
                    18.006,
                    19.339,
                    20.672,
                    22.006,
                    23.339,
                    24.672,
                    26.005,
                    27.338,
                    28.671,
                    30.004,
                    31.338,
                    32.671,
                    34.004,
                    35.337,
                    36.67,
                    38.003,
                    39.336,
                    40.669,
                    42.003,
                    43.336,
                    44.669,
                    46.002,
                    47.335,
                    48.668,
                    50.001,
                    51.335,
                    52.668,
                    54.001,
                    55.334,
                    56.667,
                    58,
                    59.333,
                    60.666,
                    62,
                    63.333,
                    64.666,
                    65.999
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    1,
                    14,
                    28,
                    61,
                    167,
                    342,
                    733,
                    1313,
                    2223,
                    3322,
                    4307,
                    5326,
                    5424,
                    5288,
                    4612,
                    3911,
                    2999,
                    2399,
                    1821,
                    1361,
                    1084,
                    888,
                    683,
                    542,
                    406,
                    321,
                    243,
                    157,
                    103,
                    81,
                    34,
                    19,
                    16,
                    7,
                    6,
                    3,
                    2,
                    1,
                    0,
                    2,
                    2,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.77,
                    -0.72,
                    -0.67,
                    -0.621,
                    -0.571,
                    -0.521,
                    -0.471,
                    -0.421,
                    -0.371,
                    -0.321,
                    -0.271,
                    -0.221,
                    -0.171,
                    -0.121,
                    -0.071,
                    -0.021,
                    0.029,
                    0.079,
                    0.129,
                    0.179,
                    0.229,
                    0.279,
                    0.329,
                    0.379,
                    0.429,
                    0.479,
                    0.529,
                    0.579,
                    0.629,
                    0.679,
                    0.728,
                    0.778,
                    0.828,
                    0.878,
                    0.928,
                    0.978,
                    1.028,
                    1.078,
                    1.128,
                    1.178,
                    1.228,
                    1.278,
                    1.328,
                    1.378,
                    1.428,
                    1.478,
                    1.528,
                    1.578,
                    1.628,
                    1.678
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyvluidk2b39nba6a4j0jiyn",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs49152-jb",
                        "index": "37264",
                        "description": "references to professors or academic titles",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-21T13:39:52.329Z",
                        "updatedAt": "2024-07-21T13:39:52.329Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk6j3tc9zifi66672ytlyar",
                        "tokens": [
                            "\n",
                            "\n",
                            "The",
                            " alleged",
                            " attackers",
                            " will",
                            " make",
                            " their",
                            " first",
                            " appearance",
                            " in",
                            " court",
                            " Friday",
                            ",",
                            " when",
                            " they",
                            " also",
                            " face",
                            " charges",
                            " of",
                            " kidnapping",
                            " and",
                            " battery",
                            " for",
                            " the",
                            " assault",
                            ",",
                            " which",
                            " was",
                            " captured",
                            " on",
                            " cellphone",
                            " video",
                            " by",
                            " one",
                            " of",
                            " the",
                            " assailants",
                            " and",
                            " viewed",
                            " by",
                            " millions",
                            " on",
                            " social",
                            " media",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "This",
                            " should",
                            " never",
                            " have",
                            " happened",
                            ",\"",
                            " said",
                            " David",
                            " Boyd",
                            ",",
                            " the",
                            " victim",
                            "'s",
                            " brother",
                            "-",
                            "in",
                            "-",
                            "law",
                            " at",
                            " a",
                            " brief",
                            " news",
                            " conference",
                            " in",
                            " suburban",
                            " Chicago",
                            ".",
                            " He",
                            " said",
                            " the",
                            " victim",
                            " was",
                            " traumat",
                            "ized",
                            " but",
                            " doing",
                            " as",
                            " well",
                            " as",
                            " could",
                            " be",
                            " expected",
                            ".",
                            " Neal",
                            " St",
                            "rom",
                            ",",
                            " who",
                            " is",
                            " acting",
                            " as",
                            " a",
                            " family",
                            " spokesman",
                            ",",
                            " told",
                            " The",
                            " Associated",
                            " Press",
                            " that",
                            " the",
                            " victim",
                            " has",
                            " had",
                            " \"",
                            "prof",
                            "ound",
                            " emotional",
                            " and",
                            " physical",
                            " disabilities",
                            " throughout",
                            " his",
                            " life",
                            ".\"",
                            " He",
                            " did",
                            " not"
                        ],
                        "dataIndex": null,
                        "index": "37264",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 66.666,
                        "maxValueTokenIndex": 114,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            66.666,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:05:55.388Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 66.666,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6j3tc9zigi666ci5ahn65",
                        "tokens": [
                            " former",
                            " employer",
                            ".",
                            "\n",
                            "\n",
                            "Media",
                            " observers",
                            " have",
                            " harshly",
                            " criticized",
                            " CNN",
                            " over",
                            " Lew",
                            "andowski",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " hiring",
                            " pointing",
                            " to",
                            " his",
                            " non",
                            "-",
                            "dis",
                            "closure",
                            " and",
                            " likely",
                            " non",
                            "-",
                            "dis",
                            "par",
                            "agement",
                            " agreements",
                            " with",
                            " the",
                            " Trump",
                            " campaign",
                            " as",
                            " \u00e2\u0122",
                            "\u013e",
                            "prof",
                            "ound",
                            "ly",
                            " disturbing",
                            "\u00e2\u0122",
                            "\u013f",
                            " ethical",
                            " conflicts",
                            ".",
                            " Since",
                            " his",
                            " hiring",
                            ",",
                            " Lew",
                            "andowski",
                            " has",
                            " by",
                            " his",
                            " own",
                            " admission",
                            " continued",
                            " to",
                            " advise",
                            " the",
                            " Trump",
                            " campaign",
                            ",",
                            " even",
                            " pushing",
                            " a",
                            " camera",
                            " away",
                            " from",
                            " the",
                            " candidate",
                            " during",
                            " a",
                            " campaign",
                            " stop",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " his",
                            " on",
                            "-",
                            "air",
                            " appearances",
                            ",",
                            " Lew",
                            "andowski",
                            " has",
                            " acted",
                            " more",
                            " like",
                            " a",
                            " spokesman",
                            " for",
                            " the",
                            " campaign",
                            " than",
                            " as",
                            " an",
                            " independent",
                            " commentator",
                            ",",
                            " defending",
                            " all",
                            " of",
                            " Trump",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " actions",
                            " in",
                            " a",
                            " way",
                            " that",
                            ",",
                            " as",
                            " one",
                            " Washington",
                            " Post",
                            " reporter",
                            " noted",
                            ",",
                            " indicates"
                        ],
                        "dataIndex": null,
                        "index": "37264",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 62.942,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            62.942,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:05:55.388Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 66.666,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6j3tc9zihi666cky00e3l",
                        "tokens": [
                            "\n",
                            "It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " not",
                            " the",
                            " actual",
                            " 1973",
                            " war",
                            " that",
                            " the",
                            " Army",
                            " believes",
                            " parallels",
                            " the",
                            " modern",
                            "-",
                            "day",
                            " conflict",
                            " in",
                            " Ukraine",
                            " but",
                            " rather",
                            " the",
                            " Army",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " approach",
                            " afterward",
                            " in",
                            " digest",
                            "ing",
                            " its",
                            " lessons",
                            "\u2014",
                            "and",
                            " folding",
                            " them",
                            " into",
                            " its",
                            " own",
                            " war",
                            " plans",
                            ".",
                            " The",
                            " study",
                            " of",
                            " that",
                            " earlier",
                            " war",
                            " \u00e2\u0122",
                            "\u013e",
                            "serv",
                            "es",
                            " as",
                            " a",
                            " useful",
                            " model",
                            " for",
                            " analyzing",
                            " the",
                            " conflict",
                            " in",
                            " Ukraine",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " says",
                            " Colonel",
                            " Kelly",
                            " Ivan",
                            "off",
                            ",",
                            " a",
                            " field",
                            " artillery",
                            " officer",
                            " and",
                            " top",
                            " aide",
                            " to",
                            " McMaster",
                            ",",
                            " who",
                            " adds",
                            " that",
                            " the",
                            " detailed",
                            " undertaking",
                            " to",
                            " study",
                            " the",
                            " 1973",
                            " war",
                            " was",
                            " to",
                            " \u00e2\u0122",
                            "\u013e",
                            "prof",
                            "ound",
                            "ly",
                            " influence",
                            " the",
                            " development",
                            " of",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " Army",
                            " for",
                            " the",
                            " next",
                            " 15",
                            " years",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " Russia",
                            " New",
                            " Generation"
                        ],
                        "dataIndex": null,
                        "index": "37264",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.684,
                        "maxValueTokenIndex": 100,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.684,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:05:55.388Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 66.666,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "97409",
            "description": "references to academic titles, specifically \"Professor\" and associated names",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 60.431,
            "frac_nonzero": 5e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "97409",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:28:32.703Z",
                "maxActApprox": 60.431,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    97409,
                    64654,
                    44,
                    46751,
                    68007,
                    38945,
                    13602,
                    91451,
                    87273,
                    86544,
                    71681,
                    10517,
                    22669,
                    35435,
                    76803,
                    12928,
                    7003,
                    16944,
                    67497,
                    19951,
                    67962,
                    53510,
                    54256,
                    57941,
                    42428
                ],
                "topkCosSimValues": [
                    1,
                    0.7089,
                    0.682,
                    0.6608,
                    0.6396,
                    0.5872,
                    0.5707,
                    0.5193,
                    0.5161,
                    0.5154,
                    0.496,
                    0.4929,
                    0.4924,
                    0.4879,
                    0.4822,
                    0.4715,
                    0.4688,
                    0.4611,
                    0.4487,
                    0.4459,
                    0.4435,
                    0.4419,
                    0.4403,
                    0.4389,
                    0.4337
                ],
                "neuron_alignment_indices": [
                    510,
                    288,
                    235
                ],
                "neuron_alignment_values": [
                    0.125,
                    0.1,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    510,
                    111,
                    235
                ],
                "correlated_neurons_pearson": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_neurons_l1": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_features_indices": [
                    97512,
                    97430,
                    97501
                ],
                "correlated_features_pearson": [
                    0.015,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.015,
                    0,
                    0
                ],
                "neg_str": [
                    " destro",
                    " compr",
                    " queen",
                    " takeoff",
                    " fracture",
                    "aukee",
                    " routed",
                    " rebound",
                    " leash",
                    " cramped"
                ],
                "neg_values": [
                    -0.877,
                    -0.774,
                    -0.709,
                    -0.702,
                    -0.692,
                    -0.687,
                    -0.685,
                    -0.666,
                    -0.66,
                    -0.654
                ],
                "pos_str": [
                    "essors",
                    " Laure",
                    " emer",
                    " Hawking",
                    " Emer",
                    " Stephen",
                    " Alan",
                    " Dawkins",
                    " Richard",
                    " Michel"
                ],
                "pos_values": [
                    1.207,
                    1.006,
                    0.99,
                    0.985,
                    0.969,
                    0.948,
                    0.936,
                    0.921,
                    0.921,
                    0.913
                ],
                "frac_nonzero": 5e-05,
                "freq_hist_data_bar_heights": [
                    31,
                    18,
                    9,
                    8,
                    9,
                    6,
                    5,
                    5,
                    2,
                    2,
                    0,
                    3,
                    1,
                    4,
                    2,
                    1,
                    1,
                    1,
                    2,
                    1,
                    1,
                    2,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    2,
                    2,
                    3,
                    4,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1,
                    3,
                    4,
                    3,
                    2,
                    3,
                    1,
                    3,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.606,
                    1.814,
                    3.023,
                    4.232,
                    5.44,
                    6.649,
                    7.857,
                    9.066,
                    10.275,
                    11.483,
                    12.692,
                    13.9,
                    15.109,
                    16.317,
                    17.526,
                    18.735,
                    19.943,
                    21.152,
                    22.36,
                    23.569,
                    24.778,
                    25.986,
                    27.195,
                    28.403,
                    29.612,
                    30.821,
                    32.029,
                    33.238,
                    34.446,
                    35.655,
                    36.864,
                    38.072,
                    39.281,
                    40.489,
                    41.698,
                    42.907,
                    44.115,
                    45.324,
                    46.532,
                    47.741,
                    48.949,
                    50.158,
                    51.367,
                    52.575,
                    53.784,
                    54.992,
                    56.201,
                    57.41,
                    58.618,
                    59.827
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    0,
                    5,
                    10,
                    15,
                    33,
                    83,
                    182,
                    331,
                    579,
                    884,
                    1383,
                    2023,
                    2658,
                    3249,
                    3651,
                    3933,
                    3994,
                    3845,
                    3702,
                    3379,
                    2894,
                    2625,
                    2199,
                    1857,
                    1539,
                    1249,
                    1086,
                    753,
                    600,
                    456,
                    323,
                    252,
                    164,
                    105,
                    76,
                    63,
                    25,
                    21,
                    12,
                    8,
                    4,
                    3,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.856,
                    -0.815,
                    -0.773,
                    -0.731,
                    -0.69,
                    -0.648,
                    -0.606,
                    -0.565,
                    -0.523,
                    -0.481,
                    -0.439,
                    -0.398,
                    -0.356,
                    -0.314,
                    -0.273,
                    -0.231,
                    -0.189,
                    -0.148,
                    -0.106,
                    -0.064,
                    -0.023,
                    0.019,
                    0.061,
                    0.102,
                    0.144,
                    0.186,
                    0.227,
                    0.269,
                    0.311,
                    0.353,
                    0.394,
                    0.436,
                    0.478,
                    0.519,
                    0.561,
                    0.603,
                    0.644,
                    0.686,
                    0.728,
                    0.769,
                    0.811,
                    0.853,
                    0.894,
                    0.936,
                    0.978,
                    1.02,
                    1.061,
                    1.103,
                    1.145,
                    1.186
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clzderyak2ryqv3wqtpcjzsf4",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "97409",
                        "description": "references to academic titles, specifically \"Professor\" and associated names",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T00:41:46.844Z",
                        "updatedAt": "2024-08-03T00:41:46.844Z"
                    },
                    {
                        "id": "clzeevrtl4jcyv3wqe0l87m79",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "97409",
                        "description": "mentions of academic titles or professions related to experts and professors",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T17:32:31.257Z",
                        "updatedAt": "2024-08-03T17:32:31.257Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygj6cqpd5ds10exj713tqg7",
                        "tokens": [
                            "\n",
                            "\n",
                            "Professor",
                            " Jeffrey",
                            " P",
                            "fe",
                            "ffer",
                            " said",
                            " that",
                            " Greene",
                            "'s",
                            " so",
                            "-",
                            "called",
                            " laws",
                            " are",
                            " based",
                            " on",
                            " isolated",
                            " examples",
                            ",",
                            " and",
                            " not",
                            " on",
                            " solid",
                            " research",
                            ".[",
                            "5",
                            "]",
                            " Kirk",
                            "us",
                            " Reviews",
                            " said",
                            " Greene",
                            " offers",
                            " no",
                            " evidence",
                            " to",
                            " support",
                            " his",
                            " world",
                            " view",
                            ",",
                            " Greene",
                            "'s",
                            " laws",
                            " contradict",
                            " each",
                            " other",
                            ",",
                            " and",
                            " the",
                            " book",
                            " is",
                            " \"",
                            "sim",
                            "ply",
                            " nonsense",
                            "\".[",
                            "21",
                            "]",
                            " Newsweek",
                            " also",
                            " points",
                            " out",
                            " ways",
                            " the",
                            " laws",
                            " contradict",
                            " each",
                            " other",
                            " and",
                            " says",
                            " \"",
                            "Int",
                            "ending",
                            " the",
                            " opposite",
                            ",",
                            " Greene",
                            " has",
                            " actually",
                            " produced",
                            " one",
                            " of",
                            " the",
                            " best",
                            " arguments",
                            " since",
                            " the",
                            " New",
                            " Testament",
                            " for",
                            " humility",
                            " and",
                            " obscurity",
                            ".\"[",
                            "22",
                            "]",
                            " Director",
                            " magazine",
                            " notes",
                            " \"",
                            "some",
                            " of",
                            " Greene",
                            "'s",
                            " '",
                            "laws",
                            "'",
                            " seem",
                            " contradictory",
                            "\"",
                            " and",
                            " the",
                            " work",
                            " is",
                            " \"",
                            "pl",
                            "odd",
                            "ing",
                            " and",
                            " did",
                            "actic",
                            "\".[",
                            "23",
                            "]"
                        ],
                        "dataIndex": null,
                        "index": "97409",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 60.431,
                        "maxValueTokenIndex": 2,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            60.431,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:28:33.356Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 60.431,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygj6cqpd5dt10ex3oayn2hj",
                        "tokens": [
                            " cannot",
                            " afford",
                            " their",
                            " medicine",
                            ".\"",
                            "\n",
                            "\n",
                            "Professor",
                            " Norris",
                            " said",
                            " there",
                            " was",
                            " a",
                            " strong",
                            " case",
                            " for",
                            " some",
                            " people",
                            " to",
                            " get",
                            " their",
                            " medicines",
                            " free",
                            " of",
                            " charge",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "It",
                            "'s",
                            " quite",
                            " likely",
                            " that",
                            " it",
                            "'s",
                            " actually",
                            " cheaper",
                            " to",
                            " provide",
                            " free",
                            " medicines",
                            " for",
                            " those",
                            " people",
                            ",",
                            " rather",
                            " than",
                            " have",
                            " them",
                            " go",
                            " without",
                            ",",
                            " get",
                            " sick",
                            "er",
                            ",",
                            " and",
                            " end",
                            " up",
                            " in",
                            " hospital",
                            " which",
                            " costs",
                            " everybody",
                            " a",
                            " lot",
                            " of",
                            " money",
                            ",\"",
                            " she",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " cost",
                            " of",
                            " prescriptions",
                            " went",
                            " from",
                            " $",
                            "3",
                            " to",
                            " $",
                            "5",
                            " on",
                            " 1",
                            " January",
                            " 2013",
                            ".",
                            "<|endoftext|>",
                            "Senate",
                            " Majority",
                            " Leader",
                            " Mitch",
                            " McConnell",
                            " (",
                            "R",
                            "-",
                            "Ky",
                            ".)",
                            " confirmed",
                            " Senate",
                            " Republicans",
                            " will",
                            " delay",
                            " a",
                            " vote",
                            " on",
                            " their",
                            " proposed",
                            " health",
                            " care",
                            " legislation",
                            " on",
                            " June",
                            " 27",
                            " at",
                            " the",
                            " Capitol",
                            ".",
                            " (",
                            "Peter",
                            " Stevenson",
                            "/",
                            "The"
                        ],
                        "dataIndex": null,
                        "index": "97409",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.548,
                        "maxValueTokenIndex": 7,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.548,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:28:33.356Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 60.431,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygj6cqpd5du10exyuqskvx5",
                        "tokens": [
                            "\"",
                            " and",
                            " needed",
                            " to",
                            " be",
                            " challenged",
                            " in",
                            " the",
                            " courts",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "A",
                            " lot",
                            " of",
                            " people",
                            " who",
                            " will",
                            " be",
                            " affected",
                            " had",
                            " seen",
                            " India",
                            " as",
                            " a",
                            " wonderful",
                            " option",
                            " for",
                            " getting",
                            " into",
                            " p",
                            "arenthood",
                            " and",
                            " now",
                            " this",
                            " option",
                            " is",
                            " closed",
                            ".",
                            " It",
                            "'s",
                            " quite",
                            " sad",
                            ",\"",
                            " he",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "Source",
                            ":",
                            " AFP",
                            "<|endoftext|>",
                            "Professor",
                            " Fired",
                            " for",
                            " Catholic",
                            " Belief",
                            "s",
                            "?",
                            "\n",
                            "\n",
                            "The",
                            " Fox",
                            " News",
                            " headline",
                            " \"",
                            "University",
                            " of",
                            " Illinois",
                            " Instructor",
                            " Fired",
                            " Over",
                            " Catholic",
                            " Belief",
                            "s",
                            "\"",
                            " is",
                            " grossly",
                            " misleading",
                            ".",
                            "\n",
                            "\n",
                            "James",
                            " Joy",
                            "ner",
                            " \u00c2\u00b7",
                            " \u00c2\u00b7",
                            " 22",
                            " comments",
                            "\n",
                            "\n",
                            "A",
                            " Fox",
                            " News",
                            " headline",
                            "*",
                            " bl",
                            "aring",
                            " \u00e2\u0122",
                            "\u013e",
                            "University",
                            " of",
                            " Illinois",
                            " Instructor",
                            " Fired",
                            " Over",
                            " Catholic",
                            " Belief",
                            "s",
                            "\u00e2\u0122",
                            "\u013f",
                            " is",
                            " grossly",
                            " misleading",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " University",
                            " of",
                            " Illinois",
                            " has",
                            " fired",
                            " an",
                            " adjunct"
                        ],
                        "dataIndex": null,
                        "index": "97409",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.272,
                        "maxValueTokenIndex": 54,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.272,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:28:33.356Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 60.431,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "97409",
            "description": "mentions of academic titles or professions related to experts and professors",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 60.431,
            "frac_nonzero": 5e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "97409",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:28:32.703Z",
                "maxActApprox": 60.431,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    97409,
                    64654,
                    44,
                    46751,
                    68007,
                    38945,
                    13602,
                    91451,
                    87273,
                    86544,
                    71681,
                    10517,
                    22669,
                    35435,
                    76803,
                    12928,
                    7003,
                    16944,
                    67497,
                    19951,
                    67962,
                    53510,
                    54256,
                    57941,
                    42428
                ],
                "topkCosSimValues": [
                    1,
                    0.7089,
                    0.682,
                    0.6608,
                    0.6396,
                    0.5872,
                    0.5707,
                    0.5193,
                    0.5161,
                    0.5154,
                    0.496,
                    0.4929,
                    0.4924,
                    0.4879,
                    0.4822,
                    0.4715,
                    0.4688,
                    0.4611,
                    0.4487,
                    0.4459,
                    0.4435,
                    0.4419,
                    0.4403,
                    0.4389,
                    0.4337
                ],
                "neuron_alignment_indices": [
                    510,
                    288,
                    235
                ],
                "neuron_alignment_values": [
                    0.125,
                    0.1,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    510,
                    111,
                    235
                ],
                "correlated_neurons_pearson": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_neurons_l1": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_features_indices": [
                    97512,
                    97430,
                    97501
                ],
                "correlated_features_pearson": [
                    0.015,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.015,
                    0,
                    0
                ],
                "neg_str": [
                    " destro",
                    " compr",
                    " queen",
                    " takeoff",
                    " fracture",
                    "aukee",
                    " routed",
                    " rebound",
                    " leash",
                    " cramped"
                ],
                "neg_values": [
                    -0.877,
                    -0.774,
                    -0.709,
                    -0.702,
                    -0.692,
                    -0.687,
                    -0.685,
                    -0.666,
                    -0.66,
                    -0.654
                ],
                "pos_str": [
                    "essors",
                    " Laure",
                    " emer",
                    " Hawking",
                    " Emer",
                    " Stephen",
                    " Alan",
                    " Dawkins",
                    " Richard",
                    " Michel"
                ],
                "pos_values": [
                    1.207,
                    1.006,
                    0.99,
                    0.985,
                    0.969,
                    0.948,
                    0.936,
                    0.921,
                    0.921,
                    0.913
                ],
                "frac_nonzero": 5e-05,
                "freq_hist_data_bar_heights": [
                    31,
                    18,
                    9,
                    8,
                    9,
                    6,
                    5,
                    5,
                    2,
                    2,
                    0,
                    3,
                    1,
                    4,
                    2,
                    1,
                    1,
                    1,
                    2,
                    1,
                    1,
                    2,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    2,
                    2,
                    3,
                    4,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1,
                    3,
                    4,
                    3,
                    2,
                    3,
                    1,
                    3,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.606,
                    1.814,
                    3.023,
                    4.232,
                    5.44,
                    6.649,
                    7.857,
                    9.066,
                    10.275,
                    11.483,
                    12.692,
                    13.9,
                    15.109,
                    16.317,
                    17.526,
                    18.735,
                    19.943,
                    21.152,
                    22.36,
                    23.569,
                    24.778,
                    25.986,
                    27.195,
                    28.403,
                    29.612,
                    30.821,
                    32.029,
                    33.238,
                    34.446,
                    35.655,
                    36.864,
                    38.072,
                    39.281,
                    40.489,
                    41.698,
                    42.907,
                    44.115,
                    45.324,
                    46.532,
                    47.741,
                    48.949,
                    50.158,
                    51.367,
                    52.575,
                    53.784,
                    54.992,
                    56.201,
                    57.41,
                    58.618,
                    59.827
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    0,
                    5,
                    10,
                    15,
                    33,
                    83,
                    182,
                    331,
                    579,
                    884,
                    1383,
                    2023,
                    2658,
                    3249,
                    3651,
                    3933,
                    3994,
                    3845,
                    3702,
                    3379,
                    2894,
                    2625,
                    2199,
                    1857,
                    1539,
                    1249,
                    1086,
                    753,
                    600,
                    456,
                    323,
                    252,
                    164,
                    105,
                    76,
                    63,
                    25,
                    21,
                    12,
                    8,
                    4,
                    3,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.856,
                    -0.815,
                    -0.773,
                    -0.731,
                    -0.69,
                    -0.648,
                    -0.606,
                    -0.565,
                    -0.523,
                    -0.481,
                    -0.439,
                    -0.398,
                    -0.356,
                    -0.314,
                    -0.273,
                    -0.231,
                    -0.189,
                    -0.148,
                    -0.106,
                    -0.064,
                    -0.023,
                    0.019,
                    0.061,
                    0.102,
                    0.144,
                    0.186,
                    0.227,
                    0.269,
                    0.311,
                    0.353,
                    0.394,
                    0.436,
                    0.478,
                    0.519,
                    0.561,
                    0.603,
                    0.644,
                    0.686,
                    0.728,
                    0.769,
                    0.811,
                    0.853,
                    0.894,
                    0.936,
                    0.978,
                    1.02,
                    1.061,
                    1.103,
                    1.145,
                    1.186
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clzderyak2ryqv3wqtpcjzsf4",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "97409",
                        "description": "references to academic titles, specifically \"Professor\" and associated names",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T00:41:46.844Z",
                        "updatedAt": "2024-08-03T00:41:46.844Z"
                    },
                    {
                        "id": "clzeevrtl4jcyv3wqe0l87m79",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "97409",
                        "description": "mentions of academic titles or professions related to experts and professors",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T17:32:31.257Z",
                        "updatedAt": "2024-08-03T17:32:31.257Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygj6cqpd5ds10exj713tqg7",
                        "tokens": [
                            "\n",
                            "\n",
                            "Professor",
                            " Jeffrey",
                            " P",
                            "fe",
                            "ffer",
                            " said",
                            " that",
                            " Greene",
                            "'s",
                            " so",
                            "-",
                            "called",
                            " laws",
                            " are",
                            " based",
                            " on",
                            " isolated",
                            " examples",
                            ",",
                            " and",
                            " not",
                            " on",
                            " solid",
                            " research",
                            ".[",
                            "5",
                            "]",
                            " Kirk",
                            "us",
                            " Reviews",
                            " said",
                            " Greene",
                            " offers",
                            " no",
                            " evidence",
                            " to",
                            " support",
                            " his",
                            " world",
                            " view",
                            ",",
                            " Greene",
                            "'s",
                            " laws",
                            " contradict",
                            " each",
                            " other",
                            ",",
                            " and",
                            " the",
                            " book",
                            " is",
                            " \"",
                            "sim",
                            "ply",
                            " nonsense",
                            "\".[",
                            "21",
                            "]",
                            " Newsweek",
                            " also",
                            " points",
                            " out",
                            " ways",
                            " the",
                            " laws",
                            " contradict",
                            " each",
                            " other",
                            " and",
                            " says",
                            " \"",
                            "Int",
                            "ending",
                            " the",
                            " opposite",
                            ",",
                            " Greene",
                            " has",
                            " actually",
                            " produced",
                            " one",
                            " of",
                            " the",
                            " best",
                            " arguments",
                            " since",
                            " the",
                            " New",
                            " Testament",
                            " for",
                            " humility",
                            " and",
                            " obscurity",
                            ".\"[",
                            "22",
                            "]",
                            " Director",
                            " magazine",
                            " notes",
                            " \"",
                            "some",
                            " of",
                            " Greene",
                            "'s",
                            " '",
                            "laws",
                            "'",
                            " seem",
                            " contradictory",
                            "\"",
                            " and",
                            " the",
                            " work",
                            " is",
                            " \"",
                            "pl",
                            "odd",
                            "ing",
                            " and",
                            " did",
                            "actic",
                            "\".[",
                            "23",
                            "]"
                        ],
                        "dataIndex": null,
                        "index": "97409",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 60.431,
                        "maxValueTokenIndex": 2,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            60.431,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:28:33.356Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 60.431,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygj6cqpd5dt10ex3oayn2hj",
                        "tokens": [
                            " cannot",
                            " afford",
                            " their",
                            " medicine",
                            ".\"",
                            "\n",
                            "\n",
                            "Professor",
                            " Norris",
                            " said",
                            " there",
                            " was",
                            " a",
                            " strong",
                            " case",
                            " for",
                            " some",
                            " people",
                            " to",
                            " get",
                            " their",
                            " medicines",
                            " free",
                            " of",
                            " charge",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "It",
                            "'s",
                            " quite",
                            " likely",
                            " that",
                            " it",
                            "'s",
                            " actually",
                            " cheaper",
                            " to",
                            " provide",
                            " free",
                            " medicines",
                            " for",
                            " those",
                            " people",
                            ",",
                            " rather",
                            " than",
                            " have",
                            " them",
                            " go",
                            " without",
                            ",",
                            " get",
                            " sick",
                            "er",
                            ",",
                            " and",
                            " end",
                            " up",
                            " in",
                            " hospital",
                            " which",
                            " costs",
                            " everybody",
                            " a",
                            " lot",
                            " of",
                            " money",
                            ",\"",
                            " she",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " cost",
                            " of",
                            " prescriptions",
                            " went",
                            " from",
                            " $",
                            "3",
                            " to",
                            " $",
                            "5",
                            " on",
                            " 1",
                            " January",
                            " 2013",
                            ".",
                            "<|endoftext|>",
                            "Senate",
                            " Majority",
                            " Leader",
                            " Mitch",
                            " McConnell",
                            " (",
                            "R",
                            "-",
                            "Ky",
                            ".)",
                            " confirmed",
                            " Senate",
                            " Republicans",
                            " will",
                            " delay",
                            " a",
                            " vote",
                            " on",
                            " their",
                            " proposed",
                            " health",
                            " care",
                            " legislation",
                            " on",
                            " June",
                            " 27",
                            " at",
                            " the",
                            " Capitol",
                            ".",
                            " (",
                            "Peter",
                            " Stevenson",
                            "/",
                            "The"
                        ],
                        "dataIndex": null,
                        "index": "97409",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.548,
                        "maxValueTokenIndex": 7,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.548,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:28:33.356Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 60.431,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygj6cqpd5du10exyuqskvx5",
                        "tokens": [
                            "\"",
                            " and",
                            " needed",
                            " to",
                            " be",
                            " challenged",
                            " in",
                            " the",
                            " courts",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "A",
                            " lot",
                            " of",
                            " people",
                            " who",
                            " will",
                            " be",
                            " affected",
                            " had",
                            " seen",
                            " India",
                            " as",
                            " a",
                            " wonderful",
                            " option",
                            " for",
                            " getting",
                            " into",
                            " p",
                            "arenthood",
                            " and",
                            " now",
                            " this",
                            " option",
                            " is",
                            " closed",
                            ".",
                            " It",
                            "'s",
                            " quite",
                            " sad",
                            ",\"",
                            " he",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "Source",
                            ":",
                            " AFP",
                            "<|endoftext|>",
                            "Professor",
                            " Fired",
                            " for",
                            " Catholic",
                            " Belief",
                            "s",
                            "?",
                            "\n",
                            "\n",
                            "The",
                            " Fox",
                            " News",
                            " headline",
                            " \"",
                            "University",
                            " of",
                            " Illinois",
                            " Instructor",
                            " Fired",
                            " Over",
                            " Catholic",
                            " Belief",
                            "s",
                            "\"",
                            " is",
                            " grossly",
                            " misleading",
                            ".",
                            "\n",
                            "\n",
                            "James",
                            " Joy",
                            "ner",
                            " \u00c2\u00b7",
                            " \u00c2\u00b7",
                            " 22",
                            " comments",
                            "\n",
                            "\n",
                            "A",
                            " Fox",
                            " News",
                            " headline",
                            "*",
                            " bl",
                            "aring",
                            " \u00e2\u0122",
                            "\u013e",
                            "University",
                            " of",
                            " Illinois",
                            " Instructor",
                            " Fired",
                            " Over",
                            " Catholic",
                            " Belief",
                            "s",
                            "\u00e2\u0122",
                            "\u013f",
                            " is",
                            " grossly",
                            " misleading",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " University",
                            " of",
                            " Illinois",
                            " has",
                            " fired",
                            " an",
                            " adjunct"
                        ],
                        "dataIndex": null,
                        "index": "97409",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.272,
                        "maxValueTokenIndex": 54,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.272,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:28:33.356Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 60.431,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "15773",
            "description": " mentions of people with the title \"Professor.\"",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 60.224,
            "frac_nonzero": 8e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "15773",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:26:43.227Z",
                "maxActApprox": 60.224,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    15773,
                    48794,
                    39715,
                    8712,
                    8681,
                    9169,
                    21281,
                    42211,
                    8330,
                    26078,
                    31459,
                    38723,
                    48190,
                    45750,
                    42517,
                    30967,
                    36846,
                    33364,
                    33728,
                    6935,
                    8668,
                    25525,
                    33986,
                    5198,
                    25164
                ],
                "topkCosSimValues": [
                    1,
                    0.7476,
                    0.6815,
                    0.6388,
                    0.5676,
                    0.5672,
                    0.5359,
                    0.5139,
                    0.5137,
                    0.4984,
                    0.4953,
                    0.4926,
                    0.468,
                    0.4581,
                    0.4552,
                    0.4485,
                    0.4269,
                    0.4252,
                    0.4247,
                    0.4164,
                    0.4141,
                    0.4137,
                    0.4069,
                    0.4048,
                    0.3979
                ],
                "neuron_alignment_indices": [
                    447,
                    510,
                    235
                ],
                "neuron_alignment_values": [
                    0.12,
                    0.119,
                    0.111
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    510,
                    111,
                    235
                ],
                "correlated_neurons_pearson": [
                    0.016,
                    0.015,
                    0.014
                ],
                "correlated_neurons_l1": [
                    0.016,
                    0.015,
                    0.015
                ],
                "correlated_features_indices": [
                    15736,
                    15691,
                    15682
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    " destro",
                    " compr",
                    "aukee",
                    " fracture",
                    " sled",
                    " queen",
                    " routed",
                    " takeoff",
                    " leash",
                    " tame"
                ],
                "neg_values": [
                    -0.924,
                    -0.77,
                    -0.712,
                    -0.686,
                    -0.674,
                    -0.672,
                    -0.672,
                    -0.671,
                    -0.671,
                    -0.658
                ],
                "pos_str": [
                    "essors",
                    " Laure",
                    " Hawking",
                    " Stephen",
                    " emer",
                    " Richard",
                    " Emer",
                    " Alan",
                    " Cornel",
                    " Christopher"
                ],
                "pos_values": [
                    1.239,
                    1.025,
                    0.984,
                    0.976,
                    0.963,
                    0.945,
                    0.944,
                    0.929,
                    0.913,
                    0.906
                ],
                "frac_nonzero": 8e-05,
                "freq_hist_data_bar_heights": [
                    63,
                    37,
                    23,
                    14,
                    11,
                    9,
                    9,
                    2,
                    1,
                    1,
                    2,
                    4,
                    2,
                    2,
                    0,
                    0,
                    0,
                    4,
                    3,
                    1,
                    2,
                    0,
                    2,
                    0,
                    0,
                    3,
                    2,
                    0,
                    3,
                    1,
                    1,
                    2,
                    1,
                    2,
                    3,
                    2,
                    0,
                    0,
                    3,
                    4,
                    4,
                    4,
                    4,
                    3,
                    4,
                    4,
                    11,
                    5,
                    3,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.639,
                    1.843,
                    3.047,
                    4.251,
                    5.454,
                    6.658,
                    7.862,
                    9.066,
                    10.269,
                    11.473,
                    12.677,
                    13.881,
                    15.084,
                    16.288,
                    17.492,
                    18.696,
                    19.899,
                    21.103,
                    22.307,
                    23.51,
                    24.714,
                    25.918,
                    27.122,
                    28.325,
                    29.529,
                    30.733,
                    31.937,
                    33.14,
                    34.344,
                    35.548,
                    36.752,
                    37.955,
                    39.159,
                    40.363,
                    41.567,
                    42.77,
                    43.974,
                    45.178,
                    46.381,
                    47.585,
                    48.789,
                    49.993,
                    51.196,
                    52.4,
                    53.604,
                    54.808,
                    56.011,
                    57.215,
                    58.419,
                    59.623
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    1,
                    1,
                    6,
                    9,
                    12,
                    47,
                    96,
                    199,
                    399,
                    666,
                    1040,
                    1656,
                    2367,
                    2946,
                    3626,
                    4007,
                    4248,
                    4225,
                    3961,
                    3744,
                    3162,
                    2835,
                    2357,
                    1946,
                    1583,
                    1292,
                    1030,
                    790,
                    594,
                    435,
                    305,
                    236,
                    151,
                    94,
                    71,
                    53,
                    25,
                    22,
                    5,
                    7,
                    4,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.903,
                    -0.859,
                    -0.816,
                    -0.773,
                    -0.73,
                    -0.686,
                    -0.643,
                    -0.6,
                    -0.557,
                    -0.513,
                    -0.47,
                    -0.427,
                    -0.384,
                    -0.34,
                    -0.297,
                    -0.254,
                    -0.211,
                    -0.167,
                    -0.124,
                    -0.081,
                    -0.038,
                    0.006,
                    0.049,
                    0.092,
                    0.135,
                    0.179,
                    0.222,
                    0.265,
                    0.308,
                    0.352,
                    0.395,
                    0.438,
                    0.482,
                    0.525,
                    0.568,
                    0.611,
                    0.655,
                    0.698,
                    0.741,
                    0.784,
                    0.828,
                    0.871,
                    0.914,
                    0.957,
                    1.001,
                    1.044,
                    1.087,
                    1.13,
                    1.174,
                    1.217
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyv46fa0106nnba6nt3zkj03",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs49152-jb",
                        "index": "15773",
                        "description": " mentions of people with the title \"Professor.\"",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-21T05:25:15.096Z",
                        "updatedAt": "2024-07-21T05:25:15.096Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk54vg0q6z2i666fgk7pgqq",
                        "tokens": [
                            " his",
                            " best",
                            " chance",
                            " of",
                            " achieving",
                            " his",
                            " objectives",
                            ".",
                            "\n",
                            "\n",
                            "Kim",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " number",
                            " one",
                            " priority",
                            " is",
                            " the",
                            " survival",
                            " of",
                            " his",
                            " regime",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "Kim",
                            " Jong",
                            "-",
                            "un",
                            " is",
                            " not",
                            " a",
                            " crazy",
                            " man",
                            ",\"",
                            " said",
                            " Professor",
                            " Sung",
                            "-",
                            "han",
                            " Kim",
                            ",",
                            " Dean",
                            " of",
                            " the",
                            " Graduate",
                            " School",
                            " of",
                            " International",
                            " Studies",
                            " at",
                            " Korea",
                            " University",
                            " in",
                            " Seoul",
                            ".",
                            " \"",
                            "He",
                            " knows",
                            " that",
                            " he",
                            " will",
                            " be",
                            " dead",
                            " if",
                            " he",
                            " triggers",
                            " a",
                            " war",
                            ".",
                            " He",
                            " is",
                            " thus",
                            " obsessed",
                            " with",
                            " preserving",
                            " his",
                            " own",
                            " regime",
                            " by",
                            " maximizing",
                            " his",
                            " leverage",
                            " -",
                            " through",
                            " improving",
                            " nuclear",
                            " and",
                            " IC",
                            "BM",
                            " capabilities",
                            " -",
                            " over",
                            " the",
                            " US",
                            " in",
                            " the",
                            " future",
                            " negotiations",
                            ".\"",
                            "\n",
                            "\n",
                            "The",
                            " point",
                            " is",
                            " that",
                            " once",
                            " he",
                            " has",
                            " reliable",
                            " nuclear",
                            " weapons",
                            " that",
                            " could",
                            " land",
                            " on",
                            " San",
                            " Francisco",
                            " within",
                            " half",
                            " an",
                            " hour",
                            "\u00e2\u0122",
                            "\u013b",
                            "s"
                        ],
                        "dataIndex": null,
                        "index": "15773",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 60.224,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            60.224,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:26:51.720Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 60.224,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk54vg0q6z3i666s1xldh2w",
                        "tokens": [
                            " Books",
                            ",",
                            " Richard",
                            " Lloyd",
                            " and",
                            " Ted",
                            " Post",
                            "ol",
                            ",",
                            " described",
                            " by",
                            " the",
                            " New",
                            " York",
                            " Times",
                            " as",
                            " '",
                            "leading",
                            " weapons",
                            " experts",
                            "',",
                            " dismissed",
                            " Higgins",
                            " as",
                            " '",
                            "a",
                            " blogger",
                            " who",
                            ",",
                            " although",
                            " he",
                            " has",
                            " been",
                            " widely",
                            " quoted",
                            " as",
                            " an",
                            " expert",
                            " in",
                            " the",
                            " American",
                            " mainstream",
                            " media",
                            ",",
                            " has",
                            " changed",
                            " his",
                            " facts",
                            " every",
                            " time",
                            " new",
                            " technical",
                            " information",
                            " has",
                            " challenged",
                            " his",
                            " conclusion",
                            " that",
                            " the",
                            " Syrian",
                            " government",
                            " must",
                            " have",
                            " been",
                            " responsible",
                            " for",
                            " the",
                            " s",
                            "arin",
                            " attack",
                            " [",
                            "in",
                            " Gh",
                            "out",
                            "a",
                            ",",
                            " August",
                            " 2013",
                            "].",
                            " In",
                            " addition",
                            ",",
                            " the",
                            " claims",
                            " that",
                            " Higgins",
                            " makes",
                            " that",
                            " are",
                            " correct",
                            " are",
                            " all",
                            " derived",
                            " from",
                            " our",
                            " findings",
                            ",",
                            " which",
                            " have",
                            " been",
                            " transmitted",
                            " to",
                            " him",
                            " in",
                            " numerous",
                            " exchanges",
                            "'.",
                            "\n",
                            "\n",
                            "Professor",
                            " Post",
                            "ol",
                            ",",
                            " a",
                            " professor",
                            " emer",
                            "itus",
                            " of",
                            " science",
                            ",",
                            " technology",
                            ",",
                            " and",
                            " national",
                            "-",
                            "security",
                            " policy"
                        ],
                        "dataIndex": null,
                        "index": "15773",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.967,
                        "maxValueTokenIndex": 109,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.967,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:26:51.720Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 60.224,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk54vg0q6z4i6667201haoy",
                        "tokens": [
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " the",
                            " Civil",
                            " Rights",
                            " Act",
                            " of",
                            " 1964",
                            " all",
                            " probably",
                            " contributed",
                            " to",
                            " the",
                            " earlier",
                            " narrowing",
                            " of",
                            " health",
                            " disparities",
                            ",",
                            " Professor",
                            " K",
                            "rie",
                            "ger",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "Robert",
                            " E",
                            ".",
                            " Moff",
                            "it",
                            ",",
                            " director",
                            " of",
                            " the",
                            " Center",
                            " for",
                            " Health",
                            " Policy",
                            " Studies",
                            " at",
                            " the",
                            " conservative",
                            " Heritage",
                            " Foundation",
                            ",",
                            " said",
                            " one",
                            " reason",
                            " for",
                            " the",
                            " growing",
                            " disparities",
                            " might",
                            " be",
                            " \u00e2\u0122",
                            "\u013e",
                            "a",
                            " very",
                            " significant",
                            " gap",
                            " in",
                            " health",
                            " literacy",
                            "\u00e2\u0122",
                            "\u013f",
                            " \u2014",
                            " what",
                            " people",
                            " know",
                            " about",
                            " diet",
                            ",",
                            " exercise",
                            " and",
                            " healthy",
                            " lifestyles",
                            ".",
                            " Middle",
                            "-",
                            "class",
                            " and",
                            " upper",
                            "-",
                            "income",
                            " people",
                            " have",
                            " greater",
                            " access",
                            " to",
                            " the",
                            " huge",
                            " amounts",
                            " of",
                            " health",
                            " information",
                            " on",
                            " the",
                            " Internet",
                            ",",
                            " Mr",
                            ".",
                            " Moff",
                            "it",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "Advertisement",
                            " Continue",
                            " reading",
                            " the",
                            " main",
                            " story",
                            "\n",
                            "\n",
                            "Thomas",
                            " P",
                            ".",
                            " Miller",
                            ",",
                            " a",
                            " health",
                            " economist",
                            " at"
                        ],
                        "dataIndex": null,
                        "index": "15773",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 58.865,
                        "maxValueTokenIndex": 20,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            58.865,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:26:51.720Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 60.224,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "64654",
            "description": "references to academic positions, particularly the term \"professor\"",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 56.254,
            "frac_nonzero": 0.00012,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "64654",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:52:58.223Z",
                "maxActApprox": 56.254,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    64654,
                    46751,
                    97409,
                    93548,
                    35435,
                    42428,
                    64882,
                    74864,
                    17380,
                    43982,
                    25167,
                    53510,
                    38575,
                    29411,
                    7003,
                    86615,
                    3486,
                    27016,
                    44,
                    48115,
                    9418,
                    84880,
                    78206,
                    9804,
                    15503
                ],
                "topkCosSimValues": [
                    1,
                    0.7346,
                    0.7089,
                    0.5919,
                    0.5586,
                    0.544,
                    0.5384,
                    0.5211,
                    0.4974,
                    0.4959,
                    0.4917,
                    0.484,
                    0.4795,
                    0.4746,
                    0.4722,
                    0.4697,
                    0.4636,
                    0.4527,
                    0.4496,
                    0.4442,
                    0.4432,
                    0.4382,
                    0.4371,
                    0.4321,
                    0.4315
                ],
                "neuron_alignment_indices": [
                    288,
                    679,
                    302
                ],
                "neuron_alignment_values": [
                    0.137,
                    0.126,
                    0.107
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    414,
                    204,
                    302
                ],
                "correlated_neurons_pearson": [
                    0.02,
                    0.019,
                    0.019
                ],
                "correlated_neurons_l1": [
                    0.018,
                    0.019,
                    0.02
                ],
                "correlated_features_indices": [
                    64715,
                    64602,
                    64657
                ],
                "correlated_features_pearson": [
                    0.001,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0.001,
                    0
                ],
                "neg_str": [
                    " Bundy",
                    " leash",
                    " spont",
                    "opter",
                    "MSN",
                    "\u00e3\u0125\u00bc\u00e3\u0125\u00b3",
                    " strang",
                    " territ",
                    " Pradesh",
                    " gratification"
                ],
                "neg_values": [
                    -0.645,
                    -0.638,
                    -0.622,
                    -0.604,
                    -0.602,
                    -0.601,
                    -0.595,
                    -0.59,
                    -0.582,
                    -0.579
                ],
                "pos_str": [
                    " emer",
                    "essors",
                    " specializing",
                    "itatively",
                    "iate",
                    "essor",
                    " professor",
                    " PhD",
                    " doctoral",
                    "hips"
                ],
                "pos_values": [
                    1.309,
                    1.131,
                    1.058,
                    0.999,
                    0.955,
                    0.953,
                    0.923,
                    0.882,
                    0.869,
                    0.867
                ],
                "frac_nonzero": 0.00012,
                "freq_hist_data_bar_heights": [
                    46,
                    39,
                    29,
                    15,
                    9,
                    11,
                    10,
                    7,
                    10,
                    12,
                    2,
                    7,
                    6,
                    8,
                    7,
                    8,
                    1,
                    4,
                    8,
                    4,
                    5,
                    6,
                    3,
                    3,
                    2,
                    7,
                    3,
                    4,
                    3,
                    3,
                    4,
                    5,
                    4,
                    1,
                    3,
                    2,
                    6,
                    7,
                    1,
                    2,
                    2,
                    3,
                    8,
                    9,
                    12,
                    10,
                    9,
                    7,
                    4,
                    6
                ],
                "freq_hist_data_bar_values": [
                    0.582,
                    1.707,
                    2.832,
                    3.956,
                    5.081,
                    6.206,
                    7.33,
                    8.455,
                    9.58,
                    10.704,
                    11.829,
                    12.954,
                    14.078,
                    15.203,
                    16.328,
                    17.452,
                    18.577,
                    19.702,
                    20.826,
                    21.951,
                    23.076,
                    24.2,
                    25.325,
                    26.45,
                    27.574,
                    28.699,
                    29.824,
                    30.948,
                    32.073,
                    33.198,
                    34.322,
                    35.447,
                    36.572,
                    37.696,
                    38.821,
                    39.946,
                    41.07,
                    42.195,
                    43.32,
                    44.444,
                    45.569,
                    46.694,
                    47.818,
                    48.943,
                    50.068,
                    51.192,
                    52.317,
                    53.442,
                    54.566,
                    55.691
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    13,
                    18,
                    51,
                    98,
                    190,
                    365,
                    606,
                    891,
                    1409,
                    1983,
                    2599,
                    3130,
                    3805,
                    4271,
                    4493,
                    4398,
                    4114,
                    3780,
                    3333,
                    2672,
                    2125,
                    1616,
                    1235,
                    913,
                    660,
                    472,
                    325,
                    239,
                    143,
                    125,
                    76,
                    34,
                    16,
                    15,
                    11,
                    9,
                    8,
                    5,
                    1,
                    3,
                    0,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.625,
                    -0.586,
                    -0.547,
                    -0.508,
                    -0.469,
                    -0.43,
                    -0.391,
                    -0.352,
                    -0.313,
                    -0.274,
                    -0.234,
                    -0.195,
                    -0.156,
                    -0.117,
                    -0.078,
                    -0.039,
                    0,
                    0.039,
                    0.078,
                    0.117,
                    0.156,
                    0.195,
                    0.235,
                    0.274,
                    0.313,
                    0.352,
                    0.391,
                    0.43,
                    0.469,
                    0.508,
                    0.547,
                    0.586,
                    0.625,
                    0.664,
                    0.703,
                    0.743,
                    0.782,
                    0.821,
                    0.86,
                    0.899,
                    0.938,
                    0.977,
                    1.016,
                    1.055,
                    1.094,
                    1.133,
                    1.172,
                    1.212,
                    1.251,
                    1.29
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clzdj4zfj34thv3wqx25vheyz",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "64654",
                        "description": "references to academic positions, particularly the term \"professor\"",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T02:43:53.312Z",
                        "updatedAt": "2024-08-03T02:43:53.312Z"
                    },
                    {
                        "id": "clzea5syo415av3wqpaov5o0k",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "64654",
                        "description": "references to individuals holding academic titles or positions, particularly professors",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T15:20:21.216Z",
                        "updatedAt": "2024-08-03T15:20:21.216Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghwnihoc4c10ex5ossyetk",
                        "tokens": [
                            " because",
                            " the",
                            " plan",
                            " will",
                            " generate",
                            " enough",
                            " economic",
                            " growth",
                            " to",
                            " essentially",
                            " pay",
                            " for",
                            " itself",
                            ".",
                            " The",
                            " most",
                            " optimistic",
                            " projections",
                            " of",
                            " the",
                            " likely",
                            " economic",
                            " benefits",
                            " of",
                            " the",
                            " tax",
                            " cuts",
                            " are",
                            " driven",
                            " by",
                            " increased",
                            " trade",
                            " deficits",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "I",
                            " do",
                            " expect",
                            " a",
                            " major",
                            " trade",
                            " deficit",
                            ",",
                            " absolutely",
                            ",",
                            " as",
                            " part",
                            " of",
                            " this",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Laure",
                            "nce",
                            " J",
                            ".",
                            " Kot",
                            "lik",
                            "off",
                            ",",
                            " a",
                            " professor",
                            " of",
                            " economics",
                            " at",
                            " Boston",
                            " University",
                            " who",
                            " supports",
                            " the",
                            " proposed",
                            " tax",
                            " cuts",
                            " and",
                            " whose",
                            " analysis",
                            " of",
                            " the",
                            " economic",
                            " benefits",
                            " has",
                            " been",
                            " cited",
                            " by",
                            " the",
                            " White",
                            " House",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "If",
                            " this",
                            " tax",
                            " plan",
                            " works",
                            ",",
                            " it",
                            " works",
                            " because",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " becomes",
                            " more",
                            " open",
                            " to",
                            " trade",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "K",
                            "ot",
                            "lik",
                            "off",
                            " also",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "this",
                            " is"
                        ],
                        "dataIndex": null,
                        "index": "64654",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.254,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            56.254,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:53:01.142Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 56.253,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghwniioc4d10exz1bucadx",
                        "tokens": [
                            " Public",
                            " Safety",
                            " in",
                            " the",
                            " Interior",
                            " of",
                            " the",
                            " United",
                            " States",
                            ",",
                            " which",
                            " instructed",
                            " the",
                            " ICE",
                            " Director",
                            " to",
                            " make",
                            " this",
                            " report",
                            " public",
                            ".",
                            "\n",
                            "\n",
                            "L",
                            "ilia",
                            " Vel",
                            "\u00c3\u00a1s",
                            "quez",
                            ",",
                            " an",
                            " associate",
                            " professor",
                            " of",
                            " law",
                            " at",
                            " the",
                            " University",
                            " of",
                            " California",
                            " at",
                            " San",
                            " Diego",
                            ",",
                            " told",
                            " Univ",
                            "ision",
                            " that",
                            " the",
                            " federal",
                            " government",
                            " is",
                            " not",
                            " breaking",
                            " any",
                            " law",
                            " by",
                            " publishing",
                            " the",
                            " list",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "It",
                            " has",
                            " the",
                            " right",
                            " to",
                            " do",
                            " so",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " says",
                            " the",
                            " lawyer",
                            ",",
                            " who",
                            " has",
                            " worked",
                            " in",
                            " immigration",
                            " law",
                            " for",
                            " more",
                            " than",
                            " 25",
                            " years",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Looking",
                            " for",
                            " them",
                            " is",
                            " a",
                            " priority",
                            " especially",
                            " if",
                            " they",
                            " are",
                            " people",
                            " who",
                            " pose",
                            " a",
                            " threat",
                            " to",
                            " public",
                            " and",
                            " national",
                            " security",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " risks",
                            ",",
                            " she",
                            " adds",
                            ",",
                            " are",
                            " when",
                            " people",
                            " are",
                            " detained"
                        ],
                        "dataIndex": null,
                        "index": "64654",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.216,
                        "maxValueTokenIndex": 31,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            56.216,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:53:01.142Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 56.253,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghwniioc4e10exfrdu5a4m",
                        "tokens": [
                            " Medicine",
                            ".",
                            "\n",
                            "\n",
                            "Of",
                            " initial",
                            " hospital",
                            " admissions",
                            " for",
                            " firearms",
                            " injuries",
                            ",",
                            " 43",
                            " percent",
                            " were",
                            " in",
                            " the",
                            " South",
                            ".",
                            " The",
                            " West",
                            " and",
                            " Midwest",
                            " each",
                            " had",
                            " 20",
                            " percent",
                            " of",
                            " hospital",
                            "izations",
                            ",",
                            " while",
                            " the",
                            " Northeast",
                            " claimed",
                            " 16",
                            " percent",
                            ".",
                            " More",
                            " than",
                            " a",
                            " third",
                            " of",
                            " patients",
                            " treated",
                            " in",
                            " the",
                            " South",
                            " were",
                            " uninsured",
                            ".",
                            "\n",
                            "\n",
                            "Dr",
                            ".",
                            " Thomas",
                            " We",
                            "iser",
                            ",",
                            " an",
                            " associate",
                            " professor",
                            " of",
                            " surgery",
                            ",",
                            " and",
                            " Sar",
                            "abeth",
                            " Sp",
                            "itzer",
                            ",",
                            " a",
                            " medical",
                            " student",
                            ",",
                            " analyzed",
                            " in",
                            "patient",
                            " hospital",
                            " records",
                            " to",
                            " conclude",
                            " that",
                            " the",
                            " initial",
                            " hospital",
                            "ization",
                            " of",
                            " patients",
                            " wounded",
                            " by",
                            " guns",
                            " over",
                            " the",
                            " eight",
                            "-",
                            "year",
                            " period",
                            " cost",
                            " Americans",
                            " more",
                            " than",
                            " $",
                            "6",
                            ".",
                            "6",
                            " billion",
                            ".",
                            " The",
                            " researchers",
                            " used",
                            " a",
                            " sample",
                            " of",
                            " more",
                            " than",
                            " 250",
                            ",",
                            "000",
                            " patients",
                            " admitted",
                            " to",
                            " American",
                            " hospitals",
                            " with",
                            " gunshot",
                            " injuries"
                        ],
                        "dataIndex": null,
                        "index": "64654",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 55.598,
                        "maxValueTokenIndex": 61,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.443,
                            55.598,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:53:01.142Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 56.253,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "64654",
            "description": "references to individuals holding academic titles or positions, particularly professors",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 56.254,
            "frac_nonzero": 0.00012,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "64654",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:52:58.223Z",
                "maxActApprox": 56.254,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    64654,
                    46751,
                    97409,
                    93548,
                    35435,
                    42428,
                    64882,
                    74864,
                    17380,
                    43982,
                    25167,
                    53510,
                    38575,
                    29411,
                    7003,
                    86615,
                    3486,
                    27016,
                    44,
                    48115,
                    9418,
                    84880,
                    78206,
                    9804,
                    15503
                ],
                "topkCosSimValues": [
                    1,
                    0.7346,
                    0.7089,
                    0.5919,
                    0.5586,
                    0.544,
                    0.5384,
                    0.5211,
                    0.4974,
                    0.4959,
                    0.4917,
                    0.484,
                    0.4795,
                    0.4746,
                    0.4722,
                    0.4697,
                    0.4636,
                    0.4527,
                    0.4496,
                    0.4442,
                    0.4432,
                    0.4382,
                    0.4371,
                    0.4321,
                    0.4315
                ],
                "neuron_alignment_indices": [
                    288,
                    679,
                    302
                ],
                "neuron_alignment_values": [
                    0.137,
                    0.126,
                    0.107
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    414,
                    204,
                    302
                ],
                "correlated_neurons_pearson": [
                    0.02,
                    0.019,
                    0.019
                ],
                "correlated_neurons_l1": [
                    0.018,
                    0.019,
                    0.02
                ],
                "correlated_features_indices": [
                    64715,
                    64602,
                    64657
                ],
                "correlated_features_pearson": [
                    0.001,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0.001,
                    0
                ],
                "neg_str": [
                    " Bundy",
                    " leash",
                    " spont",
                    "opter",
                    "MSN",
                    "\u00e3\u0125\u00bc\u00e3\u0125\u00b3",
                    " strang",
                    " territ",
                    " Pradesh",
                    " gratification"
                ],
                "neg_values": [
                    -0.645,
                    -0.638,
                    -0.622,
                    -0.604,
                    -0.602,
                    -0.601,
                    -0.595,
                    -0.59,
                    -0.582,
                    -0.579
                ],
                "pos_str": [
                    " emer",
                    "essors",
                    " specializing",
                    "itatively",
                    "iate",
                    "essor",
                    " professor",
                    " PhD",
                    " doctoral",
                    "hips"
                ],
                "pos_values": [
                    1.309,
                    1.131,
                    1.058,
                    0.999,
                    0.955,
                    0.953,
                    0.923,
                    0.882,
                    0.869,
                    0.867
                ],
                "frac_nonzero": 0.00012,
                "freq_hist_data_bar_heights": [
                    46,
                    39,
                    29,
                    15,
                    9,
                    11,
                    10,
                    7,
                    10,
                    12,
                    2,
                    7,
                    6,
                    8,
                    7,
                    8,
                    1,
                    4,
                    8,
                    4,
                    5,
                    6,
                    3,
                    3,
                    2,
                    7,
                    3,
                    4,
                    3,
                    3,
                    4,
                    5,
                    4,
                    1,
                    3,
                    2,
                    6,
                    7,
                    1,
                    2,
                    2,
                    3,
                    8,
                    9,
                    12,
                    10,
                    9,
                    7,
                    4,
                    6
                ],
                "freq_hist_data_bar_values": [
                    0.582,
                    1.707,
                    2.832,
                    3.956,
                    5.081,
                    6.206,
                    7.33,
                    8.455,
                    9.58,
                    10.704,
                    11.829,
                    12.954,
                    14.078,
                    15.203,
                    16.328,
                    17.452,
                    18.577,
                    19.702,
                    20.826,
                    21.951,
                    23.076,
                    24.2,
                    25.325,
                    26.45,
                    27.574,
                    28.699,
                    29.824,
                    30.948,
                    32.073,
                    33.198,
                    34.322,
                    35.447,
                    36.572,
                    37.696,
                    38.821,
                    39.946,
                    41.07,
                    42.195,
                    43.32,
                    44.444,
                    45.569,
                    46.694,
                    47.818,
                    48.943,
                    50.068,
                    51.192,
                    52.317,
                    53.442,
                    54.566,
                    55.691
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    13,
                    18,
                    51,
                    98,
                    190,
                    365,
                    606,
                    891,
                    1409,
                    1983,
                    2599,
                    3130,
                    3805,
                    4271,
                    4493,
                    4398,
                    4114,
                    3780,
                    3333,
                    2672,
                    2125,
                    1616,
                    1235,
                    913,
                    660,
                    472,
                    325,
                    239,
                    143,
                    125,
                    76,
                    34,
                    16,
                    15,
                    11,
                    9,
                    8,
                    5,
                    1,
                    3,
                    0,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.625,
                    -0.586,
                    -0.547,
                    -0.508,
                    -0.469,
                    -0.43,
                    -0.391,
                    -0.352,
                    -0.313,
                    -0.274,
                    -0.234,
                    -0.195,
                    -0.156,
                    -0.117,
                    -0.078,
                    -0.039,
                    0,
                    0.039,
                    0.078,
                    0.117,
                    0.156,
                    0.195,
                    0.235,
                    0.274,
                    0.313,
                    0.352,
                    0.391,
                    0.43,
                    0.469,
                    0.508,
                    0.547,
                    0.586,
                    0.625,
                    0.664,
                    0.703,
                    0.743,
                    0.782,
                    0.821,
                    0.86,
                    0.899,
                    0.938,
                    0.977,
                    1.016,
                    1.055,
                    1.094,
                    1.133,
                    1.172,
                    1.212,
                    1.251,
                    1.29
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clzdj4zfj34thv3wqx25vheyz",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "64654",
                        "description": "references to academic positions, particularly the term \"professor\"",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T02:43:53.312Z",
                        "updatedAt": "2024-08-03T02:43:53.312Z"
                    },
                    {
                        "id": "clzea5syo415av3wqpaov5o0k",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "64654",
                        "description": "references to individuals holding academic titles or positions, particularly professors",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T15:20:21.216Z",
                        "updatedAt": "2024-08-03T15:20:21.216Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghwnihoc4c10ex5ossyetk",
                        "tokens": [
                            " because",
                            " the",
                            " plan",
                            " will",
                            " generate",
                            " enough",
                            " economic",
                            " growth",
                            " to",
                            " essentially",
                            " pay",
                            " for",
                            " itself",
                            ".",
                            " The",
                            " most",
                            " optimistic",
                            " projections",
                            " of",
                            " the",
                            " likely",
                            " economic",
                            " benefits",
                            " of",
                            " the",
                            " tax",
                            " cuts",
                            " are",
                            " driven",
                            " by",
                            " increased",
                            " trade",
                            " deficits",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "I",
                            " do",
                            " expect",
                            " a",
                            " major",
                            " trade",
                            " deficit",
                            ",",
                            " absolutely",
                            ",",
                            " as",
                            " part",
                            " of",
                            " this",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Laure",
                            "nce",
                            " J",
                            ".",
                            " Kot",
                            "lik",
                            "off",
                            ",",
                            " a",
                            " professor",
                            " of",
                            " economics",
                            " at",
                            " Boston",
                            " University",
                            " who",
                            " supports",
                            " the",
                            " proposed",
                            " tax",
                            " cuts",
                            " and",
                            " whose",
                            " analysis",
                            " of",
                            " the",
                            " economic",
                            " benefits",
                            " has",
                            " been",
                            " cited",
                            " by",
                            " the",
                            " White",
                            " House",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "If",
                            " this",
                            " tax",
                            " plan",
                            " works",
                            ",",
                            " it",
                            " works",
                            " because",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " becomes",
                            " more",
                            " open",
                            " to",
                            " trade",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "K",
                            "ot",
                            "lik",
                            "off",
                            " also",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "this",
                            " is"
                        ],
                        "dataIndex": null,
                        "index": "64654",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.254,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            56.254,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:53:01.142Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 56.253,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghwniioc4d10exz1bucadx",
                        "tokens": [
                            " Public",
                            " Safety",
                            " in",
                            " the",
                            " Interior",
                            " of",
                            " the",
                            " United",
                            " States",
                            ",",
                            " which",
                            " instructed",
                            " the",
                            " ICE",
                            " Director",
                            " to",
                            " make",
                            " this",
                            " report",
                            " public",
                            ".",
                            "\n",
                            "\n",
                            "L",
                            "ilia",
                            " Vel",
                            "\u00c3\u00a1s",
                            "quez",
                            ",",
                            " an",
                            " associate",
                            " professor",
                            " of",
                            " law",
                            " at",
                            " the",
                            " University",
                            " of",
                            " California",
                            " at",
                            " San",
                            " Diego",
                            ",",
                            " told",
                            " Univ",
                            "ision",
                            " that",
                            " the",
                            " federal",
                            " government",
                            " is",
                            " not",
                            " breaking",
                            " any",
                            " law",
                            " by",
                            " publishing",
                            " the",
                            " list",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "It",
                            " has",
                            " the",
                            " right",
                            " to",
                            " do",
                            " so",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " says",
                            " the",
                            " lawyer",
                            ",",
                            " who",
                            " has",
                            " worked",
                            " in",
                            " immigration",
                            " law",
                            " for",
                            " more",
                            " than",
                            " 25",
                            " years",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Looking",
                            " for",
                            " them",
                            " is",
                            " a",
                            " priority",
                            " especially",
                            " if",
                            " they",
                            " are",
                            " people",
                            " who",
                            " pose",
                            " a",
                            " threat",
                            " to",
                            " public",
                            " and",
                            " national",
                            " security",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " risks",
                            ",",
                            " she",
                            " adds",
                            ",",
                            " are",
                            " when",
                            " people",
                            " are",
                            " detained"
                        ],
                        "dataIndex": null,
                        "index": "64654",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.216,
                        "maxValueTokenIndex": 31,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            56.216,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:53:01.142Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 56.253,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghwniioc4e10exfrdu5a4m",
                        "tokens": [
                            " Medicine",
                            ".",
                            "\n",
                            "\n",
                            "Of",
                            " initial",
                            " hospital",
                            " admissions",
                            " for",
                            " firearms",
                            " injuries",
                            ",",
                            " 43",
                            " percent",
                            " were",
                            " in",
                            " the",
                            " South",
                            ".",
                            " The",
                            " West",
                            " and",
                            " Midwest",
                            " each",
                            " had",
                            " 20",
                            " percent",
                            " of",
                            " hospital",
                            "izations",
                            ",",
                            " while",
                            " the",
                            " Northeast",
                            " claimed",
                            " 16",
                            " percent",
                            ".",
                            " More",
                            " than",
                            " a",
                            " third",
                            " of",
                            " patients",
                            " treated",
                            " in",
                            " the",
                            " South",
                            " were",
                            " uninsured",
                            ".",
                            "\n",
                            "\n",
                            "Dr",
                            ".",
                            " Thomas",
                            " We",
                            "iser",
                            ",",
                            " an",
                            " associate",
                            " professor",
                            " of",
                            " surgery",
                            ",",
                            " and",
                            " Sar",
                            "abeth",
                            " Sp",
                            "itzer",
                            ",",
                            " a",
                            " medical",
                            " student",
                            ",",
                            " analyzed",
                            " in",
                            "patient",
                            " hospital",
                            " records",
                            " to",
                            " conclude",
                            " that",
                            " the",
                            " initial",
                            " hospital",
                            "ization",
                            " of",
                            " patients",
                            " wounded",
                            " by",
                            " guns",
                            " over",
                            " the",
                            " eight",
                            "-",
                            "year",
                            " period",
                            " cost",
                            " Americans",
                            " more",
                            " than",
                            " $",
                            "6",
                            ".",
                            "6",
                            " billion",
                            ".",
                            " The",
                            " researchers",
                            " used",
                            " a",
                            " sample",
                            " of",
                            " more",
                            " than",
                            " 250",
                            ",",
                            "000",
                            " patients",
                            " admitted",
                            " to",
                            " American",
                            " hospitals",
                            " with",
                            " gunshot",
                            " injuries"
                        ],
                        "dataIndex": null,
                        "index": "64654",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 55.598,
                        "maxValueTokenIndex": 61,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.443,
                            55.598,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:53:01.142Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 56.253,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "13453",
            "description": "terms related to individuals who hold academic or esteemed titles, especially in the context of emeritus professors",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 54.545,
            "frac_nonzero": 2e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "13453",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:44:53.207Z",
                "maxActApprox": 54.545,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    13453,
                    15529,
                    92810,
                    45460,
                    39299,
                    32597,
                    42708,
                    51269,
                    30223,
                    26645,
                    53212,
                    54624,
                    88231,
                    55246,
                    23783,
                    71249,
                    14199,
                    55835,
                    43345,
                    23724,
                    17556,
                    18463,
                    57060,
                    29590,
                    88297
                ],
                "topkCosSimValues": [
                    1,
                    0.5694,
                    0.5437,
                    0.4536,
                    0.3869,
                    0.3838,
                    0.3658,
                    0.3596,
                    0.3559,
                    0.3544,
                    0.3536,
                    0.3428,
                    0.3409,
                    0.3381,
                    0.33,
                    0.3296,
                    0.3237,
                    0.3212,
                    0.3175,
                    0.3154,
                    0.3147,
                    0.3145,
                    0.3106,
                    0.3103,
                    0.3098
                ],
                "neuron_alignment_indices": [
                    642,
                    288,
                    749
                ],
                "neuron_alignment_values": [
                    0.133,
                    0.116,
                    0.11
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    555,
                    746,
                    749
                ],
                "correlated_neurons_pearson": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_l1": [
                    0.005,
                    0.004,
                    0.005
                ],
                "correlated_features_indices": [
                    13558,
                    13559,
                    13453
                ],
                "correlated_features_pearson": [
                    0.001,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0,
                    0
                ],
                "neg_str": [
                    "\u00e8\u00a6\u013c\u00e9\u0128\u0134",
                    "avorite",
                    "76561",
                    " shack",
                    " mileage",
                    "isSpecialOrderable",
                    " absorb",
                    " captcha",
                    "20439",
                    " bip"
                ],
                "neg_values": [
                    -0.803,
                    -0.788,
                    -0.769,
                    -0.698,
                    -0.697,
                    -0.687,
                    -0.671,
                    -0.642,
                    -0.634,
                    -0.631
                ],
                "pos_str": [
                    "gencies",
                    "gent",
                    "gence",
                    "itus",
                    "gency",
                    "mberg",
                    "usalem",
                    "ging",
                    "iat",
                    "inary"
                ],
                "pos_values": [
                    1.236,
                    1.235,
                    1.226,
                    1.126,
                    1.05,
                    0.957,
                    0.92,
                    0.914,
                    0.895,
                    0.89
                ],
                "frac_nonzero": 2e-05,
                "freq_hist_data_bar_heights": [
                    16,
                    10,
                    7,
                    5,
                    1,
                    0,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.606,
                    1.696,
                    2.786,
                    3.875,
                    4.965,
                    6.055,
                    7.144,
                    8.234,
                    9.324,
                    10.413,
                    11.503,
                    12.593,
                    13.682,
                    14.772,
                    15.862,
                    16.951,
                    18.041,
                    19.131,
                    20.22,
                    21.31,
                    22.4,
                    23.489,
                    24.579,
                    25.669,
                    26.758,
                    27.848,
                    28.938,
                    30.027,
                    31.117,
                    32.207,
                    33.296,
                    34.386,
                    35.476,
                    36.565,
                    37.655,
                    38.745,
                    39.834,
                    40.924,
                    42.014,
                    43.103,
                    44.193,
                    45.283,
                    46.372,
                    47.462,
                    48.552,
                    49.641,
                    50.731,
                    51.821,
                    52.91,
                    54
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    0,
                    3,
                    2,
                    8,
                    17,
                    38,
                    74,
                    129,
                    291,
                    443,
                    795,
                    1247,
                    1757,
                    2445,
                    3079,
                    3825,
                    4187,
                    4416,
                    4660,
                    4427,
                    3935,
                    3552,
                    2776,
                    2213,
                    1677,
                    1294,
                    877,
                    613,
                    443,
                    337,
                    210,
                    182,
                    100,
                    80,
                    40,
                    35,
                    15,
                    7,
                    4,
                    8,
                    5,
                    2,
                    1,
                    0,
                    1,
                    0,
                    1,
                    0,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.783,
                    -0.742,
                    -0.701,
                    -0.661,
                    -0.62,
                    -0.579,
                    -0.538,
                    -0.497,
                    -0.457,
                    -0.416,
                    -0.375,
                    -0.334,
                    -0.294,
                    -0.253,
                    -0.212,
                    -0.171,
                    -0.13,
                    -0.09,
                    -0.049,
                    -0.008,
                    0.033,
                    0.073,
                    0.114,
                    0.155,
                    0.196,
                    0.237,
                    0.277,
                    0.318,
                    0.359,
                    0.4,
                    0.441,
                    0.481,
                    0.522,
                    0.563,
                    0.604,
                    0.644,
                    0.685,
                    0.726,
                    0.767,
                    0.808,
                    0.848,
                    0.889,
                    0.93,
                    0.971,
                    1.011,
                    1.052,
                    1.093,
                    1.134,
                    1.175,
                    1.215
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyzvu3np21e35q0zmqblwge4",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "13453",
                        "description": "terms related to individuals who hold academic or esteemed titles, especially in the context of emeritus professors",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-24T13:30:34.039Z",
                        "updatedAt": "2024-07-24T13:30:34.039Z"
                    },
                    {
                        "id": "clze8dxnf3tw0v3wqt69ze57f",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "13453",
                        "description": "references to emergent figures in various contexts",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T14:30:41.307Z",
                        "updatedAt": "2024-08-03T14:30:41.307Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfh2y8lhv510exgvixah8g",
                        "tokens": [
                            " institute",
                            " itself",
                            ",",
                            " where",
                            " I",
                            " once",
                            " worked",
                            " as",
                            " director",
                            " of",
                            " education",
                            ",",
                            " was",
                            " founded",
                            " to",
                            " advocate",
                            " for",
                            " these",
                            " youth",
                            " in",
                            " 1979",
                            " by",
                            " the",
                            " late",
                            " Damien",
                            " Martin",
                            " and",
                            " Emer",
                            "y",
                            " H",
                            "et",
                            "rick",
                            ".",
                            "\n",
                            "\n",
                            "New",
                            " York",
                            "'s",
                            " S",
                            "AGE",
                            " --",
                            " for",
                            " Services",
                            " and",
                            " Advoc",
                            "acy",
                            " for",
                            " GL",
                            "BT",
                            " Eld",
                            "ers",
                            " --",
                            " was",
                            " the",
                            " first",
                            " U",
                            ".",
                            "S",
                            ".",
                            " group",
                            " for",
                            " older",
                            " gays",
                            " and",
                            " lesbians",
                            " in",
                            " 1978",
                            ".",
                            "\n",
                            "\n",
                            "Gay",
                            " journalists",
                            " founded",
                            " the",
                            " Gay",
                            " and",
                            " Lesbian",
                            " Alliance",
                            " Against",
                            " Def",
                            "amation",
                            " in",
                            " 1985",
                            " to",
                            " fight",
                            " anti",
                            "-",
                            "gay",
                            " defamation",
                            " in",
                            " the",
                            " media",
                            ",",
                            " especially",
                            " at",
                            " the",
                            " New",
                            " York",
                            " Post",
                            ".",
                            " Originally",
                            " a",
                            " fierce",
                            " watchdog",
                            ",",
                            " it",
                            " has",
                            " gone",
                            " on",
                            " to",
                            " become",
                            " a",
                            " largely",
                            " West",
                            " Coast",
                            " operation",
                            " famous",
                            " for",
                            " big",
                            " annual",
                            " dinners",
                            " honoring",
                            " positive",
                            " LGBT",
                            " portray",
                            "als",
                            " in"
                        ],
                        "dataIndex": null,
                        "index": "13453",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 54.545,
                        "maxValueTokenIndex": 27,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            54.545,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:55.449Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 43.636,
                        "binMax": 54.545,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfh2y6lhuk10ex2jp1h1z5",
                        "tokens": [
                            " institute",
                            " itself",
                            ",",
                            " where",
                            " I",
                            " once",
                            " worked",
                            " as",
                            " director",
                            " of",
                            " education",
                            ",",
                            " was",
                            " founded",
                            " to",
                            " advocate",
                            " for",
                            " these",
                            " youth",
                            " in",
                            " 1979",
                            " by",
                            " the",
                            " late",
                            " Damien",
                            " Martin",
                            " and",
                            " Emer",
                            "y",
                            " H",
                            "et",
                            "rick",
                            ".",
                            "\n",
                            "\n",
                            "New",
                            " York",
                            "'s",
                            " S",
                            "AGE",
                            " --",
                            " for",
                            " Services",
                            " and",
                            " Advoc",
                            "acy",
                            " for",
                            " GL",
                            "BT",
                            " Eld",
                            "ers",
                            " --",
                            " was",
                            " the",
                            " first",
                            " U",
                            ".",
                            "S",
                            ".",
                            " group",
                            " for",
                            " older",
                            " gays",
                            " and",
                            " lesbians",
                            " in",
                            " 1978",
                            ".",
                            "\n",
                            "\n",
                            "Gay",
                            " journalists",
                            " founded",
                            " the",
                            " Gay",
                            " and",
                            " Lesbian",
                            " Alliance",
                            " Against",
                            " Def",
                            "amation",
                            " in",
                            " 1985",
                            " to",
                            " fight",
                            " anti",
                            "-",
                            "gay",
                            " defamation",
                            " in",
                            " the",
                            " media",
                            ",",
                            " especially",
                            " at",
                            " the",
                            " New",
                            " York",
                            " Post",
                            ".",
                            " Originally",
                            " a",
                            " fierce",
                            " watchdog",
                            ",",
                            " it",
                            " has",
                            " gone",
                            " on",
                            " to",
                            " become",
                            " a",
                            " largely",
                            " West",
                            " Coast",
                            " operation",
                            " famous",
                            " for",
                            " big",
                            " annual",
                            " dinners",
                            " honoring",
                            " positive",
                            " LGBT",
                            " portray",
                            "als",
                            " in"
                        ],
                        "dataIndex": null,
                        "index": "13453",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 54.545,
                        "maxValueTokenIndex": 27,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            54.545,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:55.449Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 54.545,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfh2y6lhul10exlgg1xljb",
                        "tokens": [
                            " album",
                            " Let",
                            " It",
                            " Be",
                            " in",
                            " the",
                            " Apple",
                            " Studio",
                            ",",
                            " with",
                            " equipment",
                            " borrowed",
                            " from",
                            " E",
                            "MI",
                            ";",
                            " during",
                            " takes",
                            " they",
                            " had",
                            " to",
                            " shut",
                            " down",
                            " the",
                            " building",
                            "'s",
                            " central",
                            " heating",
                            ",",
                            " also",
                            " located",
                            " in",
                            " the",
                            " basement",
                            ",",
                            " because",
                            " the",
                            " lack",
                            " of",
                            " sound",
                            "proof",
                            "ing",
                            " allowed",
                            " the",
                            " heating",
                            " system",
                            " to",
                            " be",
                            " heard",
                            " in",
                            " the",
                            " studio",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " redesign",
                            " and",
                            " rebuilding",
                            " of",
                            " the",
                            " basement",
                            " to",
                            " accommodate",
                            " proper",
                            " recording",
                            " facilities",
                            " was",
                            " overseen",
                            " by",
                            " former",
                            " E",
                            "MI",
                            " engineer",
                            " Geoff",
                            " Emer",
                            "ick",
                            ",",
                            " and",
                            " took",
                            " eighteen",
                            " months",
                            " at",
                            " an",
                            " estimated",
                            " cost",
                            " of",
                            " $",
                            "1",
                            ".",
                            "5",
                            " million",
                            ".",
                            " Beatles",
                            "'",
                            " technical",
                            " engineer",
                            " Claude",
                            " Harper",
                            " aided",
                            " on",
                            " the",
                            " project",
                            ",",
                            " as",
                            " well",
                            ".[",
                            "51",
                            "]",
                            " The",
                            " studio",
                            " reopened",
                            " on",
                            " 30",
                            " September",
                            " 1971",
                            " and",
                            " now",
                            " included",
                            " its",
                            " own",
                            " natural",
                            " echo",
                            " chamber",
                            ",",
                            " a",
                            " wide"
                        ],
                        "dataIndex": null,
                        "index": "13453",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 47.5,
                        "maxValueTokenIndex": 75,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            47.5,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:55.449Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 54.545,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs3072-jb",
            "index": "2860",
            "description": "information related to professionals such as professors, members of committees, researchers, and advisors in various fields",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 51.534,
            "frac_nonzero": 0.00888,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs3072-jb",
                "index": "2860",
                "sourceSetName": "res_fs3072-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:43:39.416Z",
                "maxActApprox": 51.534,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    2860,
                    1436,
                    2038,
                    1642,
                    1560,
                    2846,
                    1649,
                    853,
                    458,
                    655,
                    772,
                    753,
                    401,
                    89,
                    2475,
                    692,
                    2750,
                    953,
                    1221,
                    1575,
                    2819,
                    132,
                    743,
                    880,
                    411
                ],
                "topkCosSimValues": [
                    1,
                    0.4948,
                    0.472,
                    0.3878,
                    0.3682,
                    0.3428,
                    0.3107,
                    0.3103,
                    0.3038,
                    0.298,
                    0.2907,
                    0.2892,
                    0.2884,
                    0.2534,
                    0.2532,
                    0.2498,
                    0.24,
                    0.2325,
                    0.2258,
                    0.2255,
                    0.2249,
                    0.2223,
                    0.2105,
                    0.2104,
                    0.21
                ],
                "neuron_alignment_indices": [
                    373,
                    378,
                    393
                ],
                "neuron_alignment_values": [
                    0.129,
                    0.101,
                    0.094
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    164,
                    69,
                    233
                ],
                "correlated_neurons_pearson": [
                    0.083,
                    0.082,
                    0.08
                ],
                "correlated_neurons_l1": [
                    0.088,
                    0.079,
                    0.074
                ],
                "correlated_features_indices": [
                    2846,
                    2819,
                    2871
                ],
                "correlated_features_pearson": [
                    0.052,
                    0.033,
                    0.01
                ],
                "correlated_features_l1": [
                    0.056,
                    0.037,
                    0.013
                ],
                "neg_str": [
                    " \\'",
                    "Results",
                    " trunc",
                    " ponies",
                    "Decre",
                    "urally",
                    " idiots",
                    "rats",
                    "planes",
                    "RGB"
                ],
                "neg_values": [
                    -0.697,
                    -0.63,
                    -0.627,
                    -0.619,
                    -0.613,
                    -0.61,
                    -0.608,
                    -0.59,
                    -0.582,
                    -0.582
                ],
                "pos_str": [
                    " dean",
                    " director",
                    " Managing",
                    " lecturer",
                    " professor",
                    "director",
                    " spokesman",
                    " associate",
                    " vice",
                    " managing"
                ],
                "pos_values": [
                    0.976,
                    0.976,
                    0.956,
                    0.955,
                    0.925,
                    0.925,
                    0.911,
                    0.908,
                    0.881,
                    0.867
                ],
                "frac_nonzero": 0.00888,
                "freq_hist_data_bar_heights": [
                    7414,
                    4659,
                    3060,
                    2285,
                    1733,
                    1264,
                    1039,
                    839,
                    704,
                    594,
                    480,
                    413,
                    340,
                    256,
                    230,
                    227,
                    179,
                    144,
                    131,
                    123,
                    102,
                    117,
                    103,
                    86,
                    85,
                    86,
                    72,
                    82,
                    85,
                    100,
                    66,
                    57,
                    46,
                    44,
                    39,
                    43,
                    48,
                    51,
                    52,
                    62,
                    41,
                    51,
                    67,
                    62,
                    57,
                    39,
                    36,
                    28,
                    12,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.515,
                    1.546,
                    2.577,
                    3.607,
                    4.638,
                    5.669,
                    6.7,
                    7.73,
                    8.761,
                    9.792,
                    10.822,
                    11.853,
                    12.884,
                    13.914,
                    14.945,
                    15.976,
                    17.006,
                    18.037,
                    19.068,
                    20.098,
                    21.129,
                    22.16,
                    23.19,
                    24.221,
                    25.252,
                    26.282,
                    27.313,
                    28.344,
                    29.374,
                    30.405,
                    31.436,
                    32.466,
                    33.497,
                    34.528,
                    35.558,
                    36.589,
                    37.62,
                    38.65,
                    39.681,
                    40.712,
                    41.742,
                    42.773,
                    43.804,
                    44.834,
                    45.865,
                    46.896,
                    47.926,
                    48.957,
                    49.988,
                    51.018
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    6,
                    12,
                    26,
                    40,
                    81,
                    113,
                    248,
                    359,
                    554,
                    887,
                    1242,
                    1696,
                    2099,
                    2561,
                    3068,
                    3299,
                    3479,
                    3492,
                    3509,
                    3413,
                    3112,
                    2940,
                    2594,
                    2394,
                    2145,
                    1646,
                    1399,
                    1136,
                    769,
                    571,
                    424,
                    277,
                    195,
                    131,
                    101,
                    58,
                    49,
                    31,
                    23,
                    16,
                    17,
                    11,
                    9,
                    8,
                    7,
                    2,
                    3,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.68,
                    -0.646,
                    -0.613,
                    -0.58,
                    -0.546,
                    -0.513,
                    -0.479,
                    -0.446,
                    -0.412,
                    -0.379,
                    -0.345,
                    -0.312,
                    -0.278,
                    -0.245,
                    -0.212,
                    -0.178,
                    -0.145,
                    -0.111,
                    -0.078,
                    -0.044,
                    -0.011,
                    0.023,
                    0.056,
                    0.09,
                    0.123,
                    0.157,
                    0.19,
                    0.223,
                    0.257,
                    0.29,
                    0.324,
                    0.357,
                    0.391,
                    0.424,
                    0.458,
                    0.491,
                    0.525,
                    0.558,
                    0.591,
                    0.625,
                    0.658,
                    0.692,
                    0.725,
                    0.759,
                    0.792,
                    0.826,
                    0.859,
                    0.893,
                    0.926,
                    0.96
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clym7au8m07ypj7a1erv6nxwj",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs3072-jb",
                        "index": "2860",
                        "description": "information related to professionals such as professors, members of committees, researchers, and advisors in various fields",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-07-14T23:42:44.374Z",
                        "updatedAt": "2024-07-14T23:42:44.374Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdo41blsc36i666raugya5x",
                        "tokens": [
                            " \u00e2\u0122",
                            "\u013e",
                            "But",
                            " this",
                            " lower",
                            " concern",
                            " level",
                            " is",
                            " based",
                            " on",
                            " relatively",
                            " little",
                            " data",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Laura",
                            " Vand",
                            "enberg",
                            ",",
                            " an",
                            " assistant",
                            " professor",
                            " of",
                            " environmental",
                            " health",
                            " at",
                            " the",
                            " University",
                            " of",
                            " Massachusetts",
                            " Am",
                            "her",
                            "st",
                            " who",
                            " studies",
                            " health",
                            " effects",
                            " of",
                            " B",
                            "PA",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "This",
                            " is",
                            " something",
                            " I",
                            " would",
                            " say",
                            " is",
                            " not",
                            " discussed",
                            " in",
                            "-",
                            "depth",
                            " on",
                            " our",
                            " field",
                            " but",
                            " it",
                            " should",
                            " be",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "There",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " a",
                            " lot",
                            " of",
                            " research",
                            " on",
                            " what",
                            " happens",
                            " to",
                            " B",
                            "PA",
                            " when",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " released",
                            " into",
                            " the",
                            " air",
                            ".",
                            " B",
                            "PA",
                            " de",
                            "grades",
                            " fairly",
                            " quickly",
                            ",",
                            " but",
                            " it",
                            " also",
                            " can",
                            " attach",
                            " to",
                            " dust",
                            " particles",
                            ",",
                            " Vand",
                            "enberg",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "Researchers",
                            " tested",
                            " for",
                            " B",
                            "PA",
                            " in",
                            " the",
                            " dust",
                            " of",
                            " homes",
                            ","
                        ],
                        "dataIndex": null,
                        "index": "2860",
                        "layer": "8-res_fs3072-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 51.534,
                        "maxValueTokenIndex": 20,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.023,
                            0,
                            3.8,
                            51.534,
                            34.552,
                            15.682,
                            6.313,
                            7.308,
                            0,
                            0,
                            3.281,
                            3.582,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.837,
                            1.3,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.291,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.413,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:43:42.457Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 51.534,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdo41blsc37i666g6riivwg",
                        "tokens": [
                            " are",
                            " 2",
                            ".",
                            "7",
                            " times",
                            " more",
                            " likely",
                            " to",
                            " live",
                            " in",
                            " their",
                            " parents",
                            "\u00e2\u0122",
                            "\u013b",
                            " home",
                            " than",
                            " people",
                            " under",
                            " 55",
                            " years",
                            " old",
                            " than",
                            " in",
                            " 1999",
                            ",",
                            " while",
                            " Generation",
                            "-",
                            "X",
                            "ers",
                            ",",
                            " who",
                            " are",
                            " now",
                            " in",
                            " their",
                            " mid",
                            "-",
                            "30",
                            "s",
                            " to",
                            " early",
                            " 50",
                            "s",
                            ",",
                            " were",
                            " 2",
                            ".",
                            "2",
                            " times",
                            " as",
                            " likely",
                            " to",
                            " live",
                            " with",
                            " their",
                            " parents",
                            ",",
                            " according",
                            " to",
                            " separate",
                            " data",
                            " released",
                            " last",
                            " week",
                            " by",
                            " real",
                            " estate",
                            " site",
                            " Tr",
                            "ulia",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "No",
                            " parent",
                            " is",
                            " going",
                            " to",
                            " want",
                            " to",
                            " say",
                            " no",
                            " to",
                            " a",
                            " child",
                            " who",
                            " needs",
                            " help",
                            ",",
                            " but",
                            " certainly",
                            " being",
                            " realistic",
                            " about",
                            " the",
                            " financial",
                            " situation",
                            " is",
                            " important",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Katie",
                            " Taylor",
                            ",",
                            " vice",
                            " president",
                            " of",
                            " thought",
                            " leadership",
                            " at",
                            " F",
                            "idelity",
                            ".",
                            "\n",
                            "\n",
                            "See",
                            ":",
                            " The",
                            " real",
                            " reason",
                            " college",
                            " grad",
                            "s",
                            " move"
                        ],
                        "dataIndex": null,
                        "index": "2860",
                        "layer": "8-res_fs3072-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 51.207,
                        "maxValueTokenIndex": 106,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.697,
                            3.55,
                            11.944,
                            51.207,
                            13.418,
                            13.689,
                            14.755,
                            0,
                            0,
                            6.706,
                            0,
                            0,
                            1.88,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:43:42.457Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 51.534,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdo41blsc38i666mvy6tyvh",
                        "tokens": [
                            " must",
                            " ensure",
                            " that",
                            " victims",
                            " of",
                            " crime",
                            " are",
                            " treated",
                            " with",
                            " dignity",
                            ",",
                            " compassion",
                            " and",
                            " respect",
                            ",\"",
                            " the",
                            " statement",
                            " said",
                            ".",
                            " \"",
                            "We",
                            " have",
                            " asked",
                            " a",
                            " special",
                            " committee",
                            " to",
                            " look",
                            " into",
                            " policies",
                            " and",
                            " procedures",
                            " around",
                            " ensuring",
                            " that",
                            " victims",
                            " are",
                            " supported",
                            " and",
                            " respected",
                            " through",
                            " the",
                            " justice",
                            " system",
                            ".",
                            " I",
                            " am",
                            " asking",
                            " that",
                            " committee",
                            " to",
                            " take",
                            " these",
                            " cases",
                            " into",
                            " consideration",
                            ".\"",
                            "\n",
                            "\n",
                            "That",
                            " special",
                            " committee",
                            " was",
                            " assigned",
                            " in",
                            " early",
                            " June",
                            " to",
                            " review",
                            " policies",
                            " and",
                            " procedures",
                            " after",
                            " CBC",
                            " News",
                            " revealed",
                            " the",
                            " court",
                            "'s",
                            " treatment",
                            " of",
                            " sex",
                            " assault",
                            " victim",
                            " Angela",
                            " Cardinal",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " three",
                            " cases",
                            " highlight",
                            " a",
                            " gap",
                            " in",
                            " the",
                            " justice",
                            " system",
                            ",",
                            " said",
                            " Deb",
                            " Tom",
                            "l",
                            "inson",
                            ",",
                            " a",
                            " member",
                            " of",
                            " the",
                            " committee",
                            " who",
                            " is",
                            " also",
                            " CEO",
                            " of",
                            " the",
                            " Association",
                            " of",
                            " Alberta",
                            " Sexual",
                            " Assault",
                            " Services",
                            ".",
                            "\n",
                            "\n",
                            "\""
                        ],
                        "dataIndex": null,
                        "index": "2860",
                        "layer": "8-res_fs3072-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.489,
                        "maxValueTokenIndex": 105,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.216,
                            0,
                            0,
                            0,
                            12.682,
                            50.489,
                            31.314,
                            12.784,
                            10.552,
                            7.048,
                            0,
                            8.774,
                            11.373,
                            10.166,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.799,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:43:42.457Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 51.534,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "17375",
            "description": "mentions of academic positions, particularly the title \"professor\"",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 50.455,
            "frac_nonzero": 0.0003500000000000001,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "17375",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:07:00.697Z",
                "maxActApprox": 50.455,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    17375,
                    23486,
                    15579,
                    19680,
                    23827,
                    23000,
                    11785,
                    9709,
                    16661,
                    7511,
                    15794,
                    8895,
                    11745,
                    2349,
                    17218,
                    19718,
                    1720,
                    8698,
                    9504,
                    18093,
                    48,
                    16447,
                    20005,
                    21154,
                    2701
                ],
                "topkCosSimValues": [
                    1,
                    0.5407,
                    0.5345,
                    0.5098,
                    0.5082,
                    0.505,
                    0.504,
                    0.4992,
                    0.4901,
                    0.4802,
                    0.4584,
                    0.4361,
                    0.4358,
                    0.4279,
                    0.4209,
                    0.4142,
                    0.4044,
                    0.4025,
                    0.4024,
                    0.3968,
                    0.3964,
                    0.3947,
                    0.3939,
                    0.3911,
                    0.3874
                ],
                "neuron_alignment_indices": [
                    679,
                    288,
                    447
                ],
                "neuron_alignment_values": [
                    0.132,
                    0.112,
                    0.112
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    235,
                    414,
                    145
                ],
                "correlated_neurons_pearson": [
                    0.024,
                    0.024,
                    0.023
                ],
                "correlated_neurons_l1": [
                    0.025,
                    0.021,
                    0.023
                ],
                "correlated_features_indices": [
                    17402,
                    17382,
                    17386
                ],
                "correlated_features_pearson": [
                    0.066,
                    0.002,
                    0.002
                ],
                "correlated_features_l1": [
                    0.066,
                    0.003,
                    0.003
                ],
                "neg_str": [
                    " Bundy",
                    " territ",
                    " Pradesh",
                    "opter",
                    " deployment",
                    " spont",
                    " leash",
                    "\u00e3\u0125\u00bc\u00e3\u0125\u00b3",
                    " launchers",
                    "tera"
                ],
                "neg_values": [
                    -0.661,
                    -0.656,
                    -0.652,
                    -0.633,
                    -0.63,
                    -0.618,
                    -0.616,
                    -0.61,
                    -0.598,
                    -0.595
                ],
                "pos_str": [
                    "essors",
                    " emer",
                    "iate",
                    "essor",
                    "itatively",
                    "ials",
                    "hips",
                    "sonian",
                    " specializing",
                    "onym"
                ],
                "pos_values": [
                    1.28,
                    1.13,
                    0.986,
                    0.973,
                    0.965,
                    0.937,
                    0.932,
                    0.856,
                    0.848,
                    0.842
                ],
                "frac_nonzero": 0.0003500000000000001,
                "freq_hist_data_bar_heights": [
                    241,
                    170,
                    107,
                    67,
                    52,
                    46,
                    36,
                    27,
                    21,
                    13,
                    9,
                    7,
                    3,
                    1,
                    3,
                    2,
                    2,
                    5,
                    2,
                    3,
                    4,
                    0,
                    3,
                    5,
                    9,
                    3,
                    6,
                    5,
                    6,
                    4,
                    10,
                    10,
                    9,
                    8,
                    12,
                    10,
                    14,
                    9,
                    17,
                    16,
                    9,
                    12,
                    5,
                    8,
                    20,
                    18,
                    17,
                    8,
                    16,
                    9
                ],
                "freq_hist_data_bar_values": [
                    0.518,
                    1.526,
                    2.535,
                    3.544,
                    4.553,
                    5.562,
                    6.571,
                    7.579,
                    8.588,
                    9.597,
                    10.606,
                    11.615,
                    12.624,
                    13.632,
                    14.641,
                    15.65,
                    16.659,
                    17.668,
                    18.677,
                    19.686,
                    20.694,
                    21.703,
                    22.712,
                    23.721,
                    24.73,
                    25.739,
                    26.747,
                    27.756,
                    28.765,
                    29.774,
                    30.783,
                    31.792,
                    32.801,
                    33.809,
                    34.818,
                    35.827,
                    36.836,
                    37.845,
                    38.854,
                    39.862,
                    40.871,
                    41.88,
                    42.889,
                    43.898,
                    44.907,
                    45.915,
                    46.924,
                    47.933,
                    48.942,
                    49.951
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    5,
                    14,
                    36,
                    67,
                    145,
                    245,
                    463,
                    637,
                    1077,
                    1631,
                    2245,
                    2891,
                    3610,
                    4050,
                    4456,
                    4550,
                    4462,
                    4035,
                    3456,
                    2911,
                    2304,
                    1826,
                    1373,
                    1105,
                    798,
                    569,
                    451,
                    265,
                    200,
                    140,
                    73,
                    75,
                    23,
                    18,
                    17,
                    5,
                    9,
                    7,
                    1,
                    0,
                    3,
                    2,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.642,
                    -0.603,
                    -0.564,
                    -0.525,
                    -0.486,
                    -0.448,
                    -0.409,
                    -0.37,
                    -0.331,
                    -0.292,
                    -0.254,
                    -0.215,
                    -0.176,
                    -0.137,
                    -0.098,
                    -0.059,
                    -0.021,
                    0.018,
                    0.057,
                    0.096,
                    0.135,
                    0.174,
                    0.212,
                    0.251,
                    0.29,
                    0.329,
                    0.368,
                    0.406,
                    0.445,
                    0.484,
                    0.523,
                    0.562,
                    0.601,
                    0.639,
                    0.678,
                    0.717,
                    0.756,
                    0.795,
                    0.834,
                    0.872,
                    0.911,
                    0.95,
                    0.989,
                    1.028,
                    1.066,
                    1.105,
                    1.144,
                    1.183,
                    1.222,
                    1.261
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyny4i3wga6vj7a1irmbx3xo",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs24576-jb",
                        "index": "17375",
                        "description": "mentions of academic positions, particularly the title \"professor\"",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-07-16T05:01:24.524Z",
                        "updatedAt": "2024-07-16T05:01:24.524Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmszkogijui666oyvsthuo",
                        "tokens": [
                            "idget",
                            " Fre",
                            "ist",
                            "hler",
                            ",",
                            " an",
                            " associate",
                            " professor",
                            " at",
                            " UCLA",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " L",
                            "us",
                            "kin",
                            " School",
                            " of",
                            " Public",
                            " Affairs",
                            ",",
                            " had",
                            " examined",
                            " the",
                            " effect",
                            " of",
                            " liquor",
                            " stores",
                            " on",
                            " neighborhoods",
                            " and",
                            " thought",
                            " a",
                            " similar",
                            " approach",
                            " could",
                            " be",
                            " taken",
                            " to",
                            " dispensaries",
                            ".",
                            " In",
                            " late",
                            " 2011",
                            ",",
                            " Fre",
                            "ist",
                            "hler",
                            " was",
                            " approved",
                            " by",
                            " the",
                            " National",
                            " Institute",
                            " on",
                            " Drug",
                            " Abuse",
                            " for",
                            " five",
                            " years",
                            "\u00e2\u0122",
                            "\u013b",
                            " worth",
                            " of",
                            " research",
                            " into",
                            " the",
                            " impact",
                            " of",
                            " dispensaries",
                            " on",
                            " their",
                            " communities",
                            ".",
                            "\n",
                            "\n",
                            "Her",
                            " students",
                            " are",
                            " visiting",
                            " dispensaries",
                            " and",
                            " conducting",
                            " operational",
                            " surveys",
                            ",",
                            " which",
                            " ask",
                            " about",
                            " the",
                            " condition",
                            " of",
                            " the",
                            " dispensary",
                            ",",
                            " the",
                            " patients",
                            " that",
                            " enter",
                            ",",
                            " and",
                            " the",
                            " types",
                            " of",
                            " products",
                            " the",
                            " stores",
                            " sell",
                            ".",
                            " At",
                            " the",
                            " project",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " halfway",
                            " point",
                            ",",
                            " about",
                            " 10",
                            " students",
                            " have",
                            " worked",
                            " with",
                            " Fre",
                            "ist",
                            "hler"
                        ],
                        "dataIndex": null,
                        "index": "17375",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.455,
                        "maxValueTokenIndex": 7,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.455,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:07.351Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.455,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmszkogijvi666h59vub6d",
                        "tokens": [
                            " that",
                            " the",
                            " design",
                            " \u00e2\u0122",
                            "\u013e",
                            "does",
                            " not",
                            " reduce",
                            " existing",
                            " stockp",
                            "iles",
                            " of",
                            " spent",
                            " nuclear",
                            " fuel",
                            "\u00e2\u0122",
                            "\u013f",
                            " or",
                            " use",
                            " them",
                            " as",
                            " its",
                            " fuel",
                            " source",
                            ".",
                            " The",
                            " promise",
                            " of",
                            " recycling",
                            " nuclear",
                            " waste",
                            ",",
                            " which",
                            " poses",
                            " tricky",
                            " storage",
                            " and",
                            " proliferation",
                            " challenges",
                            ",",
                            " was",
                            " a",
                            " key",
                            " initial",
                            " attraction",
                            " of",
                            " the",
                            " company",
                            " and",
                            " captured",
                            " considerable",
                            " attention",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "In",
                            " early",
                            " 2016",
                            ",",
                            " we",
                            " realized",
                            " there",
                            " was",
                            " a",
                            " problem",
                            " with",
                            " our",
                            " initial",
                            " analysis",
                            " and",
                            " started",
                            " working",
                            " to",
                            " correct",
                            " the",
                            " error",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " co",
                            "founder",
                            " Leslie",
                            " Dew",
                            "an",
                            " said",
                            " in",
                            " an",
                            " e",
                            "-",
                            "mail",
                            " response",
                            " to",
                            " an",
                            " inquiry",
                            " from",
                            " MIT",
                            " Technology",
                            " Review",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " dramatic",
                            " revisions",
                            " followed",
                            " an",
                            " analysis",
                            " in",
                            " late",
                            " 2015",
                            " by",
                            " K",
                            "ord",
                            " Smith",
                            ",",
                            " a",
                            " professor",
                            " of",
                            " nuclear",
                            " science",
                            " and",
                            " engineering",
                            " at",
                            " MIT",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "17375",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.262,
                        "maxValueTokenIndex": 118,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.262,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:07.351Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.455,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmszkogijwi6661xv9nu5l",
                        "tokens": [
                            " two",
                            " years",
                            " there",
                            " have",
                            " been",
                            " hundreds",
                            " of",
                            " data",
                            " breaches",
                            " involving",
                            " customer",
                            " information",
                            ",",
                            " some",
                            " very",
                            " serious",
                            " like",
                            " the",
                            " Target",
                            " breach",
                            " in",
                            " 2013",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Holt",
                            ",",
                            " associate",
                            " professor",
                            " of",
                            " criminal",
                            " justice",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " happening",
                            " so",
                            " often",
                            " that",
                            " average",
                            " consumers",
                            " are",
                            " just",
                            " getting",
                            " into",
                            " this",
                            " mindset",
                            " of",
                            ",",
                            " \u00e2\u0122",
                            "\u013a",
                            "Well",
                            ",",
                            " my",
                            " bank",
                            " will",
                            " just",
                            " re",
                            "-",
                            "issue",
                            " the",
                            " card",
                            ",",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " not",
                            " a",
                            " problem",
                            ".",
                            "\u00e2\u0122",
                            "\u013b",
                            " But",
                            " this",
                            " is",
                            " more",
                            " than",
                            " a",
                            " hassle",
                            " or",
                            " inconvenience",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " real",
                            " economic",
                            " phenomenon",
                            " that",
                            " has",
                            " real",
                            " economic",
                            " impact",
                            " and",
                            " consequences",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "H",
                            "olt",
                            " and",
                            " fellow",
                            " researchers",
                            " analyzed",
                            " online",
                            " forums",
                            " in",
                            " English",
                            " and",
                            " Russian",
                            " where",
                            " criminals",
                            " sold",
                            " stolen",
                            " financial",
                            " and",
                            " personal"
                        ],
                        "dataIndex": null,
                        "index": "17375",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.058,
                        "maxValueTokenIndex": 29,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.058,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.302,
                            1.268,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:07.351Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.455,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "7686",
            "description": "academics, such as professors, across various fields and topics",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 50.34,
            "frac_nonzero": 0.00068,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "7686",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:26:27.528Z",
                "maxActApprox": 50.34,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    7686,
                    5042,
                    4895,
                    7498,
                    3971,
                    5113,
                    6926,
                    11053,
                    1292,
                    10918,
                    8172,
                    3335,
                    5801,
                    2235,
                    7182,
                    5673,
                    1700,
                    6806,
                    9829,
                    7513,
                    8476,
                    1335,
                    6943,
                    4702,
                    5196
                ],
                "topkCosSimValues": [
                    1,
                    0.5569,
                    0.5274,
                    0.5052,
                    0.4912,
                    0.4909,
                    0.4744,
                    0.4696,
                    0.4443,
                    0.4337,
                    0.4164,
                    0.4146,
                    0.4038,
                    0.4002,
                    0.394,
                    0.3925,
                    0.3732,
                    0.365,
                    0.3649,
                    0.3571,
                    0.356,
                    0.3551,
                    0.3488,
                    0.3456,
                    0.3429
                ],
                "neuron_alignment_indices": [
                    679,
                    288,
                    111
                ],
                "neuron_alignment_values": [
                    0.127,
                    0.116,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    235,
                    414,
                    145
                ],
                "correlated_neurons_pearson": [
                    0.028,
                    0.026,
                    0.026
                ],
                "correlated_neurons_l1": [
                    0.029,
                    0.023,
                    0.026
                ],
                "correlated_features_indices": [
                    7695,
                    7692,
                    7765
                ],
                "correlated_features_pearson": [
                    0.013,
                    0.008,
                    0.006
                ],
                "correlated_features_l1": [
                    0.014,
                    0.009,
                    0.006
                ],
                "neg_str": [
                    " territ",
                    " Bundy",
                    " leash",
                    " Pradesh",
                    "opter",
                    " launchers",
                    " deployment",
                    "\u00e3\u0125\u00bc\u00e3\u0125\u00b3",
                    " spont",
                    " thee"
                ],
                "neg_values": [
                    -0.696,
                    -0.671,
                    -0.638,
                    -0.633,
                    -0.631,
                    -0.628,
                    -0.627,
                    -0.612,
                    -0.608,
                    -0.595
                ],
                "pos_str": [
                    "essors",
                    " emer",
                    "iate",
                    "essor",
                    "itatively",
                    "hips",
                    "ials",
                    " specializing",
                    " professors",
                    "onym"
                ],
                "pos_values": [
                    1.314,
                    1.151,
                    1.022,
                    1.003,
                    0.977,
                    0.926,
                    0.92,
                    0.871,
                    0.861,
                    0.844
                ],
                "frac_nonzero": 0.00068,
                "freq_hist_data_bar_heights": [
                    588,
                    371,
                    247,
                    146,
                    112,
                    108,
                    74,
                    52,
                    44,
                    30,
                    20,
                    16,
                    7,
                    13,
                    13,
                    5,
                    3,
                    3,
                    3,
                    5,
                    3,
                    0,
                    5,
                    2,
                    6,
                    3,
                    4,
                    9,
                    3,
                    6,
                    7,
                    12,
                    5,
                    11,
                    7,
                    12,
                    6,
                    14,
                    16,
                    17,
                    9,
                    12,
                    9,
                    11,
                    16,
                    27,
                    20,
                    18,
                    8,
                    5
                ],
                "freq_hist_data_bar_values": [
                    0.504,
                    1.511,
                    2.517,
                    3.524,
                    4.531,
                    5.538,
                    6.544,
                    7.551,
                    8.558,
                    9.565,
                    10.572,
                    11.578,
                    12.585,
                    13.592,
                    14.599,
                    15.605,
                    16.612,
                    17.619,
                    18.626,
                    19.633,
                    20.639,
                    21.646,
                    22.653,
                    23.66,
                    24.667,
                    25.673,
                    26.68,
                    27.687,
                    28.694,
                    29.7,
                    30.707,
                    31.714,
                    32.721,
                    33.728,
                    34.734,
                    35.741,
                    36.748,
                    37.755,
                    38.761,
                    39.768,
                    40.775,
                    41.782,
                    42.789,
                    43.795,
                    44.802,
                    45.809,
                    46.816,
                    47.822,
                    48.829,
                    49.836
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    5,
                    5,
                    20,
                    49,
                    77,
                    204,
                    365,
                    565,
                    874,
                    1443,
                    2084,
                    2715,
                    3395,
                    4063,
                    4361,
                    4660,
                    4517,
                    4205,
                    3695,
                    3053,
                    2493,
                    1924,
                    1507,
                    1134,
                    891,
                    634,
                    429,
                    306,
                    206,
                    147,
                    84,
                    55,
                    34,
                    13,
                    13,
                    10,
                    7,
                    6,
                    0,
                    2,
                    1,
                    2,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.676,
                    -0.635,
                    -0.595,
                    -0.555,
                    -0.515,
                    -0.475,
                    -0.434,
                    -0.394,
                    -0.354,
                    -0.314,
                    -0.274,
                    -0.234,
                    -0.193,
                    -0.153,
                    -0.113,
                    -0.073,
                    -0.033,
                    0.008,
                    0.048,
                    0.088,
                    0.128,
                    0.168,
                    0.209,
                    0.249,
                    0.289,
                    0.329,
                    0.369,
                    0.41,
                    0.45,
                    0.49,
                    0.53,
                    0.57,
                    0.61,
                    0.651,
                    0.691,
                    0.731,
                    0.771,
                    0.811,
                    0.852,
                    0.892,
                    0.932,
                    0.972,
                    1.012,
                    1.053,
                    1.093,
                    1.133,
                    1.173,
                    1.213,
                    1.253,
                    1.294
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clymll5bn0tmhj7a19eb73jhp",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs12288-jb",
                        "index": "7686",
                        "description": "academics, such as professors, across various fields and topics",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-07-15T06:22:39.924Z",
                        "updatedAt": "2024-07-15T06:22:39.924Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtxckl5u2li666wlzqjrk0",
                        "tokens": [
                            " two",
                            " years",
                            " there",
                            " have",
                            " been",
                            " hundreds",
                            " of",
                            " data",
                            " breaches",
                            " involving",
                            " customer",
                            " information",
                            ",",
                            " some",
                            " very",
                            " serious",
                            " like",
                            " the",
                            " Target",
                            " breach",
                            " in",
                            " 2013",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Holt",
                            ",",
                            " associate",
                            " professor",
                            " of",
                            " criminal",
                            " justice",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " happening",
                            " so",
                            " often",
                            " that",
                            " average",
                            " consumers",
                            " are",
                            " just",
                            " getting",
                            " into",
                            " this",
                            " mindset",
                            " of",
                            ",",
                            " \u00e2\u0122",
                            "\u013a",
                            "Well",
                            ",",
                            " my",
                            " bank",
                            " will",
                            " just",
                            " re",
                            "-",
                            "issue",
                            " the",
                            " card",
                            ",",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " not",
                            " a",
                            " problem",
                            ".",
                            "\u00e2\u0122",
                            "\u013b",
                            " But",
                            " this",
                            " is",
                            " more",
                            " than",
                            " a",
                            " hassle",
                            " or",
                            " inconvenience",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " real",
                            " economic",
                            " phenomenon",
                            " that",
                            " has",
                            " real",
                            " economic",
                            " impact",
                            " and",
                            " consequences",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "H",
                            "olt",
                            " and",
                            " fellow",
                            " researchers",
                            " analyzed",
                            " online",
                            " forums",
                            " in",
                            " English",
                            " and",
                            " Russian",
                            " where",
                            " criminals",
                            " sold",
                            " stolen",
                            " financial",
                            " and",
                            " personal"
                        ],
                        "dataIndex": null,
                        "index": "7686",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.34,
                        "maxValueTokenIndex": 29,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.34,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.834,
                            2.643,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:26:28.154Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.339,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtxckl5u2mi666hvo5y2mh",
                        "tokens": [
                            " a",
                            " long",
                            " time",
                            ",",
                            " and",
                            " people",
                            " made",
                            " careers",
                            ",",
                            " peoples",
                            "\u00e2\u0122",
                            "\u013b",
                            " livelihood",
                            "s",
                            " depended",
                            " on",
                            " the",
                            " Cold",
                            " War",
                            " continuing",
                            ".",
                            " Big",
                            " defense",
                            " contracts",
                            " depended",
                            " on",
                            " it",
                            ".",
                            "\n",
                            "\n",
                            "A",
                            " lot",
                            " of",
                            " people",
                            " had",
                            " the",
                            " motivation",
                            " to",
                            " kill",
                            " Kennedy",
                            ".",
                            "\n",
                            "\n",
                            "Guest",
                            " \u2013",
                            " Zach",
                            "ary",
                            " Sk",
                            "lar",
                            ",",
                            " Oscar",
                            "-",
                            "nom",
                            "inated",
                            " co",
                            "-",
                            "screen",
                            "writer",
                            " of",
                            " Oliver",
                            " Stone",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " film",
                            " JFK",
                            ",",
                            " and",
                            " author",
                            " of",
                            " the",
                            " book",
                            " JFK",
                            ":",
                            " The",
                            " Book",
                            " of",
                            " the",
                            " Film",
                            ".",
                            " He",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " journalist",
                            ",",
                            " and",
                            " a",
                            " professor",
                            " at",
                            " the",
                            " Columbia",
                            " School",
                            " of",
                            " Journalism",
                            ".",
                            " He",
                            " was",
                            " also",
                            " a",
                            " contributor",
                            " to",
                            " The",
                            " Lies",
                            " of",
                            " Our",
                            " Times",
                            ",",
                            " a",
                            " monthly",
                            " journal",
                            " dedicated",
                            " to",
                            " exposing",
                            " the",
                            " truth",
                            " behind",
                            " the",
                            " mainstream",
                            " media",
                            ".",
                            " Zach",
                            " collaborated",
                            " with",
                            " director",
                            " Oliver"
                        ],
                        "dataIndex": null,
                        "index": "7686",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.891,
                        "maxValueTokenIndex": 89,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.891,
                            1.154,
                            0,
                            0,
                            2.159,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:26:28.154Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.339,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtxckl5u2ni666iqlazf6j",
                        "tokens": [
                            ",",
                            " a",
                            " professor",
                            " of",
                            " police",
                            " studies",
                            " at",
                            " John",
                            " Jay",
                            " College",
                            " of",
                            " Criminal",
                            " Justice",
                            ".",
                            " \"",
                            "When",
                            " people",
                            " need",
                            " help",
                            ",",
                            " they",
                            " call",
                            " the",
                            " police",
                            ",",
                            " and",
                            " when",
                            " police",
                            " need",
                            " help",
                            ",",
                            " the",
                            " call",
                            " the",
                            " E",
                            "SU",
                            ".\"",
                            "\n",
                            "\n",
                            "O",
                            "'",
                            "Donnell",
                            " said",
                            " even",
                            " though",
                            " the",
                            " mistake",
                            " was",
                            " caught",
                            " on",
                            " camera",
                            ",",
                            " it",
                            " should",
                            " not",
                            " take",
                            " away",
                            " from",
                            " the",
                            " caliber",
                            " of",
                            " work",
                            " the",
                            " unit",
                            " and",
                            " the",
                            " officers",
                            " do",
                            " on",
                            " a",
                            " daily",
                            " basis",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "You",
                            " have",
                            " a",
                            " guy",
                            " who",
                            " made",
                            " a",
                            " mistake",
                            " where",
                            " there",
                            "'s",
                            " no",
                            " allegation",
                            " of",
                            " malice",
                            " or",
                            " ill",
                            "-",
                            "will",
                            ",\"",
                            " he",
                            " said",
                            ".",
                            " \"",
                            "And",
                            " what",
                            " happened",
                            " after",
                            " he",
                            " made",
                            " a",
                            " mistake",
                            "?",
                            " He",
                            " was",
                            " named",
                            " in",
                            " the",
                            " paper",
                            ",",
                            " sh",
                            "amed",
                            " in",
                            " the",
                            " paper",
                            ",",
                            " suspended",
                            ",",
                            " and",
                            " there",
                            " was"
                        ],
                        "dataIndex": null,
                        "index": "7686",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.439,
                        "maxValueTokenIndex": 2,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            49.439,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:26:28.154Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 50.339,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "48794",
            "description": "references to academic titles and professions, specifically those related to professors",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 49.595,
            "frac_nonzero": 0.00014,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "48794",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:26:10.852Z",
                "maxActApprox": 49.595,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    48794,
                    15773,
                    8330,
                    41472,
                    38872,
                    31459,
                    5198,
                    30967,
                    39715,
                    13657,
                    47724,
                    8748,
                    42517,
                    36846,
                    33946,
                    34564,
                    8162,
                    29334,
                    35512,
                    35244,
                    34160,
                    5131,
                    46531,
                    12493,
                    30790
                ],
                "topkCosSimValues": [
                    1,
                    0.7476,
                    0.5951,
                    0.5587,
                    0.5217,
                    0.5194,
                    0.5056,
                    0.4906,
                    0.4834,
                    0.4802,
                    0.4772,
                    0.4687,
                    0.4667,
                    0.4559,
                    0.4535,
                    0.4461,
                    0.4434,
                    0.4418,
                    0.4377,
                    0.4374,
                    0.434,
                    0.4332,
                    0.4291,
                    0.4268,
                    0.4026
                ],
                "neuron_alignment_indices": [
                    679,
                    288,
                    102
                ],
                "neuron_alignment_values": [
                    0.145,
                    0.115,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    414,
                    145,
                    235
                ],
                "correlated_neurons_pearson": [
                    0.021,
                    0.019,
                    0.019
                ],
                "correlated_neurons_l1": [
                    0.019,
                    0.019,
                    0.02
                ],
                "correlated_features_indices": [
                    48807,
                    48894,
                    48828
                ],
                "correlated_features_pearson": [
                    0.005,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.005,
                    0.001,
                    0
                ],
                "neg_str": [
                    " Pradesh",
                    " Bundy",
                    " territ",
                    "opter",
                    " launchers",
                    "tera",
                    "\u00e3\u0125\u00bc\u00e3\u0125\u00b3",
                    " leash",
                    " Passage",
                    " Clan"
                ],
                "neg_values": [
                    -0.674,
                    -0.667,
                    -0.661,
                    -0.647,
                    -0.63,
                    -0.628,
                    -0.627,
                    -0.618,
                    -0.616,
                    -0.59
                ],
                "pos_str": [
                    " emer",
                    "essors",
                    "itatively",
                    "iate",
                    "essor",
                    "ials",
                    "hips",
                    " specializing",
                    " professor",
                    " professors"
                ],
                "pos_values": [
                    1.255,
                    1.246,
                    1.015,
                    0.995,
                    0.972,
                    0.954,
                    0.942,
                    0.93,
                    0.886,
                    0.873
                ],
                "frac_nonzero": 0.00014,
                "freq_hist_data_bar_heights": [
                    58,
                    43,
                    24,
                    18,
                    12,
                    10,
                    8,
                    4,
                    1,
                    9,
                    3,
                    2,
                    6,
                    3,
                    1,
                    7,
                    2,
                    3,
                    6,
                    5,
                    3,
                    5,
                    7,
                    7,
                    3,
                    6,
                    11,
                    6,
                    8,
                    11,
                    3,
                    7,
                    7,
                    6,
                    3,
                    10,
                    4,
                    4,
                    10,
                    3,
                    10,
                    8,
                    8,
                    9,
                    10,
                    14,
                    5,
                    8,
                    11,
                    7
                ],
                "freq_hist_data_bar_values": [
                    0.499,
                    1.491,
                    2.483,
                    3.475,
                    4.467,
                    5.458,
                    6.45,
                    7.442,
                    8.434,
                    9.426,
                    10.418,
                    11.409,
                    12.401,
                    13.393,
                    14.385,
                    15.377,
                    16.369,
                    17.36,
                    18.352,
                    19.344,
                    20.336,
                    21.328,
                    22.32,
                    23.311,
                    24.303,
                    25.295,
                    26.287,
                    27.279,
                    28.271,
                    29.262,
                    30.254,
                    31.246,
                    32.238,
                    33.23,
                    34.222,
                    35.213,
                    36.205,
                    37.197,
                    38.189,
                    39.181,
                    40.173,
                    41.164,
                    42.156,
                    43.148,
                    44.14,
                    45.132,
                    46.124,
                    47.115,
                    48.107,
                    49.099
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    5,
                    11,
                    25,
                    41,
                    110,
                    180,
                    384,
                    576,
                    830,
                    1287,
                    1936,
                    2579,
                    3292,
                    3848,
                    4327,
                    4673,
                    4534,
                    4250,
                    3734,
                    3231,
                    2697,
                    1945,
                    1587,
                    1156,
                    893,
                    648,
                    459,
                    322,
                    259,
                    152,
                    96,
                    82,
                    34,
                    22,
                    14,
                    8,
                    8,
                    7,
                    1,
                    2,
                    2,
                    2,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.655,
                    -0.616,
                    -0.578,
                    -0.539,
                    -0.5,
                    -0.462,
                    -0.423,
                    -0.385,
                    -0.346,
                    -0.308,
                    -0.269,
                    -0.23,
                    -0.192,
                    -0.153,
                    -0.115,
                    -0.076,
                    -0.037,
                    0.001,
                    0.04,
                    0.078,
                    0.117,
                    0.155,
                    0.194,
                    0.233,
                    0.271,
                    0.31,
                    0.348,
                    0.387,
                    0.426,
                    0.464,
                    0.503,
                    0.541,
                    0.58,
                    0.618,
                    0.657,
                    0.696,
                    0.734,
                    0.773,
                    0.811,
                    0.85,
                    0.889,
                    0.927,
                    0.966,
                    1.004,
                    1.043,
                    1.082,
                    1.12,
                    1.159,
                    1.197,
                    1.236
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyvw8htg2pb8nba6m86qlghf",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs49152-jb",
                        "index": "48794",
                        "description": "references to academic titles and professions, specifically those related to professors",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-21T18:30:40.948Z",
                        "updatedAt": "2024-07-21T18:30:40.948Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk798j8kmb9i666nxfvyag9",
                        "tokens": [
                            "head",
                            " Wednesday",
                            " night",
                            " in",
                            " the",
                            " first",
                            " of",
                            " three",
                            " presidential",
                            " debates",
                            "\u2014",
                            "if",
                            " that",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " what",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " willing",
                            " to",
                            " call",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "These",
                            " are",
                            " more",
                            " accurately",
                            " called",
                            " joint",
                            " television",
                            " appearances",
                            " where",
                            " they",
                            " have",
                            " journalists",
                            " asking",
                            " the",
                            " questions",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " \u00e2\u0122",
                            "\u013e",
                            "J",
                            ".",
                            " Michael",
                            " Hogan",
                            ",",
                            " Ph",
                            ".",
                            "D",
                            ".,",
                            " Director",
                            " of",
                            " the",
                            " Center",
                            " for",
                            " Democratic",
                            " Del",
                            "iber",
                            "ation",
                            " and",
                            " a",
                            " professor",
                            " at",
                            " Pennsylvania",
                            " State",
                            " University",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "A",
                            " real",
                            " debate",
                            " would",
                            " be",
                            " more",
                            " unpredictable",
                            ".",
                            " They",
                            " couldn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " rely",
                            " on",
                            " the",
                            " sound",
                            " bites",
                            " they",
                            " use",
                            " to",
                            " answer",
                            " reporters",
                            "\u00e2\u0122",
                            "\u013b",
                            " questions",
                            " or",
                            " that",
                            " they",
                            " pull",
                            " right",
                            " out",
                            " of",
                            " their",
                            " campaign",
                            " stump",
                            " speeches",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Either",
                            " way",
                            ",",
                            " the",
                            " presidential",
                            " candidates"
                        ],
                        "dataIndex": null,
                        "index": "48794",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.595,
                        "maxValueTokenIndex": 71,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.595,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:26:14.883Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.595,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk798j9kmbai6662ohudjsk",
                        "tokens": [
                            " really",
                            " an",
                            " incentive",
                            " to",
                            " do",
                            " it",
                            " well",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Lib",
                            "by",
                            " Hem",
                            "ph",
                            "ill",
                            ",",
                            " a",
                            " professor",
                            " of",
                            " information",
                            " studies",
                            " at",
                            " the",
                            " University",
                            " of",
                            " Michigan",
                            " in",
                            " Ann",
                            " Arbor",
                            ".",
                            "\n",
                            "\n",
                            "T",
                            "ees",
                            "pring",
                            " is",
                            " a",
                            " San",
                            " Francisco",
                            "-",
                            "based",
                            " company",
                            " that",
                            " has",
                            " raised",
                            " millions",
                            " of",
                            " dollars",
                            " from",
                            " Silicon",
                            " Valley",
                            " sources",
                            " such",
                            " as",
                            " start",
                            "-",
                            "up",
                            " incub",
                            "ator",
                            " Y",
                            " Com",
                            "bin",
                            "ator",
                            " and",
                            " venture",
                            " capital",
                            " firms",
                            " including",
                            " Andre",
                            "essen",
                            " Horowitz",
                            " and",
                            " Kh",
                            "os",
                            "la",
                            " Ventures",
                            ".",
                            "\n",
                            "\n",
                            "Its",
                            " business",
                            " model",
                            " is",
                            " to",
                            " act",
                            " as",
                            " an",
                            " intermediary",
                            ":",
                            " Customers",
                            " upload",
                            " designs",
                            " for",
                            " custom",
                            " T",
                            "-",
                            "shirts",
                            " and",
                            " other",
                            " logo",
                            " items",
                            ".",
                            " They",
                            " then",
                            " sell",
                            " the",
                            " items",
                            " either",
                            " on",
                            " the",
                            " Te",
                            "es",
                            "pring",
                            " site",
                            " or",
                            " on",
                            " their",
                            " own",
                            " sites",
                            ".",
                            " Te",
                            "es",
                            "pring",
                            " takes",
                            " a",
                            " cut"
                        ],
                        "dataIndex": null,
                        "index": "48794",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.884,
                        "maxValueTokenIndex": 18,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.884,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:26:14.883Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.595,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk798jbkmbti666osjk03w2",
                        "tokens": [
                            " really",
                            " an",
                            " incentive",
                            " to",
                            " do",
                            " it",
                            " well",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Lib",
                            "by",
                            " Hem",
                            "ph",
                            "ill",
                            ",",
                            " a",
                            " professor",
                            " of",
                            " information",
                            " studies",
                            " at",
                            " the",
                            " University",
                            " of",
                            " Michigan",
                            " in",
                            " Ann",
                            " Arbor",
                            ".",
                            "\n",
                            "\n",
                            "T",
                            "ees",
                            "pring",
                            " is",
                            " a",
                            " San",
                            " Francisco",
                            "-",
                            "based",
                            " company",
                            " that",
                            " has",
                            " raised",
                            " millions",
                            " of",
                            " dollars",
                            " from",
                            " Silicon",
                            " Valley",
                            " sources",
                            " such",
                            " as",
                            " start",
                            "-",
                            "up",
                            " incub",
                            "ator",
                            " Y",
                            " Com",
                            "bin",
                            "ator",
                            " and",
                            " venture",
                            " capital",
                            " firms",
                            " including",
                            " Andre",
                            "essen",
                            " Horowitz",
                            " and",
                            " Kh",
                            "os",
                            "la",
                            " Ventures",
                            ".",
                            "\n",
                            "\n",
                            "Its",
                            " business",
                            " model",
                            " is",
                            " to",
                            " act",
                            " as",
                            " an",
                            " intermediary",
                            ":",
                            " Customers",
                            " upload",
                            " designs",
                            " for",
                            " custom",
                            " T",
                            "-",
                            "shirts",
                            " and",
                            " other",
                            " logo",
                            " items",
                            ".",
                            " They",
                            " then",
                            " sell",
                            " the",
                            " items",
                            " either",
                            " on",
                            " the",
                            " Te",
                            "es",
                            "pring",
                            " site",
                            " or",
                            " on",
                            " their",
                            " own",
                            " sites",
                            ".",
                            " Te",
                            "es",
                            "pring",
                            " takes",
                            " a",
                            " cut"
                        ],
                        "dataIndex": null,
                        "index": "48794",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.884,
                        "maxValueTokenIndex": 18,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.884,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:26:14.883Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 39.676,
                        "binMax": 49.595,
                        "binContains": 3e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "24986",
            "description": "words related to academic titles, particularly references to professors and their positions",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 48.344,
            "frac_nonzero": 8.999999999999999e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "24986",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:43:41.991Z",
                "maxActApprox": 48.344,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    24986,
                    28221,
                    27049,
                    31907,
                    46508,
                    12325,
                    39950,
                    6717,
                    16083,
                    21308,
                    18038,
                    21413,
                    18722,
                    12687,
                    12146,
                    4207,
                    17750,
                    14435,
                    29520,
                    3226,
                    14569,
                    19453,
                    15171,
                    35837,
                    34581
                ],
                "topkCosSimValues": [
                    1,
                    0.2915,
                    0.2913,
                    0.2913,
                    0.2898,
                    0.2892,
                    0.2886,
                    0.2853,
                    0.2796,
                    0.2755,
                    0.2742,
                    0.2717,
                    0.2691,
                    0.2675,
                    0.2648,
                    0.2636,
                    0.263,
                    0.2615,
                    0.2607,
                    0.259,
                    0.2574,
                    0.2564,
                    0.2546,
                    0.2542,
                    0.2538
                ],
                "neuron_alignment_indices": [
                    763,
                    354,
                    356
                ],
                "neuron_alignment_values": [
                    0.117,
                    0.114,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    326,
                    763,
                    659
                ],
                "correlated_neurons_pearson": [
                    0.007,
                    0.006,
                    0.006
                ],
                "correlated_neurons_l1": [
                    0.006,
                    0.006,
                    0.006
                ],
                "correlated_features_indices": [
                    24993,
                    24991,
                    25024
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.006,
                    0.003,
                    0.002
                ],
                "neg_str": [
                    "CVE",
                    " marrow",
                    "ibaba",
                    " princ",
                    " exha",
                    " gobl",
                    " silence",
                    "atch",
                    " unprepared",
                    " appropriation"
                ],
                "neg_values": [
                    -0.739,
                    -0.718,
                    -0.704,
                    -0.668,
                    -0.655,
                    -0.654,
                    -0.652,
                    -0.636,
                    -0.626,
                    -0.621
                ],
                "pos_str": [
                    "idget",
                    "uously",
                    "own",
                    "robe",
                    "uous",
                    "oad",
                    "oggle",
                    "te",
                    "tic",
                    "yll"
                ],
                "pos_values": [
                    1.075,
                    0.917,
                    0.915,
                    0.874,
                    0.843,
                    0.826,
                    0.816,
                    0.804,
                    0.801,
                    0.785
                ],
                "frac_nonzero": 8.999999999999999e-05,
                "freq_hist_data_bar_heights": [
                    113,
                    54,
                    49,
                    16,
                    14,
                    6,
                    6,
                    7,
                    5,
                    1,
                    2,
                    1,
                    2,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.484,
                    1.451,
                    2.418,
                    3.385,
                    4.352,
                    5.319,
                    6.286,
                    7.252,
                    8.219,
                    9.186,
                    10.153,
                    11.12,
                    12.087,
                    13.054,
                    14.021,
                    14.987,
                    15.954,
                    16.921,
                    17.888,
                    18.855,
                    19.822,
                    20.789,
                    21.756,
                    22.722,
                    23.689,
                    24.656,
                    25.623,
                    26.59,
                    27.557,
                    28.524,
                    29.49,
                    30.457,
                    31.424,
                    32.391,
                    33.358,
                    34.325,
                    35.292,
                    36.259,
                    37.225,
                    38.192,
                    39.159,
                    40.126,
                    41.093,
                    42.06,
                    43.027,
                    43.993,
                    44.96,
                    45.927,
                    46.894,
                    47.861
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    1,
                    4,
                    6,
                    11,
                    25,
                    53,
                    68,
                    166,
                    289,
                    535,
                    803,
                    1166,
                    1555,
                    2044,
                    2598,
                    3169,
                    3790,
                    4201,
                    4062,
                    4154,
                    3884,
                    3455,
                    3065,
                    2581,
                    2074,
                    1686,
                    1323,
                    958,
                    769,
                    547,
                    378,
                    297,
                    204,
                    100,
                    82,
                    57,
                    33,
                    18,
                    11,
                    13,
                    9,
                    4,
                    2,
                    1,
                    2,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.721,
                    -0.685,
                    -0.649,
                    -0.612,
                    -0.576,
                    -0.54,
                    -0.503,
                    -0.467,
                    -0.431,
                    -0.395,
                    -0.358,
                    -0.322,
                    -0.286,
                    -0.249,
                    -0.213,
                    -0.177,
                    -0.141,
                    -0.104,
                    -0.068,
                    -0.032,
                    0.005,
                    0.041,
                    0.077,
                    0.113,
                    0.15,
                    0.186,
                    0.222,
                    0.259,
                    0.295,
                    0.331,
                    0.367,
                    0.404,
                    0.44,
                    0.476,
                    0.513,
                    0.549,
                    0.585,
                    0.621,
                    0.658,
                    0.694,
                    0.73,
                    0.767,
                    0.803,
                    0.839,
                    0.875,
                    0.912,
                    0.948,
                    0.984,
                    1.021,
                    1.057
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyvby3f51lilnba6flbi2rs2",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs49152-jb",
                        "index": "24986",
                        "description": "words related to academic titles, particularly references to professors and their positions",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-21T09:02:43.409Z",
                        "updatedAt": "2024-07-21T09:02:43.409Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk5qn65yo4ti6661zy02m08",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "Ped",
                            "erson",
                            " told",
                            " me",
                            " that",
                            " FBI",
                            " agent",
                            " Mark",
                            " Col",
                            "burn",
                            " told",
                            " him",
                            ",",
                            " quote",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "The",
                            " Johnson",
                            " County",
                            " Prosecutor",
                            " won",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " do",
                            " anything",
                            " until",
                            " the",
                            " Grand",
                            " Jury",
                            " conven",
                            "es",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " Well",
                            ",",
                            " the",
                            " next",
                            " day",
                            " was",
                            " Sunday",
                            ",",
                            " when",
                            " Dr",
                            ".",
                            " George",
                            " T",
                            "iller",
                            " was",
                            " killed",
                            ",",
                            " allegedly",
                            " by",
                            " Scott",
                            " Ro",
                            "eder",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " called",
                            " the",
                            " Kansas",
                            " City",
                            " FBI",
                            " and",
                            " reached",
                            " Col",
                            "burn",
                            ",",
                            " who",
                            " referred",
                            " me",
                            " to",
                            " FBI",
                            " spokesperson",
                            " Br",
                            "idget",
                            " Patton",
                            ".",
                            " I",
                            " asked",
                            " her",
                            " why",
                            " Scott",
                            " Ro",
                            "eder",
                            " had",
                            " not",
                            " been",
                            " arrested",
                            " when",
                            " he",
                            " vandal",
                            "ized",
                            " the",
                            " Kansas",
                            " City",
                            " clinic",
                            " the",
                            " day",
                            " before",
                            ".",
                            "\n",
                            "\n",
                            "BR",
                            "ID",
                            "GET",
                            " PAT",
                            "TON",
                            ":",
                            " [",
                            "ina",
                            "ud",
                            "ible",
                            "]",
                            " was",
                            " notified",
                            " about",
                            " vandalism",
                            " that",
                            " occurred"
                        ],
                        "dataIndex": null,
                        "index": "24986",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.344,
                        "maxValueTokenIndex": 82,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.344,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.861,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:43:47.724Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 48.344,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5qn67yo5fi666jmzss1j0",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "Ped",
                            "erson",
                            " told",
                            " me",
                            " that",
                            " FBI",
                            " agent",
                            " Mark",
                            " Col",
                            "burn",
                            " told",
                            " him",
                            ",",
                            " quote",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "The",
                            " Johnson",
                            " County",
                            " Prosecutor",
                            " won",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " do",
                            " anything",
                            " until",
                            " the",
                            " Grand",
                            " Jury",
                            " conven",
                            "es",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " Well",
                            ",",
                            " the",
                            " next",
                            " day",
                            " was",
                            " Sunday",
                            ",",
                            " when",
                            " Dr",
                            ".",
                            " George",
                            " T",
                            "iller",
                            " was",
                            " killed",
                            ",",
                            " allegedly",
                            " by",
                            " Scott",
                            " Ro",
                            "eder",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " called",
                            " the",
                            " Kansas",
                            " City",
                            " FBI",
                            " and",
                            " reached",
                            " Col",
                            "burn",
                            ",",
                            " who",
                            " referred",
                            " me",
                            " to",
                            " FBI",
                            " spokesperson",
                            " Br",
                            "idget",
                            " Patton",
                            ".",
                            " I",
                            " asked",
                            " her",
                            " why",
                            " Scott",
                            " Ro",
                            "eder",
                            " had",
                            " not",
                            " been",
                            " arrested",
                            " when",
                            " he",
                            " vandal",
                            "ized",
                            " the",
                            " Kansas",
                            " City",
                            " clinic",
                            " the",
                            " day",
                            " before",
                            ".",
                            "\n",
                            "\n",
                            "BR",
                            "ID",
                            "GET",
                            " PAT",
                            "TON",
                            ":",
                            " [",
                            "ina",
                            "ud",
                            "ible",
                            "]",
                            " was",
                            " notified",
                            " about",
                            " vandalism",
                            " that",
                            " occurred"
                        ],
                        "dataIndex": null,
                        "index": "24986",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.344,
                        "maxValueTokenIndex": 82,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.344,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.861,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:43:47.724Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 38.675,
                        "binMax": 48.344,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5qn65yo4ui666rb2lrh5y",
                        "tokens": [
                            "\n",
                            "\n",
                            "AMY",
                            " GOODMAN",
                            ":",
                            " And",
                            " were",
                            " you",
                            " notified",
                            " more",
                            " than",
                            " once",
                            " in",
                            " two",
                            " different",
                            " incidents",
                            "?",
                            "\n",
                            "\n",
                            "BR",
                            "ID",
                            "GET",
                            " PAT",
                            "TON",
                            ":",
                            " Honestly",
                            ",",
                            " Amy",
                            ",",
                            " I",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " have",
                            " the",
                            " answer",
                            " to",
                            " that",
                            ".",
                            "\n",
                            "\n",
                            "AMY",
                            " GOODMAN",
                            ":",
                            " That",
                            " was",
                            " Br",
                            "idget",
                            " Patton",
                            ",",
                            " FBI",
                            " spokesperson",
                            " in",
                            " Kansas",
                            " City",
                            " about",
                            " why",
                            " the",
                            " FBI",
                            " did",
                            " not",
                            " respond",
                            " to",
                            " the",
                            " two",
                            " reports",
                            " of",
                            " vandalism",
                            " at",
                            " a",
                            " women",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " health",
                            " clinic",
                            " in",
                            " Kansas",
                            " City",
                            " last",
                            " week",
                            ".",
                            " The",
                            " man",
                            " who",
                            " vandal",
                            "ized",
                            " that",
                            " clinic",
                            ",",
                            " Scott",
                            " Ro",
                            "eder",
                            ",",
                            " has",
                            " now",
                            " been",
                            " charged",
                            " with",
                            " the",
                            " murder",
                            " of",
                            " Dr",
                            ".",
                            " T",
                            "iller",
                            ".",
                            "\n",
                            "\n",
                            "Scott",
                            " Ro",
                            "eder",
                            " has",
                            " a",
                            " history",
                            " of",
                            " involvement",
                            " in",
                            " anti",
                            "-",
                            "abortion",
                            " activism",
                            " and",
                            " has",
                            " ties",
                            " to"
                        ],
                        "dataIndex": null,
                        "index": "24986",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.17,
                        "maxValueTokenIndex": 48,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.853,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.17,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:43:47.724Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 48.344,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "73248",
            "description": " occurrences of the word \"Prof\" and its variations, indicating references to professors or professional titles",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 42.505,
            "frac_nonzero": 4e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "73248",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:02:16.310Z",
                "maxActApprox": 42.505,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    73248,
                    78071,
                    6218,
                    44,
                    82084,
                    83641,
                    46751,
                    10517,
                    98235,
                    92240,
                    76490,
                    94665,
                    81565,
                    7692,
                    76233,
                    4282,
                    56217,
                    25684,
                    73889,
                    1825,
                    35820,
                    35193,
                    83200,
                    44695,
                    65418
                ],
                "topkCosSimValues": [
                    1,
                    0.7921,
                    0.7639,
                    0.6403,
                    0.4589,
                    0.4237,
                    0.422,
                    0.4121,
                    0.3954,
                    0.3942,
                    0.3938,
                    0.3914,
                    0.3823,
                    0.3762,
                    0.3693,
                    0.363,
                    0.3593,
                    0.3561,
                    0.352,
                    0.3519,
                    0.3518,
                    0.3505,
                    0.3504,
                    0.3478,
                    0.3467
                ],
                "neuron_alignment_indices": [
                    575,
                    288,
                    60
                ],
                "neuron_alignment_values": [
                    0.134,
                    0.117,
                    0.115
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    60,
                    631,
                    90
                ],
                "correlated_neurons_pearson": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_neurons_l1": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_features_indices": [
                    73188,
                    73248,
                    73223
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "MENTS",
                    " halfway",
                    "warm",
                    "MENT",
                    " Mali",
                    "doors",
                    "forth",
                    " shortened",
                    " Weir",
                    " Warriors"
                ],
                "neg_values": [
                    -0.837,
                    -0.738,
                    -0.713,
                    -0.674,
                    -0.656,
                    -0.651,
                    -0.65,
                    -0.635,
                    -0.631,
                    -0.609
                ],
                "pos_str": [
                    "essor",
                    "iles",
                    "iciency",
                    "ound",
                    "essors",
                    "iler",
                    "ession",
                    "icient",
                    "iling",
                    "ilers"
                ],
                "pos_values": [
                    1.483,
                    1.343,
                    1.315,
                    1.266,
                    1.262,
                    1.247,
                    1.218,
                    1.178,
                    1.176,
                    1.171
                ],
                "frac_nonzero": 4e-05,
                "freq_hist_data_bar_heights": [
                    18,
                    11,
                    6,
                    2,
                    4,
                    3,
                    1,
                    3,
                    1,
                    1,
                    0,
                    1,
                    0,
                    1,
                    1,
                    2,
                    2,
                    1,
                    3,
                    2,
                    7,
                    4,
                    3,
                    4,
                    2,
                    5,
                    3,
                    2,
                    0,
                    3,
                    3,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    3,
                    3,
                    3,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.456,
                    1.306,
                    2.155,
                    3.004,
                    3.854,
                    4.703,
                    5.553,
                    6.402,
                    7.252,
                    8.101,
                    8.951,
                    9.8,
                    10.65,
                    11.499,
                    12.349,
                    13.198,
                    14.048,
                    14.897,
                    15.746,
                    16.596,
                    17.445,
                    18.295,
                    19.144,
                    19.994,
                    20.843,
                    21.693,
                    22.542,
                    23.392,
                    24.241,
                    25.091,
                    25.94,
                    26.79,
                    27.639,
                    28.488,
                    29.338,
                    30.187,
                    31.037,
                    31.886,
                    32.736,
                    33.585,
                    34.435,
                    35.284,
                    36.134,
                    36.983,
                    37.833,
                    38.682,
                    39.532,
                    40.381,
                    41.23,
                    42.08
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    2,
                    5,
                    16,
                    34,
                    82,
                    193,
                    421,
                    838,
                    1452,
                    2355,
                    3209,
                    4187,
                    4815,
                    5149,
                    4891,
                    4532,
                    3936,
                    3166,
                    2494,
                    1962,
                    1476,
                    1161,
                    906,
                    725,
                    600,
                    449,
                    325,
                    284,
                    197,
                    137,
                    94,
                    60,
                    40,
                    18,
                    14,
                    9,
                    5,
                    2,
                    1,
                    2,
                    3,
                    2,
                    2,
                    2,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.814,
                    -0.768,
                    -0.721,
                    -0.675,
                    -0.628,
                    -0.582,
                    -0.536,
                    -0.489,
                    -0.443,
                    -0.396,
                    -0.35,
                    -0.304,
                    -0.257,
                    -0.211,
                    -0.164,
                    -0.118,
                    -0.072,
                    -0.025,
                    0.021,
                    0.068,
                    0.114,
                    0.16,
                    0.207,
                    0.253,
                    0.3,
                    0.346,
                    0.392,
                    0.439,
                    0.485,
                    0.532,
                    0.578,
                    0.624,
                    0.671,
                    0.717,
                    0.764,
                    0.81,
                    0.857,
                    0.903,
                    0.949,
                    0.996,
                    1.042,
                    1.089,
                    1.135,
                    1.181,
                    1.228,
                    1.274,
                    1.321,
                    1.367,
                    1.413,
                    1.46
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clzdg6euh2wnuv3wqmleshzjm",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "73248",
                        "description": " occurrences of the word \"Prof\" and its variations, indicating references to professors or professional titles",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T01:21:01.097Z",
                        "updatedAt": "2024-08-03T01:21:01.097Z"
                    },
                    {
                        "id": "clze5y1kd3qinv3wq07ss68u7",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "73248",
                        "description": " instances of the term \"prof\" in various contexts, indicating a focus on professional titles or qualifications",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T13:22:20.654Z",
                        "updatedAt": "2024-08-03T13:22:20.654Z"
                    },
                    {
                        "id": "clze84iia3spov3wq7p90d40e",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "73248",
                        "description": "terms related to academic and professional titles, particularly \"professor\" and its variations",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T14:23:21.778Z",
                        "updatedAt": "2024-08-03T14:23:21.778Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi8oifuuvh10extionc3n7",
                        "tokens": [
                            ",",
                            " but",
                            " you",
                            "'re",
                            " here",
                            ",",
                            " so",
                            " you",
                            " better",
                            " f",
                            "------",
                            " deal",
                            " with",
                            " it",
                            ",",
                            " girl",
                            ".\"",
                            "<|endoftext|>",
                            "Overview",
                            "\n",
                            "\n",
                            "A",
                            "VE",
                            "X",
                            "IR",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " A",
                            "VD",
                            "3",
                            "U",
                            "H",
                            "3",
                            "100",
                            "12",
                            "04",
                            "G",
                            "-",
                            "2",
                            "CI",
                            " is",
                            " a",
                            " Dual",
                            " channel",
                            " 512",
                            "M",
                            " x",
                            " 64",
                            "-",
                            "bit",
                            " 4",
                            "GB",
                            " single",
                            " side",
                            " (",
                            "40",
                            "96",
                            "MB",
                            ")",
                            " x",
                            "2",
                            " DDR",
                            "3",
                            "-",
                            "3",
                            "100",
                            "MHz",
                            " CL",
                            "12",
                            " S",
                            "DR",
                            "AM",
                            "(",
                            "S",
                            "ynchronous",
                            " DR",
                            "AM",
                            ")",
                            " memory",
                            " modules",
                            ",",
                            " based",
                            " on",
                            " eight",
                            " 512",
                            "M",
                            " x",
                            " 8",
                            "\u2013",
                            "bit",
                            " DDR",
                            "3",
                            " FB",
                            "GA",
                            " components",
                            " per",
                            " module",
                            ".",
                            " Each",
                            " module",
                            " kit",
                            " supports",
                            " Intel",
                            " X",
                            "MP",
                            " 1",
                            ".",
                            "3",
                            " (",
                            "Extreme",
                            " Memory",
                            " Prof",
                            "iles",
                            ").",
                            " Total",
                            " kit",
                            " capacity",
                            " is",
                            " 8",
                            "GB",
                            ".",
                            " It",
                            " supports",
                            " newest",
                            " generation",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "73248",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.505,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.505,
                            3.583,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:22.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 34.004,
                        "binMax": 42.505,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi8oiduuuv10exnvub6ol3",
                        "tokens": [
                            ",",
                            " but",
                            " you",
                            "'re",
                            " here",
                            ",",
                            " so",
                            " you",
                            " better",
                            " f",
                            "------",
                            " deal",
                            " with",
                            " it",
                            ",",
                            " girl",
                            ".\"",
                            "<|endoftext|>",
                            "Overview",
                            "\n",
                            "\n",
                            "A",
                            "VE",
                            "X",
                            "IR",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " A",
                            "VD",
                            "3",
                            "U",
                            "H",
                            "3",
                            "100",
                            "12",
                            "04",
                            "G",
                            "-",
                            "2",
                            "CI",
                            " is",
                            " a",
                            " Dual",
                            " channel",
                            " 512",
                            "M",
                            " x",
                            " 64",
                            "-",
                            "bit",
                            " 4",
                            "GB",
                            " single",
                            " side",
                            " (",
                            "40",
                            "96",
                            "MB",
                            ")",
                            " x",
                            "2",
                            " DDR",
                            "3",
                            "-",
                            "3",
                            "100",
                            "MHz",
                            " CL",
                            "12",
                            " S",
                            "DR",
                            "AM",
                            "(",
                            "S",
                            "ynchronous",
                            " DR",
                            "AM",
                            ")",
                            " memory",
                            " modules",
                            ",",
                            " based",
                            " on",
                            " eight",
                            " 512",
                            "M",
                            " x",
                            " 8",
                            "\u2013",
                            "bit",
                            " DDR",
                            "3",
                            " FB",
                            "GA",
                            " components",
                            " per",
                            " module",
                            ".",
                            " Each",
                            " module",
                            " kit",
                            " supports",
                            " Intel",
                            " X",
                            "MP",
                            " 1",
                            ".",
                            "3",
                            " (",
                            "Extreme",
                            " Memory",
                            " Prof",
                            "iles",
                            ").",
                            " Total",
                            " kit",
                            " capacity",
                            " is",
                            " 8",
                            "GB",
                            ".",
                            " It",
                            " supports",
                            " newest",
                            " generation",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "73248",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.505,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.505,
                            3.583,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:22.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 42.505,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi8oiduuuw10exivjqdc30",
                        "tokens": [
                            " Google",
                            " apps",
                            " with",
                            " its",
                            " 1",
                            ".",
                            "5",
                            "GHz",
                            " quad",
                            "-",
                            "core",
                            " processor",
                            ",",
                            " and",
                            " 5",
                            ".",
                            "1",
                            " surround",
                            " sound",
                            " lends",
                            " clarity",
                            " to",
                            " business",
                            " calls",
                            " and",
                            " video",
                            " game",
                            " sound",
                            " effects",
                            ".",
                            "\n",
                            "\n",
                            "C",
                            "NET",
                            " Editor",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Choice",
                            " Tablet",
                            "\n",
                            "\n",
                            "C",
                            "NET",
                            " called",
                            " the",
                            " ASUS",
                            " Google",
                            " Nexus",
                            " 7",
                            " \u00e2\u0122",
                            "\u013e",
                            "the",
                            " best",
                            " tablet",
                            " value",
                            " on",
                            " the",
                            " market",
                            "\u00e2\u0122",
                            "\u013f",
                            " because",
                            " of",
                            " its",
                            " HD",
                            " screen",
                            ",",
                            " battery",
                            " life",
                            ",",
                            " and",
                            " speedy",
                            " performance",
                            ".",
                            " The",
                            " latter",
                            " is",
                            " thanks",
                            " to",
                            " the",
                            " quad",
                            "-",
                            "core",
                            " processor",
                            ",",
                            " which",
                            " the",
                            " review",
                            " notes",
                            " helps",
                            " seamlessly",
                            " power",
                            " racing",
                            " games",
                            " and",
                            " create",
                            " \u00e2\u0122",
                            "\u013e",
                            "the",
                            " best",
                            "-",
                            "performing",
                            " small",
                            " tablet",
                            " for",
                            " gaming",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Create",
                            " Kid",
                            "-",
                            "Friend",
                            "ly",
                            " Prof",
                            "iles",
                            " with",
                            " Android",
                            " 4",
                            ".",
                            "3",
                            "\n",
                            "\n",
                            "You",
                            " can"
                        ],
                        "dataIndex": null,
                        "index": "73248",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.245,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.245,
                            2.185,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:22.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 42.505,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "73248",
            "description": "terms related to academic and professional titles, particularly \"professor\" and its variations",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 42.505,
            "frac_nonzero": 4e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "73248",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:02:16.310Z",
                "maxActApprox": 42.505,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    73248,
                    78071,
                    6218,
                    44,
                    82084,
                    83641,
                    46751,
                    10517,
                    98235,
                    92240,
                    76490,
                    94665,
                    81565,
                    7692,
                    76233,
                    4282,
                    56217,
                    25684,
                    73889,
                    1825,
                    35820,
                    35193,
                    83200,
                    44695,
                    65418
                ],
                "topkCosSimValues": [
                    1,
                    0.7921,
                    0.7639,
                    0.6403,
                    0.4589,
                    0.4237,
                    0.422,
                    0.4121,
                    0.3954,
                    0.3942,
                    0.3938,
                    0.3914,
                    0.3823,
                    0.3762,
                    0.3693,
                    0.363,
                    0.3593,
                    0.3561,
                    0.352,
                    0.3519,
                    0.3518,
                    0.3505,
                    0.3504,
                    0.3478,
                    0.3467
                ],
                "neuron_alignment_indices": [
                    575,
                    288,
                    60
                ],
                "neuron_alignment_values": [
                    0.134,
                    0.117,
                    0.115
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    60,
                    631,
                    90
                ],
                "correlated_neurons_pearson": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_neurons_l1": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_features_indices": [
                    73188,
                    73248,
                    73223
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "MENTS",
                    " halfway",
                    "warm",
                    "MENT",
                    " Mali",
                    "doors",
                    "forth",
                    " shortened",
                    " Weir",
                    " Warriors"
                ],
                "neg_values": [
                    -0.837,
                    -0.738,
                    -0.713,
                    -0.674,
                    -0.656,
                    -0.651,
                    -0.65,
                    -0.635,
                    -0.631,
                    -0.609
                ],
                "pos_str": [
                    "essor",
                    "iles",
                    "iciency",
                    "ound",
                    "essors",
                    "iler",
                    "ession",
                    "icient",
                    "iling",
                    "ilers"
                ],
                "pos_values": [
                    1.483,
                    1.343,
                    1.315,
                    1.266,
                    1.262,
                    1.247,
                    1.218,
                    1.178,
                    1.176,
                    1.171
                ],
                "frac_nonzero": 4e-05,
                "freq_hist_data_bar_heights": [
                    18,
                    11,
                    6,
                    2,
                    4,
                    3,
                    1,
                    3,
                    1,
                    1,
                    0,
                    1,
                    0,
                    1,
                    1,
                    2,
                    2,
                    1,
                    3,
                    2,
                    7,
                    4,
                    3,
                    4,
                    2,
                    5,
                    3,
                    2,
                    0,
                    3,
                    3,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    3,
                    3,
                    3,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.456,
                    1.306,
                    2.155,
                    3.004,
                    3.854,
                    4.703,
                    5.553,
                    6.402,
                    7.252,
                    8.101,
                    8.951,
                    9.8,
                    10.65,
                    11.499,
                    12.349,
                    13.198,
                    14.048,
                    14.897,
                    15.746,
                    16.596,
                    17.445,
                    18.295,
                    19.144,
                    19.994,
                    20.843,
                    21.693,
                    22.542,
                    23.392,
                    24.241,
                    25.091,
                    25.94,
                    26.79,
                    27.639,
                    28.488,
                    29.338,
                    30.187,
                    31.037,
                    31.886,
                    32.736,
                    33.585,
                    34.435,
                    35.284,
                    36.134,
                    36.983,
                    37.833,
                    38.682,
                    39.532,
                    40.381,
                    41.23,
                    42.08
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    2,
                    5,
                    16,
                    34,
                    82,
                    193,
                    421,
                    838,
                    1452,
                    2355,
                    3209,
                    4187,
                    4815,
                    5149,
                    4891,
                    4532,
                    3936,
                    3166,
                    2494,
                    1962,
                    1476,
                    1161,
                    906,
                    725,
                    600,
                    449,
                    325,
                    284,
                    197,
                    137,
                    94,
                    60,
                    40,
                    18,
                    14,
                    9,
                    5,
                    2,
                    1,
                    2,
                    3,
                    2,
                    2,
                    2,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.814,
                    -0.768,
                    -0.721,
                    -0.675,
                    -0.628,
                    -0.582,
                    -0.536,
                    -0.489,
                    -0.443,
                    -0.396,
                    -0.35,
                    -0.304,
                    -0.257,
                    -0.211,
                    -0.164,
                    -0.118,
                    -0.072,
                    -0.025,
                    0.021,
                    0.068,
                    0.114,
                    0.16,
                    0.207,
                    0.253,
                    0.3,
                    0.346,
                    0.392,
                    0.439,
                    0.485,
                    0.532,
                    0.578,
                    0.624,
                    0.671,
                    0.717,
                    0.764,
                    0.81,
                    0.857,
                    0.903,
                    0.949,
                    0.996,
                    1.042,
                    1.089,
                    1.135,
                    1.181,
                    1.228,
                    1.274,
                    1.321,
                    1.367,
                    1.413,
                    1.46
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clzdg6euh2wnuv3wqmleshzjm",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "73248",
                        "description": " occurrences of the word \"Prof\" and its variations, indicating references to professors or professional titles",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T01:21:01.097Z",
                        "updatedAt": "2024-08-03T01:21:01.097Z"
                    },
                    {
                        "id": "clze5y1kd3qinv3wq07ss68u7",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "73248",
                        "description": " instances of the term \"prof\" in various contexts, indicating a focus on professional titles or qualifications",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T13:22:20.654Z",
                        "updatedAt": "2024-08-03T13:22:20.654Z"
                    },
                    {
                        "id": "clze84iia3spov3wq7p90d40e",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "73248",
                        "description": "terms related to academic and professional titles, particularly \"professor\" and its variations",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T14:23:21.778Z",
                        "updatedAt": "2024-08-03T14:23:21.778Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi8oifuuvh10extionc3n7",
                        "tokens": [
                            ",",
                            " but",
                            " you",
                            "'re",
                            " here",
                            ",",
                            " so",
                            " you",
                            " better",
                            " f",
                            "------",
                            " deal",
                            " with",
                            " it",
                            ",",
                            " girl",
                            ".\"",
                            "<|endoftext|>",
                            "Overview",
                            "\n",
                            "\n",
                            "A",
                            "VE",
                            "X",
                            "IR",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " A",
                            "VD",
                            "3",
                            "U",
                            "H",
                            "3",
                            "100",
                            "12",
                            "04",
                            "G",
                            "-",
                            "2",
                            "CI",
                            " is",
                            " a",
                            " Dual",
                            " channel",
                            " 512",
                            "M",
                            " x",
                            " 64",
                            "-",
                            "bit",
                            " 4",
                            "GB",
                            " single",
                            " side",
                            " (",
                            "40",
                            "96",
                            "MB",
                            ")",
                            " x",
                            "2",
                            " DDR",
                            "3",
                            "-",
                            "3",
                            "100",
                            "MHz",
                            " CL",
                            "12",
                            " S",
                            "DR",
                            "AM",
                            "(",
                            "S",
                            "ynchronous",
                            " DR",
                            "AM",
                            ")",
                            " memory",
                            " modules",
                            ",",
                            " based",
                            " on",
                            " eight",
                            " 512",
                            "M",
                            " x",
                            " 8",
                            "\u2013",
                            "bit",
                            " DDR",
                            "3",
                            " FB",
                            "GA",
                            " components",
                            " per",
                            " module",
                            ".",
                            " Each",
                            " module",
                            " kit",
                            " supports",
                            " Intel",
                            " X",
                            "MP",
                            " 1",
                            ".",
                            "3",
                            " (",
                            "Extreme",
                            " Memory",
                            " Prof",
                            "iles",
                            ").",
                            " Total",
                            " kit",
                            " capacity",
                            " is",
                            " 8",
                            "GB",
                            ".",
                            " It",
                            " supports",
                            " newest",
                            " generation",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "73248",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.505,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.505,
                            3.583,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:22.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 34.004,
                        "binMax": 42.505,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi8oiduuuv10exnvub6ol3",
                        "tokens": [
                            ",",
                            " but",
                            " you",
                            "'re",
                            " here",
                            ",",
                            " so",
                            " you",
                            " better",
                            " f",
                            "------",
                            " deal",
                            " with",
                            " it",
                            ",",
                            " girl",
                            ".\"",
                            "<|endoftext|>",
                            "Overview",
                            "\n",
                            "\n",
                            "A",
                            "VE",
                            "X",
                            "IR",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " A",
                            "VD",
                            "3",
                            "U",
                            "H",
                            "3",
                            "100",
                            "12",
                            "04",
                            "G",
                            "-",
                            "2",
                            "CI",
                            " is",
                            " a",
                            " Dual",
                            " channel",
                            " 512",
                            "M",
                            " x",
                            " 64",
                            "-",
                            "bit",
                            " 4",
                            "GB",
                            " single",
                            " side",
                            " (",
                            "40",
                            "96",
                            "MB",
                            ")",
                            " x",
                            "2",
                            " DDR",
                            "3",
                            "-",
                            "3",
                            "100",
                            "MHz",
                            " CL",
                            "12",
                            " S",
                            "DR",
                            "AM",
                            "(",
                            "S",
                            "ynchronous",
                            " DR",
                            "AM",
                            ")",
                            " memory",
                            " modules",
                            ",",
                            " based",
                            " on",
                            " eight",
                            " 512",
                            "M",
                            " x",
                            " 8",
                            "\u2013",
                            "bit",
                            " DDR",
                            "3",
                            " FB",
                            "GA",
                            " components",
                            " per",
                            " module",
                            ".",
                            " Each",
                            " module",
                            " kit",
                            " supports",
                            " Intel",
                            " X",
                            "MP",
                            " 1",
                            ".",
                            "3",
                            " (",
                            "Extreme",
                            " Memory",
                            " Prof",
                            "iles",
                            ").",
                            " Total",
                            " kit",
                            " capacity",
                            " is",
                            " 8",
                            "GB",
                            ".",
                            " It",
                            " supports",
                            " newest",
                            " generation",
                            " of"
                        ],
                        "dataIndex": null,
                        "index": "73248",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.505,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.505,
                            3.583,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:22.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 42.505,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi8oiduuuw10exivjqdc30",
                        "tokens": [
                            " Google",
                            " apps",
                            " with",
                            " its",
                            " 1",
                            ".",
                            "5",
                            "GHz",
                            " quad",
                            "-",
                            "core",
                            " processor",
                            ",",
                            " and",
                            " 5",
                            ".",
                            "1",
                            " surround",
                            " sound",
                            " lends",
                            " clarity",
                            " to",
                            " business",
                            " calls",
                            " and",
                            " video",
                            " game",
                            " sound",
                            " effects",
                            ".",
                            "\n",
                            "\n",
                            "C",
                            "NET",
                            " Editor",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Choice",
                            " Tablet",
                            "\n",
                            "\n",
                            "C",
                            "NET",
                            " called",
                            " the",
                            " ASUS",
                            " Google",
                            " Nexus",
                            " 7",
                            " \u00e2\u0122",
                            "\u013e",
                            "the",
                            " best",
                            " tablet",
                            " value",
                            " on",
                            " the",
                            " market",
                            "\u00e2\u0122",
                            "\u013f",
                            " because",
                            " of",
                            " its",
                            " HD",
                            " screen",
                            ",",
                            " battery",
                            " life",
                            ",",
                            " and",
                            " speedy",
                            " performance",
                            ".",
                            " The",
                            " latter",
                            " is",
                            " thanks",
                            " to",
                            " the",
                            " quad",
                            "-",
                            "core",
                            " processor",
                            ",",
                            " which",
                            " the",
                            " review",
                            " notes",
                            " helps",
                            " seamlessly",
                            " power",
                            " racing",
                            " games",
                            " and",
                            " create",
                            " \u00e2\u0122",
                            "\u013e",
                            "the",
                            " best",
                            "-",
                            "performing",
                            " small",
                            " tablet",
                            " for",
                            " gaming",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Create",
                            " Kid",
                            "-",
                            "Friend",
                            "ly",
                            " Prof",
                            "iles",
                            " with",
                            " Android",
                            " 4",
                            ".",
                            "3",
                            "\n",
                            "\n",
                            "You",
                            " can"
                        ],
                        "dataIndex": null,
                        "index": "73248",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.245,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.245,
                            2.185,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:02:22.305Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 42.505,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "16714",
            "description": " references to individuals with the title \"Dr.\" or \"Professor\"",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 40.834,
            "frac_nonzero": 4e-05,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "16714",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:48:40.967Z",
                "maxActApprox": 40.834,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    16714,
                    37380,
                    18227,
                    26166,
                    46858,
                    31060,
                    54579,
                    70169,
                    23720,
                    59967,
                    65479,
                    93068,
                    74052,
                    5032,
                    27593,
                    84779,
                    9144,
                    75035,
                    34934,
                    50336,
                    80068,
                    87694,
                    40690,
                    92710,
                    79920
                ],
                "topkCosSimValues": [
                    1,
                    0.4065,
                    0.4027,
                    0.4002,
                    0.3778,
                    0.377,
                    0.3761,
                    0.3755,
                    0.3497,
                    0.3463,
                    0.3421,
                    0.334,
                    0.3331,
                    0.3289,
                    0.3287,
                    0.3286,
                    0.3237,
                    0.3215,
                    0.3201,
                    0.319,
                    0.3188,
                    0.3135,
                    0.3114,
                    0.3111,
                    0.3104
                ],
                "neuron_alignment_indices": [
                    247,
                    26,
                    288
                ],
                "neuron_alignment_values": [
                    0.114,
                    0.108,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    26,
                    406,
                    46
                ],
                "correlated_neurons_pearson": [
                    0.007,
                    0.007,
                    0.006
                ],
                "correlated_neurons_l1": [
                    0.007,
                    0.007,
                    0.006
                ],
                "correlated_features_indices": [
                    16671,
                    16721,
                    16657
                ],
                "correlated_features_pearson": [
                    0.006,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.006,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    " tremend",
                    "\u012a\u0134",
                    " stocking",
                    "\u00a9\u00b6\u00e6",
                    " mathemat",
                    " sidew",
                    " preval",
                    " princ",
                    " tradem",
                    " governance"
                ],
                "neg_values": [
                    -0.914,
                    -0.84,
                    -0.709,
                    -0.704,
                    -0.691,
                    -0.651,
                    -0.647,
                    -0.641,
                    -0.636,
                    -0.631
                ],
                "pos_str": [
                    "strom",
                    "stown",
                    "TAIN",
                    "ries",
                    "hoff",
                    "bach",
                    "tha",
                    "stein",
                    "lein",
                    "ager"
                ],
                "pos_values": [
                    1.121,
                    1.021,
                    0.881,
                    0.875,
                    0.866,
                    0.858,
                    0.846,
                    0.837,
                    0.82,
                    0.819
                ],
                "frac_nonzero": 4e-05,
                "freq_hist_data_bar_heights": [
                    36,
                    20,
                    14,
                    3,
                    3,
                    3,
                    2,
                    2,
                    2,
                    2,
                    2,
                    0,
                    1,
                    2,
                    1,
                    0,
                    0,
                    0,
                    1,
                    1,
                    2,
                    2,
                    0,
                    4,
                    4,
                    1,
                    3,
                    1,
                    0,
                    2,
                    1,
                    1,
                    0,
                    1,
                    2,
                    4,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    2,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.447,
                    1.263,
                    2.079,
                    2.894,
                    3.71,
                    4.526,
                    5.342,
                    6.158,
                    6.974,
                    7.79,
                    8.606,
                    9.422,
                    10.238,
                    11.053,
                    11.869,
                    12.685,
                    13.501,
                    14.317,
                    15.133,
                    15.949,
                    16.765,
                    17.581,
                    18.397,
                    19.212,
                    20.028,
                    20.844,
                    21.66,
                    22.476,
                    23.292,
                    24.108,
                    24.924,
                    25.74,
                    26.556,
                    27.371,
                    28.187,
                    29.003,
                    29.819,
                    30.635,
                    31.451,
                    32.267,
                    33.083,
                    33.899,
                    34.715,
                    35.531,
                    36.346,
                    37.162,
                    37.978,
                    38.794,
                    39.61,
                    40.426
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    0,
                    0,
                    0,
                    3,
                    6,
                    4,
                    21,
                    33,
                    72,
                    126,
                    278,
                    432,
                    796,
                    1292,
                    1810,
                    2413,
                    3195,
                    3968,
                    4479,
                    4774,
                    4843,
                    4505,
                    4080,
                    3436,
                    2685,
                    1979,
                    1564,
                    1037,
                    745,
                    576,
                    397,
                    245,
                    161,
                    113,
                    64,
                    43,
                    29,
                    16,
                    14,
                    7,
                    6,
                    5,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.893,
                    -0.853,
                    -0.812,
                    -0.771,
                    -0.731,
                    -0.69,
                    -0.649,
                    -0.609,
                    -0.568,
                    -0.527,
                    -0.486,
                    -0.446,
                    -0.405,
                    -0.364,
                    -0.324,
                    -0.283,
                    -0.242,
                    -0.202,
                    -0.161,
                    -0.12,
                    -0.08,
                    -0.039,
                    0.002,
                    0.043,
                    0.083,
                    0.124,
                    0.165,
                    0.205,
                    0.246,
                    0.287,
                    0.327,
                    0.368,
                    0.409,
                    0.45,
                    0.49,
                    0.531,
                    0.572,
                    0.612,
                    0.653,
                    0.694,
                    0.734,
                    0.775,
                    0.816,
                    0.856,
                    0.897,
                    0.938,
                    0.979,
                    1.019,
                    1.06,
                    1.101
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyzxvy7u23ja5q0zk09ali1p",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "16714",
                        "description": "references to individuals associated with medical or academic roles",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-24T14:27:59.531Z",
                        "updatedAt": "2024-07-24T14:27:59.531Z"
                    },
                    {
                        "id": "clzeczwuy4d7av3wq07agbuml",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "16714",
                        "description": " references to individuals with the title \"Dr.\" or \"Professor\"",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-08-03T16:39:45.179Z",
                        "updatedAt": "2024-08-03T16:39:45.179Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfm2ulnywx10exmv0v303k",
                        "tokens": [
                            " H",
                            "ager",
                            ",",
                            " Ph",
                            ".",
                            "D",
                            ".,",
                            " assistant",
                            " professor",
                            " of",
                            " ped",
                            "iatrics",
                            " at",
                            " the",
                            " University",
                            " of",
                            " Maryland",
                            " School",
                            " of",
                            " Medicine",
                            ".",
                            " \"",
                            "This",
                            " paper",
                            " is",
                            " the",
                            " evidence",
                            " that",
                            " it",
                            " works",
                            ",\"",
                            " Dr",
                            ".",
                            " H",
                            "ager",
                            " says",
                            ".",
                            " \"",
                            "Now",
                            ",",
                            " this",
                            " can",
                            " immediately",
                            " be",
                            " used",
                            " by",
                            " any",
                            " social",
                            " service",
                            " agency",
                            " or",
                            " any",
                            " clinic",
                            " to",
                            " more",
                            " quickly",
                            " get",
                            " hungry",
                            " children",
                            " connected",
                            " with",
                            " the",
                            " assistance",
                            " they",
                            " need",
                            " to",
                            " stay",
                            " nour",
                            "ished",
                            ",",
                            " healthy",
                            " and",
                            " development",
                            "ally",
                            " on",
                            " track",
                            ".\"",
                            "\n",
                            "\n",
                            "Hun",
                            "ger",
                            " can",
                            " be",
                            " invisible",
                            " in",
                            " American",
                            " children",
                            " because",
                            " they",
                            " do",
                            " not",
                            " physically",
                            " appear",
                            " skinny",
                            " or",
                            " em",
                            "ac",
                            "iated",
                            ",",
                            " according",
                            " to",
                            " senior",
                            " author",
                            " Ma",
                            "ureen",
                            " Black",
                            ",",
                            " Ph",
                            ".",
                            "D",
                            ".,",
                            " the",
                            " John",
                            " A",
                            ".",
                            " Sch",
                            "oll",
                            ",",
                            " M",
                            ".",
                            "D",
                            ".,",
                            " and",
                            " Mary",
                            " Louise",
                            " Sch",
                            "oll"
                        ],
                        "dataIndex": null,
                        "index": "16714",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.834,
                        "maxValueTokenIndex": 1,
                        "minValue": 0,
                        "values": [
                            0,
                            40.834,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            22.346,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:48:48.571Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 40.834,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfm2ulnywy10exvimjw5mj",
                        "tokens": [
                            " touchdown",
                            ".",
                            " There",
                            " might",
                            " be",
                            " some",
                            " room",
                            " for",
                            " Nor",
                            "fleet",
                            " to",
                            " get",
                            " up",
                            "field",
                            " here",
                            ".",
                            "\n",
                            "\n",
                            "S",
                            "part",
                            "an",
                            " return",
                            " services",
                            " are",
                            " not",
                            " threatening",
                            ".",
                            " RJ",
                            " Shel",
                            "ton",
                            " is",
                            " tr",
                            "und",
                            "ling",
                            " out",
                            " to",
                            " the",
                            " 25",
                            " when",
                            " he",
                            " gets",
                            " a",
                            " kick",
                            " return",
                            " opportunity",
                            ";",
                            " Mac",
                            "gar",
                            "rett",
                            " Kings",
                            " is",
                            " averaging",
                            " about",
                            " seven",
                            " yards",
                            " a",
                            " pop",
                            " on",
                            " pun",
                            "ts",
                            ".",
                            " As",
                            " per",
                            " usual",
                            " Michigan",
                            "'s",
                            " combo",
                            " of",
                            " line",
                            " drives",
                            " from",
                            " H",
                            "ager",
                            "up",
                            " and",
                            " old",
                            "-",
                            "time",
                            "y",
                            " punt",
                            " formations",
                            " could",
                            " offer",
                            " Kings",
                            " a",
                            " highway",
                            " to",
                            " 20",
                            " yard",
                            " returns",
                            "\u2014",
                            "rew",
                            "atching",
                            " the",
                            " Minnesota",
                            " game",
                            " was",
                            " infuri",
                            "ating",
                            " in",
                            " this",
                            " department",
                            ".",
                            "\n",
                            "\n",
                            "Key",
                            " Match",
                            "up",
                            ":",
                            " YOU",
                            " P",
                            "UT",
                            " ELE",
                            "VEN",
                            " GU",
                            "YS",
                            " ON",
                            " THE",
                            " FI",
                            "ELD",
                            " AT",
                            " LE",
                            "AST",
                            " M",
                            "OST",
                            " OF",
                            " THE"
                        ],
                        "dataIndex": null,
                        "index": "16714",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.628,
                        "maxValueTokenIndex": 72,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.628,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:48:48.571Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 40.834,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfm2unnyxi10exo4rw897s",
                        "tokens": [
                            " touchdown",
                            ".",
                            " There",
                            " might",
                            " be",
                            " some",
                            " room",
                            " for",
                            " Nor",
                            "fleet",
                            " to",
                            " get",
                            " up",
                            "field",
                            " here",
                            ".",
                            "\n",
                            "\n",
                            "S",
                            "part",
                            "an",
                            " return",
                            " services",
                            " are",
                            " not",
                            " threatening",
                            ".",
                            " RJ",
                            " Shel",
                            "ton",
                            " is",
                            " tr",
                            "und",
                            "ling",
                            " out",
                            " to",
                            " the",
                            " 25",
                            " when",
                            " he",
                            " gets",
                            " a",
                            " kick",
                            " return",
                            " opportunity",
                            ";",
                            " Mac",
                            "gar",
                            "rett",
                            " Kings",
                            " is",
                            " averaging",
                            " about",
                            " seven",
                            " yards",
                            " a",
                            " pop",
                            " on",
                            " pun",
                            "ts",
                            ".",
                            " As",
                            " per",
                            " usual",
                            " Michigan",
                            "'s",
                            " combo",
                            " of",
                            " line",
                            " drives",
                            " from",
                            " H",
                            "ager",
                            "up",
                            " and",
                            " old",
                            "-",
                            "time",
                            "y",
                            " punt",
                            " formations",
                            " could",
                            " offer",
                            " Kings",
                            " a",
                            " highway",
                            " to",
                            " 20",
                            " yard",
                            " returns",
                            "\u2014",
                            "rew",
                            "atching",
                            " the",
                            " Minnesota",
                            " game",
                            " was",
                            " infuri",
                            "ating",
                            " in",
                            " this",
                            " department",
                            ".",
                            "\n",
                            "\n",
                            "Key",
                            " Match",
                            "up",
                            ":",
                            " YOU",
                            " P",
                            "UT",
                            " ELE",
                            "VEN",
                            " GU",
                            "YS",
                            " ON",
                            " THE",
                            " FI",
                            "ELD",
                            " AT",
                            " LE",
                            "AST",
                            " M",
                            "OST",
                            " OF",
                            " THE"
                        ],
                        "dataIndex": null,
                        "index": "16714",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.628,
                        "maxValueTokenIndex": 72,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.628,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:48:48.571Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 32.667,
                        "binMax": 40.834,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "18146",
            "description": "names of individuals, such as professors or attorneys",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 36.751,
            "frac_nonzero": 0.00169,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "18146",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:08:00.244Z",
                "maxActApprox": 36.751,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    18146,
                    22426,
                    317,
                    8673,
                    10354,
                    3469,
                    14160,
                    11310,
                    15774,
                    3238,
                    1908,
                    24023,
                    12796,
                    21020,
                    2711,
                    19429,
                    1166,
                    20698,
                    8910,
                    20952,
                    15867,
                    8595,
                    6927,
                    1407,
                    15911
                ],
                "topkCosSimValues": [
                    1,
                    0.6327,
                    0.6305,
                    0.5987,
                    0.5955,
                    0.5614,
                    0.5611,
                    0.5435,
                    0.5345,
                    0.5329,
                    0.4488,
                    0.4429,
                    0.4414,
                    0.4221,
                    0.4159,
                    0.4157,
                    0.4138,
                    0.407,
                    0.4052,
                    0.3955,
                    0.392,
                    0.3919,
                    0.3877,
                    0.387,
                    0.3805
                ],
                "neuron_alignment_indices": [
                    420,
                    111,
                    224
                ],
                "neuron_alignment_values": [
                    0.13,
                    0.123,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    111,
                    46,
                    224
                ],
                "correlated_neurons_pearson": [
                    0.064,
                    0.059,
                    0.058
                ],
                "correlated_neurons_l1": [
                    0.06,
                    0.058,
                    0.06
                ],
                "correlated_features_indices": [
                    18089,
                    18129,
                    18059
                ],
                "correlated_features_pearson": [
                    0.013,
                    0.008,
                    0.004
                ],
                "correlated_features_l1": [
                    0.014,
                    0.008,
                    0.004
                ],
                "neg_str": [
                    " Vengeance",
                    "venge",
                    "Spider",
                    "tumblr",
                    "Bound",
                    "\u00e3\u0125\u00bc\u00e3\u0125\u0128\u00e3\u0124\u00a3",
                    "akings",
                    "Santa",
                    "aunt",
                    "\u00e3\u0125\u00bc\u00e3\u0125\u00b3"
                ],
                "neg_values": [
                    -0.689,
                    -0.671,
                    -0.66,
                    -0.651,
                    -0.645,
                    -0.625,
                    -0.608,
                    -0.604,
                    -0.593,
                    -0.593
                ],
                "pos_str": [
                    " believes",
                    " concedes",
                    " explained",
                    " says",
                    " explains",
                    " cites",
                    " oversaw",
                    " advises",
                    " admits",
                    " told"
                ],
                "pos_values": [
                    1.105,
                    1.091,
                    1.06,
                    1.011,
                    1.003,
                    0.998,
                    0.992,
                    0.984,
                    0.969,
                    0.967
                ],
                "frac_nonzero": 0.00169,
                "freq_hist_data_bar_heights": [
                    911,
                    670,
                    500,
                    368,
                    332,
                    286,
                    207,
                    199,
                    183,
                    149,
                    109,
                    114,
                    89,
                    103,
                    93,
                    85,
                    82,
                    74,
                    84,
                    49,
                    69,
                    53,
                    49,
                    44,
                    35,
                    33,
                    36,
                    41,
                    31,
                    34,
                    14,
                    22,
                    18,
                    26,
                    17,
                    18,
                    16,
                    12,
                    4,
                    16,
                    7,
                    8,
                    8,
                    5,
                    7,
                    5,
                    1,
                    4,
                    2,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.368,
                    1.103,
                    1.838,
                    2.573,
                    3.308,
                    4.043,
                    4.778,
                    5.513,
                    6.248,
                    6.983,
                    7.718,
                    8.453,
                    9.188,
                    9.923,
                    10.658,
                    11.393,
                    12.128,
                    12.863,
                    13.598,
                    14.333,
                    15.068,
                    15.803,
                    16.538,
                    17.273,
                    18.008,
                    18.743,
                    19.478,
                    20.213,
                    20.948,
                    21.683,
                    22.418,
                    23.153,
                    23.888,
                    24.623,
                    25.358,
                    26.093,
                    26.828,
                    27.563,
                    28.298,
                    29.033,
                    29.768,
                    30.503,
                    31.238,
                    31.973,
                    32.708,
                    33.443,
                    34.178,
                    34.913,
                    35.648,
                    36.383
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    3,
                    9,
                    14,
                    37,
                    58,
                    85,
                    172,
                    298,
                    478,
                    768,
                    1127,
                    1687,
                    2320,
                    2870,
                    3606,
                    3992,
                    4189,
                    4349,
                    4093,
                    3784,
                    3308,
                    2845,
                    2296,
                    1840,
                    1401,
                    1075,
                    820,
                    650,
                    478,
                    372,
                    285,
                    206,
                    159,
                    121,
                    120,
                    84,
                    73,
                    40,
                    25,
                    30,
                    16,
                    22,
                    17,
                    11,
                    10,
                    5,
                    3,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.671,
                    -0.635,
                    -0.599,
                    -0.564,
                    -0.528,
                    -0.492,
                    -0.456,
                    -0.42,
                    -0.384,
                    -0.348,
                    -0.312,
                    -0.276,
                    -0.241,
                    -0.205,
                    -0.169,
                    -0.133,
                    -0.097,
                    -0.061,
                    -0.025,
                    0.011,
                    0.046,
                    0.082,
                    0.118,
                    0.154,
                    0.19,
                    0.226,
                    0.262,
                    0.298,
                    0.333,
                    0.369,
                    0.405,
                    0.441,
                    0.477,
                    0.513,
                    0.549,
                    0.585,
                    0.62,
                    0.656,
                    0.692,
                    0.728,
                    0.764,
                    0.8,
                    0.836,
                    0.872,
                    0.908,
                    0.943,
                    0.979,
                    1.015,
                    1.051,
                    1.087
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clynz2eucgbdpj7a1tz7hjmfw",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs24576-jb",
                        "index": "18146",
                        "description": "names of individuals, such as professors or attorneys",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-3.5-turbo",
                        "createdAt": "2024-07-16T05:27:46.596Z",
                        "updatedAt": "2024-07-16T05:27:46.596Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmu9emh8uui666k9o8omxz",
                        "tokens": [
                            " the",
                            " United",
                            " States",
                            ".",
                            "\n",
                            "\n",
                            "P",
                            "om",
                            "ace",
                            " oil",
                            " is",
                            " extracted",
                            " from",
                            " olive",
                            " pulp",
                            " left",
                            "-",
                            "over",
                            " from",
                            " the",
                            " production",
                            " of",
                            " higher",
                            " quality",
                            " oils",
                            " using",
                            " chemical",
                            " sol",
                            "v",
                            "ents",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            " costs",
                            " about",
                            " a",
                            " tenth",
                            " of",
                            " the",
                            " Italian",
                            " made",
                            " extra",
                            " virgin",
                            " variety",
                            ",",
                            " which",
                            " sells",
                            " at",
                            " about",
                            " 10",
                            " euro",
                            " a",
                            " liter",
                            ",",
                            " according",
                            " to",
                            " David",
                            " Gran",
                            "ieri",
                            ",",
                            " the",
                            " head",
                            " of",
                            " Italian",
                            " olive",
                            " growers",
                            "\u00e2\u0122",
                            "\u013b",
                            " association",
                            " UN",
                            "AP",
                            "R",
                            "OL",
                            ".",
                            "\n",
                            "\n",
                            "G",
                            "ran",
                            "ieri",
                            " said",
                            " counterfeit",
                            " food",
                            " products",
                            " posed",
                            " health",
                            " risks",
                            ",",
                            " as",
                            " they",
                            " might",
                            " contain",
                            " allerg",
                            "ens",
                            " not",
                            " indicated",
                            " on",
                            " the",
                            " label",
                            ",",
                            " and",
                            " damaged",
                            " the",
                            " reputation",
                            " of",
                            " Italian",
                            " delic",
                            "acies",
                            ".",
                            "\n",
                            "\n",
                            "Honest",
                            " producers",
                            ",",
                            " who",
                            " rely",
                            " on",
                            " a",
                            " perception",
                            " of",
                            " luxury",
                            " to",
                            " sell",
                            " at",
                            " higher",
                            " prices",
                            " aboard"
                        ],
                        "dataIndex": null,
                        "index": "18146",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.751,
                        "maxValueTokenIndex": 79,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.496,
                            36.751,
                            1.261,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:08:06.788Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.751,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmu9emh8uvi666x8tcz2g2",
                        "tokens": [
                            " was",
                            " once",
                            " part",
                            " of",
                            " Cape",
                            " Canaveral",
                            " rocket",
                            " range",
                            " in",
                            " Florida",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " telescope",
                            " points",
                            " at",
                            " the",
                            " sky",
                            ",",
                            " providing",
                            " what",
                            " the",
                            " US",
                            " calls",
                            " \u00e2\u0122",
                            "\u013e",
                            "space",
                            " situational",
                            " awareness",
                            "\u00e2\u0122",
                            "\u013f",
                            ".",
                            " The",
                            " rationale",
                            " is",
                            " that",
                            " it",
                            " will",
                            " find",
                            " space",
                            " junk",
                            ",",
                            " as",
                            " in",
                            " the",
                            " movie",
                            " Gravity",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " its",
                            " primary",
                            " purpose",
                            " will",
                            " be",
                            " looking",
                            " for",
                            " where",
                            " adversaries",
                            "\u00e2\u0122",
                            "\u013b",
                            " satellites",
                            " are",
                            " in",
                            " space",
                            " and",
                            " what",
                            " they",
                            " do",
                            ",",
                            " says",
                            " Professor",
                            " Richard",
                            " Tan",
                            "ter",
                            " from",
                            " the",
                            " School",
                            " of",
                            " Political",
                            " and",
                            " Social",
                            " Studies",
                            " at",
                            " the",
                            " University",
                            " of",
                            " Melbourne",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " a",
                            " country",
                            " like",
                            " Russia",
                            ",",
                            " for",
                            " example",
                            ",",
                            " was",
                            " hiding",
                            " a",
                            " satellite",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " purpose",
                            ",",
                            " the",
                            " US",
                            " might",
                            " photograph",
                            " or",
                            " neutral",
                            "ise",
                            " it",
                            ".",
                            "\n",
                            "\n",
                            "Professor",
                            " Tan",
                            "ter",
                            " warns",
                            " Australia"
                        ],
                        "dataIndex": null,
                        "index": "18146",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.429,
                        "maxValueTokenIndex": 124,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.458,
                            14.049,
                            36.429,
                            2.36,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:08:06.788Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.751,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmu9eoh8vei66683gwf310",
                        "tokens": [
                            " was",
                            " once",
                            " part",
                            " of",
                            " Cape",
                            " Canaveral",
                            " rocket",
                            " range",
                            " in",
                            " Florida",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " telescope",
                            " points",
                            " at",
                            " the",
                            " sky",
                            ",",
                            " providing",
                            " what",
                            " the",
                            " US",
                            " calls",
                            " \u00e2\u0122",
                            "\u013e",
                            "space",
                            " situational",
                            " awareness",
                            "\u00e2\u0122",
                            "\u013f",
                            ".",
                            " The",
                            " rationale",
                            " is",
                            " that",
                            " it",
                            " will",
                            " find",
                            " space",
                            " junk",
                            ",",
                            " as",
                            " in",
                            " the",
                            " movie",
                            " Gravity",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " its",
                            " primary",
                            " purpose",
                            " will",
                            " be",
                            " looking",
                            " for",
                            " where",
                            " adversaries",
                            "\u00e2\u0122",
                            "\u013b",
                            " satellites",
                            " are",
                            " in",
                            " space",
                            " and",
                            " what",
                            " they",
                            " do",
                            ",",
                            " says",
                            " Professor",
                            " Richard",
                            " Tan",
                            "ter",
                            " from",
                            " the",
                            " School",
                            " of",
                            " Political",
                            " and",
                            " Social",
                            " Studies",
                            " at",
                            " the",
                            " University",
                            " of",
                            " Melbourne",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " a",
                            " country",
                            " like",
                            " Russia",
                            ",",
                            " for",
                            " example",
                            ",",
                            " was",
                            " hiding",
                            " a",
                            " satellite",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " purpose",
                            ",",
                            " the",
                            " US",
                            " might",
                            " photograph",
                            " or",
                            " neutral",
                            "ise",
                            " it",
                            ".",
                            "\n",
                            "\n",
                            "Professor",
                            " Tan",
                            "ter",
                            " warns",
                            " Australia"
                        ],
                        "dataIndex": null,
                        "index": "18146",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.429,
                        "maxValueTokenIndex": 124,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.458,
                            14.049,
                            36.429,
                            2.36,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:08:06.788Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 29.401,
                        "binMax": 36.751,
                        "binContains": 2e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "6631",
            "description": "references to individuals with the title 'Dr.' or 'Professor.'",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "maxActApprox": 35.826,
            "frac_nonzero": 0.0001,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "6631",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:36:54.106Z",
                "maxActApprox": 35.826,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    6631,
                    63942,
                    16928,
                    43428,
                    64615,
                    15910,
                    39944,
                    22480,
                    23201,
                    87721,
                    59949,
                    58155,
                    85044,
                    45745,
                    68170,
                    37132,
                    49200,
                    80965,
                    47722,
                    63645,
                    35905,
                    92218,
                    39437,
                    97306,
                    85042
                ],
                "topkCosSimValues": [
                    1,
                    0.6906,
                    0.6289,
                    0.581,
                    0.5491,
                    0.5475,
                    0.5458,
                    0.5397,
                    0.5255,
                    0.5245,
                    0.5222,
                    0.5213,
                    0.5151,
                    0.5052,
                    0.4999,
                    0.4882,
                    0.4782,
                    0.4729,
                    0.4657,
                    0.456,
                    0.4544,
                    0.4539,
                    0.4535,
                    0.443,
                    0.4365
                ],
                "neuron_alignment_indices": [
                    373,
                    55,
                    182
                ],
                "neuron_alignment_values": [
                    0.141,
                    0.096,
                    0.096
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    659,
                    232,
                    155
                ],
                "correlated_neurons_pearson": [
                    0.014,
                    0.014,
                    0.013
                ],
                "correlated_neurons_l1": [
                    0.014,
                    0.014,
                    0.014
                ],
                "correlated_features_indices": [
                    6534,
                    6631,
                    6589
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "Reviewer",
                    "LEASE",
                    "SIGN",
                    " precon",
                    " Gleaming",
                    " confidentiality",
                    "CLASSIFIED",
                    "FAULT",
                    " satellite",
                    "REDACTED"
                ],
                "neg_values": [
                    -0.806,
                    -0.714,
                    -0.642,
                    -0.634,
                    -0.621,
                    -0.612,
                    -0.593,
                    -0.581,
                    -0.577,
                    -0.574
                ],
                "pos_str": [
                    "ources",
                    "inki",
                    "linger",
                    "aurus",
                    "wered",
                    "idy",
                    "angu",
                    "ued",
                    "acks",
                    "arah"
                ],
                "pos_values": [
                    0.991,
                    0.916,
                    0.914,
                    0.907,
                    0.905,
                    0.904,
                    0.885,
                    0.866,
                    0.861,
                    0.857
                ],
                "frac_nonzero": 0.0001,
                "freq_hist_data_bar_heights": [
                    70,
                    39,
                    34,
                    19,
                    13,
                    19,
                    10,
                    8,
                    5,
                    5,
                    4,
                    5,
                    2,
                    3,
                    3,
                    10,
                    3,
                    1,
                    0,
                    2,
                    3,
                    2,
                    4,
                    4,
                    3,
                    2,
                    5,
                    2,
                    4,
                    3,
                    2,
                    0,
                    2,
                    3,
                    1,
                    3,
                    3,
                    3,
                    4,
                    0,
                    1,
                    2,
                    2,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.367,
                    1.083,
                    1.8,
                    2.516,
                    3.232,
                    3.949,
                    4.665,
                    5.381,
                    6.098,
                    6.814,
                    7.53,
                    8.247,
                    8.963,
                    9.679,
                    10.396,
                    11.112,
                    11.828,
                    12.545,
                    13.261,
                    13.977,
                    14.694,
                    15.41,
                    16.127,
                    16.843,
                    17.559,
                    18.276,
                    18.992,
                    19.708,
                    20.425,
                    21.141,
                    21.857,
                    22.574,
                    23.29,
                    24.006,
                    24.723,
                    25.439,
                    26.155,
                    26.872,
                    27.588,
                    28.304,
                    29.021,
                    29.737,
                    30.453,
                    31.17,
                    31.886,
                    32.602,
                    33.319,
                    34.035,
                    34.752,
                    35.468
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    0,
                    2,
                    3,
                    12,
                    19,
                    30,
                    62,
                    118,
                    220,
                    373,
                    680,
                    1009,
                    1497,
                    2114,
                    2789,
                    3413,
                    4034,
                    4302,
                    4383,
                    4237,
                    4045,
                    3532,
                    3027,
                    2349,
                    1809,
                    1407,
                    1130,
                    801,
                    632,
                    510,
                    400,
                    306,
                    250,
                    212,
                    121,
                    119,
                    99,
                    80,
                    49,
                    26,
                    25,
                    12,
                    4,
                    6,
                    6,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.788,
                    -0.752,
                    -0.716,
                    -0.68,
                    -0.644,
                    -0.609,
                    -0.573,
                    -0.537,
                    -0.501,
                    -0.465,
                    -0.429,
                    -0.393,
                    -0.357,
                    -0.321,
                    -0.285,
                    -0.249,
                    -0.213,
                    -0.177,
                    -0.141,
                    -0.105,
                    -0.069,
                    -0.033,
                    0.002,
                    0.038,
                    0.074,
                    0.11,
                    0.146,
                    0.182,
                    0.218,
                    0.254,
                    0.29,
                    0.326,
                    0.362,
                    0.398,
                    0.434,
                    0.47,
                    0.506,
                    0.542,
                    0.578,
                    0.614,
                    0.649,
                    0.685,
                    0.721,
                    0.757,
                    0.793,
                    0.829,
                    0.865,
                    0.901,
                    0.937,
                    0.973
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "id": "clyzrlgfx1wx05q0zrsn9gwnh",
                        "modelId": "gpt2-small",
                        "layer": "8-res_fs98304-jb",
                        "index": "6631",
                        "description": "references to individuals with the title 'Dr.' or 'Professor.'",
                        "authorId": "clsxqq2xd0000vvp2k5itlhqj",
                        "triggeredByUserId": "cljgamm90000076zdchicy6zj",
                        "notes": null,
                        "scoreV1": 0,
                        "scoreV2": null,
                        "umap_x": 0,
                        "umap_y": 0,
                        "umap_cluster": 0,
                        "umap_log_feature_sparsity": 0,
                        "typeName": "oai_token-act-pair",
                        "explanationModelName": "gpt-4o-mini",
                        "createdAt": "2024-07-24T11:31:52.239Z",
                        "updatedAt": "2024-07-24T11:31:52.239Z"
                    }
                ],
                "activations": [
                    {
                        "id": "clygf6x51gc9410exofu1z7dl",
                        "tokens": [
                            " is",
                            " wonderful",
                            ".",
                            " Each",
                            " day",
                            " God",
                            " leads",
                            " me",
                            " closer",
                            " and",
                            " closer",
                            " to",
                            " freedom",
                            ".",
                            "<|endoftext|>",
                            "S",
                            "ING",
                            "AP",
                            "ORE",
                            " -",
                            " Twenty",
                            " fighter",
                            " jets",
                            " cut",
                            " through",
                            " the",
                            " Marina",
                            " South",
                            " skyline",
                            " in",
                            " the",
                            " shape",
                            " of",
                            " the",
                            " num",
                            "eral",
                            " \"",
                            "50",
                            "\"",
                            " on",
                            " Thursday",
                            " (",
                            "Sept",
                            " 7",
                            "),",
                            " ca",
                            "pping",
                            " off",
                            " one",
                            " of",
                            " the",
                            " highlights",
                            " of",
                            " the",
                            " golden",
                            " j",
                            "ub",
                            "ilee",
                            " celebrations",
                            " between",
                            " Singapore",
                            " and",
                            " Indonesia",
                            ".",
                            "\n",
                            "\n",
                            "Prime",
                            " Minister",
                            " Lee",
                            " H",
                            "s",
                            "ien",
                            " Lo",
                            "ong",
                            " and",
                            " Indonesia",
                            " President",
                            " J",
                            "oko",
                            " Wid",
                            "odo",
                            " were",
                            " at",
                            " Marina",
                            " Bay",
                            " Cruise",
                            " Centre",
                            " to",
                            " witness",
                            " the",
                            " fly",
                            "-",
                            "past",
                            ",",
                            " which",
                            " was",
                            " conducted",
                            " by",
                            " the",
                            " air",
                            " forces",
                            " from",
                            " each",
                            " side",
                            " to",
                            " mark",
                            " 50",
                            " years",
                            " of",
                            " diplomatic",
                            " relations",
                            " between",
                            " the",
                            " two",
                            " neighbours",
                            ".",
                            "\n",
                            "\n",
                            "Building",
                            " on",
                            " the",
                            " strong",
                            " defence",
                            " ties",
                            ",",
                            " Defence",
                            " Minister"
                        ],
                        "dataIndex": null,
                        "index": "6631",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 35.826,
                        "maxValueTokenIndex": 70,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.826,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:37:01.345Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 28.661,
                        "binMax": 35.826,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf6x4zgc8j10exgqjvgfb9",
                        "tokens": [
                            " is",
                            " wonderful",
                            ".",
                            " Each",
                            " day",
                            " God",
                            " leads",
                            " me",
                            " closer",
                            " and",
                            " closer",
                            " to",
                            " freedom",
                            ".",
                            "<|endoftext|>",
                            "S",
                            "ING",
                            "AP",
                            "ORE",
                            " -",
                            " Twenty",
                            " fighter",
                            " jets",
                            " cut",
                            " through",
                            " the",
                            " Marina",
                            " South",
                            " skyline",
                            " in",
                            " the",
                            " shape",
                            " of",
                            " the",
                            " num",
                            "eral",
                            " \"",
                            "50",
                            "\"",
                            " on",
                            " Thursday",
                            " (",
                            "Sept",
                            " 7",
                            "),",
                            " ca",
                            "pping",
                            " off",
                            " one",
                            " of",
                            " the",
                            " highlights",
                            " of",
                            " the",
                            " golden",
                            " j",
                            "ub",
                            "ilee",
                            " celebrations",
                            " between",
                            " Singapore",
                            " and",
                            " Indonesia",
                            ".",
                            "\n",
                            "\n",
                            "Prime",
                            " Minister",
                            " Lee",
                            " H",
                            "s",
                            "ien",
                            " Lo",
                            "ong",
                            " and",
                            " Indonesia",
                            " President",
                            " J",
                            "oko",
                            " Wid",
                            "odo",
                            " were",
                            " at",
                            " Marina",
                            " Bay",
                            " Cruise",
                            " Centre",
                            " to",
                            " witness",
                            " the",
                            " fly",
                            "-",
                            "past",
                            ",",
                            " which",
                            " was",
                            " conducted",
                            " by",
                            " the",
                            " air",
                            " forces",
                            " from",
                            " each",
                            " side",
                            " to",
                            " mark",
                            " 50",
                            " years",
                            " of",
                            " diplomatic",
                            " relations",
                            " between",
                            " the",
                            " two",
                            " neighbours",
                            ".",
                            "\n",
                            "\n",
                            "Building",
                            " on",
                            " the",
                            " strong",
                            " defence",
                            " ties",
                            ",",
                            " Defence",
                            " Minister"
                        ],
                        "dataIndex": null,
                        "index": "6631",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 35.826,
                        "maxValueTokenIndex": 70,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.826,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:37:01.345Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 35.826,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf6x4zgc8k10exdqr2h8ki",
                        "tokens": [
                            " that",
                            " the",
                            " Republic",
                            " of",
                            " China",
                            " also",
                            " had",
                            " designed",
                            " devices",
                            " suitable",
                            " for",
                            " nuclear",
                            " testing",
                            ".[",
                            "7",
                            "]",
                            "\n",
                            "\n",
                            "A",
                            " secret",
                            " program",
                            " was",
                            " revealed",
                            " when",
                            " Colonel",
                            " Chang",
                            " H",
                            "s",
                            "ien",
                            "-",
                            "yi",
                            ",",
                            " deputy",
                            " director",
                            " of",
                            " nuclear",
                            " research",
                            " at",
                            " IN",
                            "ER",
                            ",",
                            " who",
                            " was",
                            " secretly",
                            " working",
                            " for",
                            " the",
                            " CIA",
                            ",",
                            " def",
                            "ected",
                            " to",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " in",
                            " December",
                            " 1987",
                            " and",
                            " produced",
                            " a",
                            " cache",
                            " of",
                            " incrim",
                            "inating",
                            " documents",
                            ".",
                            " General",
                            " Hau",
                            " Pe",
                            "i",
                            "-",
                            "ts",
                            "un",
                            " claimed",
                            " that",
                            " scientists",
                            " in",
                            " Taiwan",
                            " had",
                            " already",
                            " produced",
                            " a",
                            " controlled",
                            " nuclear",
                            " reaction",
                            ".",
                            " Under",
                            " pressure",
                            " from",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".,",
                            " the",
                            " program",
                            " was",
                            " halted",
                            ".",
                            " A",
                            " study",
                            " into",
                            " the",
                            " secret",
                            " program",
                            " concluded",
                            " that",
                            " at",
                            " the",
                            " time",
                            " of",
                            " Chang",
                            "'s",
                            " def",
                            "ection",
                            ",",
                            " Taiwan",
                            " was",
                            " one",
                            " or",
                            " two",
                            " years",
                            " away",
                            " from"
                        ],
                        "dataIndex": null,
                        "index": "6631",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 31.791,
                        "maxValueTokenIndex": 27,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            31.791,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:37:01.345Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 35.826,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}