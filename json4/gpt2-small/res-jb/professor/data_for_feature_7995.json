{
    "modelId": "gpt2-small",
    "layer": "8-res-jb",
    "index": "7995",
    "sourceSetName": "res-jb",
    "creatorId": null,
    "createdAt": "2024-02-12T00:52:28.630Z",
    "maxActApprox": 68.31184387207031,
    "hasVector": false,
    "vector": [],
    "vectorLabel": null,
    "vectorDefaultSteerStrength": 10,
    "hookName": null,
    "topkCosSimIndices": [
        7995,
        20336,
        15173,
        14903,
        22502,
        17958,
        23890,
        9036,
        13209,
        16226,
        6853,
        2331,
        21202,
        8932,
        3696,
        7151,
        14465,
        8210,
        6985,
        22312,
        23492,
        6414,
        5218,
        7648,
        1692
    ],
    "topkCosSimValues": [
        1,
        0.3926,
        0.3855,
        0.3665,
        0.3495,
        0.3394,
        0.3348,
        0.3325,
        0.3305,
        0.3291,
        0.3248,
        0.3223,
        0.3155,
        0.3132,
        0.3125,
        0.3116,
        0.3077,
        0.303,
        0.303,
        0.3024,
        0.3008,
        0.3002,
        0.2969,
        0.2955,
        0.2951
    ],
    "neuron_alignment_indices": [
        679,
        60,
        90
    ],
    "neuron_alignment_values": [
        0.1117744222283363,
        0.1097646579146385,
        0.09373867511749268
    ],
    "neuron_alignment_l1": [
        0.005056462716311216,
        0.004965544678270817,
        0.004240559414029121
    ],
    "correlated_neurons_indices": [
        60,
        631,
        90
    ],
    "correlated_neurons_pearson": [
        0.01671955548226833,
        0.01409142091870308,
        0.0140461279079318
    ],
    "correlated_neurons_l1": [
        0.01632600463926792,
        0.01441285759210587,
        0.01430362928658724
    ],
    "correlated_features_indices": [],
    "correlated_features_pearson": [],
    "correlated_features_l1": [],
    "neg_str": [
        "warm",
        "MENTS",
        "forth",
        "doors",
        " halfway",
        "MENT",
        "nuts",
        "wolves",
        " Nou",
        "boat"
    ],
    "neg_values": [
        -0.8416074514389038,
        -0.8137954473495483,
        -0.7317383885383606,
        -0.726430356502533,
        -0.6838328838348389,
        -0.650086522102356,
        -0.622291088104248,
        -0.6158881187438965,
        -0.6119778752326965,
        -0.6063485145568848
    ],
    "pos_str": [
        "essor",
        "iles",
        "iler",
        "iciency",
        "ilers",
        "essors",
        "iled",
        "ession",
        "icient",
        "iling"
    ],
    "pos_values": [
        1.363836646080017,
        1.328406453132629,
        1.280909657478333,
        1.265554189682007,
        1.249772071838379,
        1.22450578212738,
        1.194715738296509,
        1.137630581855774,
        1.135065197944641,
        1.100906133651733
    ],
    "frac_nonzero": 0.0002622604370117188,
    "freq_hist_data_bar_heights": [
        373,
        210,
        104,
        33,
        12,
        5,
        1,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        2,
        1,
        2,
        1,
        3,
        2,
        2,
        4,
        4,
        3,
        0,
        6,
        3,
        7,
        4,
        5,
        3,
        6,
        2,
        3,
        5,
        5,
        11,
        2
    ],
    "freq_hist_data_bar_values": [
        0.8628542423248291,
        2.570423603057861,
        4.277992725372314,
        5.985562324523926,
        7.693131446838379,
        9.400700569152832,
        11.1082706451416,
        12.81583976745605,
        14.52340888977051,
        16.23097801208496,
        17.93854713439941,
        19.64611625671387,
        21.35368728637695,
        23.06125640869141,
        24.76882553100586,
        26.47639465332031,
        28.18396377563477,
        29.89153289794922,
        31.59910202026367,
        33.30667495727539,
        35.01424407958984,
        36.7218132019043,
        38.42938232421875,
        40.1369514465332,
        41.84452056884766,
        43.55208969116211,
        45.25965881347656,
        46.96722793579102,
        48.67479705810547,
        50.38236618041992,
        52.08993911743164,
        53.79750442504883,
        55.50507736206055,
        57.21264266967773,
        58.92021560668945,
        60.62778472900391,
        62.33535385131836,
        64.04292297363281,
        65.75048828125,
        67.45805358886719
    ],
    "logits_hist_data_bar_heights": [
        2,
        1,
        2,
        2,
        12,
        37,
        74,
        195,
        533,
        1047,
        2156,
        3503,
        4975,
        6193,
        6741,
        6206,
        5409,
        4132,
        2836,
        1944,
        1336,
        941,
        632,
        473,
        304,
        222,
        155,
        88,
        38,
        27,
        14,
        5,
        6,
        3,
        2,
        4,
        1,
        2,
        2,
        2
    ],
    "logits_hist_data_bar_values": [
        -0.814039409160614,
        -0.7589033246040344,
        -0.7037671804428101,
        -0.6486310958862305,
        -0.5934950113296509,
        -0.5383588671684265,
        -0.4832227826118469,
        -0.4280866980552673,
        -0.3729505836963654,
        -0.3178144693374634,
        -0.2626783847808838,
        -0.207542285323143,
        -0.1524061411619186,
        -0.09727006405591965,
        -0.04213397949934006,
        0.01300216652452946,
        0.0681382492184639,
        0.1232743337750435,
        0.1784104853868484,
        0.233546569943428,
        0.2886826395988464,
        0.343818724155426,
        0.3989548087120056,
        0.45409095287323,
        0.5092270374298096,
        0.5643631219863892,
        0.6194992661476135,
        0.6746353507041931,
        0.7297714352607727,
        0.7849075794219971,
        0.8400436639785767,
        0.8951797485351562,
        0.9503158926963806,
        1.005452036857605,
        1.060588121414185,
        1.115724205970764,
        1.170860290527344,
        1.225996494293213,
        1.281132578849792,
        1.336268663406372
    ],
    "decoder_weights_dist": [],
    "umap_cluster": null,
    "umap_log_feature_sparsity": null,
    "umap_x": null,
    "umap_y": null,
    "model": {
        "id": "gpt2-small",
        "displayNameShort": "GPT2-SM",
        "displayName": "GPT2-Small",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "tlensId": null,
        "dimension": 768,
        "visibility": "PUBLIC",
        "inferenceEnabled": true,
        "instruct": false,
        "layers": 12,
        "neuronsPerLayer": 3072,
        "createdAt": "2023-07-06T00:01:44.843Z",
        "owner": "OpenAI",
        "updatedAt": "2023-07-06T00:01:44.843Z",
        "website": "https://openai.com"
    },
    "lists": [],
    "creator": null,
    "source": {
        "id": "8-res-jb",
        "modelId": "gpt2-small",
        "hasDashboards": true,
        "inferenceEnabled": true,
        "saelensConfig": {
            "lr": 0.0004,
            "d_in": 768,
            "seed": 42,
            "d_sae": 24576,
            "dtype": "torch.float32",
            "device": "mps",
            "run_name": "24576-L1-8e-05-LR-0.0004-Tokens-3.000e+08",
            "hook_point": "blocks.8.hook_resid_pre",
            "model_name": "gpt2-small",
            "prepend_bos": true,
            "architecture": "standard",
            "context_size": 128,
            "dataset_path": "Skylion007/openwebtext",
            "log_to_wandb": true,
            "wandb_entity": null,
            "n_checkpoints": 10,
            "wandb_project": "mats_sae_training_gpt2_small_resid_pre_5",
            "l1_coefficient": 8e-05,
            "neuronpedia_id": "gpt2-small/8-res-jb",
            "checkpoint_path": "checkpoints/ut7lhl4q",
            "use_ghost_grads": false,
            "expansion_factor": 32,
            "hook_point_layer": 8,
            "lr_warm_up_steps": 5000,
            "resample_batches": 1028,
            "store_batch_size": 32,
            "train_batch_size": 4096,
            "activation_fn_str": "relu",
            "b_dec_init_method": "geometric_median",
            "lr_scheduler_name": null,
            "tokens_per_buffer": 67108864,
            "dead_feature_window": 5000,
            "n_batches_in_buffer": 128,
            "wandb_log_frequency": 100,
            "apply_b_dec_to_input": true,
            "feature_reinit_scale": 0.2,
            "from_pretrained_path": null,
            "is_dataset_tokenized": false,
            "hook_point_head_index": null,
            "normalize_activations": "none",
            "total_training_tokens": 300000000,
            "dead_feature_threshold": 1e-08,
            "use_cached_activations": false,
            "cached_activations_path": "activations/Skylion007_openwebtext/gpt2-small/blocks.8.hook_resid_pre",
            "feature_sampling_method": null,
            "feature_sampling_window": 1000,
            "dataset_trust_remote_code": true,
            "finetuning_scaling_factor": false,
            "sae_lens_training_version": null,
            "model_from_pretrained_kwargs": {
                "center_writing_weights": true
            },
            "dead_feature_estimation_method": "no_fire"
        },
        "saelensRelease": "gpt2-small-res-jb",
        "saelensSaeId": "blocks.8.hook_resid_pre",
        "hfRepoId": "jbloom/GPT2-Small-SAEs-Reformatted",
        "hfFolderId": "blocks.8.hook_resid_pre",
        "visibility": "PUBLIC",
        "setName": "res-jb",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "hasUmap": true,
        "hasUmapLogSparsity": true,
        "hasUmapClusters": true,
        "num_prompts": 24576,
        "num_tokens_in_prompt": 128,
        "dataset": "Skylion007/openwebtext",
        "notes": null,
        "createdAt": "2024-07-10T04:46:32.069Z"
    },
    "sourceSet": {
        "modelId": "gpt2-small",
        "name": "res-jb",
        "hasDashboards": true,
        "visibility": "PUBLIC",
        "description": "Open Source Sparse Autoencoders for all Residual Stream Layers of GPT2-Small",
        "type": "Residual Stream",
        "creatorName": "Joseph Bloom",
        "urls": [
            "https://www.lesswrong.com/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream",
            "https://huggingface.co/jbloom/GPT2-Small-SAEs/tree/main",
            "https://github.com/jbloomAus/mats_sae_training"
        ],
        "creatorEmail": null,
        "creatorId": "cljgamm90000076zdchicy6zj",
        "releaseName": "gpt2sm-res-jb",
        "defaultRange": 2,
        "defaultShowBreaks": true,
        "showDfa": false,
        "showCorrelated": false,
        "showHeadAttribution": false,
        "showUmap": true,
        "createdAt": "2024-07-10T04:46:32.075Z"
    },
    "activations": [
        {
            "id": "clsi7zj2q6iwtwf4rm7sp1eui",
            "tokens": [
                "ity",
                " on",
                " American",
                " soil",
                " would",
                " truly",
                " be",
                " a",
                " prof",
                "an",
                "ation",
                ".",
                " Though",
                " obviously",
                " not",
                " comparable",
                " to"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 68.31184387207031,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                68.31184387207031,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.588223457336426,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iciency\", \"essor\", \"essors\", \"iles\", \"ilers\"], \"v\": [12.306440353393555, 12.009428024291992, 11.694926261901855, 11.683692932128906, 10.753402709960938]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \" halfway\", \"boat\", \"doors\", \"MENTS\"], \"v\": [-25.297731399536133, -24.01919174194336, -23.61381721496582, -23.53569984436035, -22.882349014282227]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2q6iwuwf4ro7iu3uwv",
            "tokens": [
                " morning",
                " causing",
                " a",
                " heated",
                " fight",
                " between",
                " defenders",
                " of",
                " prof",
                "ane",
                " piece",
                " of",
                " protest",
                " art",
                " and",
                " women",
                " trying"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 66.40291595458984,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                66.40291595458984,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.4566259384155273,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iciency\", \"essors\", \"iles\", \"ilers\"], \"v\": [12.93211555480957, 11.378246307373047, 10.479635238647461, 10.301776885986328, 10.034908294677734]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"forth\", \"doors\", \"boat\"], \"v\": [-24.56833267211914, -23.390893936157227, -23.13280487060547, -23.100595474243164, -22.797542572021484]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2q6iwvwf4rqa8arh3p",
            "tokens": [
                " person",
                " criticized",
                " the",
                " list",
                " of",
                " alternatives",
                " for",
                " including",
                " prof",
                "anity",
                " because",
                " sw",
                "ears",
                " are",
                " fairly",
                " common",
                " triggers"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 65.83405303955078,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                65.83405303955078,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -4.261063575744629,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iciency\", \"iler\", \"essors\", \"iles\"], \"v\": [11.189197540283203, 9.309886932373047, 8.835962295532227, 8.716672897338867, 8.668201446533203]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"doors\", \"forth\", \" halfway\"], \"v\": [-25.05277442932129, -23.762718200683594, -23.670936584472656, -23.3432674407959, -22.639068603515625]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2q6iwwwf4rwk90fv3u",
            "tokens": [
                " CBS",
                " sle",
                "az",
                "ef",
                "est",
                " 60",
                " Minutes",
                ",",
                " prof",
                "iled",
                " me",
                " in",
                " March",
                " 1994",
                ",",
                " the",
                " c"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 65.80436706542969,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                65.80436706542969,
                2.621364116668701,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -5.398336887359619,
                0.05481052398681641,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iciency\", \"essors\", \"iles\", \"ession\"], \"v\": [11.674945831298828, 11.376510620117188, 10.54798698425293, 10.308881759643555, 9.241840362548828]}, {\"t\": [\"essor\", \"iles\", \"iciency\", \"iler\", \"ilers\"], \"v\": [0.8818473815917969, 0.8587551116943359, 0.8319358825683594, 0.8300590515136719, 0.8104953765869141]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"forth\", \"doors\", \" halfway\"], \"v\": [-26.17694854736328, -24.421607971191406, -24.414112091064453, -23.8325138092041, -23.615386962890625]}, {\"t\": [\"warm\", \"MENTS\", \"forth\", \"doors\", \" halfway\"], \"v\": [-0.5398788452148438, -0.5282802581787109, -0.47608375549316406, -0.4724769592285156, -0.453033447265625]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2q6iwxwf4rcu5wh6w2",
            "tokens": [
                " 36",
                "%,",
                " the",
                " Palestinians",
                " by",
                " 19",
                "%.",
                " This",
                " prof",
                "usion",
                " of",
                " numbers",
                " can",
                ",",
                "<|endoftext|>",
                " them",
                "."
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 65.58160400390625,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                65.58160400390625,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -2.287179470062256,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"essors\", \"iles\", \"iciency\", \"ilers\"], \"v\": [11.978917121887207, 11.913674354553223, 10.337410926818848, 10.129014015197754, 9.840895652770996]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"forth\", \" twist\", \"boat\"], \"v\": [-24.983854293823242, -23.481529235839844, -22.687137603759766, -21.963098526000977, -21.69855308532715]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2q6iwywf4r2zj8jvx4",
            "tokens": [
                " employees",
                " weren",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " found",
                " to",
                " be",
                " prof",
                "iting",
                " from",
                " fetal",
                " tissue",
                " sales",
                ".",
                "\u010a",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 65.53970336914062,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                65.53970336914062,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.51349925994873,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iciency\", \"essors\", \"iles\", \"ilers\"], \"v\": [9.349772453308105, 8.279648780822754, 7.71975040435791, 6.921569347381592, 6.799587249755859]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \" halfway\", \"doors\", \"forth\"], \"v\": [-27.08854866027832, -25.5380802154541, -24.6911563873291, -24.55344581604004, -24.28514289855957]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2q6iwzwf4r67lu26tj",
            "tokens": [
                " whether",
                " they",
                " had",
                " faced",
                " any",
                " protests",
                " about",
                " this",
                " prof",
                "an",
                "ation",
                " of",
                " hall",
                "owed",
                " ground",
                ".",
                " Had"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 65.45525360107422,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                65.45525360107422,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.372749805450439,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"essors\", \"iciency\", \"iles\", \"ilers\"], \"v\": [11.047966003417969, 10.316070556640625, 10.268125534057617, 9.424158096313477, 9.32703971862793]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"forth\", \" halfway\", \"boat\"], \"v\": [-26.121980667114258, -25.018091201782227, -24.712644577026367, -24.111209869384766, -24.0579833984375]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2q6ix0wf4ru9zlm3in",
            "tokens": [
                " October",
                ",",
                " Cos",
                "mo",
                " writer",
                " Michelle",
                " Ru",
                "iz",
                " prof",
                "iled",
                " the",
                " women",
                " behind",
                " the",
                " boycott",
                " of",
                " Ivanka"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 65.43848419189453,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                65.43848419189453,
                1.814871668815613,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -3.536158323287964,
                0.08954811096191406,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"essors\", \"iciency\", \"iles\", \"ilers\"], \"v\": [10.61292552947998, 9.476591110229492, 9.28943920135498, 8.563155174255371, 7.44040584564209]}, {\"t\": [\"essor\", \"iles\", \"iciency\", \"iler\", \"ilers\"], \"v\": [0.6240425109863281, 0.6047048568725586, 0.5855922698974609, 0.5828456878662109, 0.5710353851318359]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"forth\", \"doors\", \" halfway\"], \"v\": [-26.394962310791016, -24.73644256591797, -24.424964904785156, -24.298416137695312, -23.227693557739258]}, {\"t\": [\"warm\", \"MENTS\", \"forth\", \"doors\", \" halfway\"], \"v\": [-0.3913288116455078, -0.38219642639160156, -0.3464488983154297, -0.3423042297363281, -0.32692527770996094]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2q6ix1wf4ron3kzgxk",
            "tokens": [
                " er",
                "ot",
                "ica",
                " is",
                " under",
                " attack",
                ",",
                " the",
                " prof",
                "ite",
                "ers",
                " will",
                " either",
                " move",
                " on",
                " to",
                " another"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 65.31732177734375,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                65.31732177734375,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.765056610107422,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iciency\", \"essors\", \"icient\", \"iles\"], \"v\": [10.179222106933594, 10.165998458862305, 9.177988052368164, 8.90676212310791, 8.62147045135498]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"MENTS\", \"warm\", \"doors\", \"forth\", \" halfway\"], \"v\": [-25.51039695739746, -25.226707458496094, -24.362285614013672, -24.154170989990234, -23.333513259887695]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ix2wf4r7izwmzoh",
            "tokens": [
                "abb",
                ".",
                "<|endoftext|>",
                "The",
                " man",
                " heard",
                " in",
                " a",
                " prof",
                "anity",
                "-",
                "laden",
                " video",
                " ber",
                "ating",
                " Toronto",
                " police"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 65.09659576416016,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                65.09659576416016,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -2.172955989837646,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essors\", \"iciency\", \"essor\", \"iles\", \"icient\"], \"v\": [8.813762664794922, 8.611749649047852, 8.41622543334961, 8.265010833740234, 7.528469085693359]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"doors\", \"MENTS\", \"forth\", \" halfway\"], \"v\": [-27.111038208007812, -26.51986312866211, -26.308286666870117, -25.987010955810547, -25.839746475219727]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ix3wf4r9yp7p9ku",
            "tokens": [
                " have",
                " stri",
                "ved",
                " to",
                " ensure",
                " that",
                " we",
                " have",
                " prof",
                "iled",
                " most",
                " of",
                " the",
                " code",
                "base",
                " (",
                "currently"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 64.75257873535156,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                64.75257873535156,
                3.423214435577393,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -7.519847393035889,
                0.2071552276611328,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iciency\", \"essors\", \"iles\", \"iler\"], \"v\": [12.704601287841797, 11.473329544067383, 11.199787139892578, 10.623071670532227, 9.310675621032715]}, {\"t\": [\"essor\", \"iles\", \"iler\", \"iciency\", \"ilers\"], \"v\": [1.2867650985717773, 1.2465572357177734, 1.2158203125, 1.2035179138183594, 1.1792974472045898]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"doors\", \"forth\", \" halfway\"], \"v\": [-22.911806106567383, -22.66320037841797, -21.695547103881836, -20.910926818847656, -20.77815055847168]}, {\"t\": [\"warm\", \"MENTS\", \"doors\", \"forth\", \" halfway\"], \"v\": [-0.7367172241210938, -0.7280330657958984, -0.6558914184570312, -0.6518440246582031, -0.6100025177001953]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ix4wf4r4ixuesfv",
            "tokens": [
                " are",
                " predatory",
                " and",
                " are",
                " very",
                " much",
                " driven",
                " toward",
                " prof",
                "iting",
                " off",
                " drivers",
                ".\"",
                "\u010a",
                "\u010a",
                "Uber",
                ","
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 64.60530090332031,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                64.60530090332031,
                1.300339341163635,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.8038992881774902,
                0.03454685211181641,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"essors\", \"iciency\", \"iles\", \"iler\"], \"v\": [12.120594024658203, 10.805706977844238, 10.291967391967773, 9.531088829040527, 9.30679702758789]}, {\"t\": [\"essor\", \"iles\", \"iciency\", \"iler\", \"essors\"], \"v\": [0.4782428741455078, 0.46174049377441406, 0.4410972595214844, 0.44095802307128906, 0.44016075134277344]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"boat\", \"doors\", \"forth\"], \"v\": [-23.23103904724121, -22.61117935180664, -21.929946899414062, -21.835081100463867, -21.21346664428711]}, {\"t\": [\"warm\", \"MENTS\", \"doors\", \"forth\", \" halfway\"], \"v\": [-0.251708984375, -0.24776840209960938, -0.21923065185546875, -0.21762657165527344, -0.21105384826660156]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ix5wf4ryyu5vfou",
            "tokens": [
                " an",
                " idea",
                " for",
                " a",
                " game",
                " that",
                " resembles",
                " a",
                " prof",
                "ane",
                " version",
                " of",
                " App",
                "les",
                " to",
                " App",
                "les"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 64.02529907226562,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                64.02529907226562,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.18112850189209,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iles\", \"iciency\", \"essor\", \"essors\", \"ilers\"], \"v\": [9.042017936706543, 8.906952857971191, 8.75716495513916, 8.52782154083252, 7.823914527893066]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"doors\", \" halfway\", \"boat\", \"pole\"], \"v\": [-25.541147232055664, -24.413108825683594, -24.171138763427734, -24.165334701538086, -23.657262802124023]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ix6wf4r5cdwf8xy",
            "tokens": [
                " out",
                " that",
                " neither",
                " he",
                " nor",
                " Wa",
                "ite",
                " used",
                " prof",
                "anity",
                " or",
                " threatened",
                " the",
                " referee",
                " before",
                " being",
                " thrown"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 64.01187896728516,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                64.01187896728516,
                0.1529159545898438,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -5.247123241424561,
                0.0007658004760742188,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"essors\", \"iciency\", \"iles\", \"iler\"], \"v\": [13.313379287719727, 11.34898567199707, 11.306682586669922, 10.9794282913208, 10.141414642333984]}, {\"t\": [\"essor\", \"iles\", \"iler\", \"iciency\", \"ilers\"], \"v\": [0.048770904541015625, 0.047306060791015625, 0.045703887939453125, 0.04538726806640625, 0.044559478759765625]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"doors\", \" halfway\", \"forth\"], \"v\": [-24.035518646240234, -22.530122756958008, -22.418209075927734, -22.113906860351562, -21.991992950439453]}, {\"t\": [\"warm\", \"MENTS\", \"forth\", \"doors\", \" halfway\"], \"v\": [-0.029691696166992188, -0.028696060180664062, -0.02602386474609375, -0.025707244873046875, -0.024576187133789062]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ix7wf4r0n1r0ofa",
            "tokens": [
                " crude",
                " excuses",
                " have",
                " been",
                " touted",
                " to",
                " justify",
                " the",
                " prof",
                "usion",
                " of",
                " official",
                " posts",
                " to",
                " the",
                " party",
                " legislators"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 63.9041862487793,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                63.9041862487793,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.8293356895446777,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"essors\", \"iciency\", \"iles\", \"icient\"], \"v\": [10.365427017211914, 9.393463134765625, 9.168230056762695, 8.702850341796875, 7.538356781005859]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"forth\", \"boat\", \"doors\"], \"v\": [-25.040088653564453, -24.627674102783203, -24.016286849975586, -23.152217864990234, -22.73101043701172]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ix8wf4rcweqqudg",
            "tokens": [
                " their",
                " child",
                ",",
                " while",
                " proceeding",
                " to",
                " thank",
                " me",
                " prof",
                "use",
                "ly",
                " for",
                " my",
                " care",
                ".",
                "\u010a",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 62.91009521484375,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                62.91009521484375,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -6.919807910919189,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iciency\", \"essors\", \"ilers\", \"iles\"], \"v\": [16.594364166259766, 15.810893058776855, 14.911290168762207, 14.169044494628906, 14.083009719848633]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"doors\", \"forth\", \"MENTS\", \" halfway\"], \"v\": [-20.530466079711914, -20.095714569091797, -19.870878219604492, -18.66212272644043, -18.571603775024414]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ix9wf4r02otvcr4",
            "tokens": [
                ":",
                " Non",
                " ed",
                "ep",
                "ol",
                " ha",
                "be",
                "o",
                " prof",
                "ect",
                "o",
                ",",
                " n",
                "am",
                " i",
                "am",
                " pr"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 62.37395095825195,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                62.37395095825195,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                4.192855834960938,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essors\", \"essor\", \"iciency\", \"iles\", \"ilers\"], \"v\": [12.656706809997559, 12.5189790725708, 11.935635566711426, 11.843091011047363, 11.616015434265137]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"doors\", \"warm\", \"MENTS\", \"forth\", \" Nou\"], \"v\": [-19.693256378173828, -19.689279556274414, -19.26199722290039, -19.175521850585938, -18.93773078918457]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ixawf4ru445ytk0",
            "tokens": [
                " include",
                " clothing",
                " and",
                " to",
                " set",
                " increased",
                " penalties",
                " for",
                " prof",
                "ite",
                "ering",
                ".",
                " Opp",
                "onents",
                " delayed",
                " passage",
                " for"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 62.01234436035156,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                62.01234436035156,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.49718189239502,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iciency\", \"essors\", \"iles\", \"iler\"], \"v\": [9.799717903137207, 8.08764934539795, 7.913010597229004, 7.81577205657959, 7.1048994064331055]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"doors\", \"boat\", \"forth\"], \"v\": [-24.090421676635742, -23.66102409362793, -23.179697036743164, -22.736373901367188, -22.373157501220703]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ixbwf4r2swru9jd",
            "tokens": [
                " oversee",
                " exports",
                ",",
                " act",
                " against",
                " ho",
                "arding",
                " and",
                " prof",
                "ite",
                "ering",
                ",",
                " and",
                " encourage",
                " farmers",
                " to",
                " grow"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 61.73035049438477,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                61.73035049438477,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.018552780151367,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"essors\", \"iciency\", \"iles\", \"iler\"], \"v\": [10.715997695922852, 10.462820053100586, 9.575467109680176, 9.018131256103516, 8.111150741577148]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"doors\", \"boat\", \"forth\"], \"v\": [-23.27450942993164, -22.213348388671875, -22.157489776611328, -21.528400421142578, -20.99673843383789]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ixcwf4r37wnb7o5",
            "tokens": [
                "a",
                ",",
                " vomiting",
                ",",
                " frequent",
                " ur",
                "ination",
                " and",
                " prof",
                "use",
                " sweating",
                ",",
                " for",
                " example",
                " from",
                " a",
                " fever"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 61.46449279785156,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                61.46449279785156,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -2.582286834716797,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"essors\", \"iles\", \"iciency\", \"ilers\"], \"v\": [11.839839935302734, 11.03492546081543, 9.79898452758789, 9.556941986083984, 9.192018508911133]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"doors\", \" halfway\", \" freezing\"], \"v\": [-22.445476531982422, -21.378625869750977, -20.55552101135254, -20.298152923583984, -20.03971290588379]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6iy2wf4rd21hap5c",
            "tokens": [
                " properly",
                " motivated",
                ".",
                "\u010a",
                "\u010a",
                "They",
                " are",
                " deeply",
                " prof",
                "ane",
                ",",
                " blunt",
                ",",
                " and",
                " intoler",
                "ant",
                " of"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 59.77816772460938,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                59.77816772460938,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.621929168701172,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iciency\", \"essors\", \"iles\", \"iler\"], \"v\": [9.109238624572754, 7.750008583068848, 7.1551103591918945, 6.455913543701172, 5.841485977172852]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"forth\", \" halfway\", \"doors\"], \"v\": [-26.49196434020996, -24.89998435974121, -24.61624526977539, -24.568178176879883, -24.274124145507812]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6iy3wf4r2bqb755r",
            "tokens": [
                "\u00e2\u0122",
                "\u013e",
                "We",
                "\u00e2\u0122",
                "\u013b",
                "ve",
                " seen",
                " a",
                " prof",
                "usion",
                " \u00e2\u0122\u0135",
                " an",
                " explosion",
                " \u00e2\u0122\u0135",
                " of",
                " marijuana",
                " grows"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 58.0123405456543,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                58.0123405456543,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -1.591639280319214,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iles\", \"iciency\", \"essors\", \"ilers\"], \"v\": [9.552348136901855, 9.173434257507324, 9.155022621154785, 8.929849624633789, 8.177302360534668]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"doors\", \"forth\", \" halfway\"], \"v\": [-24.00712776184082, -22.386028289794922, -21.86529541015625, -21.731143951416016, -21.49346160888672]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6iy6wf4rvpkmcj0r",
            "tokens": [
                " Telegraph",
                " suggests",
                " this",
                " might",
                " include",
                " people",
                " share",
                " \"",
                "prof",
                "ound",
                "\"",
                " quotes",
                " on",
                " social",
                " media",
                " or",
                " use"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 57.50204086303711,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                57.50204086303711,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.267060518264771,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"ilers\", \"iles\", \"essor\", \"iciency\"], \"v\": [4.786045074462891, 4.114679336547852, 3.8244481086730957, 3.361107587814331, 3.090430736541748]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"MENTS\", \" halfway\", \"doors\"], \"v\": [-24.204044342041016, -21.133882522583008, -20.67249870300293, -20.324569702148438, -20.18244171142578]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6iy4wf4rpqabo0t0",
            "tokens": [
                " that",
                " the",
                " charge",
                ",",
                " Drunk",
                " in",
                " Public",
                " \u00e2\u0122\u0135",
                " Prof",
                "ane",
                " Language",
                ",",
                " was",
                " the",
                " most",
                " frequently",
                " charged"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 54.99140930175781,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                54.99140930175781,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.937221527099609,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"ilers\", \"iler\", \"iles\", \"iciency\"], \"v\": [5.1308674812316895, 4.518951416015625, 3.886446475982666, 3.4450652599334717, 2.881808042526245]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"MENTS\", \"nuts\", \" Nou\"], \"v\": [-25.50063705444336, -24.687580108642578, -22.597618103027344, -22.406291961669922, -22.19738006591797]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6iy9wf4rykigfsxw",
            "tokens": [
                " study",
                " the",
                " 1973",
                " war",
                " was",
                " to",
                " \u00e2\u0122",
                "\u013e",
                "prof",
                "ound",
                "ly",
                " influence",
                " the",
                " development",
                " of",
                " the",
                " U"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 53.95395660400391,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                53.95395660400391,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -1.017060518264771,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"iles\", \"ilers\", \"essor\", \"iciency\"], \"v\": [6.304232597351074, 6.0502424240112305, 5.9353227615356445, 5.305647850036621, 5.048381805419922]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"MENTS\", \"doors\", \" halfway\"], \"v\": [-21.54336929321289, -19.786863327026367, -18.335487365722656, -18.10359764099121, -17.890188217163086]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6iybwf4rh0ne6z1x",
            "tokens": [
                " at",
                " least",
                " 10",
                " weeks",
                " in",
                " length",
                "\u010a",
                "\u010a",
                "Prof",
                "essors",
                "/",
                "te",
                "achers",
                " employed",
                " at",
                " a",
                " US"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 53.85341644287109,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                53.85341644287109,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -1.40856146812439,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"essor\", \"ilers\", \"iles\", \"iled\"], \"v\": [4.19671630859375, 4.002307891845703, 3.751437187194824, 3.4862756729125977, 2.6239852905273438]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"MENTS\", \"rers\", \" halfway\"], \"v\": [-23.382339477539062, -20.690610885620117, -20.408357620239258, -20.124393463134766, -19.93539810180664]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6iy8wf4rnd3rh262",
            "tokens": [
                "In",
                " terms",
                " of",
                " actual",
                " ownership",
                ",",
                " You",
                "Gov",
                " Prof",
                "iles",
                " data",
                " shows",
                " the",
                " Labrador",
                " as",
                "<|endoftext|>",
                " extremely"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 51.21477508544922,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                51.21477508544922,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -2.12164306640625,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"ilers\", \"iler\", \"iciency\", \"iled\"], \"v\": [3.6533641815185547, 3.545517921447754, 3.1113224029541016, 2.314981460571289, 2.2566871643066406]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"forth\", \" Nou\", \"nuts\"], \"v\": [-25.031225204467773, -23.30960464477539, -23.21487045288086, -22.45784568786621, -22.03240203857422]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6iy7wf4rdqzx4ngp",
            "tokens": [
                " groups",
                " will",
                " look",
                " like",
                " this",
                ":",
                "\u010a",
                "\u010a",
                "Prof",
                "esse",
                "ur",
                " writes",
                " for",
                " HL",
                "TV",
                ".",
                "org"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 50.8873405456543,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                50.8873405456543,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.2067317962646484,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iler\", \"ilers\", \"iciency\", \"iles\"], \"v\": [4.953132152557373, 3.842918872833252, 3.734585762023926, 3.4071125984191895, 3.138397216796875]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"forth\", \" halfway\", \"MENT\"], \"v\": [-23.29208755493164, -21.7862548828125, -20.904726028442383, -20.117162704467773, -20.093141555786133]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iyqwf4rnijw2x06",
            "tokens": [
                "iles",
                " base",
                " and",
                " some",
                " other",
                " libraries",
                ".",
                " --",
                "prof",
                " is",
                " used",
                " to",
                " generate",
                " prof",
                "iled",
                " versions",
                " of"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 50.81963348388672,
            "maxValueTokenIndex": 13,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                27.94064140319824,
                0,
                0,
                0,
                0,
                50.81963348388672,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.932290077209473,
                0,
                0,
                0,
                0,
                -8.588071823120117,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iles\", \"essor\", \"iler\", \"ilers\", \"iciency\"], \"v\": [7.381296157836914, 7.347846984863281, 6.804725646972656, 6.7384796142578125, 6.68560791015625]}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iles\", \"iciency\", \"essors\", \"ilers\"], \"v\": [11.721553802490234, 10.75655746459961, 10.539259910583496, 9.945937156677246, 9.50783920288086]}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"doors\", \"forth\", \" halfway\"], \"v\": [-6.837491989135742, -6.663370132446289, -6.252340316772461, -6.143835067749023, -5.982048034667969]}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"doors\", \" halfway\", \"forth\"], \"v\": [-15.879188537597656, -15.877918243408203, -15.399456977844238, -14.503721237182617, -14.480987548828125]}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6iyawf4rr2u9erzj",
            "tokens": [
                " its",
                " rivals",
                ",",
                " Ford",
                " is",
                " building",
                " more",
                "-",
                "prof",
                "itable",
                " light",
                " trucks",
                " in",
                " the",
                " U",
                ".",
                "S"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 49.38695907592773,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                49.38695907592773,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.8083539009094238,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"ilers\", \"iles\", \"essor\", \"iciency\"], \"v\": [6.679271697998047, 6.417774200439453, 6.304896831512451, 5.980220317840576, 5.769226551055908]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"doors\", \" halfway\", \"MENTS\"], \"v\": [-20.40057945251465, -19.164836883544922, -16.90863800048828, -16.839797973632812, -16.797992706298828]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iygwf4r1b9t223f",
            "tokens": [
                " Berg",
                "isch",
                " Glad",
                "bach",
                " g",
                "eb",
                "ore",
                "ne",
                " Prof",
                "i",
                " hat",
                " s",
                "ich",
                " se",
                "it",
                " 2012",
                " in"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 47.51666641235352,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                47.51666641235352,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.277139663696289,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ilers\", \"essor\", \"iler\", \"iles\", \"iled\"], \"v\": [5.50798225402832, 4.917172908782959, 4.867617607116699, 4.291323184967041, 4.209099769592285]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \" Nou\", \"forth\", \"MENTS\", \"rers\"], \"v\": [-19.035717010498047, -17.997081756591797, -17.837942123413086, -17.55513572692871, -17.17621612548828]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iyewf4rx9vj0i4o",
            "tokens": [
                " targeting",
                " one",
                " thing",
                ",",
                " but",
                " it",
                " could",
                " spread",
                " Prof",
                " Alan",
                " Woodward",
                ",",
                " Computer",
                " security",
                " expert",
                "\u010a",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 47.36540603637695,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                47.36540603637695,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.800885677337646,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iler\", \"ilers\", \"iles\", \"iciency\"], \"v\": [6.369478702545166, 6.049012184143066, 6.021672248840332, 5.173671722412109, 4.831493854522705]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"MENTS\", \" Nou\", \"doors\"], \"v\": [-17.70995330810547, -16.639036178588867, -16.071102142333984, -15.868476867675781, -15.279928207397461]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6iycwf4r7vrzvn0m",
            "tokens": [
                " involve",
                " animal",
                " sacrifice",
                "\u010a",
                "\u010a",
                "Two",
                " self",
                "-",
                "prof",
                "essed",
                " witches",
                " have",
                " been",
                " detained",
                " in",
                " Romania",
                " on"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 44.30264282226562,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                44.30264282226562,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.01378162205219269,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iles\", \"iler\", \"ilers\", \"anity\"], \"v\": [4.980960845947266, 4.974213123321533, 4.719095706939697, 4.405785083770752, 4.036333084106445]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"MENTS\", \"doors\", \" halfway\"], \"v\": [-17.800243377685547, -16.457576751708984, -16.339418411254883, -15.949628829956055, -15.77238655090332]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6iydwf4reyedl25h",
            "tokens": [
                "<|endoftext|>",
                " Social",
                " and",
                " Political",
                " Science",
                ",",
                " has",
                " slammed",
                " Prof",
                ".",
                " App",
                "a",
                " Rao",
                " for",
                " using",
                " force",
                " to"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 43.47660827636719,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                43.47660827636719,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.960755348205566,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iler\", \"ilers\", \"iles\", \"iciency\"], \"v\": [3.581681251525879, 3.350247383117676, 3.2189369201660156, 2.5736865997314453, 2.4103565216064453]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"MENTS\", \" Nou\", \"doors\"], \"v\": [-17.37934112548828, -16.70808219909668, -16.12980842590332, -15.844050407409668, -15.24200439453125]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iyfwf4rubrru3is",
            "tokens": [
                "ward",
                " practices",
                "\".",
                "\u010a",
                "\u010a",
                "Most",
                " self",
                "-",
                "prof",
                "essed",
                " witches",
                " in",
                " Romania",
                " are",
                " Roma",
                ".",
                "<|endoftext|>"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 42.27434158325195,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                42.27434158325195,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.002918995916843414,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iles\", \"iler\", \"ilers\", \"iciency\"], \"v\": [5.008100986480713, 4.850499629974365, 4.835177421569824, 4.368191242218018, 4.046194553375244]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"MENTS\", \"doors\", \" halfway\"], \"v\": [-17.382593154907227, -16.115957260131836, -15.867101669311523, -15.511154174804688, -15.275623321533203]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iyhwf4ryu4nruch",
            "tokens": [
                " the",
                " Times",
                " Educational",
                " Supplement",
                " (",
                "T",
                "ES",
                "),",
                " Prof",
                " Roberts",
                ",",
                " who",
                " has",
                " presented",
                " a",
                " number",
                " of"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 40.87540435791016,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                40.87540435791016,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.525317192077637,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iler\", \"ilers\", \"iles\", \"iciency\"], \"v\": [4.224023818969727, 3.980367660522461, 3.972698211669922, 3.492978572845459, 3.2327499389648438]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"MENTS\", \" Nou\", \" halfway\"], \"v\": [-15.529571533203125, -14.707862854003906, -14.630794525146484, -14.247714042663574, -13.614448547363281]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iylwf4rnmp6fwrn",
            "tokens": [
                " of",
                " Social",
                " and",
                " Political",
                " Science",
                ",",
                " has",
                " slammed",
                " Prof",
                ".",
                " App",
                "a",
                " Rao",
                " for",
                " using",
                " force",
                " to"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 39.5610237121582,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                39.5610237121582,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.01779556274414,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"essor\", \"ilers\", \"iles\", \"iled\"], \"v\": [3.8831539154052734, 3.7699594497680664, 3.765371322631836, 3.140894889831543, 2.917724609375]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"MENTS\", \" Nou\", \"doors\"], \"v\": [-15.804948806762695, -15.233539581298828, -15.032155990600586, -14.863016128540039, -14.049283981323242]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iykwf4rghrkpb9x",
            "tokens": [
                " gh",
                "c",
                "js",
                " stack",
                "trace",
                ".",
                "hs",
                " -",
                "prof",
                " -",
                "f",
                "prof",
                "-",
                "auto",
                " and",
                " then",
                " run"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 38.14892578125,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                38.14892578125,
                0,
                0,
                28.71409606933594,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.340822219848633,
                0,
                0,
                1.802228927612305,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iles\", \"ilers\", \"essors\", \"iciency\"], \"v\": [7.250404357910156, 7.050939559936523, 6.783236503601074, 6.714577674865723, 6.596086502075195]}, {}, {}, {\"t\": [\"iles\", \"essor\", \"iler\", \"ilers\", \"iciency\"], \"v\": [8.055684089660645, 8.038009643554688, 7.606325149536133, 7.586636543273926, 7.421404838562012]}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"doors\", \"forth\", \" halfway\"], \"v\": [-12.666675567626953, -11.855445861816406, -11.773723602294922, -11.37653923034668, -11.086326599121094]}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"doors\", \"forth\", \" halfway\"], \"v\": [-7.226188659667969, -6.950954437255859, -6.609264373779297, -6.366731643676758, -6.339042663574219]}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iyjwf4r3xnbaypo",
            "tokens": [
                " will",
                " |",
                " Stuart",
                " Heritage",
                " Read",
                " more",
                "\u010a",
                "\u010a",
                "Prof",
                " Alberto",
                " N",
                "ave",
                "ira",
                " Gar",
                "ab",
                "ato",
                " from"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 37.48850631713867,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                37.48850631713867,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.680736541748047,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iler\", \"ilers\", \"iles\", \"iciency\"], \"v\": [3.837581157684326, 3.8101415634155273, 3.467226028442383, 2.9925668239593506, 2.8289999961853027]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"forth\", \" Nou\", \" halfway\"], \"v\": [-15.274177551269531, -14.495553970336914, -13.982355117797852, -13.695695877075195, -13.459859848022461]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iyiwf4rpcyqlfy2",
            "tokens": [
                " damage",
                " critical",
                " infrastructure",
                " could",
                " drastically",
                " back",
                "fire",
                ",",
                " Prof",
                " Alan",
                " Woodward",
                ",",
                " a",
                " computer",
                " security",
                " expert",
                " at"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 35.50800704956055,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                35.50800704956055,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.214135646820068,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"ilers\", \"iler\", \"iles\", \"iled\"], \"v\": [2.8170032501220703, 2.8089046478271484, 2.770054817199707, 2.2190632820129395, 1.9621915817260742]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"MENTS\", \" Nou\", \"doors\"], \"v\": [-15.591175079345703, -14.819787979125977, -14.432535171508789, -14.36945629119873, -13.928144454956055]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iyowf4rps4c0gek",
            "tokens": [
                "ello",
                " che",
                "all",
                "'",
                "event",
                "o",
                " #",
                "le",
                "prof",
                "ession",
                "idel",
                "f",
                "ut",
                "uro",
                " ,",
                " qu",
                "ando"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 32.73562622070312,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                32.73562622070312,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.14637279510498,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ilers\", \"iler\", \"iles\", \"iciency\", \"iled\"], \"v\": [1.0859737396240234, 0.9716148376464844, 0.8658180236816406, 0.7703580856323242, 0.3528919219970703]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"doors\", \"forth\", \" Nou\"], \"v\": [-17.009227752685547, -16.58474349975586, -15.886547088623047, -15.855180740356445, -15.44189453125]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iymwf4rswt07vwh",
            "tokens": [
                " reversing",
                " their",
                " decreases",
                " since",
                " 2013",
                ".",
                "Lead",
                " researcher",
                " Prof",
                " Cor",
                "in",
                "ne",
                " Le",
                " Qu\u00c3\u00a9",
                "r\u00c3\u00a9",
                ",",
                "<|endoftext|>"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 31.99310874938965,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                31.99310874938965,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.791618347167969,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"ilers\", \"iler\", \"iles\", \"iled\"], \"v\": [2.8300180435180664, 2.644540786743164, 2.630430221557617, 2.206333637237549, 2.0083560943603516]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \" Nou\", \"MENTS\", \"doors\"], \"v\": [-13.513959884643555, -12.836374282836914, -12.804778099060059, -12.707527160644531, -12.229232788085938]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iypwf4r9aiqo50b",
            "tokens": [
                "'",
                "\u00c3\u00a8",
                " lo",
                " sp",
                "ie",
                "ga",
                " #",
                "le",
                "prof",
                "ession",
                "idel",
                "f",
                "ut",
                "uro",
                " 23",
                " mar",
                "zo"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 31.62989616394043,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                31.62989616394043,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.007610571570694447,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"iles\", \"ilers\", \"essor\", \"iciency\"], \"v\": [2.226146697998047, 2.0958690643310547, 2.018238067626953, 1.9594058990478516, 1.8035812377929688]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"doors\", \"forth\", \"MENT\"], \"v\": [-11.788816452026367, -11.312206268310547, -10.767932891845703, -10.595195770263672, -10.499300003051758]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iynwf4r99y0l2s6",
            "tokens": [
                " one",
                " thing",
                ",",
                " but",
                " it",
                " could",
                " spread",
                ",\"",
                " Prof",
                " Woodward",
                " said",
                ".",
                " \"",
                "All",
                "<|endoftext|>",
                "s",
                " CP"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 29.32191467285156,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                29.32191467285156,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.809864521026611,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"essor\", \"iles\", \"ilers\", \"iled\"], \"v\": [4.7367095947265625, 4.669704437255859, 4.625282287597656, 4.589021682739258, 4.204067230224609]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"forth\", \" Nou\", \"doors\"], \"v\": [-9.423128128051758, -9.035789489746094, -8.990816116333008, -8.531335830688477, -8.497201919555664]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iyswf4r0h0tfa73",
            "tokens": [
                " from",
                " the",
                " border",
                ".",
                "<|endoftext|>",
                "Obama",
                " Me",
                "ets",
                " Priv",
                "ately",
                " With",
                " the",
                " Dead",
                "\u010a",
                "\u010a",
                "Mus",
                "icians"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 10.69105911254883,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                10.69105911254883,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.2632980346679688,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iles\", \"essor\", \"ilers\", \"iciency\", \"iler\"], \"v\": [1.9304370880126953, 1.9031753540039062, 1.8134212493896484, 1.8113040924072266, 1.7856502532958984]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"doors\", \"forth\", \" halfway\"], \"v\": [-3.552886962890625, -3.346302032470703, -3.247283935546875, -3.1735305786132812, -3.102916717529297]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iyrwf4rvlh3i7jx",
            "tokens": [
                " image",
                " on",
                " the",
                " ob",
                "verse",
                ".",
                "\u010a",
                "\u010a",
                "Priv",
                "ately",
                " mint",
                "ed",
                " in",
                " the",
                " United",
                " States",
                "."
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 8.302223205566406,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.302223205566406,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.2513718605041504,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iles\", \"ilers\", \"iler\", \"iciency\"], \"v\": [1.3989133834838867, 1.3984870910644531, 1.2980899810791016, 1.2805519104003906, 1.2499446868896484]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"forth\", \"doors\", \" halfway\"], \"v\": [-2.6332149505615234, -2.465229034423828, -2.4133129119873047, -2.3556671142578125, -2.265911102294922]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iyvwf4rfdacrco1",
            "tokens": [
                "\u010a",
                "\u010a",
                "He",
                " said",
                " that",
                " the",
                " allegations",
                " concerning",
                " Priv",
                "at",
                "Bank",
                " were",
                " \u00e2\u0122",
                "\u013e",
                "un",
                "sub",
                "stant"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 7.871627330780029,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.871627330780029,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.5829095840454102,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iles\", \"iler\", \"iciency\", \"ilers\"], \"v\": [1.2965011596679688, 1.2461729049682617, 1.1574125289916992, 1.1331291198730469, 1.1230010986328125]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"forth\", \"doors\", \"MENT\"], \"v\": [-2.6274795532226562, -2.561969757080078, -2.461862564086914, -2.4517879486083984, -2.325519561767578]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iytwf4rbrr8i5hz",
            "tokens": [
                " in",
                " fighting",
                " the",
                " drug",
                " war",
                ".",
                "\u010a",
                "\u010a",
                "Priv",
                "ately",
                " the",
                " U",
                ".",
                "S",
                ".",
                " notes",
                ":"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 7.233066082000732,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.233066082000732,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.02131503075361252,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"essor\", \"iles\", \"iler\", \"ilers\", \"iciency\"], \"v\": [1.6695003509521484, 1.6332416534423828, 1.5853290557861328, 1.5666007995605469, 1.5172042846679688]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"doors\", \"forth\", \" Nou\"], \"v\": [-2.1681766510009766, -1.9319534301757812, -1.8825149536132812, -1.865478515625, -1.7438087463378906]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iyuwf4rhdzjcqr2",
            "tokens": [
                "Av",
                "acy",
                "n",
                ",",
                " Angel",
                " of",
                " Hope",
                "),",
                " Priv",
                "ileged",
                " Position",
                ",",
                " Sterling",
                " Grove",
                ".",
                " And",
                " I"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 6.961701393127441,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                6.961701393127441,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.1992197036743164,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iles\", \"essor\", \"ilers\", \"iler\", \"iciency\"], \"v\": [1.3534297943115234, 1.2932634353637695, 1.26104736328125, 1.2316322326660156, 1.2301177978515625]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"MENTS\", \"forth\", \"doors\", \"nuts\"], \"v\": [-2.3891372680664062, -2.2589340209960938, -2.1549606323242188, -2.147754669189453, -2.0590438842773438]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iyywf4r5d69819i",
            "tokens": [
                " their",
                " proverbial",
                " noses",
                " and",
                " given",
                " cries",
                " of",
                " \u00e2\u0122",
                "\u013e",
                "bub",
                "ble",
                "\u00e2\u0122",
                "\u013f",
                " and",
                " \u00e2\u0122",
                "\u013e",
                "f"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ixdwf4r72iiglh4",
            "tokens": [
                " you",
                " need",
                " for",
                "<|endoftext|>",
                "Speed",
                " tip",
                " #",
                "1",
                ":",
                " Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " worry",
                " about",
                " grammar",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ixmwf4rsoz4xdhi",
            "tokens": [
                " Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " worry",
                " about",
                " grammar",
                "\u010a",
                "\u010a",
                "Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " bother",
                " putting",
                " together",
                " well"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ixlwf4rzckuksqo",
            "tokens": [
                ":",
                " Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " worry",
                " about",
                " grammar",
                "\u010a",
                "\u010a",
                "Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " bother",
                " putting",
                " together"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6ixtwf4rjnljqdl4",
            "tokens": [
                "\u010a",
                "\u010a",
                "Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " bother",
                " putting",
                " together",
                " well",
                "-",
                "con",
                "structed",
                " sentences",
                ".",
                " Just",
                " string"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6ixqwf4r3kqagzb7",
            "tokens": [
                " worry",
                " about",
                " grammar",
                "\u010a",
                "\u010a",
                "Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " bother",
                " putting",
                " together",
                " well",
                "-",
                "con",
                "structed",
                " sentences"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ixpwf4r1wgmwfr0",
            "tokens": [
                "t",
                " worry",
                " about",
                " grammar",
                "\u010a",
                "\u010a",
                "Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " bother",
                " putting",
                " together",
                " well",
                "-",
                "con",
                "structed"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iyzwf4r0h7pn72n",
            "tokens": [
                " of",
                " southern",
                " Congress",
                " people",
                " who",
                " really",
                " didn",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " have",
                " much",
                " power",
                ".",
                " Ultimately",
                ",",
                " the"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ixowf4r745sxo8d",
            "tokens": [
                "\u013b",
                "t",
                " worry",
                " about",
                " grammar",
                "\u010a",
                "\u010a",
                "Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " bother",
                " putting",
                " together",
                " well",
                "-",
                "con"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ixkwf4r8xy9fbfl",
            "tokens": [
                "1",
                ":",
                " Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " worry",
                " about",
                " grammar",
                "\u010a",
                "\u010a",
                "Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " bother",
                " putting"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iywwf4ryu1g6rdv",
            "tokens": [
                "/",
                "fl",
                "ickr",
                ")",
                "\u010a",
                "\u010a",
                "Baby",
                " wom",
                "bat",
                " (",
                "Photo",
                ":",
                " Greg",
                " Wood",
                "/",
                "Getty",
                " Images"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iz0wf4rrs5c25y8",
            "tokens": [
                " one",
                " at",
                " the",
                " university",
                ",",
                " and",
                " one",
                " at",
                " AT",
                "R",
                ",\"",
                " Ish",
                "ig",
                "uro",
                " qu",
                "ipped",
                ","
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6ixwwf4rd6hj1fdf",
            "tokens": [
                "\u00e2\u0122",
                "\u013b",
                "t",
                " bother",
                " putting",
                " together",
                " well",
                "-",
                "con",
                "structed",
                " sentences",
                ".",
                " Just",
                " string",
                " words",
                " together",
                " to"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6ixvwf4rbc8205dd",
            "tokens": [
                "Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " bother",
                " putting",
                " together",
                " well",
                "-",
                "con",
                "structed",
                " sentences",
                ".",
                " Just",
                " string",
                " words",
                " together"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6ixuwf4r8o3qy57z",
            "tokens": [
                "\u010a",
                "Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " bother",
                " putting",
                " together",
                " well",
                "-",
                "con",
                "structed",
                " sentences",
                ".",
                " Just",
                " string",
                " words"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ixnwf4rbjw7yf1r",
            "tokens": [
                "\u00e2\u0122",
                "\u013b",
                "t",
                " worry",
                " about",
                " grammar",
                "\u010a",
                "\u010a",
                "Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " bother",
                " putting",
                " together",
                " well",
                "-"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6ixswf4rnoz6maa7",
            "tokens": [
                " grammar",
                "\u010a",
                "\u010a",
                "Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " bother",
                " putting",
                " together",
                " well",
                "-",
                "con",
                "structed",
                " sentences",
                ".",
                " Just"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2s6ixrwf4r04pxaqio",
            "tokens": [
                " about",
                " grammar",
                "\u010a",
                "\u010a",
                "Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " bother",
                " putting",
                " together",
                " well",
                "-",
                "con",
                "structed",
                " sentences",
                "."
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2t6iyxwf4r11fmnreu",
            "tokens": [
                " an",
                " abstraction",
                " that",
                " everyone",
                " relies",
                " on",
                ".",
                "\u010a",
                "\u010a",
                "One",
                " thing",
                " that",
                " the",
                " relational",
                " model",
                " does",
                " not"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ixjwf4rrkrsko85",
            "tokens": [
                " #",
                "1",
                ":",
                " Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " worry",
                " about",
                " grammar",
                "\u010a",
                "\u010a",
                "Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " bother"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ixiwf4regzyotq2",
            "tokens": [
                " tip",
                " #",
                "1",
                ":",
                " Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " worry",
                " about",
                " grammar",
                "\u010a",
                "\u010a",
                "Don",
                "\u00e2\u0122",
                "\u013b",
                "t"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ixhwf4r13ko7byp",
            "tokens": [
                "Speed",
                " tip",
                " #",
                "1",
                ":",
                " Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " worry",
                " about",
                " grammar",
                "\u010a",
                "\u010a",
                "Don",
                "\u00e2\u0122",
                "\u013b"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ixgwf4rzow7fb4e",
            "tokens": [
                "<|endoftext|>",
                "Speed",
                " tip",
                " #",
                "1",
                ":",
                " Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " worry",
                " about",
                " grammar",
                "\u010a",
                "\u010a",
                "Don",
                "\u00e2\u0122"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ixfwf4rwlpsxlbe",
            "tokens": [
                " for",
                "<|endoftext|>",
                "Speed",
                " tip",
                " #",
                "1",
                ":",
                " Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " worry",
                " about",
                " grammar",
                "\u010a",
                "\u010a",
                "Don"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi7zj2r6ixewf4rbzik7klq",
            "tokens": [
                " need",
                " for",
                "<|endoftext|>",
                "Speed",
                " tip",
                " #",
                "1",
                ":",
                " Don",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " worry",
                " about",
                " grammar",
                "\u010a",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "7995",
            "layer": "8-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T00:52:35.812Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        }
    ],
    "explanations": [
        {
            "id": "clsxxw6y31y6dkad1g6r40axr",
            "description": "words related to profanity or inappropriate language",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "scores": []
        },
        {
            "id": "l5m1h752xyza2w9amjav54tq4",
            "description": " words related to profanity or explicit language",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "scores": []
        }
    ]
}