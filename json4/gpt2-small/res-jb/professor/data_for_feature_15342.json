{
    "modelId": "gpt2-small",
    "layer": "10-res-jb",
    "index": "15342",
    "sourceSetName": "res-jb",
    "creatorId": null,
    "createdAt": "2024-02-12T04:18:39.605Z",
    "maxActApprox": 93.97177124023438,
    "hasVector": false,
    "vector": [],
    "vectorLabel": null,
    "vectorDefaultSteerStrength": 10,
    "hookName": null,
    "topkCosSimIndices": [
        15342,
        21497,
        18199,
        12929,
        6793,
        13669,
        17556,
        1278,
        10719,
        2524,
        17433,
        13712,
        16157,
        18637,
        12431,
        5044,
        12507,
        19981,
        8200,
        22236,
        23565,
        11868,
        336,
        18597,
        18649
    ],
    "topkCosSimValues": [
        1,
        0.4739,
        0.4203,
        0.4077,
        0.4021,
        0.3762,
        0.3762,
        0.3687,
        0.3658,
        0.3622,
        0.3562,
        0.3539,
        0.3508,
        0.3461,
        0.3444,
        0.3389,
        0.3369,
        0.3363,
        0.3305,
        0.3263,
        0.3242,
        0.3238,
        0.3179,
        0.3124,
        0.3115
    ],
    "neuron_alignment_indices": [
        60,
        232,
        237
    ],
    "neuron_alignment_values": [
        0.100772462785244,
        0.09295504540205002,
        0.09046349674463272
    ],
    "neuron_alignment_l1": [
        0.004587469156831503,
        0.004231596365571022,
        0.004118173383176327
    ],
    "correlated_neurons_indices": [
        232,
        60,
        251
    ],
    "correlated_neurons_pearson": [
        0.01311691012233496,
        0.01247347239404917,
        0.0109231835231185
    ],
    "correlated_neurons_l1": [
        0.01380067318677902,
        0.01243206299841404,
        0.01034712698310614
    ],
    "correlated_features_indices": [],
    "correlated_features_pearson": [],
    "correlated_features_l1": [],
    "neg_str": [
        "warm",
        "WARE",
        "forth",
        "MENTS",
        " shortened",
        " halfway",
        " coupled",
        "WAY",
        "WAYS",
        "\u00e2\u0136\u0122\u00e2\u0136\u0122\u00e2\u0136\u0122\u00e2\u0136\u0122"
    ],
    "neg_values": [
        -0.68858402967453,
        -0.6748708486557007,
        -0.6545647382736206,
        -0.6438576579093933,
        -0.6403779983520508,
        -0.6398093104362488,
        -0.6359089016914368,
        -0.6230565309524536,
        -0.6216102242469788,
        -0.5890228152275085
    ],
    "pos_str": [
        "iled",
        "iler",
        "anity",
        "ilers",
        "iles",
        "iling",
        "essor",
        "usion",
        "aned",
        "ession"
    ],
    "pos_values": [
        1.349763989448547,
        1.328524827957153,
        1.289432525634766,
        1.248033046722412,
        1.213471412658691,
        1.192892909049988,
        1.167565584182739,
        1.150616884231567,
        1.14316987991333,
        1.140548586845398
    ],
    "frac_nonzero": 0.0001595815022786458,
    "freq_hist_data_bar_heights": [
        229,
        101,
        52,
        29,
        17,
        3,
        0,
        2,
        2,
        2,
        0,
        0,
        1,
        3,
        3,
        3,
        1,
        4,
        3,
        2,
        1,
        2,
        3,
        0,
        2,
        1,
        3,
        2,
        2,
        1,
        1,
        2,
        1,
        3,
        1,
        4,
        7,
        3,
        2,
        4
    ],
    "freq_hist_data_bar_values": [
        1.182015538215637,
        3.531123399734497,
        5.880230903625488,
        8.229338645935059,
        10.57844638824463,
        12.9275541305542,
        15.27666187286377,
        17.62577056884766,
        19.97487640380859,
        22.3239860534668,
        24.67309188842773,
        27.02220153808594,
        29.37130737304688,
        31.72041702270508,
        34.06952285766602,
        36.41863250732422,
        38.76773834228516,
        41.11684417724609,
        43.4659538269043,
        45.8150634765625,
        48.16416931152344,
        50.51327514648438,
        52.86238479614258,
        55.21149444580078,
        57.56060028076172,
        59.90970611572266,
        62.25881576538086,
        64.60792541503906,
        66.95703125,
        69.30613708496094,
        71.6552505493164,
        74.00435638427734,
        76.35346221923828,
        78.70256805419922,
        81.05167388916016,
        83.40078735351562,
        85.74989318847656,
        88.0989990234375,
        90.44811248779297,
        92.7972183227539
    ],
    "logits_hist_data_bar_heights": [
        6,
        4,
        14,
        43,
        142,
        306,
        679,
        1459,
        2357,
        3551,
        4755,
        5740,
        5926,
        5577,
        4714,
        3766,
        2940,
        2211,
        1535,
        1126,
        913,
        701,
        551,
        396,
        283,
        194,
        146,
        71,
        59,
        40,
        14,
        8,
        12,
        2,
        5,
        3,
        3,
        1,
        2,
        2
    ],
    "logits_hist_data_bar_values": [
        -0.6631046533584595,
        -0.6121459603309631,
        -0.5611872673034668,
        -0.5102285742759705,
        -0.4592698812484741,
        -0.4083111882209778,
        -0.3573524653911591,
        -0.3063937723636627,
        -0.2554350793361664,
        -0.20447638630867,
        -0.1535176932811737,
        -0.1025590002536774,
        -0.05160024389624596,
        -0.0006415508687496185,
        0.05031714215874672,
        0.1012758314609528,
        0.1522345244884491,
        0.2031932175159454,
        0.2541519105434418,
        0.3051106035709381,
        0.3560693562030792,
        0.4070280492305756,
        0.4579867422580719,
        0.5089454650878906,
        0.559904158115387,
        0.6108628511428833,
        0.6618215441703796,
        0.712780237197876,
        0.7637389302253723,
        0.8146976828575134,
        0.8656563758850098,
        0.9166150689125061,
        0.9675737619400024,
        1.018532395362854,
        1.069491147994995,
        1.120449781417847,
        1.171408534049988,
        1.222367167472839,
        1.27332592010498,
        1.324284553527832
    ],
    "decoder_weights_dist": [],
    "umap_cluster": null,
    "umap_log_feature_sparsity": null,
    "umap_x": null,
    "umap_y": null,
    "model": {
        "id": "gpt2-small",
        "displayNameShort": "GPT2-SM",
        "displayName": "GPT2-Small",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "tlensId": null,
        "dimension": 768,
        "visibility": "PUBLIC",
        "inferenceEnabled": true,
        "instruct": false,
        "layers": 12,
        "neuronsPerLayer": 3072,
        "createdAt": "2023-07-06T00:01:44.843Z",
        "owner": "OpenAI",
        "updatedAt": "2023-07-06T00:01:44.843Z",
        "website": "https://openai.com"
    },
    "lists": [],
    "creator": null,
    "source": {
        "id": "10-res-jb",
        "modelId": "gpt2-small",
        "hasDashboards": true,
        "inferenceEnabled": true,
        "saelensConfig": {
            "lr": 0.0004,
            "d_in": 768,
            "seed": 42,
            "d_sae": 24576,
            "dtype": "torch.float32",
            "device": "mps",
            "run_name": "24576-L1-8e-05-LR-0.0004-Tokens-3.000e+08",
            "hook_point": "blocks.10.hook_resid_pre",
            "model_name": "gpt2-small",
            "prepend_bos": true,
            "architecture": "standard",
            "context_size": 128,
            "dataset_path": "Skylion007/openwebtext",
            "log_to_wandb": true,
            "wandb_entity": null,
            "n_checkpoints": 10,
            "wandb_project": "mats_sae_training_gpt2_small_resid_pre_5",
            "l1_coefficient": 8e-05,
            "neuronpedia_id": "gpt2-small/10-res-jb",
            "checkpoint_path": "checkpoints/9vu4ulem",
            "use_ghost_grads": false,
            "expansion_factor": 32,
            "hook_point_layer": 10,
            "lr_warm_up_steps": 5000,
            "resample_batches": 1028,
            "store_batch_size": 32,
            "train_batch_size": 4096,
            "activation_fn_str": "relu",
            "b_dec_init_method": "geometric_median",
            "lr_scheduler_name": null,
            "tokens_per_buffer": 67108864,
            "dead_feature_window": 5000,
            "n_batches_in_buffer": 128,
            "wandb_log_frequency": 100,
            "apply_b_dec_to_input": true,
            "feature_reinit_scale": 0.2,
            "from_pretrained_path": null,
            "is_dataset_tokenized": false,
            "hook_point_head_index": null,
            "normalize_activations": "none",
            "total_training_tokens": 300000000,
            "dead_feature_threshold": 1e-08,
            "use_cached_activations": false,
            "cached_activations_path": "activations/Skylion007_openwebtext/gpt2-small/blocks.10.hook_resid_pre",
            "feature_sampling_method": null,
            "feature_sampling_window": 1000,
            "dataset_trust_remote_code": true,
            "finetuning_scaling_factor": false,
            "sae_lens_training_version": null,
            "model_from_pretrained_kwargs": {
                "center_writing_weights": true
            },
            "dead_feature_estimation_method": "no_fire"
        },
        "saelensRelease": "gpt2-small-res-jb",
        "saelensSaeId": "blocks.10.hook_resid_pre",
        "hfRepoId": "jbloom/GPT2-Small-SAEs-Reformatted",
        "hfFolderId": "blocks.10.hook_resid_pre",
        "visibility": "PUBLIC",
        "setName": "res-jb",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "hasUmap": true,
        "hasUmapLogSparsity": true,
        "hasUmapClusters": true,
        "num_prompts": 24576,
        "num_tokens_in_prompt": 128,
        "dataset": "Skylion007/openwebtext",
        "notes": null,
        "createdAt": "2024-07-10T04:46:32.069Z"
    },
    "sourceSet": {
        "modelId": "gpt2-small",
        "name": "res-jb",
        "hasDashboards": true,
        "visibility": "PUBLIC",
        "description": "Open Source Sparse Autoencoders for all Residual Stream Layers of GPT2-Small",
        "type": "Residual Stream",
        "creatorName": "Joseph Bloom",
        "urls": [
            "https://www.lesswrong.com/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream",
            "https://huggingface.co/jbloom/GPT2-Small-SAEs/tree/main",
            "https://github.com/jbloomAus/mats_sae_training"
        ],
        "creatorEmail": null,
        "creatorId": "cljgamm90000076zdchicy6zj",
        "releaseName": "gpt2sm-res-jb",
        "defaultRange": 2,
        "defaultShowBreaks": true,
        "showDfa": false,
        "showCorrelated": false,
        "showHeadAttribution": false,
        "showUmap": true,
        "createdAt": "2024-07-10T04:46:32.075Z"
    },
    "activations": [
        {
            "id": "clsifcp633uq0wf4r9pqkv4h0",
            "tokens": [
                "ity",
                " on",
                " American",
                " soil",
                " would",
                " truly",
                " be",
                " a",
                " prof",
                "an",
                "ation",
                ".",
                " Though",
                " obviously",
                " not",
                " comparable",
                " to"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 93.97177124023438,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                93.97177124023438,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.4604511260986328,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ilers\", \"iled\", \"iler\", \"iles\", \"anity\"], \"v\": [14.461030006408691, 14.415440559387207, 13.84949016571045, 13.535155296325684, 12.761487007141113]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \" halfway\", \"WAY\", \"forth\", \" upholding\"], \"v\": [-23.287677764892578, -23.234447479248047, -23.084590911865234, -22.611474990844727, -22.35410499572754]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uq1wf4r7u9ix8rg",
            "tokens": [
                " CBS",
                " sle",
                "az",
                "ef",
                "est",
                " 60",
                " Minutes",
                ",",
                " prof",
                "iled",
                " me",
                " in",
                " March",
                " 1994",
                ",",
                " the",
                " c"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 93.44284057617188,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                93.44284057617188,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -2.958523750305176,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"anity\", \"ilers\", \"essor\", \"usion\"], \"v\": [4.891199111938477, 4.591156005859375, 4.45754337310791, 3.35933780670166, 3.274738311767578]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \" coupled\", \" shortened\", \" capped\", \" halfway\"], \"v\": [-30.005691528320312, -29.910457611083984, -29.498598098754883, -29.452159881591797, -29.147689819335938]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uq2wf4riqmb6syl",
            "tokens": [
                " employees",
                " weren",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " found",
                " to",
                " be",
                " prof",
                "iting",
                " from",
                " fetal",
                " tissue",
                " sales",
                ".",
                "\u010a",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 92.54290008544922,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                92.54290008544922,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -2.628365516662598,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"anity\", \"ilers\", \"iled\", \"essor\"], \"v\": [10.372483253479004, 10.105545997619629, 9.598834037780762, 9.457843780517578, 8.560376167297363]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"WARE\", \" coupled\", \" halfway\", \" upholding\"], \"v\": [-22.388961791992188, -22.121315002441406, -22.056013107299805, -21.966045379638672, -21.63913917541504]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uq3wf4rmzm7n319",
            "tokens": [
                " crude",
                " excuses",
                " have",
                " been",
                " touted",
                " to",
                " justify",
                " the",
                " prof",
                "usion",
                " of",
                " official",
                " posts",
                " to",
                " the",
                " party",
                " legislators"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 91.72819519042969,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                91.72819519042969,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -6.67809009552002,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"iled\", \"iles\", \"ilers\", \"essor\"], \"v\": [11.389540672302246, 11.183966636657715, 10.086838722229004, 10.005646705627441, 9.556693077087402]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"forth\", \"warm\", \" tightening\", \"MENTS\", \" coupled\"], \"v\": [-24.799625396728516, -23.926332473754883, -23.796171188354492, -23.647605895996094, -23.069732666015625]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uq4wf4r97bv1k93",
            "tokens": [
                " 36",
                "%,",
                " the",
                " Palestinians",
                " by",
                " 19",
                "%.",
                " This",
                " prof",
                "usion",
                " of",
                " numbers",
                " can",
                ",",
                "<|endoftext|>",
                ",",
                " thus"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 91.09136199951172,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                91.09136199951172,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -7.56873083114624,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"ilers\", \"iler\", \"anity\", \"iles\"], \"v\": [11.832050323486328, 11.794286727905273, 11.74058723449707, 10.71628189086914, 10.47463607788086]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \" coupled\", \" tightening\", \"forth\", \" halfway\"], \"v\": [-24.945240020751953, -23.73922348022461, -23.615474700927734, -23.078994750976562, -22.990875244140625]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uq5wf4rvljrczhk",
            "tokens": [
                " whether",
                " they",
                " had",
                " faced",
                " any",
                " protests",
                " about",
                " this",
                " prof",
                "an",
                "ation",
                " of",
                " hall",
                "owed",
                " ground",
                ".",
                " Had"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 90.75320434570312,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                90.75320434570312,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                4.481812000274658,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ilers\", \"iler\", \"iled\", \"iles\", \"essor\"], \"v\": [8.854408264160156, 8.543140411376953, 8.003878593444824, 7.831045150756836, 7.177013397216797]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"forth\", \"warm\", \" halfway\", \" tightening\", \" coupled\"], \"v\": [-27.184795379638672, -27.119688034057617, -26.658323287963867, -26.585018157958984, -26.454811096191406]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uq6wf4rgk3sxwzc",
            "tokens": [
                " oversee",
                " exports",
                ",",
                " act",
                " against",
                " ho",
                "arding",
                " and",
                " prof",
                "ite",
                "ering",
                ",",
                " and",
                " encourage",
                " farmers",
                " to",
                " grow"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 87.7917251586914,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                87.7917251586914,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -4.182712554931641,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"iled\", \"anity\", \"ilers\", \"iles\"], \"v\": [14.601728439331055, 14.327903747558594, 13.335798263549805, 13.167173385620117, 12.263177871704102]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" capped\", \"warm\", \" coupled\", \"forth\", \"WARE\"], \"v\": [-19.510862350463867, -19.139122009277344, -19.111312866210938, -18.97063636779785, -18.837656021118164]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uq7wf4reewmrcka",
            "tokens": [
                " morning",
                " causing",
                " a",
                " heated",
                " fight",
                " between",
                " defenders",
                " of",
                " prof",
                "ane",
                " piece",
                " of",
                " protest",
                " art",
                " and",
                " women",
                " trying"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 87.60845184326172,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                87.60845184326172,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -3.344058990478516,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"iled\", \"ilers\", \"anity\", \"iles\"], \"v\": [10.29924488067627, 9.649778366088867, 9.49781322479248, 8.493871688842773, 8.278792381286621]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" halfway\", \"forth\", \"warm\", \" coupled\", \"WARE\"], \"v\": [-23.879732131958008, -23.795446395874023, -23.652677536010742, -23.517751693725586, -23.340330123901367]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uq8wf4r6ll9aulm",
            "tokens": [
                " October",
                ",",
                " Cos",
                "mo",
                " writer",
                " Michelle",
                " Ru",
                "iz",
                " prof",
                "iled",
                " the",
                " women",
                " behind",
                " the",
                " boycott",
                " of",
                " Ivanka"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 87.19193267822266,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                87.19193267822266,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -1.623044610023499,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"anity\", \"iler\", \"ilers\", \"essor\", \"usion\"], \"v\": [3.7636289596557617, 3.7092437744140625, 3.204545021057129, 2.4838027954101562, 2.3018627166748047]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \" coupled\", \" capped\", \" shortened\"], \"v\": [-29.310869216918945, -29.14691162109375, -28.966936111450195, -28.79668426513672, -28.64056396484375]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uq9wf4rloyf84mx",
            "tokens": [
                " are",
                " predatory",
                " and",
                " are",
                " very",
                " much",
                " driven",
                " toward",
                " prof",
                "iting",
                " off",
                " drivers",
                ".\"",
                "\u010a",
                "\u010a",
                "Uber",
                ","
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 86.25960540771484,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                86.25960540771484,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -4.736244201660156,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"essor\"], \"v\": [12.437528610229492, 12.136573791503906, 10.957015037536621, 10.838111877441406, 10.32943344116211]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"WARE\", \" coupled\", \"MENTS\", \"warm\", \" capped\"], \"v\": [-20.25281524658203, -19.405452728271484, -19.305892944335938, -19.26384735107422, -19.108863830566406]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uqawf4rop65hjjc",
            "tokens": [
                " er",
                "ot",
                "ica",
                " is",
                " under",
                " attack",
                ",",
                " the",
                " prof",
                "ite",
                "ers",
                " will",
                " either",
                " move",
                " on",
                " to",
                " another"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 85.70246887207031,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                85.70246887207031,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.67731237411499,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"iles\"], \"v\": [7.993669033050537, 7.211967945098877, 6.532273769378662, 5.934268474578857, 5.705432415008545]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"WARE\", \"forth\", \" halfway\", \"MENTS\"], \"v\": [-24.454273223876953, -24.375160217285156, -24.042762756347656, -23.81713104248047, -23.73332977294922]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uqbwf4rc2mk43qs",
            "tokens": [
                " an",
                " idea",
                " for",
                " a",
                " game",
                " that",
                " resembles",
                " a",
                " prof",
                "ane",
                " version",
                " of",
                " App",
                "les",
                " to",
                " App",
                "les"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 85.48002624511719,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                85.48002624511719,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -2.947748184204102,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"ilers\", \"iler\", \"iles\", \"anity\"], \"v\": [9.437650680541992, 8.636478424072266, 8.356667518615723, 8.263425827026367, 7.9678449630737305]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \" coupled\", \" halfway\", \"forth\", \"WAY\"], \"v\": [-23.636796951293945, -23.49420738220215, -23.440181732177734, -23.382226943969727, -23.353416442871094]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uqcwf4rljdxl125",
            "tokens": [
                " their",
                " child",
                ",",
                " while",
                " proceeding",
                " to",
                " thank",
                " me",
                " prof",
                "use",
                "ly",
                " for",
                " my",
                " care",
                ".",
                "\u010a",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 85.13813781738281,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                85.13813781738281,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -15.21716117858887,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ilers\", \"iler\", \"anity\", \"iles\", \"essor\"], \"v\": [21.07236671447754, 20.59706687927246, 20.192035675048828, 19.079328536987305, 19.046337127685547]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \" halfway\", \"ingly\", \"WAY\"], \"v\": [-16.708831787109375, -16.646804809570312, -15.460395812988281, -15.403615951538086, -14.921957015991211]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uqdwf4rk2otc9hb",
            "tokens": [
                "abb",
                ".",
                "<|endoftext|>",
                "The",
                " man",
                " heard",
                " in",
                " a",
                " prof",
                "anity",
                "-",
                "laden",
                " video",
                " ber",
                "ating",
                " Toronto",
                " police"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 84.8985595703125,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                84.8985595703125,
                0.1420039236545563,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -7.489263534545898,
                -0.000423431396484375,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"ilers\", \"iles\", \"iler\", \"anity\"], \"v\": [9.241517066955566, 8.360444068908691, 8.213240623474121, 8.022965431213379, 7.489263534545898]}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"iles\"], \"v\": [0.03522300720214844, 0.03470420837402344, 0.03369712829589844, 0.03254127502441406, 0.0316925048828125]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \" shortened\", \" halfway\", \" coupled\", \"forth\"], \"v\": [-23.756534576416016, -23.5587100982666, -23.50641441345215, -23.47452735900879, -23.43258285522461]}, {\"t\": [\"warm\", \"WARE\", \"forth\", \"MENTS\", \" halfway\"], \"v\": [-0.017297744750976562, -0.016956329345703125, -0.016458511352539062, -0.016239166259765625, -0.015954971313476562]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uqewf4r04rjq0t7",
            "tokens": [
                " properly",
                " motivated",
                ".",
                "\u010a",
                "\u010a",
                "They",
                " are",
                " deeply",
                " prof",
                "ane",
                ",",
                " blunt",
                ",",
                " and",
                " intoler",
                "ant",
                " of"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 84.57421875,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                84.57421875,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.4075584411621094,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"anity\", \"iler\", \"ilers\", \"iled\", \"iles\"], \"v\": [6.685035705566406, 6.306344985961914, 5.292749404907227, 4.689021110534668, 4.304553985595703]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \" coupled\", \"forth\", \" halfway\", \"WARE\"], \"v\": [-28.888402938842773, -28.390583038330078, -27.93031883239746, -27.78761100769043, -27.498048782348633]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uqfwf4rt2k0abcv",
            "tokens": [
                " have",
                " stri",
                "ved",
                " to",
                " ensure",
                " that",
                " we",
                " have",
                " prof",
                "iled",
                " most",
                " of",
                " the",
                " code",
                "base",
                " (",
                "currently"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 84.46427154541016,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                84.46427154541016,
                3.362858057022095,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -8.665143966674805,
                0.02258110046386719,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"anity\", \"iled\", \"iler\", \"essor\", \"ilers\"], \"v\": [9.107393264770508, 8.665143966674805, 8.607568740844727, 7.397312164306641, 7.386214256286621]}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"iles\"], \"v\": [0.957305908203125, 0.9394626617431641, 0.9176120758056641, 0.8937110900878906, 0.8713340759277344]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"WARE\", \" coupled\", \"warm\", \"forth\", \" capped\"], \"v\": [-22.733619689941406, -22.503170013427734, -22.25335693359375, -21.846080780029297, -21.65839385986328]}, {\"t\": [\"warm\", \"WARE\", \"forth\", \"MENTS\", \" halfway\"], \"v\": [-0.3120880126953125, -0.2983894348144531, -0.28144073486328125, -0.2778491973876953, -0.27300262451171875]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uqgwf4rq4ufqhdp",
            "tokens": [
                " out",
                " that",
                " neither",
                " he",
                " nor",
                " Wa",
                "ite",
                " used",
                " prof",
                "anity",
                " or",
                " threatened",
                " the",
                " referee",
                " before",
                " being",
                " thrown"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 83.09059143066406,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                83.09059143066406,
                0.484652191400528,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -5.095215320587158,
                -0.006176471710205078,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"iler\", \"ilers\", \"essor\", \"anity\"], \"v\": [7.035634517669678, 6.812906742095947, 5.667032718658447, 5.336248397827148, 5.095215320587158]}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"iles\"], \"v\": [0.12368965148925781, 0.12184333801269531, 0.11873054504394531, 0.11481475830078125, 0.11200332641601562]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \" halfway\", \" coupled\", \"forth\", \" shortened\"], \"v\": [-25.07605743408203, -24.737937927246094, -24.527217864990234, -24.471220016479492, -24.402183532714844]}, {\"t\": [\"warm\", \"WARE\", \"forth\", \"MENTS\", \" shortened\"], \"v\": [-0.05413818359375, -0.052631378173828125, -0.05073356628417969, -0.05030250549316406, -0.04905128479003906]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uqhwf4rdc8tz9dp",
            "tokens": [
                " include",
                " clothing",
                " and",
                " to",
                " set",
                " increased",
                " penalties",
                " for",
                " prof",
                "ite",
                "ering",
                ".",
                " Opp",
                "onents",
                " delayed",
                " passage",
                " for"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 82.9068832397461,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                82.9068832397461,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.7597589492797852,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"iler\", \"anity\", \"essor\", \"ilers\"], \"v\": [9.369848251342773, 9.033697128295898, 8.427324295043945, 7.614398956298828, 7.422232151031494]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"WARE\", \" coupled\", \"warm\", \" halfway\", \"forth\"], \"v\": [-20.673927307128906, -20.48382568359375, -20.44647216796875, -20.427982330322266, -20.398296356201172]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uqiwf4r23rl9qdx",
            "tokens": [
                " person",
                " criticized",
                " the",
                " list",
                " of",
                " alternatives",
                " for",
                " including",
                " prof",
                "anity",
                " because",
                " sw",
                "ears",
                " are",
                " fairly",
                " common",
                " triggers"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 81.20896911621094,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                81.20896911621094,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -7.333600521087646,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"essor\"], \"v\": [8.992398262023926, 8.836261749267578, 7.3336005210876465, 7.29914665222168, 6.694913864135742]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \" shortened\", \"forth\", \" coupled\", \" halfway\"], \"v\": [-21.42648696899414, -21.100187301635742, -20.868711471557617, -20.837505340576172, -20.7196044921875]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uqjwf4refex09a5",
            "tokens": [
                "\u00e2\u0122",
                "\u013e",
                "We",
                "\u00e2\u0122",
                "\u013b",
                "ve",
                " seen",
                " a",
                " prof",
                "usion",
                " \u00e2\u0122\u0135",
                " an",
                " explosion",
                " \u00e2\u0122\u0135",
                " of",
                " marijuana",
                " grows"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 79.87067413330078,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                79.87067413330078,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -5.062851905822754,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"iler\", \"ilers\", \"iles\", \"anity\"], \"v\": [9.110231399536133, 8.436474800109863, 8.16226863861084, 7.914569854736328, 7.468579292297363]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \" halfway\", \" coupled\", \"WAY\"], \"v\": [-22.87867546081543, -21.96402359008789, -21.914854049682617, -21.870555877685547, -21.436248779296875]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urbwf4rwo9zfmfm",
            "tokens": [
                " the",
                " other",
                " boot",
                " after",
                " it",
                " while",
                " screaming",
                " a",
                " prof",
                "anity",
                ".",
                " It",
                "'s",
                " a",
                " cath",
                "art",
                "ic"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 78.29869079589844,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                78.29869079589844,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -9.623699188232422,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"ilers\", \"iler\", \"iles\", \"anity\"], \"v\": [11.683170318603516, 11.366878509521484, 10.808082580566406, 10.708106994628906, 9.623699188232422]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \" halfway\", \" coupled\", \" shortened\", \"WAY\"], \"v\": [-22.67658042907715, -22.413738250732422, -22.10515594482422, -21.867475509643555, -21.693601608276367]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urgwf4rzsqhcqdn",
            "tokens": [
                " in",
                " Africa",
                ".",
                "\u010a",
                "\u010a",
                "Compl",
                "ications",
                " include",
                " prof",
                "use",
                " bleeding",
                " in",
                " the",
                " digestive",
                " system",
                " that",
                " can"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 74.99663543701172,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                74.99663543701172,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -8.15451717376709,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"ilers\", \"iled\", \"essor\", \"anity\"], \"v\": [12.876720428466797, 12.066871643066406, 12.045543670654297, 11.819511413574219, 11.358349800109863]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \" shortened\", \" tightening\", \" halfway\", \" coupled\"], \"v\": [-17.312925338745117, -16.92156410217285, -16.90750503540039, -16.46149253845215, -16.400718688964844]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urfwf4rk2uwulzu",
            "tokens": [
                " the",
                " senior",
                " tore",
                " off",
                " his",
                " jersey",
                " and",
                " yelled",
                " prof",
                "an",
                "ities",
                " before",
                " breaking",
                " down",
                " in",
                " tears",
                "."
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 70.69331359863281,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                70.69331359863281,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -4.747063636779785,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"iled\", \"ilers\", \"iles\", \"essor\"], \"v\": [15.824947357177734, 15.72861099243164, 15.044950485229492, 14.256479263305664, 14.230080604553223]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"forth\", \"warm\", \"WAY\", \" halfway\", \" coupled\"], \"v\": [-14.61224365234375, -14.550628662109375, -14.17697525024414, -14.020517349243164, -13.63583755493164]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653uriwf4r5clpvtlk",
            "tokens": [
                ".",
                " Jag",
                " h",
                "\u00c3\u00b6",
                "ll",
                " l",
                "\u00c3\u00a5",
                "g",
                " prof",
                "il",
                " k",
                "ring",
                " hur",
                " j",
                "ag",
                " t",
                "\u00c3\u00a4"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 69.35858154296875,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                69.35858154296875,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -9.216400146484375,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"ilers\", \"anity\", \"iling\", \"iler\"], \"v\": [19.464542388916016, 18.007274627685547, 17.566993713378906, 17.519927978515625, 17.140804290771484]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \" shortened\", \" til\", \" halfway\", \" till\"], \"v\": [-10.133113861083984, -9.534872055053711, -9.45738697052002, -9.160404205322266, -9.08877182006836]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urhwf4rj9l59ypy",
            "tokens": [
                " agreements",
                " with",
                " the",
                " Trump",
                " campaign",
                " as",
                " \u00e2\u0122",
                "\u013e",
                "prof",
                "ound",
                "ly",
                " disturbing",
                "\u00e2\u0122",
                "\u013f",
                " ethical",
                " conflicts",
                "."
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 66.35282897949219,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                66.35282897949219,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.045480728149414,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"ilers\", \"iled\", \"anity\", \"usion\"], \"v\": [6.303709983825684, 5.714489936828613, 5.439143180847168, 5.23992919921875, 3.5378494262695312]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"\\u00e2\\u0136\\u0122\\u00e2\\u0136\\u0122\\u00e2\\u0136\\u0122\\u00e2\\u0136\\u0122\", \" halfway\", \"ARY\"], \"v\": [-19.727022171020508, -18.561887741088867, -18.059764862060547, -17.999435424804688, -17.888290405273438]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urewf4rqfm3vjn8",
            "tokens": [
                " also",
                " going",
                " to",
                " use",
                " the",
                " Java",
                " Your",
                "Kit",
                " prof",
                "iler",
                " throughout",
                " the",
                " article",
                ",",
                " to",
                " analyze",
                " the"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 66.0800552368164,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                66.0800552368164,
                0.2902316749095917,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -2.482103824615479,
                0.007228851318359375,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"anity\", \"iler\", \"ilers\", \"iles\"], \"v\": [3.483719825744629, 3.376577377319336, 2.4821038246154785, 2.1024203300476074, 1.9273757934570312]}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"iles\"], \"v\": [0.06664657592773438, 0.0660858154296875, 0.06322097778320312, 0.0614471435546875, 0.05932044982910156]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" coupled\", \"warm\", \"WARE\", \" shortened\", \" halfway\"], \"v\": [-20.105648040771484, -19.8546085357666, -19.77579116821289, -19.43398666381836, -19.359859466552734]}, {\"t\": [\"warm\", \"WARE\", \"forth\", \"MENTS\", \" halfway\"], \"v\": [-0.0428314208984375, -0.041477203369140625, -0.04096412658691406, -0.04027557373046875, -0.03975486755371094]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urjwf4r90l17fqz",
            "tokens": [
                " meets",
                " with",
                " five",
                " survivors",
                " and",
                " is",
                " \u00e2\u0122",
                "\u013a",
                "prof",
                "ound",
                "ly",
                " sorry",
                "\u00e2\u0122",
                "\u013b",
                " but",
                " advocates",
                " say"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 63.68034362792969,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                63.68034362792969,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.04212906956672668,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"anity\", \"ilers\", \"iled\", \"usion\"], \"v\": [6.833734512329102, 6.346952438354492, 6.340458869934082, 5.901397705078125, 4.763216018676758]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \" halfway\", \" shortened\", \" coupled\"], \"v\": [-17.28354263305664, -16.721193313598633, -16.24317169189453, -15.741294860839844, -15.59736442565918]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663us7wf4r4xf4jrtz",
            "tokens": [
                "iles",
                " base",
                " and",
                " some",
                " other",
                " libraries",
                ".",
                " --",
                "prof",
                " is",
                " used",
                " to",
                " generate",
                " prof",
                "iled",
                " versions",
                " of"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 62.86886215209961,
            "maxValueTokenIndex": 13,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                17.51020431518555,
                0,
                0,
                0,
                0,
                62.86886215209961,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.3767962455749512,
                0,
                0,
                0,
                0,
                -8.680502891540527,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"iles\"], \"v\": [4.042970180511475, 3.9788689613342285, 3.907376289367676, 3.7474288940429688, 3.5991082191467285]}, {}, {}, {}, {}, {\"t\": [\"iled\", \"anity\", \"iler\", \"ilers\", \"essor\"], \"v\": [8.680502891540527, 8.349104881286621, 8.197473526000977, 7.442014694213867, 7.188004493713379]}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"WARE\", \"warm\", \" shortened\", \"forth\", \" halfway\"], \"v\": [-2.474203109741211, -2.454570770263672, -2.3689842224121094, -2.3598690032958984, -2.3332462310791016]}, {}, {}, {}, {}, {\"t\": [\"WARE\", \"warm\", \" shortened\", \" coupled\", \"forth\"], \"v\": [-14.28920841217041, -14.008844375610352, -13.74660873413086, -13.743289947509766, -13.485321044921875]}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urnwf4r1wuo6pzc",
            "tokens": [
                " street",
                ",",
                " Key",
                " Route",
                " Boulevard",
                ",",
                " \u00e2\u0122",
                "\u013e",
                "prof",
                "use",
                "ly",
                " at",
                " night",
                ".",
                "\u00e2\u0122",
                "\u013f",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 62.02148818969727,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                62.02148818969727,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -3.003238677978516,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"ilers\", \"anity\", \"iled\", \"usion\"], \"v\": [7.153380393981934, 6.9239654541015625, 5.92209529876709, 5.857282638549805, 4.727992057800293]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \" halfway\", \"mere\", \"WAYS\"], \"v\": [-17.720230102539062, -16.738693237304688, -16.63387107849121, -16.572452545166016, -16.565967559814453]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urmwf4r0ekuiqve",
            "tokens": [
                " You",
                " can",
                " even",
                " store",
                " multiple",
                " custom",
                "izations",
                " (",
                "prof",
                "iles",
                "),",
                " and",
                " trigger",
                " a",
                " different",
                " profile",
                " when"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 61.20167541503906,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                61.20167541503906,
                0.8245570659637451,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.3871687054634094,
                -0.02553677558898926,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"iled\", \"anity\", \"ilers\", \"aned\"], \"v\": [2.6534414291381836, 2.538942813873291, 2.153733253479004, 2.000551223754883, 1.4571399688720703]}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"iles\"], \"v\": [0.23686599731445312, 0.2334136962890625, 0.22699737548828125, 0.2204132080078125, 0.21467971801757812]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \" coupled\", \"WARE\", \" shortened\", \"forth\"], \"v\": [-18.91897964477539, -18.13576316833496, -18.041780471801758, -18.032672882080078, -17.9706974029541]}, {\"t\": [\"warm\", \"WARE\", \"forth\", \" shortened\", \"MENTS\"], \"v\": [-0.09288978576660156, -0.09055900573730469, -0.08726310729980469, -0.0852508544921875, -0.08521652221679688]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urlwf4r64cdknke",
            "tokens": [
                " study",
                " the",
                " 1973",
                " war",
                " was",
                " to",
                " \u00e2\u0122",
                "\u013e",
                "prof",
                "ound",
                "ly",
                " influence",
                " the",
                " development",
                " of",
                " the",
                " U"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 60.11878204345703,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                60.11878204345703,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.620184600353241,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"iled\", \"anity\", \"ilers\", \"aned\"], \"v\": [6.524352073669434, 6.4557952880859375, 6.365083694458008, 6.017784118652344, 5.023767471313477]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \" coupled\", \"WAYS\", \"\\u00e2\\u0136\\u0122\\u00e2\\u0136\\u0122\\u00e2\\u0136\\u0122\\u00e2\\u0136\\u0122\"], \"v\": [-15.909608840942383, -15.620615005493164, -14.652379989624023, -14.634769439697266, -14.527843475341797]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urkwf4rpeg05u2c",
            "tokens": [
                " Telegraph",
                " suggests",
                " this",
                " might",
                " include",
                " people",
                " share",
                " \"",
                "prof",
                "ound",
                "\"",
                " quotes",
                " on",
                " social",
                " media",
                " or",
                " use"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 56.42932891845703,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                56.42932891845703,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.4844797253608704,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"iled\", \"ilers\", \"anity\", \"aned\"], \"v\": [5.3928680419921875, 4.937603950500488, 4.695400238037109, 4.413022994995117, 3.7139854431152344]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"WAYS\", \"forth\", \" coupled\", \" shortened\"], \"v\": [-15.823808670043945, -14.493368148803711, -14.375707626342773, -14.306259155273438, -14.045631408691406]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urswf4rhlvm5ihf",
            "tokens": [
                " like",
                " that",
                ".",
                " Oh",
                " and",
                " it",
                " makes",
                " un",
                "prof",
                "itable",
                " but",
                " fun",
                " episodes",
                ",",
                " like",
                " \"",
                "Our"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 52.99271392822266,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                52.99271392822266,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.06968581676483154,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"anity\", \"ilers\", \"iled\", \"iles\"], \"v\": [3.520326614379883, 3.170464515686035, 3.0458803176879883, 3.026613235473633, 2.3749799728393555]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \" shortened\", \"WARE\", \"forth\", \" coupled\"], \"v\": [-15.556720733642578, -15.199199676513672, -15.052665710449219, -15.021774291992188, -14.816608428955078]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urowf4rnfpqttj2",
            "tokens": [
                "On",
                " the",
                " reception",
                " and",
                " detection",
                " of",
                " pseudo",
                "-",
                "prof",
                "ound",
                " bulls",
                "***",
                "',",
                " was",
                " published",
                " in",
                " the"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 52.61010360717773,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                52.61010360717773,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.296572685241699,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"aned\"], \"v\": [3.2232871055603027, 3.112668991088867, 2.57905912399292, 2.3524227142333984, 1.4877777099609375]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"WARE\", \"forth\", \"WAYS\", \" coupled\"], \"v\": [-16.247854232788086, -15.457975387573242, -15.45545768737793, -15.433948516845703, -15.275262832641602]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urqwf4rf8r5244x",
            "tokens": [
                " and",
                " that",
                " he",
                " often",
                " hears",
                " stories",
                " about",
                " \"",
                "prof",
                "essors",
                " who",
                " attack",
                " and",
                " target",
                " conservatives",
                ",",
                " promote"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 50.53939056396484,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                50.53939056396484,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.8521080017089844,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"iled\", \"anity\", \"ilers\", \"aned\"], \"v\": [3.7971296310424805, 3.766294479370117, 3.13394832611084, 2.9840564727783203, 2.342121124267578]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"WARE\", \"WAYS\", \"forth\", \" halfway\"], \"v\": [-14.02052116394043, -13.155691146850586, -13.13432502746582, -13.059768676757812, -13.035869598388672]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urpwf4rolwefr8x",
            "tokens": [
                "aut",
                "ap",
                "el",
                "io",
                "pp",
                "aan",
                " Facebook",
                "-",
                "prof",
                "i",
                "ili",
                ".",
                " Sa",
                "ari",
                " on",
                " p",
                "alk"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 49.51403045654297,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                49.51403045654297,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.334480285644531,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"iling\"], \"v\": [2.9561357498168945, 2.657886505126953, 2.517324447631836, 2.2604103088378906, 1.4798717498779297]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \" shortened\", \" coupled\", \"WARE\"], \"v\": [-14.995311737060547, -14.041797637939453, -13.893657684326172, -13.862579345703125, -13.78778076171875]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urrwf4r5ggler9j",
            "tokens": [
                " that",
                " the",
                " charge",
                ",",
                " Drunk",
                " in",
                " Public",
                " \u00e2\u0122\u0135",
                " Prof",
                "ane",
                " Language",
                ",",
                " was",
                " the",
                " most",
                " frequently",
                " charged"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 47.22676849365234,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                47.22676849365234,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.6107769012451172,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"iler\", \"ilers\", \"anity\", \"usion\"], \"v\": [2.3765268325805664, 2.284846305847168, 2.1193084716796875, 1.7766246795654297, 1.3749065399169922]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"WAYS\", \"WAY\", \" halfway\"], \"v\": [-13.682090759277344, -13.579755783081055, -13.137090682983398, -13.10567855834961, -13.068784713745117]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urxwf4rjqwqxn6m",
            "tokens": [
                " jokes",
                "ters",
                " under",
                " the",
                " hashtag",
                " #",
                "t",
                "roll",
                "prof",
                "watch",
                "list",
                ",",
                " with",
                " complaints",
                " about",
                "<|endoftext|>",
                "\u013b"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 45.24399948120117,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                45.24399948120117,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.205476760864258,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"iling\"], \"v\": [3.862423896789551, 3.6462783813476562, 3.403397560119629, 2.9604263305664062, 2.626950263977051]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"WARE\", \"WAY\", \"WAYS\"], \"v\": [-12.783575057983398, -12.163822174072266, -12.036176681518555, -11.828310012817383, -11.720756530761719]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urtwf4rqdpkj6fb",
            "tokens": [
                " involve",
                " animal",
                " sacrifice",
                "\u010a",
                "\u010a",
                "Two",
                " self",
                "-",
                "prof",
                "essed",
                " witches",
                " have",
                " been",
                " detained",
                " in",
                " Romania",
                " on"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 43.38965606689453,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                43.38965606689453,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.0009289558511227369,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"anity\", \"iler\", \"iled\", \"ilers\", \"iles\"], \"v\": [6.292804718017578, 5.201385498046875, 5.157753944396973, 4.726020812988281, 3.925384521484375]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \" shortened\", \" Parties\", \" halfway\"], \"v\": [-11.564422607421875, -11.246135711669922, -11.073043823242188, -11.02206039428711, -10.922626495361328]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urwwf4rq3r3t6gu",
            "tokens": [
                " and",
                " Khalid",
                " Sheikh",
                " Mohammed",
                ",",
                " the",
                " self",
                "-",
                "prof",
                "essed",
                " mastermind",
                " of",
                " the",
                " 9",
                "/",
                "11",
                " attacks"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 42.19404220581055,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                42.19404220581055,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.0008657395374029875,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"anity\", \"iler\", \"iled\", \"ilers\", \"usion\"], \"v\": [6.575532913208008, 5.284132957458496, 5.139475345611572, 5.085359573364258, 4.103124618530273]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \" shortened\", \" halfway\", \" coupled\"], \"v\": [-11.34475326538086, -11.18460464477539, -10.830196380615234, -10.660652160644531, -10.60513687133789]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653uruwf4rkark4gg9",
            "tokens": [
                "js",
                "-",
                "boot",
                " --",
                "init",
                " -",
                "q",
                " --",
                "prof",
                " .",
                " This",
                " takes",
                " about",
                " 20",
                " minutes",
                " on",
                " my"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 41.50825500488281,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                41.50825500488281,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.334577560424805,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"anity\", \"iler\", \"ilers\", \"aned\"], \"v\": [1.5217218399047852, 1.4574909210205078, 1.2950334548950195, 0.8873634338378906, 0.4999732971191406]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"WARE\", \" shortened\", \"forth\", \" halfway\"], \"v\": [-12.594549179077148, -12.431867599487305, -12.226398468017578, -12.204843521118164, -12.164152145385742]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp653urvwf4r9sqbnklr",
            "tokens": [
                " groups",
                " will",
                " look",
                " like",
                " this",
                ":",
                "\u010a",
                "\u010a",
                "Prof",
                "esse",
                "ur",
                " writes",
                " for",
                " HL",
                "TV",
                ".",
                "org"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 38.2056884765625,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                38.2056884765625,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.013149261474609,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"iling\"], \"v\": [2.1362009048461914, 1.8335752487182617, 1.3845140933990479, 1.336695671081543, 0.8858737945556641]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"WARE\", \"forth\", \"WAY\", \" halfway\"], \"v\": [-12.017951965332031, -11.289449691772461, -11.264402389526367, -11.250631332397461, -11.20128059387207]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663us0wf4rnwmx5g2j",
            "tokens": [
                " (",
                "and",
                " growing",
                ")",
                " animals",
                " in",
                " You",
                "Gov",
                " Prof",
                "iles",
                ",",
                " 16",
                "%",
                " have",
                " given",
                " a",
                " positive"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 37.24104690551758,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                37.24104690551758,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.008028822019696236,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"anity\", \"iler\", \"ilers\", \"aned\"], \"v\": [1.7688961029052734, 1.7500858306884766, 1.569061279296875, 1.2137203216552734, 0.9028892517089844]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"WARE\", \"MENTS\", \" Box\"], \"v\": [-11.578489303588867, -11.540824890136719, -11.190567016601562, -11.055154800415039, -10.97182846069336]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663us4wf4rn11l4jr3",
            "tokens": [
                " stack",
                "trace",
                ".",
                "hs",
                " -",
                "prof",
                " -",
                "f",
                "prof",
                "-",
                "auto",
                " and",
                " then",
                " run",
                " generated",
                " stack",
                "trace"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 35.44530487060547,
            "maxValueTokenIndex": 5,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                35.44530487060547,
                0,
                0,
                22.76450347900391,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                6.806625366210938,
                0,
                0,
                0.9290595054626465,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"anity\", \"iler\", \"ilers\", \"aned\"], \"v\": [2.4974887371063232, 2.363152503967285, 2.3535048961639404, 2.032099723815918, 1.5588512420654297]}, {}, {}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"iles\"], \"v\": [4.870119094848633, 4.826301574707031, 4.663006782531738, 4.519850730895996, 4.292506217956543]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"WARE\", \"forth\", \" shortened\", \" coupled\"], \"v\": [-10.206390380859375, -10.031988143920898, -9.945833206176758, -9.917600631713867, -9.900333404541016]}, {}, {}, {\"t\": [\"warm\", \"WARE\", \"forth\", \" shortened\", \" halfway\"], \"v\": [-3.6354408264160156, -3.5882339477539062, -3.515531539916992, -3.4802093505859375, -3.4461517333984375]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663urzwf4rn8ndcv78",
            "tokens": [
                "'",
                "\u00c3\u00a8",
                " lo",
                " sp",
                "ie",
                "ga",
                " #",
                "le",
                "prof",
                "ession",
                "idel",
                "f",
                "ut",
                "uro",
                " 23",
                " mar",
                "zo"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 35.36377334594727,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                35.36377334594727,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -3.385477975825779e-05,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"iled\", \"anity\", \"ilers\", \"iling\"], \"v\": [2.2376461029052734, 2.195737838745117, 1.9314136505126953, 1.7747745513916016, 1.498453140258789]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"WAY\", \"MENTS\", \"\\u00e2\\u0136\\u0122\\u00e2\\u0136\\u0122\\u00e2\\u0136\\u0122\\u00e2\\u0136\\u0122\", \"forth\"], \"v\": [-8.74509048461914, -8.299823760986328, -8.19485092163086, -8.131431579589844, -8.12417984008789]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663urywf4r1436edbw",
            "tokens": [
                " many",
                " more",
                " :)",
                "<|endoftext|>",
                " Karma",
                ",",
                " Lex",
                ",",
                " Prof",
                ",",
                " Rainbow",
                ",",
                " Fro",
                "do",
                ",",
                " D",
                "ach"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 33.13173294067383,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                33.13173294067383,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.640682220458984,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"iling\"], \"v\": [2.200686454772949, 2.060540199279785, 1.8041105270385742, 1.761610984802246, 1.3489131927490234]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"WAY\", \"WARE\", \" halfway\"], \"v\": [-8.691070556640625, -8.453659057617188, -8.25515365600586, -8.197294235229492, -8.166193008422852]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663us2wf4rmh1givb0",
            "tokens": [
                "In",
                " terms",
                " of",
                " actual",
                " ownership",
                ",",
                " You",
                "Gov",
                " Prof",
                "iles",
                " data",
                " shows",
                " the",
                " Labrador",
                " as",
                "<|endoftext|>",
                " or"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 32.3616943359375,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                32.3616943359375,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.3773723244667053,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"iling\"], \"v\": [1.9163236618041992, 1.5581674575805664, 1.5244560241699219, 1.246668815612793, 0.9139957427978516]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"WARE\", \"MENTS\", \" Nou\"], \"v\": [-9.56951904296875, -9.317787170410156, -9.12929916381836, -9.06114387512207, -9.03494644165039]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663us1wf4ri7p9l6m8",
            "tokens": [
                " Interest",
                " Lit",
                "igation",
                " (",
                "P",
                "IL",
                ")",
                " regarding",
                " Prof",
                " Amb",
                "ik",
                "esh",
                " Mah",
                "ap",
                "atra",
                ",",
                "who"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 29.54167938232422,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                29.54167938232422,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                4.83868408203125,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"aned\"], \"v\": [2.1050643920898438, 2.033341407775879, 1.8080759048461914, 1.7480287551879883, 1.3241405487060547]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"WARE\", \"WAY\", \"MENTS\"], \"v\": [-6.880769729614258, -6.801858901977539, -6.726202011108398, -6.604789733886719, -6.57927131652832]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663us3wf4r4vp5cuux",
            "tokens": [
                " targeting",
                " one",
                " thing",
                ",",
                " but",
                " it",
                " could",
                " spread",
                " Prof",
                " Alan",
                " Woodward",
                ",",
                " Computer",
                " security",
                " expert",
                "\u010a",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 20.6906681060791,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                20.6906681060791,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.063394069671631,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"aned\"], \"v\": [1.9409961700439453, 1.9054555892944336, 1.7160673141479492, 1.680337905883789, 1.415445327758789]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"WARE\", \"WAY\", \" halfway\"], \"v\": [-4.718112945556641, -4.619121551513672, -4.574760437011719, -4.462614059448242, -4.453495025634766]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663us5wf4rgn5twlpn",
            "tokens": [
                " court",
                " also",
                " asked",
                " why",
                " the",
                " person",
                " concerned",
                " (",
                " Prof",
                " Mah",
                "ap",
                "atra",
                ")",
                " not",
                " filed",
                " a",
                " case"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 19.98976898193359,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                19.98976898193359,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.726116180419922,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"iled\", \"anity\", \"ilers\", \"usion\"], \"v\": [2.6722145080566406, 2.668600082397461, 2.5308542251586914, 2.470770835876465, 2.129150390625]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \"WARE\", \" coupled\", \" Nou\"], \"v\": [-3.8359642028808594, -3.831022262573242, -3.7371673583984375, -3.661836624145508, -3.6457977294921875]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663usawf4rsupc8vvx",
            "tokens": [
                " the",
                " filibuster",
                " rule",
                " for",
                " Supreme",
                " Court",
                " nominations",
                ".",
                " Priv",
                "ately",
                ",",
                " some",
                " Democrats",
                " would",
                " rather",
                " wave",
                " Gorsuch"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 11.60090446472168,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                11.60090446472168,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.01724188029766083,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"iled\", \"ilers\", \"anity\", \"iles\"], \"v\": [1.8412494659423828, 1.7824935913085938, 1.6634292602539062, 1.6539936065673828, 1.53277587890625]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"WARE\", \"forth\", \" coupled\", \" halfway\"], \"v\": [-2.7062644958496094, -2.6332931518554688, -2.622028350830078, -2.582723617553711, -2.5369644165039062]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663us8wf4rf6mx53rk",
            "tokens": [
                "Ann",
                "ouncing",
                " the",
                " list",
                ",",
                " AM",
                "RC",
                " chairman",
                " Prof",
                " Dame",
                " Sue",
                " Bailey",
                " said",
                " patients",
                "\u00e2\u0122\u0136",
                "and",
                " doctors"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 11.22191047668457,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                11.22191047668457,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.177019119262695,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iled\", \"iler\", \"anity\", \"ilers\", \"iling\"], \"v\": [1.2633533477783203, 1.151815414428711, 1.1408672332763672, 1.0508766174316406, 0.8971767425537109]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"forth\", \"warm\", \" Nou\", \"WAY\", \" halfway\"], \"v\": [-2.683330535888672, -2.6228294372558594, -2.608968734741211, -2.5718307495117188, -2.533740997314453]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663us9wf4ri7nlqqjy",
            "tokens": [
                "'re",
                " not",
                " exactly",
                " in",
                " a",
                " comfortable",
                " position",
                ".\"",
                " Priv",
                "ately",
                ",",
                " many",
                " in",
                " the",
                " commission",
                "'s",
                " Ber"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 11.21973133087158,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                11.21973133087158,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.194996578618884e-05,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"iled\", \"anity\", \"ilers\", \"iles\"], \"v\": [1.695138931274414, 1.6599540710449219, 1.5722503662109375, 1.5427703857421875, 1.4052352905273438]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"WARE\", \"forth\", \" coupled\", \"MENTS\"], \"v\": [-2.468524932861328, -2.4101333618164062, -2.34344482421875, -2.3218002319335938, -2.3181076049804688]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663us6wf4r9o5dl7ve",
            "tokens": [
                " surrounded",
                " the",
                " Haz",
                "rat",
                "bal",
                " shrine",
                " were",
                " absolutely",
                " incons",
                "ol",
                "able",
                " and",
                " refused",
                " to",
                " move",
                " away",
                " from"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 9.490951538085938,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                9.490951538085938,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.6415109634399414,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"iler\", \"iled\", \"anity\", \"ilers\", \"iles\"], \"v\": [2.1104297637939453, 2.0907669067382812, 2.0652027130126953, 1.9894046783447266, 1.926809310913086]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"warm\", \"forth\", \" coupled\", \" halfway\", \"WARE\"], \"v\": [-1.6826057434082031, -1.6108322143554688, -1.5618438720703125, -1.5418205261230469, -1.529541015625]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp643uqzwf4r3xvgj818",
            "tokens": [
                " have",
                " seen",
                " to",
                " date",
                " I",
                " have",
                " concluded",
                " that",
                " the",
                " test",
                " that",
                " I",
                " am",
                " bound",
                " to",
                " apply",
                ","
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp643uqywf4rfgj39a2l",
            "tokens": [
                " I",
                " have",
                " seen",
                " to",
                " date",
                " I",
                " have",
                " concluded",
                " that",
                " the",
                " test",
                " that",
                " I",
                " am",
                " bound",
                " to",
                " apply"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp643uqpwf4rsv0i42eq",
            "tokens": [
                "\u010a",
                "\u00e2\u0122",
                "\u013e",
                "However",
                ",",
                " from",
                " the",
                " evidence",
                " which",
                " I",
                " have",
                " seen",
                " to",
                " date",
                " I",
                " have",
                " concluded"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp643uqowf4ri4mi1s14",
            "tokens": [
                "\u010a",
                "\u010a",
                "\u00e2\u0122",
                "\u013e",
                "However",
                ",",
                " from",
                " the",
                " evidence",
                " which",
                " I",
                " have",
                " seen",
                " to",
                " date",
                " I",
                " have"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uqnwf4ruvowrxxl",
            "tokens": [
                "<|endoftext|>",
                "\u010a",
                "\u010a",
                "\u00e2\u0122",
                "\u013e",
                "However",
                ",",
                " from",
                " the",
                " evidence",
                " which",
                " I",
                " have",
                " seen",
                " to",
                " date",
                " I"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uqmwf4rso4s4owc",
            "tokens": [
                ":",
                "<|endoftext|>",
                "\u010a",
                "\u010a",
                "\u00e2\u0122",
                "\u013e",
                "However",
                ",",
                " from",
                " the",
                " evidence",
                " which",
                " I",
                " have",
                " seen",
                " to",
                " date"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uqlwf4rd9k76cfn",
            "tokens": [
                " said",
                ":",
                "<|endoftext|>",
                "\u010a",
                "\u010a",
                "\u00e2\u0122",
                "\u013e",
                "However",
                ",",
                " from",
                " the",
                " evidence",
                " which",
                " I",
                " have",
                " seen",
                " to"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp633uqkwf4rqza2h9o2",
            "tokens": [
                " Speaker",
                " said",
                ":",
                "<|endoftext|>",
                "\u010a",
                "\u010a",
                "\u00e2\u0122",
                "\u013e",
                "However",
                ",",
                " from",
                " the",
                " evidence",
                " which",
                " I",
                " have",
                " seen"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp643uqxwf4rq1df0e9a",
            "tokens": [
                " which",
                " I",
                " have",
                " seen",
                " to",
                " date",
                " I",
                " have",
                " concluded",
                " that",
                " the",
                " test",
                " that",
                " I",
                " am",
                " bound",
                " to"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp643uqwwf4rs5hmu72a",
            "tokens": [
                " evidence",
                " which",
                " I",
                " have",
                " seen",
                " to",
                " date",
                " I",
                " have",
                " concluded",
                " that",
                " the",
                " test",
                " that",
                " I",
                " am",
                " bound"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp643uqvwf4rb59kq6vv",
            "tokens": [
                " the",
                " evidence",
                " which",
                " I",
                " have",
                " seen",
                " to",
                " date",
                " I",
                " have",
                " concluded",
                " that",
                " the",
                " test",
                " that",
                " I",
                " am"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp643uquwf4rwn1cynoj",
            "tokens": [
                " from",
                " the",
                " evidence",
                " which",
                " I",
                " have",
                " seen",
                " to",
                " date",
                " I",
                " have",
                " concluded",
                " that",
                " the",
                " test",
                " that",
                " I"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp643uqtwf4rtz970to8",
            "tokens": [
                ",",
                " from",
                " the",
                " evidence",
                " which",
                " I",
                " have",
                " seen",
                " to",
                " date",
                " I",
                " have",
                " concluded",
                " that",
                " the",
                " test",
                " that"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp643uqswf4r7nfsde2z",
            "tokens": [
                "However",
                ",",
                " from",
                " the",
                " evidence",
                " which",
                " I",
                " have",
                " seen",
                " to",
                " date",
                " I",
                " have",
                " concluded",
                " that",
                " the",
                " test"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp643uqrwf4rlw29xps8",
            "tokens": [
                "\u013e",
                "However",
                ",",
                " from",
                " the",
                " evidence",
                " which",
                " I",
                " have",
                " seen",
                " to",
                " date",
                " I",
                " have",
                " concluded",
                " that",
                " the"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp643uqqwf4rryasasqh",
            "tokens": [
                "\u00e2\u0122",
                "\u013e",
                "However",
                ",",
                " from",
                " the",
                " evidence",
                " which",
                " I",
                " have",
                " seen",
                " to",
                " date",
                " I",
                " have",
                " concluded",
                " that"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663uscwf4rjjyk5m7d",
            "tokens": [
                " start",
                " using",
                " Grad",
                "le",
                " regularly",
                ",",
                " you",
                "\u00e2\u0122",
                "\u013b",
                "ll",
                " start",
                " thinking",
                " of",
                " projects",
                " by",
                " their",
                " path"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663usbwf4rt7vd3gq4",
            "tokens": [
                " for",
                " their",
                " generous",
                " approach",
                " to",
                " social",
                " spending",
                ".",
                "\u010a",
                "\u010a",
                "-",
                " San",
                "ctions",
                " woes",
                " -",
                "\u010a",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663usdwf4rb69ytoaf",
            "tokens": [
                " meantime",
                ",",
                " have",
                " a",
                " few",
                " beers",
                " and",
                " embrace",
                " the",
                " tank",
                " 2",
                ".",
                "0",
                "??",
                "\u010a",
                "\u010a",
                "2010"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663usewf4rmf8hpex3",
            "tokens": [
                "\u010a",
                "But",
                " what",
                " about",
                " the",
                " wife",
                " and",
                " young",
                " family",
                " he",
                "'s",
                " left",
                " behind",
                "?",
                "\u010a",
                "\u010a",
                "Much"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp643ur3wf4r16oueuoh",
            "tokens": [
                " I",
                " have",
                " concluded",
                " that",
                " the",
                " test",
                " that",
                " I",
                " am",
                " bound",
                " to",
                " apply",
                ",",
                " that",
                " there",
                " is",
                " an"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp663usfwf4rkbwsjzl9",
            "tokens": [
                " Airlines",
                ",",
                " but",
                " she",
                " hasn",
                "'t",
                " heard",
                " back",
                ".",
                "\u010a",
                "\u010a",
                "\"",
                "I",
                " don",
                "'t",
                " want",
                " another"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp643ur2wf4r39s4rf1s",
            "tokens": [
                " date",
                " I",
                " have",
                " concluded",
                " that",
                " the",
                " test",
                " that",
                " I",
                " am",
                " bound",
                " to",
                " apply",
                ",",
                " that",
                " there",
                " is"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp643ur1wf4rwduh08z9",
            "tokens": [
                " to",
                " date",
                " I",
                " have",
                " concluded",
                " that",
                " the",
                " test",
                " that",
                " I",
                " am",
                " bound",
                " to",
                " apply",
                ",",
                " that",
                " there"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsifcp643ur0wf4rhsc11fjt",
            "tokens": [
                " seen",
                " to",
                " date",
                " I",
                " have",
                " concluded",
                " that",
                " the",
                " test",
                " that",
                " I",
                " am",
                " bound",
                " to",
                " apply",
                ",",
                " that"
            ],
            "dataIndex": null,
            "index": "15342",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:18:46.867Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        }
    ],
    "explanations": [
        {
            "id": "clsy3it5a5pjzkad17n3brg5q",
            "description": "phrases related to profit or benefit",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "scores": []
        },
        {
            "id": "d9u8fkutvw4rh4vlnh1n1tikk",
            "description": " occurrences of the word \"prof\" in various contexts",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "scores": []
        }
    ]
}