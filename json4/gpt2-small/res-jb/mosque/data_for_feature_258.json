{
    "modelId": "gpt2-small",
    "layer": "10-res-jb",
    "index": "258",
    "sourceSetName": "res-jb",
    "creatorId": null,
    "createdAt": "2024-02-12T04:05:23.813Z",
    "maxActApprox": 79.37913513183594,
    "hasVector": false,
    "vector": [],
    "vectorLabel": null,
    "vectorDefaultSteerStrength": 10,
    "hookName": null,
    "topkCosSimIndices": [
        258,
        7976,
        17052,
        22175,
        4808,
        15403,
        9257,
        20381,
        17852,
        2858,
        14659,
        5818,
        12815,
        21512,
        7842,
        1427,
        20278,
        22012,
        15224,
        21920,
        12427,
        23934,
        11463,
        14071,
        10979
    ],
    "topkCosSimValues": [
        1,
        0.4409,
        0.4308,
        0.4262,
        0.3952,
        0.3942,
        0.3913,
        0.3679,
        0.3679,
        0.3595,
        0.3494,
        0.3437,
        0.3388,
        0.3386,
        0.3304,
        0.3285,
        0.3142,
        0.3088,
        0.3021,
        0.3013,
        0.2999,
        0.2985,
        0.2965,
        0.2955,
        0.291
    ],
    "neuron_alignment_indices": [
        124,
        57,
        349
    ],
    "neuron_alignment_values": [
        0.1317449957132339,
        0.1262095421552658,
        0.0921919196844101
    ],
    "neuron_alignment_l1": [
        0.006035520695149899,
        0.005781929474323988,
        0.004223509225994349
    ],
    "correlated_neurons_indices": [
        57,
        124,
        628
    ],
    "correlated_neurons_pearson": [
        0.01338576804846525,
        0.01285785529762506,
        0.01098934002220631
    ],
    "correlated_neurons_l1": [
        0.01139995642006397,
        0.01411062572151423,
        0.011121716350317
    ],
    "correlated_features_indices": [],
    "correlated_features_pearson": [],
    "correlated_features_l1": [],
    "neg_str": [
        "istics",
        " Thumbnails",
        "ordinate",
        " Archdemon",
        " Rite",
        "OWN",
        "istically",
        " Volks",
        "ocument",
        "istical"
    ],
    "neg_values": [
        -0.7342726588249207,
        -0.6789818406105042,
        -0.6647436022758484,
        -0.6540240049362183,
        -0.636638343334198,
        -0.6242613196372986,
        -0.6188353896141052,
        -0.6055548191070557,
        -0.6052035689353943,
        -0.6036744117736816
    ],
    "pos_str": [
        "aic",
        "quit",
        "bian",
        "qu",
        "ques",
        "lems",
        "daq",
        "adiq",
        "cos",
        "kov"
    ],
    "pos_values": [
        1.213742971420288,
        1.170892834663391,
        1.049140572547913,
        1.036515235900879,
        1.012258052825928,
        1.001293420791626,
        0.9927515983581543,
        0.9906544089317322,
        0.9892076253890991,
        0.9819018244743347
    ],
    "frac_nonzero": 0.0002740224202473958,
    "freq_hist_data_bar_heights": [
        376,
        167,
        123,
        53,
        55,
        36,
        14,
        2,
        2,
        2,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        2,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        1,
        1,
        2,
        1,
        4,
        5,
        0,
        3,
        4,
        3,
        5
    ],
    "freq_hist_data_bar_values": [
        1.003769278526306,
        3.008820533752441,
        5.013872146606445,
        7.018923282623291,
        9.023974418640137,
        11.02902603149414,
        13.03407669067383,
        15.03912830352783,
        17.04417991638184,
        19.04923057556152,
        21.05428314208984,
        23.05933380126953,
        25.06438446044922,
        27.06943702697754,
        29.07448768615723,
        31.07954025268555,
        33.08459091186523,
        35.08964157104492,
        37.09469223022461,
        39.09974670410156,
        41.10479736328125,
        43.10984802246094,
        45.11490249633789,
        47.11995315551758,
        49.12500381469727,
        51.13005447387695,
        53.13510894775391,
        55.14015960693359,
        57.14521026611328,
        59.15026092529297,
        61.15531158447266,
        63.16036224365234,
        65.16541290283203,
        67.17046356201172,
        69.1755142211914,
        71.1805648803711,
        73.18562316894531,
        75.190673828125,
        77.19572448730469,
        79.20077514648438
    ],
    "logits_hist_data_bar_heights": [
        1,
        3,
        9,
        15,
        37,
        89,
        172,
        371,
        772,
        1588,
        2522,
        3868,
        5108,
        5858,
        6125,
        5887,
        4893,
        3729,
        2734,
        1896,
        1459,
        932,
        675,
        459,
        319,
        250,
        173,
        115,
        64,
        48,
        28,
        19,
        17,
        5,
        7,
        6,
        2,
        0,
        0,
        2
    ],
    "logits_hist_data_bar_values": [
        -0.7099224328994751,
        -0.6612221002578735,
        -0.6125216484069824,
        -0.5638213157653809,
        -0.5151208639144897,
        -0.4664205014705658,
        -0.4177201092243195,
        -0.3690197169780731,
        -0.3203193247318268,
        -0.2716189324855804,
        -0.2229185402393341,
        -0.1742181479930878,
        -0.1255177557468414,
        -0.07681736350059509,
        -0.02811697125434875,
        0.02058342099189758,
        0.06928381323814392,
        0.1179842054843903,
        0.1666845977306366,
        0.2153849899768829,
        0.2640853226184845,
        0.3127857148647308,
        0.3614861071109772,
        0.4101864993572235,
        0.4588868916034698,
        0.5075873136520386,
        0.5562876462936401,
        0.6049880981445312,
        0.6536884307861328,
        0.7023888826370239,
        0.7510892152786255,
        0.7997896671295166,
        0.8484899997711182,
        0.8971904516220093,
        0.9458907842636108,
        0.994591236114502,
        1.043291568756104,
        1.091991901397705,
        1.140692353248596,
        1.189392805099487
    ],
    "decoder_weights_dist": [],
    "umap_cluster": null,
    "umap_log_feature_sparsity": null,
    "umap_x": null,
    "umap_y": null,
    "model": {
        "id": "gpt2-small",
        "displayNameShort": "GPT2-SM",
        "displayName": "GPT2-Small",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "tlensId": null,
        "dimension": 768,
        "visibility": "PUBLIC",
        "inferenceEnabled": true,
        "instruct": false,
        "layers": 12,
        "neuronsPerLayer": 3072,
        "createdAt": "2023-07-06T00:01:44.843Z",
        "owner": "OpenAI",
        "updatedAt": "2023-07-06T00:01:44.843Z",
        "website": "https://openai.com"
    },
    "lists": [],
    "creator": null,
    "source": {
        "id": "10-res-jb",
        "modelId": "gpt2-small",
        "hasDashboards": true,
        "inferenceEnabled": true,
        "saelensConfig": {
            "lr": 0.0004,
            "d_in": 768,
            "seed": 42,
            "d_sae": 24576,
            "dtype": "torch.float32",
            "device": "mps",
            "run_name": "24576-L1-8e-05-LR-0.0004-Tokens-3.000e+08",
            "hook_point": "blocks.10.hook_resid_pre",
            "model_name": "gpt2-small",
            "prepend_bos": true,
            "architecture": "standard",
            "context_size": 128,
            "dataset_path": "Skylion007/openwebtext",
            "log_to_wandb": true,
            "wandb_entity": null,
            "n_checkpoints": 10,
            "wandb_project": "mats_sae_training_gpt2_small_resid_pre_5",
            "l1_coefficient": 8e-05,
            "neuronpedia_id": "gpt2-small/10-res-jb",
            "checkpoint_path": "checkpoints/9vu4ulem",
            "use_ghost_grads": false,
            "expansion_factor": 32,
            "hook_point_layer": 10,
            "lr_warm_up_steps": 5000,
            "resample_batches": 1028,
            "store_batch_size": 32,
            "train_batch_size": 4096,
            "activation_fn_str": "relu",
            "b_dec_init_method": "geometric_median",
            "lr_scheduler_name": null,
            "tokens_per_buffer": 67108864,
            "dead_feature_window": 5000,
            "n_batches_in_buffer": 128,
            "wandb_log_frequency": 100,
            "apply_b_dec_to_input": true,
            "feature_reinit_scale": 0.2,
            "from_pretrained_path": null,
            "is_dataset_tokenized": false,
            "hook_point_head_index": null,
            "normalize_activations": "none",
            "total_training_tokens": 300000000,
            "dead_feature_threshold": 1e-08,
            "use_cached_activations": false,
            "cached_activations_path": "activations/Skylion007_openwebtext/gpt2-small/blocks.10.hook_resid_pre",
            "feature_sampling_method": null,
            "feature_sampling_window": 1000,
            "dataset_trust_remote_code": true,
            "finetuning_scaling_factor": false,
            "sae_lens_training_version": null,
            "model_from_pretrained_kwargs": {
                "center_writing_weights": true
            },
            "dead_feature_estimation_method": "no_fire"
        },
        "saelensRelease": "gpt2-small-res-jb",
        "saelensSaeId": "blocks.10.hook_resid_pre",
        "hfRepoId": "jbloom/GPT2-Small-SAEs-Reformatted",
        "hfFolderId": "blocks.10.hook_resid_pre",
        "visibility": "PUBLIC",
        "setName": "res-jb",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "hasUmap": true,
        "hasUmapLogSparsity": true,
        "hasUmapClusters": true,
        "num_prompts": 24576,
        "num_tokens_in_prompt": 128,
        "dataset": "Skylion007/openwebtext",
        "notes": null,
        "createdAt": "2024-07-10T04:46:32.069Z"
    },
    "sourceSet": {
        "modelId": "gpt2-small",
        "name": "res-jb",
        "hasDashboards": true,
        "visibility": "PUBLIC",
        "description": "Open Source Sparse Autoencoders for all Residual Stream Layers of GPT2-Small",
        "type": "Residual Stream",
        "creatorName": "Joseph Bloom",
        "urls": [
            "https://www.lesswrong.com/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream",
            "https://huggingface.co/jbloom/GPT2-Small-SAEs/tree/main",
            "https://github.com/jbloomAus/mats_sae_training"
        ],
        "creatorEmail": null,
        "creatorId": "cljgamm90000076zdchicy6zj",
        "releaseName": "gpt2sm-res-jb",
        "defaultRange": 2,
        "defaultShowBreaks": true,
        "showDfa": false,
        "showCorrelated": false,
        "showHeadAttribution": false,
        "showUmap": true,
        "createdAt": "2024-07-10T04:46:32.075Z"
    },
    "activations": [
        {
            "id": "clsievnuabqlgwf4rzueqrwan",
            "tokens": [
                " can",
                "\u00e2\u0122",
                "\u013b",
                "<|endoftext|>",
                "ases",
                ".",
                "\u010a",
                "\u010a",
                "Mos",
                "'",
                "ab",
                " El",
                "sh",
                "amy",
                " A",
                " graffiti",
                " artist"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 79.37913513183594,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                1.17173171043396,
                0,
                0,
                0,
                79.37913513183594,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0.1016921997070312,
                0,
                0,
                0,
                4.598512649536133,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"bian\", \"qu\", \"lems\"], \"v\": [0.1864147186279297, 0.1709747314453125, 0.14064884185791016, 0.13646459579467773, 0.13535118103027344]}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"bian\", \"lems\", \"daq\"], \"v\": [8.873319625854492, 7.249140739440918, 6.395881175994873, 5.84188175201416, 5.803623199462891]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Thumbnails\", \" Archdemon\", \"ordinate\", \" Rite\"], \"v\": [-0.2756977081298828, -0.260955810546875, -0.25835609436035156, -0.2577381134033203, -0.25382041931152344]}, {}, {}, {}, {\"t\": [\"istics\", \"ordinate\", \" Rite\", \" Archdemon\", \" Thumbnails\"], \"v\": [-17.695566177368164, -16.82069969177246, -16.612943649291992, -16.301456451416016, -16.063194274902344]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqlywf4rzct4e1gx",
            "tokens": [
                ".",
                "<|endoftext|>",
                "Mos",
                "he",
                " Kah",
                "lon",
                "\u010a",
                "\u010a",
                "Mos",
                "he",
                " Kah",
                "lon",
                " is",
                " not",
                " a",
                " household",
                " name"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 79.08055114746094,
            "maxValueTokenIndex": 2,
            "minValue": 0,
            "values": [
                0,
                0,
                79.08055114746094,
                1.115122675895691,
                0,
                0,
                0,
                0,
                66.83214569091797,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                -2.14779806137085,
                0.05013394355773926,
                0,
                0,
                0,
                0,
                0.0007619261741638184,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {\"t\": [\"aic\", \"quit\", \"bian\", \"daq\", \"lems\"], \"v\": [9.541101455688477, 7.978879451751709, 6.903367519378662, 6.621044158935547, 6.466179370880127]}, {\"t\": [\"aic\", \"quit\", \"bian\", \"cos\", \"qu\"], \"v\": [0.2542762756347656, 0.24880409240722656, 0.21078872680664062, 0.2084674835205078, 0.20799732208251953]}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"bian\", \"qu\", \"daq\"], \"v\": [6.396943092346191, 5.61600399017334, 4.735540390014648, 4.107979774475098, 4.057104110717773]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {\"t\": [\"istics\", \"ordinate\", \" Rite\", \" Archdemon\", \"istical\"], \"v\": [-17.164836883544922, -16.458871841430664, -16.209274291992188, -15.836402893066406, -15.564169883728027]}, {\"t\": [\"istics\", \" Rite\", \" Archdemon\", \"OWN\", \" Thumbnails\"], \"v\": [-0.1835803985595703, -0.1715230941772461, -0.17032623291015625, -0.1578235626220703, -0.1572418212890625]}, {}, {}, {}, {}, {\"t\": [\"istics\", \"ordinate\", \" Archdemon\", \" Thumbnails\", \"govtrack\"], \"v\": [-13.856422424316406, -13.203821182250977, -12.841190338134766, -12.611139297485352, -12.584901809692383]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqlhwf4ramsx79p3",
            "tokens": [
                " do",
                " need",
                " to",
                " click",
                " here",
                " to",
                " read",
                " Colonel",
                " Mos",
                "ch",
                "gat",
                "'s",
                " account",
                " at",
                " Together",
                " We",
                " Serv"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 78.26818084716797,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                78.26818084716797,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.7431478500366211,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"daq\", \"bian\", \"ques\"], \"v\": [8.118227005004883, 7.789020538330078, 5.957200050354004, 5.551272392272949, 5.403285980224609]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Archdemon\", \" Rite\", \"OWN\", \"ordinate\"], \"v\": [-20.173282623291016, -18.578514099121094, -18.516117095947266, -18.42450714111328, -18.282926559448242]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqliwf4r4ukt3a2f",
            "tokens": [
                " of",
                " fun",
                " in",
                " terms",
                " of",
                " his",
                " status",
                " when",
                " Mos",
                "he",
                " Day",
                "an",
                ",",
                " Gold",
                "a",
                " Me",
                "ir"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 78.22982025146484,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                78.22982025146484,
                4.658160209655762,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -2.985795021057129,
                0.07577109336853027,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"bian\", \"qu\", \"ques\"], \"v\": [10.053159713745117, 10.045970916748047, 7.818050384521484, 7.329136848449707, 7.298831939697266]}, {\"t\": [\"aic\", \"quit\", \"bian\", \"ques\", \"lems\"], \"v\": [1.0321884155273438, 0.9883193969726562, 0.8449306488037109, 0.835296630859375, 0.8340682983398438]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Archdemon\", \" Rite\", \"OWN\", \"ordinate\"], \"v\": [-16.93822479248047, -16.775043487548828, -16.27216339111328, -15.850224494934082, -15.72140121459961]}, {\"t\": [\"istics\", \" Archdemon\", \" Rite\", \"OWN\", \" Thumbnails\"], \"v\": [-0.7674884796142578, -0.7345066070556641, -0.7180671691894531, -0.6824283599853516, -0.6747093200683594]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqljwf4rrf0yrjp5",
            "tokens": [
                " of",
                " palate",
                "-",
                "wreck",
                "ing",
                " Cit",
                "ra",
                " and",
                " Mos",
                "aic",
                " hops",
                ".",
                "\u010a",
                "\u010a",
                "This",
                " beer",
                " was"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 78.0562973022461,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                78.0562973022461,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -7.182090759277344,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"quit\", \"bian\", \"aic\", \"lems\", \"adiq\"], \"v\": [7.6229658126831055, 7.282831192016602, 7.182090759277344, 6.830718994140625, 6.465877532958984]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Rite\", \" Archdemon\", \" Thumbnails\", \"ordinate\"], \"v\": [-22.156511306762695, -21.94561767578125, -20.771394729614258, -20.73578643798828, -20.670211791992188]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqlkwf4rtybsvc0v",
            "tokens": [
                "/",
                "\u010a",
                "\u010a",
                "Sh",
                "it",
                " sn",
                "iped",
                " by",
                " Mos",
                "ko",
                " >",
                ".<",
                " @",
                "K",
                "ant",
                "u",
                "va"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 77.38449096679688,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                77.38449096679688,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.17078161239624,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"bian\", \"adiq\", \"qu\"], \"v\": [8.168256759643555, 7.440825939178467, 6.261059761047363, 6.015013694763184, 5.673316478729248]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Archdemon\", \" Thumbnails\", \" Rite\", \"ordinate\"], \"v\": [-16.56190299987793, -16.0148983001709, -15.523935317993164, -15.094833374023438, -15.044351577758789]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqllwf4r3qbysa5r",
            "tokens": [
                " one",
                " weekend",
                " in",
                " 1976",
                ",",
                " when",
                " Cad",
                "et",
                " Mos",
                "ch",
                "gat",
                " was",
                " reading",
                " a",
                " history",
                " of",
                " WWII"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 76.68485260009766,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                76.68485260009766,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.2778158187866211,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"daq\", \"bian\", \"lems\"], \"v\": [8.63484001159668, 7.744564056396484, 6.469555854797363, 6.385959625244141, 5.990636825561523]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \"OWN\", \" Rite\", \"ordinate\", \" Archdemon\"], \"v\": [-19.518346786499023, -17.979270935058594, -17.94404411315918, -17.61321449279785, -17.47754669189453]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqlnwf4rr91inztb",
            "tokens": [
                "izer",
                ",",
                " and",
                " Sad",
                " Panda",
                ".",
                "\u010a",
                "\u010a",
                "Mos",
                "'",
                "ab",
                " El",
                "sh",
                "amy",
                " During",
                " the",
                " presidential"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 74.9811782836914,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                74.9811782836914,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.048442840576172,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"bian\", \"qu\", \"daq\"], \"v\": [11.773414611816406, 10.67094612121582, 8.46927261352539, 8.16058349609375, 8.123427391052246]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Archdemon\", \"ordinate\", \" Rite\", \"OWN\"], \"v\": [-15.827953338623047, -14.97806167602539, -14.830999374389648, -14.758079528808594, -14.446969985961914]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqlowf4rrsvnxcgz",
            "tokens": [
                " struggle",
                " between",
                " art",
                " and",
                " regime",
                ".",
                "\u010a",
                "\u010a",
                "Mos",
                "'",
                "ab",
                " El",
                "sh",
                "amy",
                " An",
                " onlook",
                "er"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 74.03599548339844,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                74.03599548339844,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.292941093444824,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"bian\", \"daq\", \"qu\"], \"v\": [12.975780487060547, 12.097536087036133, 9.996604919433594, 9.579496383666992, 9.49195384979248]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Archdemon\", \"ordinate\", \" Rite\", \"OWN\"], \"v\": [-13.726295471191406, -12.89912223815918, -12.75634765625, -12.72442626953125, -12.558059692382812]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqlpwf4rutwqdp3z",
            "tokens": [
                " E",
                "-",
                "Mail",
                " List",
                " Get",
                " the",
                " latest",
                " from",
                " Mos",
                "aic",
                " right",
                " in",
                " your",
                " inbox",
                " Daily",
                " Weekly",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 74.02947998046875,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                74.02947998046875,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -13.62228775024414,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"quit\", \"aic\", \"bian\", \"chal\", \"adiq\"], \"v\": [15.062629699707031, 13.62228775024414, 12.646078109741211, 11.924840927124023, 11.54994010925293]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Volks\", \"OWN\", \"ordinate\", \" Rite\"], \"v\": [-13.79819107055664, -12.130449295043945, -11.465919494628906, -11.440851211547852, -11.432451248168945]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqlqwf4re99i2g52",
            "tokens": [
                " something",
                " better",
                " for",
                " their",
                " country",
                ".",
                "\u010a",
                "\u010a",
                "Mos",
                "'",
                "ab",
                " El",
                "sh",
                "amy",
                " A",
                " child",
                " on"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 73.5483169555664,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                73.5483169555664,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.220211029052734,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"bian\", \"qu\", \"cone\"], \"v\": [12.895898818969727, 11.992942810058594, 9.87614917755127, 9.444247245788574, 9.223590850830078]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Rite\", \" Archdemon\", \"ordinate\", \" Thumbnails\"], \"v\": [-13.674692153930664, -12.855344772338867, -12.64937973022461, -12.572151184082031, -12.257356643676758]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqlrwf4r2xeizqhs",
            "tokens": [
                " terrifying",
                " for",
                " him",
                ",\"",
                " sheriff",
                "'s",
                " spokeswoman",
                " Dani",
                " Mos",
                "che",
                "lla",
                " said",
                ".",
                " \"",
                "There",
                " was",
                " ["
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 70.14823913574219,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                70.14823913574219,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.8414897918701172,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"daq\", \"adiq\", \"bian\"], \"v\": [9.785730361938477, 8.616471290588379, 8.012901306152344, 7.230019569396973, 6.949459075927734]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Rite\", \"istic\", \"OWN\", \"ordinate\"], \"v\": [-18.60919189453125, -16.513731002807617, -16.37978172302246, -16.298322677612305, -16.29724884033203]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqlswf4rr6q788r5",
            "tokens": [
                " on",
                " and",
                " advocating",
                " for",
                " the",
                " appointment",
                " of",
                " Darius",
                " Mos",
                "un",
                " -",
                " chair",
                " and",
                " CEO",
                " of",
                " Dec",
                "o"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 68.86955261230469,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                68.86955261230469,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.81594181060791,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"daq\", \"bian\", \"qu\"], \"v\": [8.39675521850586, 7.334821701049805, 6.196181297302246, 5.899208068847656, 5.323644638061523]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \"govtrack\", \" Rite\", \"OWN\", \" Archdemon\"], \"v\": [-19.643157958984375, -17.948596954345703, -17.883291244506836, -17.802736282348633, -17.721437454223633]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqltwf4r7nkugvfd",
            "tokens": [
                " Mayweather",
                ",",
                " Manny",
                " Pac",
                "qu",
                "iao",
                " and",
                " Shane",
                " Mos",
                "ley",
                ".",
                "\u010a",
                "\u010a",
                "\u00e2\u0122",
                "\u013e",
                "When",
                " I"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 68.8034439086914,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                68.8034439086914,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -1.658555150032043,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"daq\", \"ques\", \"lems\"], \"v\": [10.012185096740723, 8.227441787719727, 7.793439865112305, 7.524179458618164, 7.324666976928711]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Rite\", \"istics\", \" Archdemon\", \" Thumbnails\", \" Beckham\"], \"v\": [-20.380064010620117, -20.119831085205078, -19.41010856628418, -19.288311004638672, -18.812829971313477]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqluwf4rpwhzsjel",
            "tokens": [
                "\u010a",
                "Earlier",
                ",",
                " the",
                " inquiry",
                " heard",
                " how",
                " Max",
                " Mos",
                "ley",
                " believed",
                " that",
                " the",
                " News",
                " of",
                " the",
                " World"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 68.76395416259766,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                68.76395416259766,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -1.948426485061646,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"daq\", \"bian\", \"adiq\"], \"v\": [7.527400016784668, 6.987100601196289, 5.784208297729492, 5.540497779846191, 5.008254051208496]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \"OWN\", \" Rite\", \"istically\", \"ordinate\"], \"v\": [-18.80682945251465, -17.444917678833008, -17.20680809020996, -17.019392013549805, -16.96210289001465]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqlvwf4rub6s2woe",
            "tokens": [
                " newsletter",
                " Dis",
                "pat",
                "ches",
                ",",
                " Col",
                ".",
                " James",
                " Mos",
                "ch",
                "gat",
                ",",
                " USAF",
                " retired",
                ",",
                " recounts",
                " that"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 67.91063690185547,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                67.91063690185547,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.837918758392334,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"daq\", \"bian\", \"qu\"], \"v\": [7.611834526062012, 6.8212385177612305, 5.930423736572266, 5.198664665222168, 4.700085639953613]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Rite\", \"OWN\", \"ordinate\", \"govtrack\"], \"v\": [-18.034212112426758, -16.417030334472656, -16.345720291137695, -16.137746810913086, -16.080812454223633]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqlwwf4rgbv08kxg",
            "tokens": [
                " the",
                " language",
                " is",
                " so",
                " fragile",
                ",\"",
                " said",
                " David",
                " Mos",
                "er",
                ",",
                " a",
                " China",
                " commentator",
                " who",
                " is",
                " academic"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 67.70928192138672,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                67.70928192138672,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                4.899635314941406,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"daq\", \"bian\", \"qu\"], \"v\": [8.16892147064209, 7.658469200134277, 6.029824256896973, 5.629822731018066, 5.19630241394043]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \"istically\", \"istic\", \"OWN\", \" Rite\"], \"v\": [-18.916431427001953, -16.83606719970703, -16.779541015625, -16.752544403076172, -16.69711685180664]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqlxwf4rl5fqepji",
            "tokens": [
                " and",
                " scanned",
                " is",
                " unknown",
                ".",
                "\u010a",
                "\u010a",
                "Kate",
                " Mos",
                "er",
                ",",
                " a",
                " UC",
                "OP",
                " spokeswoman",
                ",",
                "<|endoftext|>"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 67.65217590332031,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                67.65217590332031,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                4.406838417053223,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"daq\", \"adiq\", \"bian\"], \"v\": [8.56045150756836, 7.93997049331665, 7.110883712768555, 6.262795448303223, 6.095223903656006]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Rite\", \"ordinate\", \"OWN\", \"istically\"], \"v\": [-17.993350982666016, -16.527633666992188, -16.455827713012695, -16.240070343017578, -16.01413917541504]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqlzwf4rg2wefwxp",
            "tokens": [
                "Volume",
                " 27",
                "\u010a",
                "\u010a",
                "*",
                "Gab",
                "riel",
                "le",
                " Mos",
                "er",
                " \u00e2\u0122",
                "\u013e",
                "Working",
                "-",
                "through",
                "\u00e2\u0122",
                "\u013f"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 65.26641082763672,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                65.26641082763672,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3.52607250213623,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"daq\", \"bian\", \"lems\"], \"v\": [10.13169002532959, 8.594415664672852, 7.891088485717773, 6.958401679992676, 6.366827011108398]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Rite\", \" Archdemon\", \"istic\", \"govtrack\"], \"v\": [-17.64554786682129, -16.14521598815918, -15.834024429321289, -15.799135208129883, -15.722936630249023]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqmuwf4rc02eyugd",
            "tokens": [
                " some",
                " excellent",
                " leadership",
                " guidelines",
                " listed",
                " by",
                " Col",
                ".",
                " Mos",
                "ch",
                "gat",
                " that",
                " this",
                " experience",
                " inst",
                "illed",
                " in"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 64.15242004394531,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                64.15242004394531,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.1043691858649254,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"adiq\", \"bian\", \"daq\"], \"v\": [7.792441368103027, 7.125617027282715, 6.085428237915039, 5.87093448638916, 5.636615753173828]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Archdemon\", \"ordinate\", \" Rite\", \"istically\"], \"v\": [-13.816612243652344, -12.290868759155273, -12.20181655883789, -12.142999649047852, -12.099462509155273]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqmvwf4riwdgtf70",
            "tokens": [
                " first",
                "-",
                "round",
                " pick",
                " C",
                ".",
                "J",
                ".",
                " Mos",
                "ley",
                " developing",
                " into",
                " a",
                " Pro",
                " Bowl",
                " linebacker",
                "."
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 64.01715087890625,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                64.01715087890625,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -2.21695351600647,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"quit\", \"aic\", \"daq\", \"bian\", \"adiq\"], \"v\": [9.099939346313477, 8.863388061523438, 7.607732772827148, 6.840845108032227, 6.369806289672852]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \"OWN\", \" Rite\", \" Yankee\", \"ordinate\"], \"v\": [-18.95890998840332, -18.12409782409668, -17.660930633544922, -17.58831024169922, -17.53571128845215]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqmxwf4rw7mrvtge",
            "tokens": [
                " CEO",
                " of",
                " Dec",
                "o",
                " client",
                " So",
                "he",
                "il",
                " Mos",
                "un",
                " -",
                " to",
                " the",
                " board",
                " of",
                " the",
                " Toronto"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 60.68503189086914,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                60.68503189086914,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.01255074329674244,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"bian\", \"qu\", \"lems\"], \"v\": [9.854455947875977, 9.083318710327148, 8.344457626342773, 7.978643417358398, 7.912635803222656]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Archdemon\", \"ordinate\", \" Rite\", \"OWN\"], \"v\": [-12.033063888549805, -10.848628997802734, -10.811038970947266, -10.659835815429688, -10.620437622070312]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqmwwf4rrp28bkqm",
            "tokens": [
                "\u010a",
                "\"",
                "He",
                " did",
                " everything",
                " he",
                " could",
                ",\"",
                " Mos",
                "che",
                "lla",
                " said",
                ".",
                "\u010a",
                "\u010a",
                "Ari",
                "as"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 58.21372222900391,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                58.21372222900391,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.003185996785759926,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"adiq\", \"bian\", \"daq\"], \"v\": [6.872564315795898, 6.089395523071289, 5.2726593017578125, 5.055728912353516, 4.784202575683594]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \"ordinate\", \"istically\", \"sburgh\", \"istic\"], \"v\": [-12.242088317871094, -11.080272674560547, -10.724143981933594, -10.472179412841797, -10.406637191772461]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqmywf4rkrndf7a2",
            "tokens": [
                "rir",
                " square",
                ".",
                "\u010a",
                "\u010a",
                "All",
                " images",
                " by",
                " Mos",
                "\u00e2\u0122",
                "\u013b",
                "ab",
                " El",
                "sh",
                "amy",
                ".",
                " Follow"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 55.91466522216797,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                55.91466522216797,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.516349792480469,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"quit\", \"aic\", \"bian\", \"qu\", \"cos\"], \"v\": [10.703359603881836, 10.637116432189941, 9.352131843566895, 9.287631034851074, 9.070758819580078]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Thumbnails\", \" Archdemon\", \"OWN\", \" Rite\"], \"v\": [-7.591564178466797, -6.828283309936523, -6.504192352294922, -6.34356689453125, -6.3192138671875]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqn0wf4ryr9ldtzf",
            "tokens": [
                " little",
                " narrow",
                " for",
                " my",
                " taste",
                ".",
                "\u010a",
                "\u010a",
                "mos",
                "k",
                "onia",
                " Profile",
                " Joined",
                " January",
                " 2011",
                " Israel",
                " 14"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 43.43906021118164,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                43.43906021118164,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.7739896774291992,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"lems\", \"bian\", \"ques\"], \"v\": [3.586491584777832, 2.6562840938568115, 2.3718299865722656, 1.9362516403198242, 1.786850929260254]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \"ordinate\", \" Archdemon\", \" Thumbnails\", \" Takeru\"], \"v\": [-11.824468612670898, -11.483001708984375, -11.153793334960938, -11.138341903686523, -11.09646987915039]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqmzwf4rdirs0xmm",
            "tokens": [
                " and",
                " others",
                ".",
                " C",
                "uc",
                "ur",
                "bit",
                "a",
                " mos",
                "ch",
                "ata",
                " contains",
                " the",
                " but",
                "tern",
                "ut",
                " squ"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 42.47097778320312,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                42.47097778320312,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.01563358306884766,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"bian\", \"daq\", \"lems\"], \"v\": [5.3747944831848145, 4.971376895904541, 4.2597198486328125, 3.91705322265625, 3.8773393630981445]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Thumbnails\", \"ordinate\", \"IVERS\", \"ocument\"], \"v\": [-10.824914932250977, -10.253564834594727, -10.187845230102539, -9.952583312988281, -9.717172622680664]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqn3wf4rs01hui5w",
            "tokens": [
                " only",
                " light",
                " on",
                " it",
                ".",
                " The",
                " dramatic",
                " at",
                "mos",
                "here",
                " have",
                " caused",
                " a",
                " bit",
                " of",
                " a",
                " stir"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 19.89533805847168,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                19.89533805847168,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.008845329284667969,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"bian\", \"lems\", \"adiq\"], \"v\": [3.6779966354370117, 3.6226987838745117, 3.234811782836914, 3.0659866333007812, 3.014913558959961]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Thumbnails\", \"ordinate\", \"istically\", \" Archdemon\"], \"v\": [-4.338251113891602, -3.954822540283203, -3.900300979614258, -3.817577362060547, -3.816812515258789]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqn1wf4r19ja4h9l",
            "tokens": [
                " 28",
                ".",
                "\u010a",
                "\u010a",
                "In",
                " response",
                " to",
                " Sheikh",
                " Ras",
                "heed",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " grievance",
                ",",
                " the",
                " PT"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 18.8601131439209,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                18.8601131439209,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -1.192092682344992e-07,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"cos\", \"lems\", \"bian\"], \"v\": [2.0983009338378906, 1.76385498046875, 1.2842330932617188, 1.2463302612304688, 1.245107650756836]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \"ordinate\", \" Archdemon\", \"govtrack\", \"istically\"], \"v\": [-4.2303466796875, -3.979167938232422, -3.9737319946289062, -3.9255218505859375, -3.8956871032714844]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqn2wf4rm4p1zvor",
            "tokens": [
                "rawling",
                " Spider",
                "-",
                "Men",
                " and",
                " extortion",
                "ist",
                " El",
                "mos",
                " bes",
                "mir",
                "ch",
                " the",
                " \u00e2\u0122",
                "\u013e",
                "Cross",
                "roads"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 16.43842697143555,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                16.43842697143555,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.182586669921875,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"bian\", \"qu\", \"lems\"], \"v\": [2.103299140930176, 1.7991247177124023, 1.3977327346801758, 1.3692035675048828, 1.3613128662109375]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Archdemon\", \" Thumbnails\", \" Rite\", \"ordinate\"], \"v\": [-4.106565475463867, -4.000619888305664, -3.9576663970947266, -3.8839282989501953, -3.8830318450927734]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqn4wf4ru3y7rz2k",
            "tokens": [
                " and",
                " M",
                "omm",
                "a",
                " Id",
                "a",
                " (",
                "Fr",
                "ances",
                " McD",
                "orm",
                "and",
                ").",
                " Ar",
                "lo",
                " has",
                " a"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 11.11153125762939,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                11.11153125762939,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.350677490234375,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"quit\", \"aic\", \"adiq\", \"daq\", \"lems\"], \"v\": [1.4565868377685547, 1.4105663299560547, 1.155181884765625, 1.1412353515625, 1.1279983520507812]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\" Marie\", \"istics\", \" Thumbnails\", \" Rite\", \"OWN\"], \"v\": [-3.112028121948242, -3.0861663818359375, -3.0590896606445312, -3.057392120361328, -3.036558151245117]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqn7wf4rab3y0129",
            "tokens": [
                "\u00e2\u0122",
                "\u013e",
                "I",
                " am",
                "<|endoftext|>",
                "C",
                "FO",
                " Jay",
                " Ras",
                "ulo",
                " just",
                " told",
                " analysts",
                " that",
                " the",
                " company",
                " is"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 10.83001232147217,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                10.83001232147217,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.025052070617676,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"lems\", \"daq\", \"cos\"], \"v\": [1.149545669555664, 0.9031744003295898, 0.7138919830322266, 0.6728744506835938, 0.6564321517944336]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Archdemon\", \" Rite\", \"OWN\", \"ordinate\"], \"v\": [-2.641979217529297, -2.590616226196289, -2.567728042602539, -2.5322494506835938, -2.5171775817871094]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqn5wf4rpoti2gxi",
            "tokens": [
                " States",
                ".",
                "\u010a",
                "\u010a",
                "But",
                " hints",
                " about",
                " the",
                " Moss",
                "ad",
                " connection",
                " to",
                " Sex",
                "gate",
                " surfaced",
                " in",
                " evidence"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 10.25685024261475,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                10.25685024261475,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.01934486627578735,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"quit\", \"aic\", \"bian\", \"qu\", \"ques\"], \"v\": [1.3413715362548828, 1.3359661102294922, 1.1423511505126953, 1.086233139038086, 1.0695581436157227]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \"ordinate\", \" Archdemon\", \" Thumbnails\", \"istically\"], \"v\": [-1.7240734100341797, -1.6046218872070312, -1.5575199127197266, -1.5542030334472656, -1.5393905639648438]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqn6wf4rbcn8jsge",
            "tokens": [
                "-",
                "ev",
                "ident",
                ".",
                "\u00e2\u0122",
                "\u013f",
                "\u010a",
                "\u010a",
                "Cos",
                "mos",
                " Chief",
                " Operating",
                " Officer",
                " Erik",
                " St",
                "over",
                " declined"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 9.724989891052246,
            "maxValueTokenIndex": 9,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                8.942852973937988,
                9.724989891052246,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.01507824659347534,
                0.3819580078125,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"bian\", \"lems\", \"adiq\"], \"v\": [1.0153913497924805, 0.9742326736450195, 0.8193206787109375, 0.8103771209716797, 0.8054237365722656]}, {\"t\": [\"aic\", \"quit\", \"bian\", \"qu\", \"ques\"], \"v\": [2.256420135498047, 2.139298439025879, 1.9729995727539062, 1.9312705993652344, 1.9110050201416016]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \"ordinate\", \"sburgh\", \"istical\", \"istically\"], \"v\": [-1.778116226196289, -1.6978607177734375, -1.6072254180908203, -1.6016216278076172, -1.5644454956054688]}, {\"t\": [\"istics\", \" Thumbnails\", \" Archdemon\", \"ordinate\", \" Rite\"], \"v\": [-1.0899925231933594, -0.9925785064697266, -0.9811038970947266, -0.9470481872558594, -0.9311885833740234]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqn8wf4rktgno04o",
            "tokens": [
                " their",
                " suit",
                "cases",
                ".",
                "\u010a",
                "\u010a",
                "Ryan",
                " Marc",
                " Pere",
                "ira",
                " and",
                " Edward",
                " Choi",
                " Gou",
                " Hang",
                ",",
                " both"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 9.06229019165039,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                9.06229019165039,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.4792637825012207,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"aic\", \"quit\", \"bian\", \"daq\", \"lems\"], \"v\": [1.6471195220947266, 1.5580921173095703, 1.3604955673217773, 1.3397483825683594, 1.2688817977905273]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"istics\", \" Thumbnails\", \" Archdemon\", \"ordinate\", \" Rite\"], \"v\": [-1.6315937042236328, -1.5146045684814453, -1.4981842041015625, -1.486806869506836, -1.4517803192138672]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnucbqmfwf4rnjjy0f3e",
            "tokens": [
                " a",
                " bi",
                "oph",
                "arm",
                "aceutical",
                " company",
                " awarded",
                " scholarships",
                " this",
                " year",
                " to",
                " 25",
                " students",
                " with",
                " ADHD",
                ".",
                " Those"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnucbqmgwf4roxi6dwc2",
            "tokens": [
                " bi",
                "oph",
                "arm",
                "aceutical",
                " company",
                " awarded",
                " scholarships",
                " this",
                " year",
                " to",
                " 25",
                " students",
                " with",
                " ADHD",
                ".",
                " Those",
                " scholarships"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnucbqmhwf4r9dyr94mk",
            "tokens": [
                "oph",
                "arm",
                "aceutical",
                " company",
                " awarded",
                " scholarships",
                " this",
                " year",
                " to",
                " 25",
                " students",
                " with",
                " ADHD",
                ".",
                " Those",
                " scholarships",
                " include"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnucbqmiwf4rpdqazooo",
            "tokens": [
                "arm",
                "aceutical",
                " company",
                " awarded",
                " scholarships",
                " this",
                " year",
                " to",
                " 25",
                " students",
                " with",
                " ADHD",
                ".",
                " Those",
                " scholarships",
                " include",
                " cash"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnucbqmjwf4ryk17o8s0",
            "tokens": [
                "aceutical",
                " company",
                " awarded",
                " scholarships",
                " this",
                " year",
                " to",
                " 25",
                " students",
                " with",
                " ADHD",
                ".",
                " Those",
                " scholarships",
                " include",
                " cash",
                " plus"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnucbqmcwf4reh59yc4a",
            "tokens": [
                " ago",
                ".",
                " And",
                " a",
                " bi",
                "oph",
                "arm",
                "aceutical",
                " company",
                " awarded",
                " scholarships",
                " this",
                " year",
                " to",
                " 25",
                " students",
                " with"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnucbqmbwf4rlnlkpxf7",
            "tokens": [
                " years",
                " ago",
                ".",
                " And",
                " a",
                " bi",
                "oph",
                "arm",
                "aceutical",
                " company",
                " awarded",
                " scholarships",
                " this",
                " year",
                " to",
                " 25",
                " students"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnucbqm6wf4rkt8dvzfo",
            "tokens": [
                " up",
                " from",
                " one",
                " program",
                " three",
                " years",
                " ago",
                ".",
                " And",
                " a",
                " bi",
                "oph",
                "arm",
                "aceutical",
                " company",
                " awarded",
                " scholarships"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnucbqm5wf4rtw1445mn",
            "tokens": [
                ",",
                " up",
                " from",
                " one",
                " program",
                " three",
                " years",
                " ago",
                ".",
                " And",
                " a",
                " bi",
                "oph",
                "arm",
                "aceutical",
                " company",
                " awarded"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnucbqm4wf4rt8dg854l",
            "tokens": [
                " campuses",
                ",",
                " up",
                " from",
                " one",
                " program",
                " three",
                " years",
                " ago",
                ".",
                " And",
                " a",
                " bi",
                "oph",
                "arm",
                "aceutical",
                " company"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqm3wf4res1hoomz",
            "tokens": [
                "<|endoftext|>",
                " campuses",
                ",",
                " up",
                " from",
                " one",
                " program",
                " three",
                " years",
                " ago",
                ".",
                " And",
                " a",
                " bi",
                "oph",
                "arm",
                "aceutical"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqndwf4rqonag22z",
            "tokens": [
                "?",
                " Are",
                " you",
                " going",
                " to",
                " be",
                " good",
                " on",
                " transportation",
                " issues",
                "?",
                " Are",
                " you",
                " going",
                " to",
                " respect",
                " the"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqm2wf4r9zv4cqi4",
            "tokens": [
                ".,",
                "<|endoftext|>",
                " campuses",
                ",",
                " up",
                " from",
                " one",
                " program",
                " three",
                " years",
                " ago",
                ".",
                " And",
                " a",
                " bi",
                "oph",
                "arm"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqm1wf4ruhwkca6z",
            "tokens": [
                "H",
                ".,",
                "<|endoftext|>",
                " campuses",
                ",",
                " up",
                " from",
                " one",
                " program",
                " three",
                " years",
                " ago",
                ".",
                " And",
                " a",
                " bi",
                "oph"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnubbqm0wf4ruw4lcncn",
            "tokens": [
                ".",
                "H",
                ".,",
                "<|endoftext|>",
                " campuses",
                ",",
                " up",
                " from",
                " one",
                " program",
                " three",
                " years",
                " ago",
                ".",
                " And",
                " a",
                " bi"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnucbqm8wf4rm247hid4",
            "tokens": [
                " one",
                " program",
                " three",
                " years",
                " ago",
                ".",
                " And",
                " a",
                " bi",
                "oph",
                "arm",
                "aceutical",
                " company",
                " awarded",
                " scholarships",
                " this",
                " year"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnucbqm7wf4rt1oeo44c",
            "tokens": [
                " from",
                " one",
                " program",
                " three",
                " years",
                " ago",
                ".",
                " And",
                " a",
                " bi",
                "oph",
                "arm",
                "aceutical",
                " company",
                " awarded",
                " scholarships",
                " this"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnucbqm9wf4rqetepzwh",
            "tokens": [
                " program",
                " three",
                " years",
                " ago",
                ".",
                " And",
                " a",
                " bi",
                "oph",
                "arm",
                "aceutical",
                " company",
                " awarded",
                " scholarships",
                " this",
                " year",
                " to"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnucbqmawf4r3q1f4kx3",
            "tokens": [
                " three",
                " years",
                " ago",
                ".",
                " And",
                " a",
                " bi",
                "oph",
                "arm",
                "aceutical",
                " company",
                " awarded",
                " scholarships",
                " this",
                " year",
                " to",
                " 25"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqn9wf4r1wibmshn",
            "tokens": [
                "-",
                "Islam",
                "i",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " (",
                "J",
                "I",
                ")",
                " Rash",
                "da",
                " R",
                "iff",
                "at",
                ",",
                " was"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqnawf4rk0qu8u10",
            "tokens": [
                "\u010a",
                "\u010a",
                "This",
                " m",
                "ala",
                "ise",
                " has",
                " continued",
                ".",
                " This",
                " year",
                ",",
                " about",
                " five",
                " million",
                " Ken",
                "y"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqnbwf4rzzjx39sz",
            "tokens": [
                " Sean",
                " Taylor",
                ",",
                " who",
                " was",
                " killed",
                " a",
                " few",
                " days",
                " before",
                " the",
                " game",
                ".",
                " Whether",
                " Texas",
                " scores",
                " a"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnucbqmdwf4rgefmq1qg",
            "tokens": [
                ".",
                " And",
                " a",
                " bi",
                "oph",
                "arm",
                "aceutical",
                " company",
                " awarded",
                " scholarships",
                " this",
                " year",
                " to",
                " 25",
                " students",
                " with",
                " ADHD"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnudbqncwf4rd7djy1lz",
            "tokens": [
                "meaning",
                "ful",
                " pre",
                "lude",
                "\"",
                " to",
                " containing",
                " Guam",
                ",",
                " which",
                " is",
                " home",
                " to",
                " key",
                " US",
                " military",
                " bases"
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsievnucbqmewf4r9ngraefc",
            "tokens": [
                " And",
                " a",
                " bi",
                "oph",
                "arm",
                "aceutical",
                " company",
                " awarded",
                " scholarships",
                " this",
                " year",
                " to",
                " 25",
                " students",
                " with",
                " ADHD",
                "."
            ],
            "dataIndex": null,
            "index": "258",
            "layer": "10-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T04:05:32.835Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        }
    ],
    "explanations": [
        {
            "id": "clsxrx78q04phenuxz6jtix5n",
            "description": "mentions of the name \"Mos\" with decreasing levels of importance indicated by the activation values",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "scores": []
        },
        {
            "id": "tsdadlpfh0ciwvea08c6tngn0",
            "description": " mentions of the name \"Mos\"",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "scores": []
        }
    ]
}