{
    "modelId": "gpt2-small",
    "layer": "9-res-jb",
    "index": "23158",
    "sourceSetName": "res-jb",
    "creatorId": null,
    "createdAt": "2024-02-12T01:29:31.670Z",
    "maxActApprox": 82.66680145263672,
    "hasVector": false,
    "vector": [],
    "vectorLabel": null,
    "vectorDefaultSteerStrength": 10,
    "hookName": null,
    "topkCosSimIndices": [
        23158,
        23592,
        22631,
        24516,
        17798,
        12695,
        8044,
        2812,
        21242,
        23229,
        3509,
        5063,
        2404,
        22993,
        8018,
        13879,
        7024,
        21133,
        26,
        14546,
        4624,
        23201,
        21096,
        17554,
        21788
    ],
    "topkCosSimValues": [
        1,
        0.4579,
        0.3569,
        0.3529,
        0.3141,
        0.3006,
        0.2987,
        0.2942,
        0.2936,
        0.2928,
        0.2915,
        0.2905,
        0.2867,
        0.2796,
        0.2789,
        0.2756,
        0.275,
        0.2746,
        0.2735,
        0.2731,
        0.2701,
        0.2682,
        0.2668,
        0.265,
        0.2603
    ],
    "neuron_alignment_indices": [
        0,
        132,
        57
    ],
    "neuron_alignment_values": [
        0.132268562912941,
        0.09935168921947479,
        0.09906517714262009
    ],
    "neuron_alignment_l1": [
        0.006027059629559517,
        0.004527142271399498,
        0.004514086525887251
    ],
    "correlated_neurons_indices": [
        0,
        57,
        137
    ],
    "correlated_neurons_pearson": [
        0.01554938592016697,
        0.01383268460631371,
        0.01277059130370617
    ],
    "correlated_neurons_l1": [
        0.01575375534594059,
        0.0119124399498105,
        0.009609623812139034
    ],
    "correlated_features_indices": [],
    "correlated_features_pearson": [],
    "correlated_features_l1": [],
    "neg_str": [
        "ORED",
        "ModLoader",
        "DERR",
        "een",
        "OIL",
        "\u0133\u00e5\u00a3\u00ab",
        "iage",
        "lessness",
        " LIA",
        "enance"
    ],
    "neg_values": [
        -0.9747641682624817,
        -0.8224616646766663,
        -0.7254147529602051,
        -0.7062548995018005,
        -0.697218656539917,
        -0.6887916922569275,
        -0.6880294680595398,
        -0.661520779132843,
        -0.6488829255104065,
        -0.6468722224235535
    ],
    "pos_str": [
        "apse",
        "onyms",
        "apses",
        "agog",
        "onym",
        "chron",
        "opsis",
        "esthesia",
        "agogue",
        "apt"
    ],
    "pos_values": [
        1.334592461585999,
        1.288981676101685,
        1.249895453453064,
        1.243812322616577,
        1.21710991859436,
        1.207327246665955,
        1.172627449035645,
        1.153098702430725,
        1.125286340713501,
        1.098713636398315
    ],
    "frac_nonzero": 0.0003350575764973958,
    "freq_hist_data_bar_heights": [
        503,
        237,
        120,
        56,
        42,
        16,
        18,
        5,
        7,
        7,
        4,
        2,
        1,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        1,
        0,
        1,
        1,
        2,
        1,
        3,
        2,
        3,
        2,
        5,
        2,
        3,
        3,
        2,
        3
    ],
    "freq_hist_data_bar_values": [
        1.039503216743469,
        3.106017112731934,
        5.172530651092529,
        7.239044189453125,
        9.305558204650879,
        11.37207221984863,
        13.43858528137207,
        15.50509929656982,
        17.57161331176758,
        19.63812637329102,
        21.70464134216309,
        23.77115440368652,
        25.83766746520996,
        27.90418243408203,
        29.97069549560547,
        32.03721237182617,
        34.10372161865234,
        36.17023468017578,
        38.23674774169922,
        40.30326461791992,
        42.36978149414062,
        44.43629455566406,
        46.50281143188477,
        48.5693244934082,
        50.63583755493164,
        52.70235061645508,
        54.76886749267578,
        56.83538055419922,
        58.90189361572266,
        60.96840667724609,
        63.03491973876953,
        65.10143280029297,
        67.1679458618164,
        69.23445892333984,
        71.30097198486328,
        73.36748504638672,
        75.43400573730469,
        77.50051879882812,
        79.56703186035156,
        81.633544921875
    ],
    "logits_hist_data_bar_heights": [
        1,
        0,
        1,
        0,
        5,
        7,
        12,
        43,
        80,
        261,
        552,
        1235,
        2311,
        3814,
        5523,
        6801,
        6995,
        6388,
        5118,
        3742,
        2525,
        1711,
        1140,
        749,
        456,
        324,
        209,
        104,
        69,
        33,
        18,
        7,
        5,
        1,
        7,
        1,
        2,
        3,
        2,
        2
    ],
    "logits_hist_data_bar_values": [
        -0.9458972215652466,
        -0.8881633281707764,
        -0.8304293751716614,
        -0.7726954817771912,
        -0.714961588382721,
        -0.657227635383606,
        -0.5994937419891357,
        -0.5417597889900208,
        -0.4840258955955505,
        -0.4262920022010803,
        -0.3685580492019653,
        -0.3108241558074951,
        -0.2530902624130249,
        -0.1953562945127487,
        -0.1376224011182785,
        -0.07988844811916351,
        -0.0221545584499836,
        0.03557933494448662,
        0.09331323206424713,
        0.1510472446680069,
        0.2087810784578323,
        0.2665149569511414,
        0.3242489695549011,
        0.3819828629493713,
        0.4397167563438416,
        0.4974506497383118,
        0.5551846027374268,
        0.612918496131897,
        0.670652449131012,
        0.7283863425254822,
        0.7861202359199524,
        0.8438541889190674,
        0.9015880823135376,
        0.9593220353126526,
        1.017055988311768,
        1.074789881706238,
        1.132523775100708,
        1.190257787704468,
        1.247991681098938,
        1.305725574493408
    ],
    "decoder_weights_dist": [],
    "umap_cluster": null,
    "umap_log_feature_sparsity": null,
    "umap_x": null,
    "umap_y": null,
    "model": {
        "id": "gpt2-small",
        "displayNameShort": "GPT2-SM",
        "displayName": "GPT2-Small",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "tlensId": null,
        "dimension": 768,
        "visibility": "PUBLIC",
        "inferenceEnabled": true,
        "instruct": false,
        "layers": 12,
        "neuronsPerLayer": 3072,
        "createdAt": "2023-07-06T00:01:44.843Z",
        "owner": "OpenAI",
        "updatedAt": "2023-07-06T00:01:44.843Z",
        "website": "https://openai.com"
    },
    "lists": [],
    "creator": null,
    "source": {
        "id": "9-res-jb",
        "modelId": "gpt2-small",
        "hasDashboards": true,
        "inferenceEnabled": true,
        "saelensConfig": {
            "lr": 0.0004,
            "d_in": 768,
            "seed": 42,
            "d_sae": 24576,
            "dtype": "torch.float32",
            "device": "mps",
            "run_name": "24576-L1-8e-05-LR-0.0004-Tokens-3.000e+08",
            "hook_point": "blocks.9.hook_resid_pre",
            "model_name": "gpt2-small",
            "prepend_bos": true,
            "architecture": "standard",
            "context_size": 128,
            "dataset_path": "Skylion007/openwebtext",
            "log_to_wandb": true,
            "wandb_entity": null,
            "n_checkpoints": 10,
            "wandb_project": "mats_sae_training_gpt2_small_resid_pre_5",
            "l1_coefficient": 8e-05,
            "neuronpedia_id": "gpt2-small/9-res-jb",
            "checkpoint_path": "checkpoints/wg1xo7vo",
            "use_ghost_grads": false,
            "expansion_factor": 32,
            "hook_point_layer": 9,
            "lr_warm_up_steps": 5000,
            "resample_batches": 1028,
            "store_batch_size": 32,
            "train_batch_size": 4096,
            "activation_fn_str": "relu",
            "b_dec_init_method": "geometric_median",
            "lr_scheduler_name": null,
            "tokens_per_buffer": 67108864,
            "dead_feature_window": 5000,
            "n_batches_in_buffer": 128,
            "wandb_log_frequency": 100,
            "apply_b_dec_to_input": true,
            "feature_reinit_scale": 0.2,
            "from_pretrained_path": null,
            "is_dataset_tokenized": false,
            "hook_point_head_index": null,
            "normalize_activations": "none",
            "total_training_tokens": 300000000,
            "dead_feature_threshold": 1e-08,
            "use_cached_activations": false,
            "cached_activations_path": "activations/Skylion007_openwebtext/gpt2-small/blocks.9.hook_resid_pre",
            "feature_sampling_method": null,
            "feature_sampling_window": 1000,
            "dataset_trust_remote_code": true,
            "finetuning_scaling_factor": false,
            "sae_lens_training_version": null,
            "model_from_pretrained_kwargs": {
                "center_writing_weights": true
            },
            "dead_feature_estimation_method": "no_fire"
        },
        "saelensRelease": "gpt2-small-res-jb",
        "saelensSaeId": "blocks.9.hook_resid_pre",
        "hfRepoId": "jbloom/GPT2-Small-SAEs-Reformatted",
        "hfFolderId": "blocks.9.hook_resid_pre",
        "visibility": "PUBLIC",
        "setName": "res-jb",
        "creatorId": "cljgamm90000076zdchicy6zj",
        "hasUmap": true,
        "hasUmapLogSparsity": true,
        "hasUmapClusters": true,
        "num_prompts": 24576,
        "num_tokens_in_prompt": 128,
        "dataset": "Skylion007/openwebtext",
        "notes": null,
        "createdAt": "2024-07-10T04:46:32.069Z"
    },
    "sourceSet": {
        "modelId": "gpt2-small",
        "name": "res-jb",
        "hasDashboards": true,
        "visibility": "PUBLIC",
        "description": "Open Source Sparse Autoencoders for all Residual Stream Layers of GPT2-Small",
        "type": "Residual Stream",
        "creatorName": "Joseph Bloom",
        "urls": [
            "https://www.lesswrong.com/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream",
            "https://huggingface.co/jbloom/GPT2-Small-SAEs/tree/main",
            "https://github.com/jbloomAus/mats_sae_training"
        ],
        "creatorEmail": null,
        "creatorId": "cljgamm90000076zdchicy6zj",
        "releaseName": "gpt2sm-res-jb",
        "defaultRange": 2,
        "defaultShowBreaks": true,
        "showDfa": false,
        "showCorrelated": false,
        "showHeadAttribution": false,
        "showUmap": true,
        "createdAt": "2024-07-10T04:46:32.075Z"
    },
    "activations": [
        {
            "id": "clsi9b5ts8m48wf4rntdyecd1",
            "tokens": [
                " am",
                " a",
                " collection",
                " of",
                " the",
                " nerve",
                " impulses",
                " and",
                " syn",
                "apses",
                " in",
                " my",
                " brain",
                " responding",
                " to",
                " physical",
                " stimuli"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 82.66680145263672,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                82.66680145263672,
                1.836989402770996,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -7.262519836425781,
                0.04168605804443359,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"onyms\", \"onym\", \"opsis\", \"chron\"], \"v\": [10.847485542297363, 10.478766441345215, 9.683598518371582, 9.432456016540527, 9.060246467590332]}, {\"t\": [\"onyms\", \"apse\", \"agog\", \"onym\", \"chron\"], \"v\": [0.5172805786132812, 0.5146961212158203, 0.4878578186035156, 0.4865703582763672, 0.4778118133544922]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"lessness\", \"een\", \" LIA\", \" bearer\"], \"v\": [-25.68320083618164, -23.99355697631836, -23.89581298828125, -22.259803771972656, -22.22003173828125]}, {\"t\": [\"ORED\", \"ModLoader\", \"DERR\", \"een\", \"lessness\"], \"v\": [-0.3341560363769531, -0.2635765075683594, -0.2465076446533203, -0.23868751525878906, -0.23678207397460938]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m49wf4rociwb4ua",
            "tokens": [
                " in",
                " this",
                " instance",
                " \u00e2\u0122\u0135",
                " the",
                " table",
                " and",
                ",",
                " syn",
                "onym",
                "ously",
                ",",
                " the",
                " results",
                " don",
                "\u00e2\u0122",
                "\u013b"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 82.16526794433594,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                82.16526794433594,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -3.523120641708374,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"apses\", \"agogue\", \"agog\", \"onyms\"], \"v\": [12.33230209350586, 11.87554931640625, 9.97170639038086, 9.729301452636719, 8.693402290344238]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \" bearer\", \"een\", \" Tonight\", \" shining\"], \"v\": [-28.816062927246094, -27.224842071533203, -26.677661895751953, -26.442399978637695, -26.00931167602539]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4awf4rduu3ol0h",
            "tokens": [
                "They",
                "<|endoftext|>",
                " generally",
                " bum",
                "med",
                " all",
                " the",
                " other",
                " syn",
                "hak",
                "kers",
                " out",
                ".",
                "\u010a",
                "\u010a",
                "I",
                " really"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 80.7957763671875,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                80.7957763671875,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.772796630859375,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"chron\", \"opsis\", \"agog\", \"apses\"], \"v\": [10.15560531616211, 9.185935020446777, 8.680302619934082, 8.33651351928711, 8.062861442565918]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"een\", \"lessness\", \"OIL\", \"iage\"], \"v\": [-25.37530517578125, -22.85940170288086, -22.152252197265625, -21.926063537597656, -21.69049072265625]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4bwf4rvlcy61zh",
            "tokens": [
                " float",
                " over",
                "top",
                " bro",
                "oding",
                " was",
                "hes",
                " of",
                " syn",
                "ths",
                " crafted",
                " by",
                " her",
                " musical",
                " partner",
                " Cor",
                "in"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 79.75269317626953,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                79.75269317626953,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -5.234166145324707,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"chron\", \"agogue\", \"opsis\", \"apses\"], \"v\": [13.199030876159668, 12.605171203613281, 12.299189567565918, 12.138745307922363, 11.843605041503906]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"lessness\", \"enance\", \"een\", \" Neon\"], \"v\": [-25.654142379760742, -24.524337768554688, -23.93417739868164, -23.595285415649414, -22.78314781188965]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4cwf4rysjxm42z",
            "tokens": [
                " myself",
                ",",
                " here",
                " are",
                " some",
                " examples",
                " of",
                " the",
                " syn",
                "ch",
                "c",
                "ronic",
                "ities",
                " I",
                "ve",
                " experienced",
                " lately"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 79.46711730957031,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                79.46711730957031,
                11.01010417938232,
                0,
                1.001227974891663,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.5525178909301758,
                -0.5116138458251953,
                0,
                0.02686953544616699,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"apses\", \"opsis\", \"chron\", \"onyms\"], \"v\": [11.367831230163574, 10.06472396850586, 9.59807014465332, 9.548114776611328, 9.367569923400879]}, {\"t\": [\"onyms\", \"apse\", \"onym\", \"apses\", \"agog\"], \"v\": [3.468881607055664, 3.4348411560058594, 3.2653369903564453, 3.245105743408203, 3.2442760467529297]}, {}, {\"t\": [\"apse\", \"onyms\", \"apses\", \"onym\", \"agog\"], \"v\": [0.25293731689453125, 0.2481689453125, 0.236358642578125, 0.233978271484375, 0.23063087463378906]}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"lessness\", \"een\", \"OIL\", \"enance\"], \"v\": [-24.827970504760742, -24.381418228149414, -22.900135040283203, -21.649120330810547, -21.178184509277344]}, {\"t\": [\"ORED\", \"ModLoader\", \"een\", \"lessness\", \"enance\"], \"v\": [-2.9878273010253906, -2.286731719970703, -2.2296180725097656, -2.1767959594726562, -2.0546836853027344]}, {}, {\"t\": [\"ORED\", \"ModLoader\", \"een\", \"lessness\", \"DERR\"], \"v\": [-0.2734489440917969, -0.22955322265625, -0.22632217407226562, -0.21871185302734375, -0.21404266357421875]}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4dwf4r6lh9837q",
            "tokens": [
                "ies",
                " the",
                " track",
                " through",
                " its",
                " entirety",
                ";",
                " the",
                " syn",
                "ths",
                " on",
                " \"",
                "S",
                "ink",
                "\";",
                " \"",
                "Com"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 78.16062927246094,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                78.16062927246094,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -6.989545822143555,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"onyms\", \"apse\", \"chron\", \"onym\", \"agogue\"], \"v\": [16.797367095947266, 15.647594451904297, 15.347644805908203, 15.264989852905273, 15.187026977539062]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"lessness\", \"een\", \"enance\", \"OIL\"], \"v\": [-20.647560119628906, -19.324800491333008, -18.59555435180664, -17.59983253479004, -17.49472999572754]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4ewf4riytr7739",
            "tokens": [
                " se",
                "ing",
                " how",
                " Roland",
                " have",
                " brought",
                " their",
                " iconic",
                " syn",
                "ths",
                " and",
                " drum",
                " machines",
                ",",
                " 202",
                ",",
                " 505"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 77.30191802978516,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                77.30191802978516,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -7.796215534210205,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"onyms\", \"apse\", \"agog\", \"apses\", \"chron\"], \"v\": [15.309942245483398, 15.27205753326416, 14.777509689331055, 14.708860397338867, 14.558820724487305]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"iage\", \"lessness\", \"DERR\", \"een\"], \"v\": [-18.432010650634766, -15.406591415405273, -14.81541633605957, -14.782032012939453, -14.76539421081543]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4fwf4rqvosfn69",
            "tokens": [
                " because",
                " they",
                " weren",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " all",
                " really",
                " syn",
                "ced",
                " together",
                ".",
                " They",
                " weren",
                "\u00e2\u0122",
                "\u013b",
                "t"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 75.80270385742188,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                75.80270385742188,
                12.43418502807617,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -4.18657922744751,
                -0.000376259908080101,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"opsis\", \"apse\", \"apses\", \"chron\", \"onym\"], \"v\": [11.437360763549805, 11.23353385925293, 9.919471740722656, 9.561407089233398, 9.062784194946289]}, {\"t\": [\"apse\", \"onyms\", \"apses\", \"agog\", \"onym\"], \"v\": [3.6341094970703125, 3.4584808349609375, 3.3581790924072266, 3.353086471557617, 3.325258255004883]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"een\", \"DERR\", \"lessness\", \"IVE\"], \"v\": [-26.67896842956543, -23.850757598876953, -22.010173797607422, -21.808380126953125, -21.637371063232422]}, {\"t\": [\"ORED\", \"ModLoader\", \"DERR\", \"een\", \"lessness\"], \"v\": [-2.6407413482666016, -2.148345947265625, -2.0111656188964844, -1.9668712615966797, -1.8799514770507812]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4gwf4rquyc7sqk",
            "tokens": [
                ",",
                " I",
                " really",
                "<|endoftext|>",
                "\u013b",
                "s",
                " often",
                " a",
                " syn",
                "onym",
                " of",
                " ip",
                "se",
                ".",
                " Random",
                " example",
                " from"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 75.26839447021484,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                75.26839447021484,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -2.45575737953186,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apses\", \"apse\", \"chron\", \"opsis\", \"agog\"], \"v\": [9.549139022827148, 8.627229690551758, 8.103927612304688, 7.75941276550293, 7.502080917358398]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"een\", \" bearer\", \"lessness\", \" LIA\"], \"v\": [-26.305688858032227, -23.666465759277344, -23.16211700439453, -23.104890823364258, -23.088468551635742]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4hwf4r03056vx7",
            "tokens": [
                " am",
                " therefore",
                " hopeful",
                " that",
                " the",
                " bishops",
                "\u00e2\u0122",
                "\u013b",
                " syn",
                "od",
                " on",
                " the",
                " family",
                " may",
                " help",
                " us",
                " find"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 74.78008270263672,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                74.78008270263672,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -2.599946975708008,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"onyms\", \"apses\", \"opsis\", \"esthesia\"], \"v\": [14.224989891052246, 13.338105201721191, 13.250336647033691, 12.58012866973877, 12.146113395690918]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"een\", \" bearer\", \"iage\", \" LIA\"], \"v\": [-21.89720916748047, -19.663497924804688, -17.196523666381836, -17.134504318237305, -17.0654239654541]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4iwf4r9cco0alc",
            "tokens": [
                " attacks",
                " in",
                " Russian",
                " media",
                "\u010a",
                "\u010a",
                "Some",
                " local",
                " syn",
                "agog",
                "ues",
                " have",
                " also",
                " joined",
                " the",
                " war",
                " effort"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 74.09550476074219,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                74.09550476074219,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -6.86466121673584,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"opsis\", \"chron\", \"esthesia\", \"onyms\"], \"v\": [10.584951400756836, 9.84188461303711, 9.301182746887207, 9.018034934997559, 9.002073287963867]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"een\", \"lessness\", \"OIL\", \"iage\"], \"v\": [-24.294940948486328, -23.180421829223633, -21.50543975830078, -21.149559020996094, -21.069557189941406]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4jwf4ri7r5medo",
            "tokens": [
                " more",
                " delay",
                ",",
                " so",
                " with",
                " any",
                " luck",
                ",",
                " syn",
                "cing",
                " issues",
                " shouldn",
                "\u00e2\u0122",
                "\u013b",
                "t",
                " be",
                " as"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 74.07164764404297,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                74.07164764404297,
                10.01321792602539,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -4.16447639465332,
                0.3816437721252441,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"opsis\", \"agogue\", \"onyms\", \"agog\"], \"v\": [11.695755958557129, 11.280868530273438, 11.194352149963379, 11.10269832611084, 10.690425872802734]}, {\"t\": [\"apse\", \"onyms\", \"agog\", \"onym\", \"apses\"], \"v\": [2.888395309448242, 2.8379764556884766, 2.720338821411133, 2.6634597778320312, 2.6299972534179688]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"ModLoader\", \"OIL\", \"DERR\", \"lessness\"], \"v\": [-23.409385681152344, -20.858251571655273, -19.758411407470703, -19.486051559448242, -19.43450355529785]}, {\"t\": [\"ORED\", \"ModLoader\", \"DERR\", \"lessness\", \"OIL\"], \"v\": [-2.4355392456054688, -1.9985408782958984, -1.8546123504638672, -1.7279644012451172, -1.7197761535644531]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4kwf4ryj2cwzap",
            "tokens": [
                " shootings",
                ",",
                " arson",
                " at",
                " mosques",
                ",",
                " vandalism",
                " at",
                " syn",
                "agog",
                "ues",
                ",",
                " and",
                " yes",
                ",",
                " even",
                " hateful"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 71.79058837890625,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                71.79058837890625,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -6.343207359313965,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"opsis\", \"onyms\", \"chron\", \"onym\"], \"v\": [11.751646995544434, 11.02644157409668, 10.86158275604248, 10.179265022277832, 9.718611717224121]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"een\", \"iage\", \"DERR\", \" Salvation\"], \"v\": [-24.921865463256836, -22.828664779663086, -22.453285217285156, -21.18303108215332, -21.120670318603516]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4lwf4rk5k5sp43",
            "tokens": [
                " on",
                " the",
                " day",
                "'s",
                " agenda",
                ".",
                "\u010a",
                "\u010a",
                "Syn",
                "onymous",
                " with",
                " asking",
                " for",
                " something",
                " by",
                " close",
                " of"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 71.63285827636719,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                71.63285827636719,
                4.710099220275879,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -3.856178283691406,
                -0.02358055114746094,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"apses\", \"agog\", \"onyms\", \"chron\"], \"v\": [8.54288387298584, 7.894513130187988, 7.674899101257324, 6.930808067321777, 6.442143440246582]}, {\"t\": [\"apse\", \"apses\", \"agog\", \"chron\", \"onyms\"], \"v\": [1.3479461669921875, 1.2805652618408203, 1.2386045455932617, 1.2255935668945312, 1.2124967575073242]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"ModLoader\", \"een\", \"iage\", \"OIL\"], \"v\": [-22.655376434326172, -19.868412017822266, -19.797901153564453, -18.69546127319336, -18.548358917236328]}, {\"t\": [\"ORED\", \"ModLoader\", \"een\", \"DERR\", \" LIA\"], \"v\": [-1.1544055938720703, -0.9863815307617188, -0.8913726806640625, -0.8889598846435547, -0.8561019897460938]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4mwf4ru6e5uv4z",
            "tokens": [
                " tempting",
                " to",
                " think",
                " that",
                " spending",
                " thousands",
                " on",
                " new",
                " syn",
                "ths",
                " and",
                " drum",
                " machines",
                " will",
                " automatically",
                " make",
                " your"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 71.3936767578125,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                71.3936767578125,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -4.391312122344971,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"onyms\", \"apse\", \"chron\", \"opsis\", \"onym\"], \"v\": [12.206888198852539, 12.03715705871582, 11.817451477050781, 11.708328247070312, 11.478097915649414]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"een\", \"DERR\", \"iage\", \"lessness\"], \"v\": [-20.194664001464844, -16.83043670654297, -16.518341064453125, -16.40073013305664, -16.17616844177246]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4nwf4rq85fbvi9",
            "tokens": [
                " mode",
                "\u010a",
                "\u010a",
                "-",
                "id",
                " <",
                "dir",
                ">:",
                " syn",
                "onym",
                " for",
                " -",
                "rd",
                "\u010a",
                "\u010a",
                "-",
                "c"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 71.35037994384766,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                71.35037994384766,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -2.66465950012207,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"apses\", \"opsis\", \"agog\", \"onyms\"], \"v\": [7.430177688598633, 6.524129867553711, 5.617778778076172, 5.482877731323242, 5.226508140563965]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"DERR\", \"een\", \"ModLoader\", \" Tonight\"], \"v\": [-26.640522003173828, -22.98712921142578, -22.969623565673828, -22.628164291381836, -21.9486083984375]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4owf4r780tegcj",
            "tokens": [
                " /",
                " audio",
                " calls",
                ".",
                " All",
                " the",
                " conversations",
                " are",
                " syn",
                "ced",
                " between",
                " PCs",
                ",",
                " tablets",
                ",",
                " and",
                " phones"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 71.17942810058594,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                71.17942810058594,
                8.981948852539062,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -3.256920337677002,
                0.08926820755004883,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"opsis\", \"apses\", \"esthesia\", \"onyms\"], \"v\": [12.284444808959961, 12.005237579345703, 11.006446838378906, 10.402440071105957, 10.3048095703125]}, {\"t\": [\"apse\", \"onyms\", \"agog\", \"apses\", \"chron\"], \"v\": [2.5298118591308594, 2.4296913146972656, 2.391033172607422, 2.3665332794189453, 2.2951927185058594]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"lessly\", \"DERR\", \"een\", \"ModLoader\"], \"v\": [-23.886152267456055, -19.493511199951172, -18.969696044921875, -18.73716926574707, -18.088520050048828]}, {\"t\": [\"ORED\", \"ModLoader\", \"DERR\", \"een\", \"lessness\"], \"v\": [-1.9705429077148438, -1.5918731689453125, -1.4908828735351562, -1.4121246337890625, -1.410858154296875]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4pwf4rb5khm4fm",
            "tokens": [
                "port",
                "-",
                " (",
                "from",
                " port",
                "are",
                ",",
                " a",
                " syn",
                "onym",
                ").",
                " Bing",
                "o",
                ",",
                " there",
                "\u00e2\u0122",
                "\u013b"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 69.90079498291016,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                69.90079498291016,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -4.536214828491211,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apses\", \"apse\", \"chron\", \"agog\", \"opsis\"], \"v\": [13.949823379516602, 13.819755554199219, 11.764657974243164, 11.056316375732422, 10.748001098632812]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \" bearer\", \"een\", \" LIA\", \"IVE\"], \"v\": [-22.995990753173828, -21.39345359802246, -20.61874008178711, -19.889198303222656, -19.694211959838867]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4qwf4rj11jaacp",
            "tokens": [
                "\u010a",
                "\"",
                "Dragon",
                " Ball",
                " Super",
                "\"",
                " Episode",
                " 74",
                " Syn",
                "opsis",
                ",",
                " Title",
                " and",
                " Air",
                " date",
                "\u010a",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 68.33564758300781,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                68.33564758300781,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -1.242677688598633,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apses\", \"agog\", \"apse\", \"onyms\", \"agogue\"], \"v\": [6.621364593505859, 6.302853584289551, 6.209577560424805, 5.303821563720703, 4.133537292480469]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"OIL\", \" Tonight\", \"een\", \"ModLoader\"], \"v\": [-26.022871017456055, -22.475048065185547, -22.253501892089844, -22.229520797729492, -21.868330001831055]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5ts8m4rwf4rrvhko274",
            "tokens": [
                "-",
                "T",
                "uner",
                ",",
                " or",
                " both",
                " for",
                " a",
                " Syn",
                "ch",
                "ro",
                " Summon",
                ".",
                " L",
                "osing",
                " 2000",
                " Life"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 68.17623138427734,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                68.17623138427734,
                3.314684391021729,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -1.240740776062012,
                -0.1209917068481445,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apses\", \"apse\", \"onyms\", \"agog\", \"esthesia\"], \"v\": [10.648200988769531, 10.475259780883789, 9.982854843139648, 9.907766342163086, 8.560857772827148]}, {\"t\": [\"onyms\", \"apse\", \"agog\", \"onym\", \"apses\"], \"v\": [1.0252742767333984, 0.9979839324951172, 0.9738883972167969, 0.9573020935058594, 0.9546546936035156]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"een\", \"ModLoader\", \" Coral\", \" Salvation\"], \"v\": [-23.26671028137207, -19.73490333557129, -18.85030174255371, -18.67750358581543, -18.62847137451172]}, {\"t\": [\"ORED\", \"ModLoader\", \"een\", \"enance\", \"IVE\"], \"v\": [-0.9271659851074219, -0.7100257873535156, -0.7056427001953125, -0.6715526580810547, -0.6629085540771484]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tu8m5lwf4raz9z9is7",
            "tokens": [
                " Work",
                " with",
                " confidence",
                "\u00e2\u0122\u0136",
                "One",
                "Note",
                " Mobile",
                " automatically",
                " syn",
                "cs",
                " your",
                " notes",
                " with",
                " Windows",
                " Live",
                " in",
                " the"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 66.80732727050781,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                66.80732727050781,
                6.811113357543945,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -8.401906967163086,
                0.3258471488952637,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"onyms\", \"apse\", \"opsis\", \"agog\", \"esthesia\"], \"v\": [15.356647491455078, 14.310174942016602, 13.798726081848145, 13.611871719360352, 13.58688735961914]}, {\"t\": [\"apse\", \"onyms\", \"agog\", \"apses\", \"onym\"], \"v\": [1.7948188781738281, 1.7944564819335938, 1.7141380310058594, 1.6943798065185547, 1.6706962585449219]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"DERR\", \"lessly\", \"ModLoader\", \" Tonight\"], \"v\": [-15.675617218017578, -12.515010833740234, -11.38843822479248, -11.305076599121094, -11.165491104125977]}, {\"t\": [\"ORED\", \"ModLoader\", \"DERR\", \"enance\", \"lessness\"], \"v\": [-1.4551563262939453, -1.1230201721191406, -1.109243392944336, -1.0528831481933594, -1.0126953125]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tu8m5qwf4rypv5ik34",
            "tokens": [
                "ace",
                "ke",
                "lly",
                " A",
                " Best",
                " Eff",
                "ort",
                " Cache",
                " Syn",
                "chron",
                "ization",
                " Library",
                " In",
                " Java",
                " Project",
                " maintained",
                " by"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 65.50434875488281,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                65.50434875488281,
                11.93483924865723,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -1.3896803855896,
                0.0009992942214012146,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apses\", \"agog\", \"apse\", \"onyms\", \"esthesia\"], \"v\": [5.083193778991699, 4.315173149108887, 4.027172565460205, 3.610231876373291, 3.1301918029785156]}, {\"t\": [\"onyms\", \"apse\", \"apses\", \"agog\", \"onym\"], \"v\": [2.6565475463867188, 2.589475631713867, 2.524921417236328, 2.49127197265625, 2.360950469970703]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"een\", \"ModLoader\", \" Neon\", \" Redemption\"], \"v\": [-25.720544815063477, -22.69741439819336, -21.71160125732422, -21.597026824951172, -21.56332778930664]}, {\"t\": [\"ORED\", \"een\", \"ModLoader\", \"lessness\", \"DERR\"], \"v\": [-3.2065963745117188, -2.5479698181152344, -2.4786033630371094, -2.4015331268310547, -2.3892059326171875]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tu8m5nwf4r01t2t4iz",
            "tokens": [
                " space",
                " (",
                "a",
                " process",
                " known",
                " as",
                " geo",
                "-",
                "syn",
                "ching",
                ").",
                "\u010a",
                "\u010a",
                "The",
                " analysis",
                "<|endoftext|>",
                "Is"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 63.95244979858398,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                63.95244979858398,
                4.407815933227539,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.039177894592285,
                0.01415634155273438,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apses\", \"onyms\", \"apse\", \"agog\", \"onym\"], \"v\": [4.659080505371094, 4.610630989074707, 4.277368068695068, 3.9392099380493164, 2.529252529144287]}, {\"t\": [\"apse\", \"onyms\", \"apses\", \"agog\", \"onym\"], \"v\": [1.4199390411376953, 1.3875083923339844, 1.340005874633789, 1.3153400421142578, 1.296121597290039]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"een\", \"lessness\", \"aneers\", \"iard\"], \"v\": [-23.760345458984375, -21.177997589111328, -20.51500701904297, -20.10655975341797, -20.0574951171875]}, {\"t\": [\"ORED\", \"ModLoader\", \"een\", \"DERR\", \"lessness\"], \"v\": [-0.9239044189453125, -0.7080802917480469, -0.6617221832275391, -0.6616172790527344, -0.6404991149902344]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tu8m5pwf4rt6zeby7b",
            "tokens": [
                " of",
                " them",
                " licensed",
                " by",
                " the",
                " National",
                " Evangel",
                "ical",
                " Syn",
                "od",
                " of",
                " Syria",
                " and",
                " Lebanon",
                ",",
                " have",
                " been"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 63.55276489257812,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                63.55276489257812,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.676687240600586,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apses\", \"apse\", \"onyms\", \"agog\", \"onym\"], \"v\": [6.29502010345459, 6.189313888549805, 6.002371788024902, 4.978752136230469, 3.8391966819763184]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"een\", \"iage\", \" Salvation\", \"enance\"], \"v\": [-23.02678871154785, -21.2022705078125, -20.316558837890625, -20.243953704833984, -19.621376037597656]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tu8m5owf4ripsua95n",
            "tokens": [
                "yo",
                " Noct",
                "i",
                " Rev",
                "o",
                "Drive",
                " Hybrid",
                " Summit",
                " Syn",
                "apse",
                " On",
                "yx",
                " Series",
                " Solid",
                " Series",
                " OC",
                "Z"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 63.17285537719727,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                63.17285537719727,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -9.18558120727539,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apses\", \"onyms\", \"agog\", \"apse\", \"onym\"], \"v\": [11.442900657653809, 10.534783363342285, 10.294190406799316, 9.18558120727539, 9.125405311584473]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"een\", \"ModLoader\", \" Neon\", \"iage\"], \"v\": [-20.728471755981445, -18.535503387451172, -18.109806060791016, -17.8583927154541, -17.834436416625977]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tu8m5mwf4rxby8q91l",
            "tokens": [
                "\u010a",
                "To",
                ":",
                " SH",
                " Members",
                " <",
                "members",
                "@",
                "syn",
                "hak",
                ".",
                "org",
                ">",
                "\u010a",
                "\u010a",
                "Mar",
                " 11"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 60.93701553344727,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                60.93701553344727,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                7.014509201049805,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"onyms\", \"apses\", \"apse\", \"agog\", \"esthesia\"], \"v\": [5.8715972900390625, 5.775594711303711, 5.489713191986084, 5.441976547241211, 4.256830215454102]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"een\", \"iage\", \"\\u0133\\u00e5\\u00a3\\u00ab\", \"OIL\"], \"v\": [-20.709762573242188, -19.044645309448242, -18.12628936767578, -18.121402740478516, -17.85383415222168]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tu8m5rwf4rluqm5zv7",
            "tokens": [
                " from",
                " Syn",
                "H",
                "ak",
                " (",
                "this",
                " will",
                " include",
                " Syn",
                "H",
                "ak",
                "'s",
                " mailing",
                " lists",
                " and",
                " any",
                " other"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 58.69566345214844,
            "maxValueTokenIndex": 1,
            "minValue": 0,
            "values": [
                0,
                58.69566345214844,
                0,
                0,
                0,
                0,
                0,
                0,
                49.98934555053711,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                6.359773635864258,
                0,
                0,
                0,
                0,
                0,
                0,
                1.894208908081055,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {\"t\": [\"apse\", \"onyms\", \"apses\", \"agog\", \"onym\"], \"v\": [8.164655685424805, 8.139253616333008, 7.902498245239258, 7.426149368286133, 6.966684341430664]}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"apses\", \"onyms\", \"agog\", \"onym\"], \"v\": [12.518858909606934, 11.948016166687012, 11.929709434509277, 11.59250259399414, 10.96764850616455]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {\"t\": [\"ORED\", \"ModLoader\", \"een\", \"OIL\", \"\\u0133\\u00e5\\u00a3\\u00ab\"], \"v\": [-15.720132827758789, -14.212224960327148, -13.263863563537598, -12.702339172363281, -12.57442855834961]}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"ModLoader\", \"OIL\", \"DERR\", \"een\"], \"v\": [-10.373050689697266, -8.969934463500977, -8.055718421936035, -7.853471755981445, -7.722562789916992]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tu8m5swf4r78nxmhtj",
            "tokens": [
                "<|endoftext|>",
                " this",
                " goal",
                ",",
                " including",
                " IBM",
                "'s",
                " neuro",
                "syn",
                "aptic",
                " chips",
                " (",
                "and",
                " accompanying",
                " programming",
                " language",
                "),"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 57.06982803344727,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                57.06982803344727,
                0.9588949680328369,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.0902884379029274,
                -0.02491283416748047,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"onyms\", \"apse\", \"onym\", \"apses\", \"chron\"], \"v\": [7.621513366699219, 6.851363658905029, 6.164445877075195, 6.007291316986084, 5.681408882141113]}, {\"t\": [\"onyms\", \"apse\", \"onym\", \"chron\", \"apses\"], \"v\": [0.2666645050048828, 0.2620983123779297, 0.24747848510742188, 0.24361610412597656, 0.24222564697265625]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \" Redemption\", \"een\", \"lessness\", \"IVE\"], \"v\": [-18.36030387878418, -15.946910858154297, -15.818731307983398, -15.60422134399414, -15.498323440551758]}, {\"t\": [\"ORED\", \"ModLoader\", \"DERR\", \"lessness\", \" LIA\"], \"v\": [-0.19402694702148438, -0.16012191772460938, -0.14540863037109375, -0.14007949829101562, -0.139862060546875]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tu8m5twf4rspi7n7wj",
            "tokens": [
                "mails",
                " from",
                " the",
                " public",
                "ally",
                " available",
                " discuss",
                "@",
                "syn",
                "hak",
                ".",
                "org",
                " mailing",
                " list",
                ".",
                " Here",
                "<|endoftext|>"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 54.86922073364258,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                54.86922073364258,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                5.152519226074219,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"onyms\", \"apse\", \"apses\", \"agog\", \"onym\"], \"v\": [6.929973602294922, 6.553802013397217, 6.384438991546631, 6.262998104095459, 5.545073986053467]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"een\", \"ModLoader\", \"iage\", \"\\u0133\\u00e5\\u00a3\\u00ab\"], \"v\": [-15.510250091552734, -14.211015701293945, -13.843450546264648, -13.505706787109375, -13.289163589477539]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tu8m5uwf4r859lvjas",
            "tokens": [
                " my",
                " god",
                ",",
                " it",
                " even",
                " does",
                " lip",
                "-",
                "syn",
                "ch",
                "\u00e2\u0122",
                "\u013f",
                ".",
                " The",
                " Roman",
                " soldiers",
                " are"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 47.37820053100586,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                47.37820053100586,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -1.828010559082031,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"onyms\", \"apses\", \"agog\", \"onym\"], \"v\": [7.634082317352295, 7.613379001617432, 7.480130195617676, 7.030124187469482, 7.003020286560059]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"een\", \" Tonight\", \"iage\", \"INA\"], \"v\": [-14.999526977539062, -12.286287307739258, -12.145484924316406, -11.876274108886719, -11.855541229248047]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tu8m5vwf4rvjpkil5k",
            "tokens": [
                " way",
                ".",
                "\u00e2\u0122",
                "\u013f",
                " He",
                " characterized",
                " the",
                " surprise",
                " sync",
                " as",
                " two",
                " nations",
                " seizing",
                " an",
                " opportunity",
                " to",
                " undercut"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 28.20829200744629,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                28.20829200744629,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2.103359222412109,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"onyms\", \"apse\", \"agog\", \"apses\", \"onym\"], \"v\": [7.711747169494629, 7.213827610015869, 7.207683563232422, 6.967933177947998, 6.808197021484375]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"lessness\", \"ModLoader\", \"een\", \"enance\"], \"v\": [-6.6451873779296875, -5.84065580368042, -5.200672149658203, -5.1296234130859375, -4.955007553100586]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tu8m5wwf4rdga6955s",
            "tokens": [
                "0",
                ":",
                "99",
                "999",
                ":",
                "7",
                "::",
                ":",
                " sync",
                ":",
                "*:",
                "16",
                "270",
                ":",
                "0",
                ":",
                "99"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 24.80973815917969,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                24.80973815917969,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.7082128524780273,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"onyms\", \"agog\", \"apses\", \"onym\"], \"v\": [5.450592994689941, 5.370865821838379, 5.103588104248047, 5.093018531799316, 4.96923828125]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"ModLoader\", \"DERR\", \"een\", \"OIL\"], \"v\": [-4.947652816772461, -3.993196487426758, -3.8100624084472656, -3.5764007568359375, -3.5049781799316406]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tu8m5ywf4r2kaw4y38",
            "tokens": [
                " by",
                " leveraging",
                " the",
                " success",
                " of",
                " App",
                "Link",
                " and",
                " Sync",
                ",",
                " much",
                " like",
                " Google",
                " used",
                " Android",
                " in",
                " the"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 20.61302947998047,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                20.61302947998047,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1.43589973449707,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"onyms\", \"apses\", \"onym\", \"agog\"], \"v\": [4.456242561340332, 4.436397552490234, 4.277162551879883, 4.180171966552734, 4.0935564041137695]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"ModLoader\", \"een\", \"DERR\", \"LESS\"], \"v\": [-4.935026168823242, -4.205106735229492, -3.8267383575439453, -3.796968460083008, -3.700662612915039]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tu8m61wf4r76t9ixxg",
            "tokens": [
                " the",
                " SSH",
                " tunnels",
                " to",
                " automate",
                " tasks",
                " such",
                " as",
                " synchron",
                "izing",
                " the",
                " directories",
                " on",
                " each",
                " server",
                " from",
                " a"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 19.51142501831055,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                19.51142501831055,
                2.636700630187988,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.002690830267965794,
                0.04813003540039062,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"onyms\", \"agog\", \"apses\", \"agogue\"], \"v\": [4.662239074707031, 4.594686508178711, 4.408359527587891, 4.397674560546875, 4.269084930419922]}, {\"t\": [\"apse\", \"onyms\", \"agog\", \"apses\", \"onym\"], \"v\": [0.8253116607666016, 0.801971435546875, 0.7821006774902344, 0.7799205780029297, 0.7565765380859375]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"ModLoader\", \"een\", \"DERR\", \"OIL\"], \"v\": [-4.056606292724609, -3.3007431030273438, -3.155017852783203, -3.1056671142578125, -2.933277130126953]}, {\"t\": [\"ORED\", \"ModLoader\", \"DERR\", \"een\", \"enance\"], \"v\": [-0.49551963806152344, -0.40076446533203125, -0.3675384521484375, -0.32764244079589844, -0.3243122100830078]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tu8m5zwf4r3zn6wd20",
            "tokens": [
                " associated",
                " with",
                " a",
                " swinging",
                " motion",
                " exert",
                "s",
                " a",
                " synchron",
                "izing",
                " action",
                " in",
                " the",
                " brain",
                " that",
                " reinforces",
                " endogenous"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 18.84734344482422,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                18.84734344482422,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.04878050088882446,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"onyms\", \"apse\", \"apses\", \"agog\", \"onym\"], \"v\": [4.479026794433594, 4.377098083496094, 4.105171203613281, 3.982227325439453, 3.8632259368896484]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"een\", \"ModLoader\", \"lessness\", \"IVE\"], \"v\": [-3.945117950439453, -3.2099342346191406, -3.06890869140625, -3.026508331298828, -3.0131092071533203]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tu8m60wf4rd6kj5dgz",
            "tokens": [
                " st",
                "on",
                "ers",
                " who",
                " watch",
                " the",
                " film",
                " in",
                " sync",
                " with",
                " Pink",
                " Floyd",
                "\u00e2\u0122",
                "\u013b",
                "s",
                " Dark",
                " Side"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 18.20541763305664,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                18.20541763305664,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.135230541229248,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"onyms\", \"onym\", \"apses\", \"agog\"], \"v\": [4.897775650024414, 4.882053375244141, 4.621721267700195, 4.618856430053711, 4.577274322509766]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"ModLoader\", \"DERR\", \"een\", \"lessness\"], \"v\": [-3.7826805114746094, -3.0262584686279297, -2.895977020263672, -2.861337661743164, -2.84018611907959]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tu8m5xwf4ray6t4ws0",
            "tokens": [
                "\u010a",
                "\u010a",
                "set",
                "x",
                " GPU",
                "_",
                "USE",
                "_",
                "SY",
                "NC",
                "_",
                "OB",
                "J",
                "EC",
                "TS",
                " 1",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 16.73233413696289,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                16.73233413696289,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.9820690155029297,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apses\", \"apse\", \"onyms\", \"agog\", \"onym\"], \"v\": [4.93028450012207, 4.920831680297852, 4.912057876586914, 4.899946212768555, 4.708368301391602]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"IVE\", \"ModLoader\", \"DERR\", \" LIA\"], \"v\": [-3.03228759765625, -2.3353328704833984, -2.3182334899902344, -2.308605194091797, -2.2707138061523438]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tv8m66wf4rfw6c3s8o",
            "tokens": [
                "\u010a",
                "\u010a",
                "PS",
                "Y",
                "CH",
                "OS",
                "IS",
                ",",
                " SY",
                "N",
                "CHR",
                "ON",
                "IC",
                "ITIES",
                ",",
                " SH",
                "AM"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 13.78310012817383,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                13.78310012817383,
                9.91550064086914,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.1147689819335938,
                -0.1946206092834473,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"apses\", \"agog\", \"onyms\", \"onym\"], \"v\": [4.35047721862793, 4.186012268066406, 3.9592971801757812, 3.9454851150512695, 3.8664283752441406]}, {\"t\": [\"apse\", \"onyms\", \"apses\", \"opsis\", \"agog\"], \"v\": [3.0179452896118164, 2.88778018951416, 2.883197784423828, 2.7187137603759766, 2.705646514892578]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"OIL\", \"IVE\", \" LIA\", \"WIN\"], \"v\": [-2.418792724609375, -2.238208770751953, -2.0674800872802734, -1.9821491241455078, -1.9539613723754883]}, {\"t\": [\"ORED\", \"IVE\", \"OIL\", \"ModLoader\", \"DERR\"], \"v\": [-2.353208541870117, -1.7202262878417969, -1.6785926818847656, -1.6403579711914062, -1.6276626586914062]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tv8m64wf4rylvqsj5o",
            "tokens": [
                "ur",
                " Mis",
                "u",
                "ari",
                "\u010a",
                "\u010a",
                "During",
                " the",
                " sym",
                "posium",
                ",",
                " Duterte",
                " said",
                " that",
                " he",
                " was",
                " not"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 13.63092613220215,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                13.63092613220215,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -2.384172148595098e-07,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"onyms\", \"apses\", \"agog\", \"onym\"], \"v\": [2.444967269897461, 2.429868698120117, 2.3746471405029297, 2.15771484375, 2.0394973754882812]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"ModLoader\", \"een\", \"iage\", \" LIA\"], \"v\": [-3.226238250732422, -2.7827301025390625, -2.6046104431152344, -2.5350570678710938, -2.4595489501953125]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tv8m65wf4r2f4rv755",
            "tokens": [
                " contains",
                " the",
                " 13",
                " tracks",
                " from",
                " P",
                "az",
                "'s",
                " synth",
                "-",
                "heavy",
                " independent",
                " release",
                " \"",
                "From",
                " the",
                " Bottom"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 9.741565704345703,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                9.741565704345703,
                2.622366428375244,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                -0.2134084701538086,
                -0.03030776977539062,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"onyms\", \"apses\", \"agog\", \"onym\"], \"v\": [2.5390777587890625, 2.5258102416992188, 2.477783203125, 2.43865966796875, 2.4115142822265625]}, {\"t\": [\"apse\", \"onyms\", \"apses\", \"onym\", \"agog\"], \"v\": [0.8218841552734375, 0.7989654541015625, 0.7893829345703125, 0.7627716064453125, 0.7401962280273438]}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"ModLoader\", \"lessness\", \"iage\", \"LESS\"], \"v\": [-1.8712520599365234, -1.4450721740722656, -1.3281612396240234, -1.2975406646728516, -1.2836761474609375]}, {\"t\": [\"ORED\", \"een\", \"ModLoader\", \"lessness\", \"OIL\"], \"v\": [-0.5543708801269531, -0.4212989807128906, -0.42078399658203125, -0.4036979675292969, -0.40004730224609375]}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tv8m62wf4rz2mni94n",
            "tokens": [
                " N",
                "TP",
                ",",
                " keeping",
                " clocks",
                " on",
                " the",
                " network",
                " synchronized",
                " within",
                " a",
                " few",
                " seconds",
                " of",
                " one",
                " another",
                "."
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 9.604808807373047,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                9.604808807373047,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.4958057403564453,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"onyms\", \"apses\", \"agog\", \"onym\"], \"v\": [2.3882923126220703, 2.3080062866210938, 2.2129783630371094, 2.2084388732910156, 2.145719528198242]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"ModLoader\", \"DERR\", \"lessness\", \"enance\"], \"v\": [-2.281087875366211, -1.945333480834961, -1.8091316223144531, -1.7156143188476562, -1.7143783569335938]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tv8m63wf4r7u8e8mc4",
            "tokens": [
                " the",
                " London",
                " Eye",
                " was",
                " sixth",
                ".",
                "\u010a",
                "\u010a",
                "----------------------------------------------------------------",
                "------------------------------------------------",
                "--------------",
                "\u010a",
                "\u010a",
                "Most",
                " photographed",
                " landmarks",
                " according"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 9.449075698852539,
            "maxValueTokenIndex": 8,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                9.449075698852539,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0.1386666297912598,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"apse\", \"onyms\", \"agog\", \"apses\", \"onym\"], \"v\": [2.2254581451416016, 2.2170181274414062, 2.1318435668945312, 2.128559112548828, 2.060077667236328]}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {\"t\": [\"ORED\", \"ModLoader\", \"DERR\", \"een\", \"OIL\"], \"v\": [-2.0731582641601562, -1.711456298828125, -1.6464042663574219, -1.6359596252441406, -1.615335464477539]}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m4wwf4rj3dywqmj",
            "tokens": [
                "state",
                " solution",
                " of",
                " the",
                " Israeli",
                "-",
                "Palestinian",
                " conflict",
                " which",
                " we",
                " want",
                " to",
                " see",
                ".",
                "\u010a",
                "\u010a",
                "The"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m4vwf4rv4urykv5",
            "tokens": [
                "<|endoftext|>",
                "state",
                " solution",
                " of",
                " the",
                " Israeli",
                "-",
                "Palestinian",
                " conflict",
                " which",
                " we",
                " want",
                " to",
                " see",
                ".",
                "\u010a",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m4uwf4rzoj06sbr",
            "tokens": [
                " Territories",
                "<|endoftext|>",
                "state",
                " solution",
                " of",
                " the",
                " Israeli",
                "-",
                "Palestinian",
                " conflict",
                " which",
                " we",
                " want",
                " to",
                " see",
                ".",
                "\u010a"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m4twf4rqt6evbwf",
            "tokens": [
                "ied",
                " Territories",
                "<|endoftext|>",
                "state",
                " solution",
                " of",
                " the",
                " Israeli",
                "-",
                "Palestinian",
                " conflict",
                " which",
                " we",
                " want",
                " to",
                " see",
                "."
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m4swf4rmvvxiwzn",
            "tokens": [
                " Occup",
                "ied",
                " Territories",
                "<|endoftext|>",
                "state",
                " solution",
                " of",
                " the",
                " Israeli",
                "-",
                "Palestinian",
                " conflict",
                " which",
                " we",
                " want",
                " to",
                " see"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m4zwf4r7zlbu3uo",
            "tokens": [
                " the",
                " Israeli",
                "-",
                "Palestinian",
                " conflict",
                " which",
                " we",
                " want",
                " to",
                " see",
                ".",
                "\u010a",
                "\u010a",
                "The",
                " British",
                " Government",
                " has"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m4ywf4rhqvdp3b7",
            "tokens": [
                " of",
                " the",
                " Israeli",
                "-",
                "Palestinian",
                " conflict",
                " which",
                " we",
                " want",
                " to",
                " see",
                ".",
                "\u010a",
                "\u010a",
                "The",
                " British",
                " Government"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m50wf4rf3eosnbi",
            "tokens": [
                " Israeli",
                "-",
                "Palestinian",
                " conflict",
                " which",
                " we",
                " want",
                " to",
                " see",
                ".",
                "\u010a",
                "\u010a",
                "The",
                " British",
                " Government",
                " has",
                " placed"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tv8m6bwf4rlu26n30h",
            "tokens": [
                " expression",
                " levels",
                " are",
                " regulated",
                " by",
                " genes",
                " and",
                " their",
                " epigen",
                "etic",
                " states",
                " in",
                " response",
                " to",
                " external",
                " influences",
                " or"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m5bwf4ra2tnfenj",
            "tokens": [
                "\u010a",
                "The",
                " British",
                " Government",
                " has",
                " placed",
                " online",
                " guidance",
                " to",
                " raise",
                " awareness",
                " of",
                " the",
                " key",
                " security",
                " and",
                " political"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m5awf4rlhg6d3c1",
            "tokens": [
                "\u010a",
                "\u010a",
                "The",
                " British",
                " Government",
                " has",
                " placed",
                " online",
                " guidance",
                " to",
                " raise",
                " awareness",
                " of",
                " the",
                " key",
                " security",
                " and"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m59wf4r4ud4qwjb",
            "tokens": [
                ".",
                "\u010a",
                "\u010a",
                "The",
                " British",
                " Government",
                " has",
                " placed",
                " online",
                " guidance",
                " to",
                " raise",
                " awareness",
                " of",
                " the",
                " key",
                " security"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m58wf4r6estbkpb",
            "tokens": [
                " see",
                ".",
                "\u010a",
                "\u010a",
                "The",
                " British",
                " Government",
                " has",
                " placed",
                " online",
                " guidance",
                " to",
                " raise",
                " awareness",
                " of",
                " the",
                " key"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m57wf4r4zn15bws",
            "tokens": [
                " to",
                " see",
                ".",
                "\u010a",
                "\u010a",
                "The",
                " British",
                " Government",
                " has",
                " placed",
                " online",
                " guidance",
                " to",
                " raise",
                " awareness",
                " of",
                " the"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m56wf4ri07k4dlj",
            "tokens": [
                " want",
                " to",
                " see",
                ".",
                "\u010a",
                "\u010a",
                "The",
                " British",
                " Government",
                " has",
                " placed",
                " online",
                " guidance",
                " to",
                " raise",
                " awareness",
                " of"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m55wf4rpkebrfdy",
            "tokens": [
                " we",
                " want",
                " to",
                " see",
                ".",
                "\u010a",
                "\u010a",
                "The",
                " British",
                " Government",
                " has",
                " placed",
                " online",
                " guidance",
                " to",
                " raise",
                " awareness"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m51wf4ra5re9sv9",
            "tokens": [
                "-",
                "Palestinian",
                " conflict",
                " which",
                " we",
                " want",
                " to",
                " see",
                ".",
                "\u010a",
                "\u010a",
                "The",
                " British",
                " Government",
                " has",
                " placed",
                " online"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m54wf4rjgusj59c",
            "tokens": [
                " which",
                " we",
                " want",
                " to",
                " see",
                ".",
                "\u010a",
                "\u010a",
                "The",
                " British",
                " Government",
                " has",
                " placed",
                " online",
                " guidance",
                " to",
                " raise"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m53wf4rb4aihuj4",
            "tokens": [
                " conflict",
                " which",
                " we",
                " want",
                " to",
                " see",
                ".",
                "\u010a",
                "\u010a",
                "The",
                " British",
                " Government",
                " has",
                " placed",
                " online",
                " guidance",
                " to"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m52wf4r81ssutb5",
            "tokens": [
                "Palestinian",
                " conflict",
                " which",
                " we",
                " want",
                " to",
                " see",
                ".",
                "\u010a",
                "\u010a",
                "The",
                " British",
                " Government",
                " has",
                " placed",
                " online",
                " guidance"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tv8m67wf4rxxhlc221",
            "tokens": [
                " databases",
                ".",
                " The",
                " intr",
                "usions",
                " allowed",
                " them",
                " to",
                " obtain",
                " extra",
                " \"",
                "trans",
                "port",
                " permits",
                "\"",
                " to",
                " remove"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tv8m68wf4rbgxwwf0h",
            "tokens": [
                " noticed",
                ".",
                "\u010a",
                "\u010a",
                "I",
                " know",
                " you",
                "\u00e2\u0122",
                "\u013b",
                "re",
                " a",
                " warrior",
                " and",
                " that",
                " you",
                "\u00e2\u0122",
                "\u013b"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tv8m69wf4r22jowzc1",
            "tokens": [
                "And",
                "ros",
                " Townsend",
                " offered",
                " a",
                " few",
                " fl",
                "ickers",
                " of",
                " encouragement",
                " and",
                " Joe",
                " Hart",
                ",",
                " barring",
                " one",
                " moment"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tt8m4xwf4rmbh0ftwt",
            "tokens": [
                " solution",
                " of",
                " the",
                " Israeli",
                "-",
                "Palestinian",
                " conflict",
                " which",
                " we",
                " want",
                " to",
                " see",
                ".",
                "\u010a",
                "\u010a",
                "The",
                " British"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        },
        {
            "id": "clsi9b5tv8m6awf4ro6supcqv",
            "tokens": [
                "<|endoftext|>",
                "Read",
                " University",
                " of",
                " Michigan",
                " acqu",
                "ires",
                " archive",
                " of",
                " filmmaker",
                " John",
                " Say",
                "les",
                "\"",
                "Icon",
                "oc",
                "u"
            ],
            "dataIndex": null,
            "index": "23158",
            "layer": "9-res-jb",
            "modelId": "gpt2-small",
            "dataSource": null,
            "maxValue": 0,
            "maxValueTokenIndex": 0,
            "minValue": 0,
            "values": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "dfaValues": [],
            "dfaTargetIndex": null,
            "dfaMaxValue": null,
            "creatorId": "clkht01d40000jv08hvalcvly",
            "createdAt": "2024-02-12T01:29:38.891Z",
            "lossValues": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ],
            "logitContributions": "{\"pos\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], \"neg\": [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]}",
            "binMin": null,
            "binMax": null,
            "binContains": null,
            "qualifyingTokenIndex": null
        }
    ],
    "explanations": [
        {
            "id": "clsya5ws89if1kad1i49yj9z1",
            "description": "words related to synaptic transmission",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "scores": []
        },
        {
            "id": "z9zuya1x66bfhia234nyn2ok7",
            "description": "terms related to synapses and their functions in the brain",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "scores": []
        }
    ]
}