{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "interactive learning"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "83399",
            "description": "discussions about motivation and collaborative learning in educational settings",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6095324521978182,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "83399",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:13:16.516Z",
                "maxActApprox": 7.105,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    83399,
                    45264,
                    37869,
                    26707,
                    49613,
                    65325,
                    83479,
                    40522,
                    1730,
                    71574,
                    26774,
                    15189,
                    8445,
                    76152,
                    4199,
                    30861,
                    4334,
                    24950,
                    67841,
                    85418,
                    45803,
                    95922,
                    44877,
                    81076,
                    83568
                ],
                "topkCosSimValues": [
                    1,
                    0.5039,
                    0.5011,
                    0.4889,
                    0.4861,
                    0.4776,
                    0.4733,
                    0.4715,
                    0.4699,
                    0.4595,
                    0.4582,
                    0.4582,
                    0.4557,
                    0.4449,
                    0.4443,
                    0.441,
                    0.4396,
                    0.4357,
                    0.4338,
                    0.4315,
                    0.427,
                    0.4257,
                    0.4253,
                    0.4252,
                    0.4244
                ],
                "neuron_alignment_indices": [
                    480,
                    192,
                    654
                ],
                "neuron_alignment_values": [
                    0.414,
                    0.107,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.021,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    480,
                    351,
                    266
                ],
                "correlated_neurons_pearson": [
                    0.057,
                    0.054,
                    0.045
                ],
                "correlated_neurons_l1": [
                    0.002,
                    0.045,
                    0.071
                ],
                "correlated_features_indices": [
                    83479,
                    83475,
                    83421
                ],
                "correlated_features_pearson": [
                    0.056,
                    0.007,
                    0.005
                ],
                "correlated_features_l1": [
                    0.059,
                    0.008,
                    0.005
                ],
                "neg_str": [
                    "\u00d9\u012c",
                    "Nev",
                    "north",
                    " Belg",
                    " 1961",
                    "warning",
                    " Coulter",
                    " outlawed",
                    "upt",
                    "ahon"
                ],
                "neg_values": [
                    -0.651,
                    -0.613,
                    -0.611,
                    -0.61,
                    -0.607,
                    -0.599,
                    -0.598,
                    -0.595,
                    -0.593,
                    -0.589
                ],
                "pos_str": [
                    " iter",
                    " collabor",
                    " feedback",
                    " workflow",
                    " deadlines",
                    " improv",
                    " collaborate",
                    " interact",
                    " timelines",
                    " creatively"
                ],
                "pos_values": [
                    0.908,
                    0.883,
                    0.869,
                    0.814,
                    0.785,
                    0.773,
                    0.769,
                    0.759,
                    0.759,
                    0.752
                ],
                "frac_nonzero": 0.006979999999999999,
                "freq_hist_data_bar_heights": [
                    2675,
                    2416,
                    2115,
                    1934,
                    1638,
                    1462,
                    1297,
                    1172,
                    995,
                    800,
                    746,
                    676,
                    542,
                    498,
                    460,
                    405,
                    330,
                    308,
                    214,
                    218,
                    152,
                    137,
                    116,
                    129,
                    74,
                    87,
                    52,
                    58,
                    45,
                    40,
                    30,
                    21,
                    18,
                    24,
                    13,
                    10,
                    8,
                    4,
                    5,
                    4,
                    3,
                    5,
                    5,
                    2,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.071,
                    0.213,
                    0.355,
                    0.497,
                    0.639,
                    0.782,
                    0.924,
                    1.066,
                    1.208,
                    1.35,
                    1.492,
                    1.634,
                    1.776,
                    1.918,
                    2.06,
                    2.203,
                    2.345,
                    2.487,
                    2.629,
                    2.771,
                    2.913,
                    3.055,
                    3.197,
                    3.339,
                    3.481,
                    3.623,
                    3.766,
                    3.908,
                    4.05,
                    4.192,
                    4.334,
                    4.476,
                    4.618,
                    4.76,
                    4.902,
                    5.044,
                    5.187,
                    5.329,
                    5.471,
                    5.613,
                    5.755,
                    5.897,
                    6.039,
                    6.181,
                    6.323,
                    6.465,
                    6.608,
                    6.75,
                    6.892,
                    7.034
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    9,
                    21,
                    27,
                    51,
                    86,
                    140,
                    246,
                    355,
                    577,
                    788,
                    1031,
                    1405,
                    1766,
                    2058,
                    2479,
                    2811,
                    3138,
                    3048,
                    3278,
                    3248,
                    3107,
                    3001,
                    2767,
                    2493,
                    2272,
                    1891,
                    1700,
                    1327,
                    1190,
                    946,
                    702,
                    594,
                    483,
                    340,
                    273,
                    179,
                    137,
                    102,
                    63,
                    45,
                    23,
                    28,
                    16,
                    5,
                    5,
                    2,
                    0,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.636,
                    -0.605,
                    -0.573,
                    -0.542,
                    -0.511,
                    -0.48,
                    -0.449,
                    -0.418,
                    -0.386,
                    -0.355,
                    -0.324,
                    -0.293,
                    -0.262,
                    -0.23,
                    -0.199,
                    -0.168,
                    -0.137,
                    -0.106,
                    -0.074,
                    -0.043,
                    -0.012,
                    0.019,
                    0.05,
                    0.082,
                    0.113,
                    0.144,
                    0.175,
                    0.206,
                    0.238,
                    0.269,
                    0.3,
                    0.331,
                    0.362,
                    0.394,
                    0.425,
                    0.456,
                    0.487,
                    0.518,
                    0.549,
                    0.581,
                    0.612,
                    0.643,
                    0.674,
                    0.705,
                    0.737,
                    0.768,
                    0.799,
                    0.83,
                    0.861,
                    0.893
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " concepts related to project management and effective teamwork",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "discussions about motivation and collaborative learning in educational settings",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygimqez2jaj10exclclhntq",
                        "tokens": [
                            "\u013f",
                            " grants",
                            " whose",
                            " informational",
                            " value",
                            " comes",
                            " from",
                            " (",
                            "a",
                            ")",
                            " following",
                            " through",
                            " on",
                            " initial",
                            " expressions",
                            " of",
                            " interest",
                            ";",
                            " (",
                            "b",
                            ")",
                            " signaling",
                            " our",
                            " further",
                            " interests",
                            ";",
                            " and",
                            " (",
                            "c",
                            ")",
                            " giving",
                            " us",
                            " opportunities",
                            " to",
                            " follow",
                            " up",
                            " over",
                            " time",
                            " and",
                            " learn",
                            " about",
                            " the",
                            " relevant",
                            " people",
                            " and",
                            " organizations",
                            " and",
                            " their",
                            " progress",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " a",
                            " few",
                            " comments",
                            " that",
                            " we",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " seem",
                            " to",
                            " place",
                            " much",
                            " value",
                            " on",
                            " \u00e2\u0122",
                            "\u013e",
                            "value",
                            " of",
                            " information",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " since",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " primarily",
                            " funding",
                            " direct",
                            " work",
                            " of",
                            " various",
                            " kinds",
                            " rather",
                            " than",
                            " research",
                            " projects",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ".",
                            " I",
                            " disagree",
                            " with",
                            " comments",
                            " along",
                            " these",
                            " lines",
                            ".",
                            " Our",
                            " work",
                            " is",
                            " a",
                            " research",
                            " project",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ",",
                            " and",
                            " funding",
                            " projects"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.105,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            3.344,
                            1.85,
                            3.61,
                            2.098,
                            2.933,
                            2.859,
                            2.916,
                            3.892,
                            4.399,
                            7.105,
                            4.183,
                            3.765,
                            2.972,
                            1.324,
                            0,
                            1.929,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.105,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygimqf22jb410exu9dxomnj",
                        "tokens": [
                            "\u013f",
                            " grants",
                            " whose",
                            " informational",
                            " value",
                            " comes",
                            " from",
                            " (",
                            "a",
                            ")",
                            " following",
                            " through",
                            " on",
                            " initial",
                            " expressions",
                            " of",
                            " interest",
                            ";",
                            " (",
                            "b",
                            ")",
                            " signaling",
                            " our",
                            " further",
                            " interests",
                            ";",
                            " and",
                            " (",
                            "c",
                            ")",
                            " giving",
                            " us",
                            " opportunities",
                            " to",
                            " follow",
                            " up",
                            " over",
                            " time",
                            " and",
                            " learn",
                            " about",
                            " the",
                            " relevant",
                            " people",
                            " and",
                            " organizations",
                            " and",
                            " their",
                            " progress",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " a",
                            " few",
                            " comments",
                            " that",
                            " we",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " seem",
                            " to",
                            " place",
                            " much",
                            " value",
                            " on",
                            " \u00e2\u0122",
                            "\u013e",
                            "value",
                            " of",
                            " information",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " since",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " primarily",
                            " funding",
                            " direct",
                            " work",
                            " of",
                            " various",
                            " kinds",
                            " rather",
                            " than",
                            " research",
                            " projects",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ".",
                            " I",
                            " disagree",
                            " with",
                            " comments",
                            " along",
                            " these",
                            " lines",
                            ".",
                            " Our",
                            " work",
                            " is",
                            " a",
                            " research",
                            " project",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ",",
                            " and",
                            " funding",
                            " projects"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.105,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            3.344,
                            1.85,
                            3.61,
                            2.098,
                            2.933,
                            2.859,
                            2.916,
                            3.892,
                            4.399,
                            7.105,
                            4.183,
                            3.765,
                            2.972,
                            1.324,
                            0,
                            1.929,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 5.684,
                        "binMax": 7.105,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygimqez2jak10ex3wiuo4gq",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " the",
                            " end",
                            ",",
                            " doing",
                            " it",
                            " yourself",
                            " is",
                            " great",
                            ",",
                            " but",
                            " it",
                            "'s",
                            " also",
                            " good",
                            " to",
                            " know",
                            " when",
                            " a",
                            " project",
                            " is",
                            " over",
                            " your",
                            " head",
                            " and",
                            " it",
                            "'s",
                            " time",
                            " to",
                            " call",
                            " someone",
                            " else",
                            ".",
                            " In",
                            " addition",
                            ",",
                            " sometimes",
                            " it",
                            " actually",
                            " is",
                            " better",
                            " to",
                            " replace",
                            " your",
                            " gear",
                            " instead",
                            " of",
                            " fix",
                            " it",
                            ",",
                            " so",
                            " make",
                            " sure",
                            " you",
                            " aren",
                            "'t",
                            " on",
                            " a",
                            " fool",
                            "'s",
                            " err",
                            "and",
                            " trying",
                            " to",
                            " fix",
                            " a",
                            " gadget",
                            " that",
                            "'s",
                            " just",
                            " reached",
                            " its",
                            " time",
                            " to",
                            " die",
                            ".",
                            " Got",
                            " your",
                            " own",
                            " favorite",
                            " repair",
                            " project",
                            " that",
                            " you",
                            " did",
                            " on",
                            " your",
                            " own",
                            ",",
                            " or",
                            " a",
                            " skill",
                            " any",
                            " DIY",
                            "er",
                            " should",
                            " know",
                            " how",
                            " to",
                            " do",
                            "?",
                            " Share",
                            " it",
                            " with",
                            " us",
                            " in",
                            " the",
                            " comments",
                            ".",
                            "<|endoftext|>",
                            "So",
                            " i",
                            " opened",
                            " up",
                            " my",
                            " gift",
                            " that",
                            " came",
                            " earlier",
                            " on",
                            " tonight",
                            ".",
                            " The",
                            " post"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 6.744,
                        "maxValueTokenIndex": 20,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.37,
                            1.73,
                            6.744,
                            4.1,
                            0.725,
                            2.35,
                            1.713,
                            0.702,
                            0.523,
                            0.642,
                            2.552,
                            1.152,
                            1.972,
                            2.65,
                            1.368,
                            1.601,
                            0.519,
                            0,
                            0,
                            0,
                            0,
                            0.865,
                            0,
                            0,
                            0,
                            0,
                            0.551,
                            0,
                            0.336,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.089,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.105,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "9729",
            "description": " discussions and interactions that involve multiple parties",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5820902835076889,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "9729",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:15:10.687Z",
                "maxActApprox": 18.044,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    9729,
                    7825,
                    38975,
                    36133,
                    2621,
                    25048,
                    14203,
                    6010,
                    35641,
                    28080,
                    12560,
                    15019,
                    42439,
                    32077,
                    4979,
                    46711,
                    17834,
                    7397,
                    4607,
                    22055,
                    6557,
                    46174,
                    41545,
                    29156,
                    12507
                ],
                "topkCosSimValues": [
                    1,
                    0.4978,
                    0.4769,
                    0.4385,
                    0.4328,
                    0.4299,
                    0.4282,
                    0.4158,
                    0.3869,
                    0.3812,
                    0.3732,
                    0.3688,
                    0.3677,
                    0.3636,
                    0.3634,
                    0.3578,
                    0.3576,
                    0.3556,
                    0.3525,
                    0.3522,
                    0.3508,
                    0.3474,
                    0.3427,
                    0.3354,
                    0.3353
                ],
                "neuron_alignment_indices": [
                    88,
                    584,
                    519
                ],
                "neuron_alignment_values": [
                    0.106,
                    0.096,
                    0.096
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    113,
                    517,
                    704
                ],
                "correlated_neurons_pearson": [
                    0.024,
                    0.023,
                    0.023
                ],
                "correlated_neurons_l1": [
                    0.022,
                    0.022,
                    0.017
                ],
                "correlated_features_indices": [
                    9734,
                    9711,
                    9632
                ],
                "correlated_features_pearson": [
                    0.009,
                    0.008,
                    0.004
                ],
                "correlated_features_l1": [
                    0.01,
                    0.009,
                    0.005
                ],
                "neg_str": [
                    " landfall",
                    " Lucky",
                    "\u00e3\u0125\u0125\u00e3\u0125\u012a",
                    "\u00a9\u00b6\u00e6\u00a5\u00b5",
                    " invincible",
                    " sacrific",
                    " Defender",
                    " penn",
                    " trophies",
                    " miraculous"
                ],
                "neg_values": [
                    -0.703,
                    -0.683,
                    -0.68,
                    -0.676,
                    -0.645,
                    -0.635,
                    -0.63,
                    -0.63,
                    -0.626,
                    -0.626
                ],
                "pos_str": [
                    " discussion",
                    " discussing",
                    " forums",
                    " discussions",
                    " debates",
                    " heated",
                    " debating",
                    " topics",
                    " Discussion",
                    " forum"
                ],
                "pos_values": [
                    1.127,
                    1.098,
                    1.009,
                    1.008,
                    0.991,
                    0.988,
                    0.98,
                    0.98,
                    0.971,
                    0.962
                ],
                "frac_nonzero": 0.00224,
                "freq_hist_data_bar_heights": [
                    1484,
                    1107,
                    866,
                    669,
                    539,
                    412,
                    307,
                    264,
                    235,
                    178,
                    140,
                    117,
                    99,
                    82,
                    67,
                    58,
                    57,
                    34,
                    46,
                    39,
                    23,
                    33,
                    26,
                    14,
                    22,
                    16,
                    22,
                    19,
                    16,
                    10,
                    8,
                    9,
                    5,
                    3,
                    4,
                    0,
                    3,
                    2,
                    2,
                    2,
                    3,
                    0,
                    1,
                    1,
                    0,
                    2,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.181,
                    0.542,
                    0.903,
                    1.264,
                    1.624,
                    1.985,
                    2.346,
                    2.707,
                    3.068,
                    3.429,
                    3.79,
                    4.15,
                    4.511,
                    4.872,
                    5.233,
                    5.594,
                    5.955,
                    6.316,
                    6.676,
                    7.037,
                    7.398,
                    7.759,
                    8.12,
                    8.481,
                    8.842,
                    9.202,
                    9.563,
                    9.924,
                    10.285,
                    10.646,
                    11.007,
                    11.368,
                    11.728,
                    12.089,
                    12.45,
                    12.811,
                    13.172,
                    13.533,
                    13.894,
                    14.254,
                    14.615,
                    14.976,
                    15.337,
                    15.698,
                    16.059,
                    16.42,
                    16.781,
                    17.141,
                    17.502,
                    17.863
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    3,
                    11,
                    18,
                    47,
                    73,
                    131,
                    232,
                    300,
                    547,
                    765,
                    1150,
                    1498,
                    2088,
                    2777,
                    3359,
                    3735,
                    4156,
                    4261,
                    4229,
                    3899,
                    3566,
                    2950,
                    2467,
                    1967,
                    1602,
                    1213,
                    891,
                    659,
                    465,
                    368,
                    228,
                    176,
                    140,
                    79,
                    56,
                    33,
                    24,
                    20,
                    18,
                    13,
                    12,
                    3,
                    7,
                    4,
                    7,
                    4,
                    0,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.685,
                    -0.648,
                    -0.612,
                    -0.575,
                    -0.539,
                    -0.502,
                    -0.465,
                    -0.429,
                    -0.392,
                    -0.356,
                    -0.319,
                    -0.282,
                    -0.246,
                    -0.209,
                    -0.173,
                    -0.136,
                    -0.099,
                    -0.063,
                    -0.026,
                    0.01,
                    0.047,
                    0.084,
                    0.12,
                    0.157,
                    0.193,
                    0.23,
                    0.267,
                    0.303,
                    0.34,
                    0.376,
                    0.413,
                    0.45,
                    0.486,
                    0.523,
                    0.559,
                    0.596,
                    0.633,
                    0.669,
                    0.706,
                    0.742,
                    0.779,
                    0.816,
                    0.852,
                    0.889,
                    0.925,
                    0.962,
                    0.999,
                    1.035,
                    1.072,
                    1.108
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " discussions and interactions that involve multiple parties",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4pzz2kmf1i666m3479h2y",
                        "tokens": [
                            " political",
                            " conversations",
                            " being",
                            " played",
                            " out",
                            " in",
                            " the",
                            " national",
                            " media",
                            " are",
                            " usually",
                            " at",
                            " their",
                            " lowest",
                            " level",
                            ".",
                            "\n",
                            "\n",
                            "A",
                            " Nation",
                            " of",
                            " Drug",
                            " Warriors",
                            "\n",
                            "\n",
                            "Not",
                            " that",
                            " they",
                            " get",
                            " much",
                            " coverage",
                            " at",
                            " the",
                            " best",
                            " of",
                            " times",
                            ",",
                            " but",
                            " you",
                            " can",
                            " add",
                            " mass",
                            " incarceration",
                            " and",
                            " the",
                            " war",
                            " on",
                            " drugs",
                            " (",
                            "the",
                            " interconnected",
                            " subjects",
                            " of",
                            " The",
                            " House",
                            " I",
                            " Live",
                            " In",
                            ")",
                            " to",
                            " the",
                            " US",
                            " drone",
                            " strikes",
                            " program",
                            ",",
                            " climate",
                            " change",
                            " and",
                            " any",
                            " other",
                            " urgent",
                            ",",
                            " hugely",
                            " important",
                            " issue",
                            " that",
                            " was",
                            " either",
                            " left",
                            " out",
                            " of",
                            " the",
                            " presidential",
                            " debates",
                            " and",
                            " campaigns",
                            " or",
                            " had",
                            " its",
                            " worst",
                            " aspects",
                            " actively",
                            " celebrated",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " is",
                            " hardly",
                            " surprising",
                            ":",
                            " J",
                            "are",
                            "cki",
                            " makes",
                            " it",
                            " very",
                            ",",
                            " very",
                            " clear",
                            " that",
                            " support",
                            " for",
                            " the",
                            " drug",
                            " war",
                            " \u2013",
                            " not",
                            " just",
                            " perpet",
                            "uating",
                            " it",
                            ",",
                            " but",
                            " constantly",
                            " rat"
                        ],
                        "dataIndex": null,
                        "index": "9729",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.044,
                        "maxValueTokenIndex": 2,
                        "minValue": 0,
                        "values": [
                            0,
                            3.595,
                            18.044,
                            9.737,
                            10.936,
                            6.519,
                            5.972,
                            0,
                            0,
                            6.666,
                            7.861,
                            7.922,
                            2.421,
                            0,
                            0,
                            0.425,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.792,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:15:18.067Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 14.435,
                        "binMax": 18.044,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4pzz0kmeei666ufsplu7y",
                        "tokens": [
                            " political",
                            " conversations",
                            " being",
                            " played",
                            " out",
                            " in",
                            " the",
                            " national",
                            " media",
                            " are",
                            " usually",
                            " at",
                            " their",
                            " lowest",
                            " level",
                            ".",
                            "\n",
                            "\n",
                            "A",
                            " Nation",
                            " of",
                            " Drug",
                            " Warriors",
                            "\n",
                            "\n",
                            "Not",
                            " that",
                            " they",
                            " get",
                            " much",
                            " coverage",
                            " at",
                            " the",
                            " best",
                            " of",
                            " times",
                            ",",
                            " but",
                            " you",
                            " can",
                            " add",
                            " mass",
                            " incarceration",
                            " and",
                            " the",
                            " war",
                            " on",
                            " drugs",
                            " (",
                            "the",
                            " interconnected",
                            " subjects",
                            " of",
                            " The",
                            " House",
                            " I",
                            " Live",
                            " In",
                            ")",
                            " to",
                            " the",
                            " US",
                            " drone",
                            " strikes",
                            " program",
                            ",",
                            " climate",
                            " change",
                            " and",
                            " any",
                            " other",
                            " urgent",
                            ",",
                            " hugely",
                            " important",
                            " issue",
                            " that",
                            " was",
                            " either",
                            " left",
                            " out",
                            " of",
                            " the",
                            " presidential",
                            " debates",
                            " and",
                            " campaigns",
                            " or",
                            " had",
                            " its",
                            " worst",
                            " aspects",
                            " actively",
                            " celebrated",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " is",
                            " hardly",
                            " surprising",
                            ":",
                            " J",
                            "are",
                            "cki",
                            " makes",
                            " it",
                            " very",
                            ",",
                            " very",
                            " clear",
                            " that",
                            " support",
                            " for",
                            " the",
                            " drug",
                            " war",
                            " \u2013",
                            " not",
                            " just",
                            " perpet",
                            "uating",
                            " it",
                            ",",
                            " but",
                            " constantly",
                            " rat"
                        ],
                        "dataIndex": null,
                        "index": "9729",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.044,
                        "maxValueTokenIndex": 2,
                        "minValue": 0,
                        "values": [
                            0,
                            3.595,
                            18.044,
                            9.737,
                            10.936,
                            6.519,
                            5.972,
                            0,
                            0,
                            6.666,
                            7.861,
                            7.922,
                            2.421,
                            0,
                            0,
                            0.425,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.792,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:15:18.067Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 18.044,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4pzz0kmefi666ocxnzvzw",
                        "tokens": [
                            " Saturday",
                            " Night",
                            " Live",
                            ".",
                            " Either",
                            " way",
                            ",",
                            " it",
                            " was",
                            " ble",
                            "ep",
                            "ed",
                            ".",
                            " Either",
                            " way",
                            ",",
                            " it",
                            " didn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " mesh",
                            " with",
                            " the",
                            " Wilson",
                            " ordinarily",
                            " projects",
                            ".)",
                            "\n",
                            "\n",
                            "The",
                            " discussion",
                            " quickly",
                            " turned",
                            " to",
                            " Wilson",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " contractual",
                            " status",
                            ",",
                            " with",
                            " Kimmel",
                            " asking",
                            " Wilson",
                            " if",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " more",
                            " tired",
                            " of",
                            " talking",
                            " about",
                            " the",
                            " Super",
                            " Bowl",
                            " loss",
                            " or",
                            " his",
                            " contract",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Both",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Wilson",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "K",
                            "imm",
                            "el",
                            " then",
                            " pointed",
                            " out",
                            " how",
                            " under",
                            "paid",
                            " Wilson",
                            " is",
                            ",",
                            " suggesting",
                            " that",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " making",
                            " only",
                            " $",
                            "37",
                            ",",
                            "000",
                            " per",
                            " year",
                            ".",
                            " (",
                            "The",
                            " audience",
                            " didn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " get",
                            " the",
                            " joke",
                            ".)",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "So",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " ready",
                            " for",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "9729",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.598,
                        "maxValueTokenIndex": 32,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.141,
                            16.598,
                            10.911,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:15:18.067Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 18.044,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "9563",
            "description": "conversational interactions and discussions",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5768279685480624,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "9563",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:56:56.192Z",
                "maxActApprox": 49.857,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    9563,
                    3500,
                    18153,
                    7042,
                    8326,
                    23578,
                    2343,
                    4824,
                    11792,
                    18149,
                    10347,
                    9472,
                    13647,
                    19905,
                    21327,
                    22246,
                    3034,
                    12960,
                    23439,
                    9536,
                    17068,
                    2695,
                    2694,
                    21729,
                    9166
                ],
                "topkCosSimValues": [
                    1,
                    0.7182,
                    0.6083,
                    0.5877,
                    0.5508,
                    0.5307,
                    0.5264,
                    0.5235,
                    0.513,
                    0.5004,
                    0.4805,
                    0.4767,
                    0.4717,
                    0.4678,
                    0.4647,
                    0.4642,
                    0.4635,
                    0.4544,
                    0.4322,
                    0.4321,
                    0.4171,
                    0.4079,
                    0.3997,
                    0.3964,
                    0.3908
                ],
                "neuron_alignment_indices": [
                    447,
                    247,
                    756
                ],
                "neuron_alignment_values": [
                    0.113,
                    0.097,
                    0.096
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    247,
                    399,
                    337
                ],
                "correlated_neurons_pearson": [
                    0.021,
                    0.02,
                    0.019
                ],
                "correlated_neurons_l1": [
                    0.02,
                    0.018,
                    0.019
                ],
                "correlated_features_indices": [
                    9472,
                    9517,
                    9557
                ],
                "correlated_features_pearson": [
                    0.032,
                    0.015,
                    0.003
                ],
                "correlated_features_l1": [
                    0.032,
                    0.015,
                    0.004
                ],
                "neg_str": [
                    "rule",
                    "fitting",
                    "ADA",
                    "cheat",
                    "elin",
                    "anmar",
                    "peria",
                    " Flavoring",
                    "rikes",
                    "iverpool"
                ],
                "neg_values": [
                    -0.675,
                    -0.649,
                    -0.64,
                    -0.637,
                    -0.614,
                    -0.607,
                    -0.603,
                    -0.588,
                    -0.585,
                    -0.577
                ],
                "pos_str": [
                    " conversation",
                    "ogue",
                    " overheard",
                    " banter",
                    " conversations",
                    "osphere",
                    "ues",
                    " Conversation",
                    " about",
                    " chatter"
                ],
                "pos_values": [
                    0.944,
                    0.911,
                    0.853,
                    0.834,
                    0.81,
                    0.78,
                    0.763,
                    0.76,
                    0.754,
                    0.754
                ],
                "frac_nonzero": 0.00044,
                "freq_hist_data_bar_heights": [
                    290,
                    224,
                    170,
                    111,
                    78,
                    67,
                    49,
                    39,
                    23,
                    22,
                    16,
                    9,
                    7,
                    5,
                    6,
                    2,
                    4,
                    0,
                    4,
                    5,
                    3,
                    2,
                    7,
                    4,
                    5,
                    6,
                    5,
                    10,
                    6,
                    13,
                    10,
                    8,
                    11,
                    18,
                    14,
                    19,
                    15,
                    13,
                    13,
                    10,
                    9,
                    17,
                    6,
                    11,
                    5,
                    2,
                    2,
                    0,
                    0,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.503,
                    1.5,
                    2.497,
                    3.494,
                    4.491,
                    5.488,
                    6.485,
                    7.482,
                    8.479,
                    9.476,
                    10.473,
                    11.47,
                    12.467,
                    13.465,
                    14.462,
                    15.459,
                    16.456,
                    17.453,
                    18.45,
                    19.447,
                    20.444,
                    21.441,
                    22.438,
                    23.435,
                    24.432,
                    25.429,
                    26.426,
                    27.423,
                    28.42,
                    29.418,
                    30.415,
                    31.412,
                    32.409,
                    33.406,
                    34.403,
                    35.4,
                    36.397,
                    37.394,
                    38.391,
                    39.388,
                    40.385,
                    41.382,
                    42.379,
                    43.376,
                    44.373,
                    45.371,
                    46.368,
                    47.365,
                    48.362,
                    49.359
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    3,
                    4,
                    12,
                    20,
                    32,
                    56,
                    111,
                    163,
                    267,
                    436,
                    653,
                    973,
                    1321,
                    1767,
                    2255,
                    2846,
                    3352,
                    3630,
                    4080,
                    4184,
                    4028,
                    3867,
                    3389,
                    3072,
                    2501,
                    1914,
                    1532,
                    1144,
                    800,
                    626,
                    374,
                    279,
                    190,
                    125,
                    76,
                    54,
                    36,
                    23,
                    12,
                    15,
                    9,
                    4,
                    9,
                    6,
                    1,
                    1,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.659,
                    -0.626,
                    -0.594,
                    -0.562,
                    -0.529,
                    -0.497,
                    -0.464,
                    -0.432,
                    -0.4,
                    -0.367,
                    -0.335,
                    -0.303,
                    -0.27,
                    -0.238,
                    -0.205,
                    -0.173,
                    -0.141,
                    -0.108,
                    -0.076,
                    -0.044,
                    -0.011,
                    0.021,
                    0.054,
                    0.086,
                    0.118,
                    0.151,
                    0.183,
                    0.216,
                    0.248,
                    0.28,
                    0.313,
                    0.345,
                    0.378,
                    0.41,
                    0.442,
                    0.475,
                    0.507,
                    0.539,
                    0.572,
                    0.604,
                    0.637,
                    0.669,
                    0.701,
                    0.734,
                    0.766,
                    0.799,
                    0.831,
                    0.863,
                    0.896,
                    0.928
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "conversational interactions and discussions",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmg0nl9363i666dn4xabxe",
                        "tokens": [
                            " a",
                            " conversation",
                            " with",
                            " him",
                            " specifically",
                            " about",
                            " that",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " explained",
                            " again",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "The",
                            " one",
                            " thing",
                            " I",
                            " give",
                            " him",
                            " an",
                            " enormous",
                            " amount",
                            " of",
                            " credit",
                            " for",
                            " was",
                            ",",
                            " after",
                            " I",
                            " talked",
                            " after",
                            " the",
                            " game",
                            ",",
                            " he",
                            " was",
                            " waiting",
                            " for",
                            " me",
                            " in",
                            " the",
                            " locker",
                            " room",
                            " and",
                            " he",
                            " wanted",
                            " to",
                            " talk",
                            ",",
                            " just",
                            " [",
                            "show",
                            " me",
                            "]",
                            " his",
                            " commitment",
                            " to",
                            " try",
                            " to",
                            " get",
                            " better",
                            ".",
                            " He",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " freshman",
                            ".",
                            " There",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " going",
                            " to",
                            " be",
                            " learning",
                            " experience",
                            ",",
                            " there",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " going",
                            " to",
                            " be",
                            " growing",
                            " experience",
                            ".",
                            " \u00e2\u0122\u00a6",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "I",
                            " think",
                            " offensively",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " playing",
                            " with",
                            " a",
                            " better",
                            " pace",
                            " and",
                            " tempo",
                            " and",
                            " a",
                            " better",
                            " mindset",
                            " \u2013",
                            " trying",
                            " to",
                            " get",
                            " him",
                            " out",
                            " of",
                            " the",
                            " fact",
                            " that"
                        ],
                        "dataIndex": null,
                        "index": "9563",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.857,
                        "maxValueTokenIndex": 1,
                        "minValue": 0,
                        "values": [
                            0,
                            49.857,
                            1.88,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.141,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:57:02.242Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.857,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmg0nl9362i6662xxhqd6y",
                        "tokens": [
                            " a",
                            " conversation",
                            " by",
                            " ending",
                            " it",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " Since",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " actually",
                            " having",
                            " a",
                            " conversation",
                            " about",
                            " the",
                            " chart",
                            " and",
                            " what",
                            " it",
                            " shows",
                            ",",
                            " and",
                            " since",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " had",
                            " countless",
                            " such",
                            " conversations",
                            " over",
                            " the",
                            " years",
                            ",",
                            " perhaps",
                            " we",
                            " can",
                            " agree",
                            " that",
                            " the",
                            " last",
                            " of",
                            " those",
                            " accusations",
                            " is",
                            " more",
                            " of",
                            " a",
                            " rhetorical",
                            " flourish",
                            " than",
                            " a",
                            " serious",
                            " argument",
                            ".",
                            "\n",
                            "\n",
                            "Di",
                            "Car",
                            "lo",
                            " links",
                            " to",
                            " a",
                            " couple",
                            " of",
                            " earlier",
                            " critics",
                            " to",
                            " do",
                            " the",
                            " heavy",
                            " lifting",
                            " in",
                            " support",
                            " of",
                            " his",
                            " antip",
                            "athy",
                            ",",
                            " but",
                            " he",
                            " does",
                            " admon",
                            "ish",
                            " the",
                            " use",
                            " of",
                            " a",
                            " single",
                            " percent",
                            "-",
                            "change",
                            " y",
                            "-",
                            "axis",
                            " as",
                            " \u00e2\u0122",
                            "\u013e",
                            "not",
                            " appropriate",
                            " for",
                            " and",
                            " totally",
                            " obsc",
                            "ur",
                            "[",
                            "ing",
                            "]",
                            " changes",
                            " in",
                            " NA",
                            "EP",
                            " scale",
                            " scores",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " This",
                            " is",
                            " ironic",
                            ".",
                            " When"
                        ],
                        "dataIndex": null,
                        "index": "9563",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.857,
                        "maxValueTokenIndex": 1,
                        "minValue": 0,
                        "values": [
                            0,
                            49.857,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            37.467,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.219,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.159,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:57:02.242Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.857,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmg0nl9364i666hkblncfn",
                        "tokens": [
                            " long",
                            ",",
                            " accurate",
                            " throw",
                            "-",
                            "in",
                            ",",
                            " but",
                            " that",
                            "'s",
                            " been",
                            " demonstrated",
                            " less",
                            " and",
                            " less",
                            " after",
                            " a",
                            " right",
                            " shoulder",
                            " injury",
                            " late",
                            " in",
                            " the",
                            " 2010",
                            " season",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            "'s",
                            " also",
                            " a",
                            " huge",
                            " fan",
                            " favorite",
                            ".",
                            "\n",
                            "\n",
                            "W",
                            "es",
                            " was",
                            " Vancouver",
                            "'s",
                            " most",
                            " popular",
                            " player",
                            " because",
                            " he",
                            " loved",
                            " the",
                            " fans",
                            " as",
                            " much",
                            " as",
                            " they",
                            " loved",
                            " him",
                            ".",
                            " You",
                            "'d",
                            " see",
                            " him",
                            " standing",
                            " outside",
                            " of",
                            " Empire",
                            " Field",
                            " after",
                            " a",
                            " game",
                            " or",
                            " a",
                            " practice",
                            " talking",
                            " to",
                            " nobody",
                            " in",
                            " particular",
                            ":",
                            " just",
                            " a",
                            " fan",
                            " who",
                            " recognized",
                            " him",
                            " and",
                            " wanted",
                            " to",
                            " say",
                            " hi",
                            ".",
                            " You",
                            " could",
                            " count",
                            " on",
                            " him",
                            " for",
                            " an",
                            " aut",
                            "ograph",
                            ",",
                            " of",
                            " course",
                            ",",
                            " but",
                            " also",
                            " for",
                            " a",
                            " conversation",
                            ",",
                            " for",
                            " cand",
                            "our",
                            ",",
                            " and",
                            " for",
                            " the",
                            " sort",
                            " of",
                            " \"",
                            "Southern",
                            " hospitality",
                            "\"",
                            " that",
                            "'s",
                            " become",
                            " a"
                        ],
                        "dataIndex": null,
                        "index": "9563",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.88,
                        "maxValueTokenIndex": 108,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.322,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.88,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:57:02.242Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.857,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "81641",
            "description": "dialogue and conversational interactions",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5755989723086054,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "81641",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:11:21.058Z",
                "maxActApprox": 14.577,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    81641,
                    89135,
                    78698,
                    12023,
                    61119,
                    27729,
                    90313,
                    18174,
                    42456,
                    58019,
                    14043,
                    91275,
                    51335,
                    56802,
                    49702,
                    74258,
                    15931,
                    14800,
                    45804,
                    84706,
                    95003,
                    94636,
                    26941,
                    10283,
                    76840
                ],
                "topkCosSimValues": [
                    1,
                    0.6669,
                    0.6149,
                    0.6081,
                    0.6017,
                    0.5898,
                    0.5889,
                    0.5799,
                    0.5729,
                    0.5725,
                    0.5565,
                    0.553,
                    0.5484,
                    0.5457,
                    0.538,
                    0.5289,
                    0.5283,
                    0.5219,
                    0.5134,
                    0.5114,
                    0.5075,
                    0.5068,
                    0.5056,
                    0.5048,
                    0.5013
                ],
                "neuron_alignment_indices": [
                    640,
                    447,
                    481
                ],
                "neuron_alignment_values": [
                    0.267,
                    0.18,
                    0.174
                ],
                "neuron_alignment_l1": [
                    0.013,
                    0.009,
                    0.008
                ],
                "correlated_neurons_indices": [
                    640,
                    6,
                    107
                ],
                "correlated_neurons_pearson": [
                    0.082,
                    0.068,
                    0.065
                ],
                "correlated_neurons_l1": [
                    0.078,
                    0.072,
                    0.063
                ],
                "correlated_features_indices": [
                    81556,
                    81569,
                    81641
                ],
                "correlated_features_pearson": [
                    0.001,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0,
                    0
                ],
                "neg_str": [
                    " distingu",
                    " legisl",
                    " migr",
                    " perce",
                    " innov",
                    " credential",
                    " constituency",
                    " outsourcing",
                    " agre",
                    " negoti"
                ],
                "neg_values": [
                    -0.921,
                    -0.883,
                    -0.849,
                    -0.847,
                    -0.837,
                    -0.83,
                    -0.824,
                    -0.813,
                    -0.813,
                    -0.811
                ],
                "pos_str": [
                    "RAW",
                    "Chapter",
                    "\u00e2\u0136\u0122\u00e2\u0136\u0122\u00e2\u0136\u0122\u00e2\u0136\u0122",
                    "Trivia",
                    "=-=-=-=-=-=-=-=-",
                    "Episode",
                    "Alright",
                    "Notes",
                    "\u00e2\u0136\u0122\u00e2\u0136\u0122\u00e2\u0136\u0122\u00e2\u0136\u0122\u00e2\u0136\u0122\u00e2\u0136\u0122\u00e2\u0136\u0122\u00e2\u0136\u0122",
                    "Anyway"
                ],
                "pos_values": [
                    1.67,
                    1.464,
                    1.461,
                    1.396,
                    1.342,
                    1.32,
                    1.297,
                    1.265,
                    1.251,
                    1.23
                ],
                "frac_nonzero": 0.00124,
                "freq_hist_data_bar_heights": [
                    510,
                    428,
                    349,
                    308,
                    316,
                    235,
                    212,
                    171,
                    136,
                    145,
                    118,
                    103,
                    116,
                    86,
                    63,
                    59,
                    58,
                    57,
                    62,
                    45,
                    37,
                    29,
                    31,
                    27,
                    28,
                    17,
                    22,
                    22,
                    17,
                    11,
                    12,
                    8,
                    8,
                    9,
                    10,
                    5,
                    7,
                    6,
                    4,
                    4,
                    0,
                    2,
                    2,
                    1,
                    2,
                    1,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.146,
                    0.437,
                    0.729,
                    1.02,
                    1.312,
                    1.604,
                    1.895,
                    2.187,
                    2.478,
                    2.77,
                    3.061,
                    3.353,
                    3.644,
                    3.936,
                    4.227,
                    4.519,
                    4.81,
                    5.102,
                    5.394,
                    5.685,
                    5.977,
                    6.268,
                    6.56,
                    6.851,
                    7.143,
                    7.434,
                    7.726,
                    8.017,
                    8.309,
                    8.601,
                    8.892,
                    9.184,
                    9.475,
                    9.767,
                    10.058,
                    10.35,
                    10.641,
                    10.933,
                    11.224,
                    11.516,
                    11.808,
                    12.099,
                    12.391,
                    12.682,
                    12.974,
                    13.265,
                    13.557,
                    13.848,
                    14.14,
                    14.431
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    5,
                    13,
                    34,
                    102,
                    189,
                    334,
                    574,
                    952,
                    1384,
                    1918,
                    2470,
                    2912,
                    3266,
                    3649,
                    3669,
                    3560,
                    3414,
                    3238,
                    2867,
                    2492,
                    2245,
                    1832,
                    1573,
                    1361,
                    1092,
                    927,
                    789,
                    736,
                    659,
                    565,
                    425,
                    364,
                    227,
                    158,
                    104,
                    58,
                    45,
                    23,
                    13,
                    4,
                    5,
                    2,
                    2,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.895,
                    -0.843,
                    -0.791,
                    -0.74,
                    -0.688,
                    -0.636,
                    -0.584,
                    -0.532,
                    -0.48,
                    -0.429,
                    -0.377,
                    -0.325,
                    -0.273,
                    -0.221,
                    -0.17,
                    -0.118,
                    -0.066,
                    -0.014,
                    0.038,
                    0.09,
                    0.141,
                    0.193,
                    0.245,
                    0.297,
                    0.349,
                    0.401,
                    0.452,
                    0.504,
                    0.556,
                    0.608,
                    0.66,
                    0.712,
                    0.763,
                    0.815,
                    0.867,
                    0.919,
                    0.971,
                    1.022,
                    1.074,
                    1.126,
                    1.178,
                    1.23,
                    1.282,
                    1.333,
                    1.385,
                    1.437,
                    1.489,
                    1.541,
                    1.593,
                    1.644
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "indications of tension and conflict within a narrative",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "dialogue and conversational interactions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygikc7t183310exqvsml3is",
                        "tokens": [
                            "\u013e",
                            "Pro",
                            "l",
                            "ogue",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " The",
                            " tension",
                            " builds",
                            ",",
                            " ending",
                            " with",
                            " the",
                            " sounds",
                            " of",
                            " a",
                            " tele",
                            "porter",
                            ".",
                            " It",
                            " seems",
                            " like",
                            " the",
                            " man",
                            " is",
                            " taken",
                            " back",
                            " to",
                            " 1981",
                            ".",
                            " He",
                            " remembers",
                            " everything",
                            " he",
                            " saw",
                            ",",
                            " but",
                            " seems",
                            " excited",
                            " to",
                            " be",
                            " going",
                            " back",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "You",
                            " should",
                            " be",
                            " so",
                            " happy",
                            " /",
                            " You",
                            " should",
                            " be",
                            " so",
                            " glad",
                            " /",
                            " 21",
                            "st",
                            " century",
                            " man",
                            ".",
                            " //",
                            " Though",
                            " you",
                            " ride",
                            " on",
                            " the",
                            " wheels",
                            " of",
                            " tomorrow",
                            " /",
                            " You",
                            " still",
                            " wander",
                            " the",
                            " fields",
                            " of",
                            " your",
                            " sorrow",
                            ".",
                            " //",
                            " Tomorrow",
                            ",",
                            " tomorrow",
                            ",",
                            " tomorrow",
                            ",",
                            " tomorrow",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " man",
                            " goes",
                            " home",
                            ".",
                            "\n",
                            "\n",
                            "Electric",
                            " Light",
                            " Orchestra",
                            " takes",
                            " us",
                            " through",
                            " every",
                            " bit",
                            " of",
                            " this",
                            " man",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " struggle",
                            ".",
                            " Amid",
                            "st",
                            " a",
                            " time",
                            " when",
                            " the",
                            " world",
                            " was"
                        ],
                        "dataIndex": null,
                        "index": "81641",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.577,
                        "maxValueTokenIndex": 95,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.79,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.137,
                            0,
                            0,
                            0,
                            0,
                            0.274,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.85,
                            11.129,
                            14.577,
                            3.52,
                            0,
                            0,
                            0,
                            0,
                            1.048,
                            7.828,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:11:26.256Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.577,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygikc7u183k10exdasge913",
                        "tokens": [
                            "\u013e",
                            "Pro",
                            "l",
                            "ogue",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " The",
                            " tension",
                            " builds",
                            ",",
                            " ending",
                            " with",
                            " the",
                            " sounds",
                            " of",
                            " a",
                            " tele",
                            "porter",
                            ".",
                            " It",
                            " seems",
                            " like",
                            " the",
                            " man",
                            " is",
                            " taken",
                            " back",
                            " to",
                            " 1981",
                            ".",
                            " He",
                            " remembers",
                            " everything",
                            " he",
                            " saw",
                            ",",
                            " but",
                            " seems",
                            " excited",
                            " to",
                            " be",
                            " going",
                            " back",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "You",
                            " should",
                            " be",
                            " so",
                            " happy",
                            " /",
                            " You",
                            " should",
                            " be",
                            " so",
                            " glad",
                            " /",
                            " 21",
                            "st",
                            " century",
                            " man",
                            ".",
                            " //",
                            " Though",
                            " you",
                            " ride",
                            " on",
                            " the",
                            " wheels",
                            " of",
                            " tomorrow",
                            " /",
                            " You",
                            " still",
                            " wander",
                            " the",
                            " fields",
                            " of",
                            " your",
                            " sorrow",
                            ".",
                            " //",
                            " Tomorrow",
                            ",",
                            " tomorrow",
                            ",",
                            " tomorrow",
                            ",",
                            " tomorrow",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " man",
                            " goes",
                            " home",
                            ".",
                            "\n",
                            "\n",
                            "Electric",
                            " Light",
                            " Orchestra",
                            " takes",
                            " us",
                            " through",
                            " every",
                            " bit",
                            " of",
                            " this",
                            " man",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " struggle",
                            ".",
                            " Amid",
                            "st",
                            " a",
                            " time",
                            " when",
                            " the",
                            " world",
                            " was"
                        ],
                        "dataIndex": null,
                        "index": "81641",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.577,
                        "maxValueTokenIndex": 95,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.79,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.137,
                            0,
                            0,
                            0,
                            0,
                            0.274,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.85,
                            11.129,
                            14.577,
                            3.52,
                            0,
                            0,
                            0,
                            0,
                            1.048,
                            7.828,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:11:26.256Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.577,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygikc7v183o10exlavcjn3v",
                        "tokens": [
                            "\u013e",
                            "Pro",
                            "l",
                            "ogue",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " The",
                            " tension",
                            " builds",
                            ",",
                            " ending",
                            " with",
                            " the",
                            " sounds",
                            " of",
                            " a",
                            " tele",
                            "porter",
                            ".",
                            " It",
                            " seems",
                            " like",
                            " the",
                            " man",
                            " is",
                            " taken",
                            " back",
                            " to",
                            " 1981",
                            ".",
                            " He",
                            " remembers",
                            " everything",
                            " he",
                            " saw",
                            ",",
                            " but",
                            " seems",
                            " excited",
                            " to",
                            " be",
                            " going",
                            " back",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "You",
                            " should",
                            " be",
                            " so",
                            " happy",
                            " /",
                            " You",
                            " should",
                            " be",
                            " so",
                            " glad",
                            " /",
                            " 21",
                            "st",
                            " century",
                            " man",
                            ".",
                            " //",
                            " Though",
                            " you",
                            " ride",
                            " on",
                            " the",
                            " wheels",
                            " of",
                            " tomorrow",
                            " /",
                            " You",
                            " still",
                            " wander",
                            " the",
                            " fields",
                            " of",
                            " your",
                            " sorrow",
                            ".",
                            " //",
                            " Tomorrow",
                            ",",
                            " tomorrow",
                            ",",
                            " tomorrow",
                            ",",
                            " tomorrow",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " man",
                            " goes",
                            " home",
                            ".",
                            "\n",
                            "\n",
                            "Electric",
                            " Light",
                            " Orchestra",
                            " takes",
                            " us",
                            " through",
                            " every",
                            " bit",
                            " of",
                            " this",
                            " man",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " struggle",
                            ".",
                            " Amid",
                            "st",
                            " a",
                            " time",
                            " when",
                            " the",
                            " world",
                            " was"
                        ],
                        "dataIndex": null,
                        "index": "81641",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.577,
                        "maxValueTokenIndex": 95,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.79,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.137,
                            0,
                            0,
                            0,
                            0,
                            0.274,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.85,
                            11.129,
                            14.577,
                            3.52,
                            0,
                            0,
                            0,
                            0,
                            1.048,
                            7.828,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:11:26.256Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 11.662,
                        "binMax": 14.577,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "641",
            "description": "dialogue and conversational interactions",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5755834236393329,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "641",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:29:21.037Z",
                "maxActApprox": 13.303,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    641,
                    70124,
                    18640,
                    611,
                    20835,
                    45238,
                    14553,
                    79025,
                    21808,
                    26119,
                    66426,
                    51723,
                    36361,
                    95700,
                    35212,
                    10357,
                    17278,
                    29011,
                    68873,
                    36307,
                    3241,
                    93017,
                    61629,
                    5158,
                    81578
                ],
                "topkCosSimValues": [
                    1,
                    0.4911,
                    0.4869,
                    0.4693,
                    0.4638,
                    0.4554,
                    0.4412,
                    0.4177,
                    0.3899,
                    0.3893,
                    0.3875,
                    0.3852,
                    0.3848,
                    0.3812,
                    0.3808,
                    0.3792,
                    0.379,
                    0.3758,
                    0.3752,
                    0.3744,
                    0.3686,
                    0.368,
                    0.3678,
                    0.366,
                    0.3648
                ],
                "neuron_alignment_indices": [
                    87,
                    373,
                    163
                ],
                "neuron_alignment_values": [
                    0.172,
                    0.096,
                    0.094
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    391,
                    105,
                    279
                ],
                "correlated_neurons_pearson": [
                    0.034,
                    0.031,
                    0.03
                ],
                "correlated_neurons_l1": [
                    0.024,
                    0.03,
                    0.032
                ],
                "correlated_features_indices": [
                    611,
                    688,
                    704
                ],
                "correlated_features_pearson": [
                    0.134,
                    0.006,
                    0.004
                ],
                "correlated_features_l1": [
                    0.136,
                    0.006,
                    0.004
                ],
                "neg_str": [
                    "uably",
                    "obyl",
                    "umerable",
                    "\u00a5\u00b5",
                    "\u00a9\u00b6\u00e6\u00a5\u00b5",
                    "ocaly",
                    " eclips",
                    "\u0124\u00aa",
                    "NAS",
                    "\u00a3\u0131"
                ],
                "neg_values": [
                    -0.793,
                    -0.758,
                    -0.652,
                    -0.616,
                    -0.609,
                    -0.609,
                    -0.607,
                    -0.601,
                    -0.599,
                    -0.587
                ],
                "pos_str": [
                    "\u2014\"",
                    "-\"",
                    "Alright",
                    " hurry",
                    " bye",
                    " Alright",
                    " alright",
                    " proceed",
                    " please",
                    " uh"
                ],
                "pos_values": [
                    0.904,
                    0.889,
                    0.887,
                    0.822,
                    0.807,
                    0.801,
                    0.777,
                    0.769,
                    0.744,
                    0.742
                ],
                "frac_nonzero": 0.00217,
                "freq_hist_data_bar_heights": [
                    1046,
                    846,
                    736,
                    580,
                    529,
                    420,
                    394,
                    289,
                    256,
                    231,
                    196,
                    175,
                    136,
                    128,
                    98,
                    90,
                    95,
                    63,
                    68,
                    63,
                    47,
                    49,
                    32,
                    34,
                    33,
                    22,
                    28,
                    25,
                    15,
                    9,
                    22,
                    13,
                    11,
                    7,
                    9,
                    6,
                    3,
                    6,
                    6,
                    3,
                    8,
                    2,
                    2,
                    3,
                    0,
                    1,
                    0,
                    0,
                    1,
                    4
                ],
                "freq_hist_data_bar_values": [
                    0.133,
                    0.399,
                    0.665,
                    0.931,
                    1.197,
                    1.463,
                    1.729,
                    1.996,
                    2.262,
                    2.528,
                    2.794,
                    3.06,
                    3.326,
                    3.592,
                    3.858,
                    4.124,
                    4.39,
                    4.656,
                    4.922,
                    5.188,
                    5.454,
                    5.72,
                    5.987,
                    6.253,
                    6.519,
                    6.785,
                    7.051,
                    7.317,
                    7.583,
                    7.849,
                    8.115,
                    8.381,
                    8.647,
                    8.913,
                    9.179,
                    9.445,
                    9.711,
                    9.978,
                    10.244,
                    10.51,
                    10.776,
                    11.042,
                    11.308,
                    11.574,
                    11.84,
                    12.106,
                    12.372,
                    12.638,
                    12.904,
                    13.17
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    0,
                    0,
                    1,
                    6,
                    13,
                    22,
                    31,
                    60,
                    113,
                    187,
                    287,
                    491,
                    729,
                    1027,
                    1432,
                    2047,
                    2493,
                    3193,
                    3558,
                    3939,
                    4352,
                    4288,
                    4105,
                    3833,
                    3311,
                    2678,
                    2174,
                    1698,
                    1169,
                    891,
                    680,
                    460,
                    306,
                    220,
                    172,
                    94,
                    67,
                    42,
                    23,
                    18,
                    15,
                    10,
                    8,
                    4,
                    3,
                    2,
                    0,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.776,
                    -0.742,
                    -0.709,
                    -0.675,
                    -0.641,
                    -0.607,
                    -0.573,
                    -0.539,
                    -0.505,
                    -0.471,
                    -0.437,
                    -0.403,
                    -0.369,
                    -0.335,
                    -0.301,
                    -0.267,
                    -0.233,
                    -0.199,
                    -0.165,
                    -0.131,
                    -0.097,
                    -0.063,
                    -0.029,
                    0.005,
                    0.038,
                    0.072,
                    0.106,
                    0.14,
                    0.174,
                    0.208,
                    0.242,
                    0.276,
                    0.31,
                    0.344,
                    0.378,
                    0.412,
                    0.446,
                    0.48,
                    0.514,
                    0.548,
                    0.582,
                    0.616,
                    0.65,
                    0.684,
                    0.718,
                    0.752,
                    0.785,
                    0.819,
                    0.853,
                    0.887
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "interactions involving requests or inquiries",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "dialogue and conversational interactions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygex4dbbti710excjd5kvq2",
                        "tokens": [
                            " seat",
                            " Labor",
                            " is",
                            " running",
                            " its",
                            " '",
                            "list",
                            "ening",
                            " post",
                            "'.",
                            "\n",
                            "\n",
                            "From",
                            " desks",
                            " covered",
                            " with",
                            " phones",
                            " and",
                            " computers",
                            ",",
                            " thousands",
                            " of",
                            " conversations",
                            " between",
                            " volunteers",
                            " and",
                            " the",
                            " voting",
                            " public",
                            " take",
                            " place",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            " is",
                            " just",
                            " one",
                            " of",
                            " the",
                            " phone",
                            " banks",
                            " the",
                            " major",
                            " parties",
                            " are",
                            " util",
                            "ising",
                            " around",
                            " the",
                            " country",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "Hello",
                            ",",
                            " is",
                            " that",
                            " Jill",
                            "ian",
                            "?\"",
                            " the",
                            " volunteer",
                            " operator",
                            " asked",
                            " the",
                            " person",
                            " at",
                            " the",
                            " other",
                            " end",
                            " of",
                            " the",
                            " phone",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "My",
                            " name",
                            " is",
                            " Jacob",
                            " and",
                            " I",
                            "'m",
                            " a",
                            " friend",
                            " of",
                            " Tony",
                            " Clarke",
                            "'s",
                            ",",
                            " he",
                            "'s",
                            " your",
                            " local",
                            " Labor",
                            " candidate",
                            ".",
                            " Do",
                            " you",
                            " mind",
                            " telling",
                            " me",
                            " what",
                            " issues",
                            " matter",
                            " to",
                            " you",
                            " Jill",
                            "ian",
                            "?\"",
                            "\n",
                            "\n",
                            "Speaking",
                            " to",
                            " voters",
                            " the",
                            " most",
                            " effective",
                            " interaction",
                            ":",
                            " campaign",
                            " guru",
                            "\n",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "641",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.303,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.631,
                            0.705,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.281,
                            9.131,
                            7.653,
                            13.303,
                            3.536,
                            5.065,
                            1.718,
                            0,
                            0,
                            0,
                            0,
                            2.122,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:29:24.159Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.303,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygex4ddbtiu10exf3tpdtfq",
                        "tokens": [
                            " seat",
                            " Labor",
                            " is",
                            " running",
                            " its",
                            " '",
                            "list",
                            "ening",
                            " post",
                            "'.",
                            "\n",
                            "\n",
                            "From",
                            " desks",
                            " covered",
                            " with",
                            " phones",
                            " and",
                            " computers",
                            ",",
                            " thousands",
                            " of",
                            " conversations",
                            " between",
                            " volunteers",
                            " and",
                            " the",
                            " voting",
                            " public",
                            " take",
                            " place",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            " is",
                            " just",
                            " one",
                            " of",
                            " the",
                            " phone",
                            " banks",
                            " the",
                            " major",
                            " parties",
                            " are",
                            " util",
                            "ising",
                            " around",
                            " the",
                            " country",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "Hello",
                            ",",
                            " is",
                            " that",
                            " Jill",
                            "ian",
                            "?\"",
                            " the",
                            " volunteer",
                            " operator",
                            " asked",
                            " the",
                            " person",
                            " at",
                            " the",
                            " other",
                            " end",
                            " of",
                            " the",
                            " phone",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "My",
                            " name",
                            " is",
                            " Jacob",
                            " and",
                            " I",
                            "'m",
                            " a",
                            " friend",
                            " of",
                            " Tony",
                            " Clarke",
                            "'s",
                            ",",
                            " he",
                            "'s",
                            " your",
                            " local",
                            " Labor",
                            " candidate",
                            ".",
                            " Do",
                            " you",
                            " mind",
                            " telling",
                            " me",
                            " what",
                            " issues",
                            " matter",
                            " to",
                            " you",
                            " Jill",
                            "ian",
                            "?\"",
                            "\n",
                            "\n",
                            "Speaking",
                            " to",
                            " voters",
                            " the",
                            " most",
                            " effective",
                            " interaction",
                            ":",
                            " campaign",
                            " guru",
                            "\n",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "641",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.303,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.631,
                            0.705,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.281,
                            9.131,
                            7.653,
                            13.303,
                            3.536,
                            5.065,
                            1.718,
                            0,
                            0,
                            0,
                            0,
                            2.122,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:29:24.159Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 10.643,
                        "binMax": 13.303,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygex4debtiw10ex3izctydx",
                        "tokens": [
                            " seat",
                            " Labor",
                            " is",
                            " running",
                            " its",
                            " '",
                            "list",
                            "ening",
                            " post",
                            "'.",
                            "\n",
                            "\n",
                            "From",
                            " desks",
                            " covered",
                            " with",
                            " phones",
                            " and",
                            " computers",
                            ",",
                            " thousands",
                            " of",
                            " conversations",
                            " between",
                            " volunteers",
                            " and",
                            " the",
                            " voting",
                            " public",
                            " take",
                            " place",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            " is",
                            " just",
                            " one",
                            " of",
                            " the",
                            " phone",
                            " banks",
                            " the",
                            " major",
                            " parties",
                            " are",
                            " util",
                            "ising",
                            " around",
                            " the",
                            " country",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "Hello",
                            ",",
                            " is",
                            " that",
                            " Jill",
                            "ian",
                            "?\"",
                            " the",
                            " volunteer",
                            " operator",
                            " asked",
                            " the",
                            " person",
                            " at",
                            " the",
                            " other",
                            " end",
                            " of",
                            " the",
                            " phone",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "My",
                            " name",
                            " is",
                            " Jacob",
                            " and",
                            " I",
                            "'m",
                            " a",
                            " friend",
                            " of",
                            " Tony",
                            " Clarke",
                            "'s",
                            ",",
                            " he",
                            "'s",
                            " your",
                            " local",
                            " Labor",
                            " candidate",
                            ".",
                            " Do",
                            " you",
                            " mind",
                            " telling",
                            " me",
                            " what",
                            " issues",
                            " matter",
                            " to",
                            " you",
                            " Jill",
                            "ian",
                            "?\"",
                            "\n",
                            "\n",
                            "Speaking",
                            " to",
                            " voters",
                            " the",
                            " most",
                            " effective",
                            " interaction",
                            ":",
                            " campaign",
                            " guru",
                            "\n",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "641",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.303,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.631,
                            0.705,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.281,
                            9.131,
                            7.653,
                            13.303,
                            3.536,
                            5.065,
                            1.718,
                            0,
                            0,
                            0,
                            0,
                            2.122,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:29:24.159Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 7.982,
                        "binMax": 10.643,
                        "binContains": 3e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "8385",
            "description": "phrases that depict learning from others and building upon shared knowledge",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.574857388428295,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "8385",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:55:28.122Z",
                "maxActApprox": 14.867,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    8385,
                    3301,
                    16642,
                    11621,
                    4513,
                    17830,
                    12237,
                    9003,
                    9986,
                    18039,
                    3143,
                    21375,
                    1196,
                    8374,
                    21762,
                    9203,
                    1886,
                    13617,
                    15074,
                    14505,
                    12556,
                    17036,
                    21530,
                    18191,
                    16918
                ],
                "topkCosSimValues": [
                    1,
                    0.3621,
                    0.3287,
                    0.3267,
                    0.3252,
                    0.3199,
                    0.3045,
                    0.2834,
                    0.2798,
                    0.2784,
                    0.2778,
                    0.2777,
                    0.2705,
                    0.2614,
                    0.2599,
                    0.2493,
                    0.2471,
                    0.2436,
                    0.2423,
                    0.2393,
                    0.2384,
                    0.238,
                    0.2356,
                    0.2335,
                    0.2322
                ],
                "neuron_alignment_indices": [
                    760,
                    283,
                    382
                ],
                "neuron_alignment_values": [
                    0.102,
                    0.101,
                    0.095
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    283,
                    382,
                    703
                ],
                "correlated_neurons_pearson": [
                    0.042,
                    0.035,
                    0.034
                ],
                "correlated_neurons_l1": [
                    0.019,
                    0.032,
                    0.029
                ],
                "correlated_features_indices": [
                    8374,
                    8328,
                    8393
                ],
                "correlated_features_pearson": [
                    0.045,
                    0.018,
                    0.008
                ],
                "correlated_features_l1": [
                    0.047,
                    0.02,
                    0.015
                ],
                "neg_str": [
                    "BuyableInstoreAndOnline",
                    "portation",
                    "stead",
                    "pool",
                    "requ",
                    "................................",
                    " subsidy",
                    " redemption",
                    " cancell",
                    "................................................................"
                ],
                "neg_values": [
                    -0.749,
                    -0.679,
                    -0.667,
                    -0.643,
                    -0.611,
                    -0.608,
                    -0.607,
                    -0.603,
                    -0.6,
                    -0.598
                ],
                "pos_str": [
                    "\u00bb\u0134",
                    " glance",
                    " analys",
                    " analyzing",
                    " hindsight",
                    " studying",
                    " FAC",
                    " hier",
                    " subconscious",
                    " decipher"
                ],
                "pos_values": [
                    0.959,
                    0.916,
                    0.873,
                    0.852,
                    0.842,
                    0.809,
                    0.788,
                    0.781,
                    0.78,
                    0.765
                ],
                "frac_nonzero": 0.00485,
                "freq_hist_data_bar_heights": [
                    2952,
                    2361,
                    1854,
                    1507,
                    1241,
                    923,
                    772,
                    626,
                    512,
                    432,
                    368,
                    300,
                    211,
                    183,
                    150,
                    141,
                    127,
                    89,
                    96,
                    58,
                    50,
                    48,
                    36,
                    34,
                    27,
                    21,
                    21,
                    19,
                    13,
                    12,
                    8,
                    9,
                    9,
                    9,
                    4,
                    5,
                    2,
                    4,
                    5,
                    1,
                    1,
                    0,
                    0,
                    1,
                    2,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.149,
                    0.446,
                    0.743,
                    1.041,
                    1.338,
                    1.635,
                    1.933,
                    2.23,
                    2.527,
                    2.825,
                    3.122,
                    3.419,
                    3.717,
                    4.014,
                    4.312,
                    4.609,
                    4.906,
                    5.204,
                    5.501,
                    5.798,
                    6.096,
                    6.393,
                    6.69,
                    6.988,
                    7.285,
                    7.582,
                    7.88,
                    8.177,
                    8.474,
                    8.772,
                    9.069,
                    9.366,
                    9.664,
                    9.961,
                    10.258,
                    10.556,
                    10.853,
                    11.15,
                    11.448,
                    11.745,
                    12.042,
                    12.34,
                    12.637,
                    12.934,
                    13.232,
                    13.529,
                    13.826,
                    14.124,
                    14.421,
                    14.719
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    1,
                    13,
                    18,
                    33,
                    61,
                    83,
                    160,
                    261,
                    390,
                    638,
                    925,
                    1300,
                    1804,
                    2351,
                    2876,
                    3399,
                    3835,
                    4018,
                    4157,
                    4047,
                    3734,
                    3304,
                    2741,
                    2363,
                    1871,
                    1545,
                    1086,
                    935,
                    650,
                    475,
                    337,
                    252,
                    195,
                    125,
                    96,
                    55,
                    39,
                    31,
                    16,
                    13,
                    6,
                    8,
                    2,
                    2,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.732,
                    -0.698,
                    -0.664,
                    -0.63,
                    -0.596,
                    -0.562,
                    -0.527,
                    -0.493,
                    -0.459,
                    -0.425,
                    -0.391,
                    -0.357,
                    -0.322,
                    -0.288,
                    -0.254,
                    -0.22,
                    -0.186,
                    -0.152,
                    -0.117,
                    -0.083,
                    -0.049,
                    -0.015,
                    0.019,
                    0.054,
                    0.088,
                    0.122,
                    0.156,
                    0.19,
                    0.224,
                    0.259,
                    0.293,
                    0.327,
                    0.361,
                    0.395,
                    0.429,
                    0.464,
                    0.498,
                    0.532,
                    0.566,
                    0.6,
                    0.634,
                    0.669,
                    0.703,
                    0.737,
                    0.771,
                    0.805,
                    0.839,
                    0.874,
                    0.908,
                    0.942
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases that depict learning from others and building upon shared knowledge",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdme3px7ys5i6667niic835",
                        "tokens": [
                            ".",
                            " As",
                            " individuals",
                            ",",
                            " we",
                            " cannot",
                            " figure",
                            " out",
                            " very",
                            " much",
                            " by",
                            " ourselves",
                            ",",
                            " but",
                            " we",
                            " learn",
                            " a",
                            " remarkable",
                            " amount",
                            " from",
                            " others",
                            ".",
                            " In",
                            " short",
                            ",",
                            " some",
                            " social",
                            " scientists",
                            " in",
                            " recent",
                            " years",
                            " have",
                            " been",
                            " building",
                            " (",
                            "or",
                            " rebuilding",
                            ")",
                            " a",
                            " powerful",
                            " case",
                            " for",
                            " cultural",
                            " intelligence",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " implication",
                            " of",
                            " their",
                            " findings",
                            " and",
                            " arguments",
                            " is",
                            " that",
                            " two",
                            " sets",
                            " of",
                            " institutions",
                            " in",
                            " particular",
                            " \u2014",
                            " markets",
                            " and",
                            " traditional",
                            " social",
                            " and",
                            " familial",
                            " practices",
                            " \u2014",
                            " are",
                            " the",
                            " most",
                            " important",
                            " products",
                            " of",
                            " the",
                            " process",
                            " of",
                            " social",
                            " evolution",
                            " building",
                            " on",
                            " cultural",
                            " intelligence",
                            " because",
                            " they",
                            " are",
                            " the",
                            " foremost",
                            " means",
                            " by",
                            " which",
                            " that",
                            " process",
                            " operates",
                            " in",
                            " free",
                            " societies",
                            ".",
                            " It",
                            " should",
                            " hardly",
                            " surprise",
                            " us",
                            ",",
                            " therefore",
                            ",",
                            " that",
                            " these",
                            " two",
                            " sets",
                            " of",
                            " institutions",
                            " are",
                            " also",
                            " the",
                            " foremost",
                            " targets",
                            " and",
                            " objects",
                            " of",
                            " scorn",
                            " of",
                            " today",
                            "'s"
                        ],
                        "dataIndex": null,
                        "index": "8385",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.867,
                        "maxValueTokenIndex": 10,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.294,
                            0,
                            14.867,
                            6.038,
                            1.103,
                            3.152,
                            0,
                            0,
                            0,
                            0,
                            3.68,
                            7.722,
                            0.22,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.529,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:55:32.909Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 14.867,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdme3pz7ysri666uzzv756q",
                        "tokens": [
                            ".",
                            " As",
                            " individuals",
                            ",",
                            " we",
                            " cannot",
                            " figure",
                            " out",
                            " very",
                            " much",
                            " by",
                            " ourselves",
                            ",",
                            " but",
                            " we",
                            " learn",
                            " a",
                            " remarkable",
                            " amount",
                            " from",
                            " others",
                            ".",
                            " In",
                            " short",
                            ",",
                            " some",
                            " social",
                            " scientists",
                            " in",
                            " recent",
                            " years",
                            " have",
                            " been",
                            " building",
                            " (",
                            "or",
                            " rebuilding",
                            ")",
                            " a",
                            " powerful",
                            " case",
                            " for",
                            " cultural",
                            " intelligence",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " implication",
                            " of",
                            " their",
                            " findings",
                            " and",
                            " arguments",
                            " is",
                            " that",
                            " two",
                            " sets",
                            " of",
                            " institutions",
                            " in",
                            " particular",
                            " \u2014",
                            " markets",
                            " and",
                            " traditional",
                            " social",
                            " and",
                            " familial",
                            " practices",
                            " \u2014",
                            " are",
                            " the",
                            " most",
                            " important",
                            " products",
                            " of",
                            " the",
                            " process",
                            " of",
                            " social",
                            " evolution",
                            " building",
                            " on",
                            " cultural",
                            " intelligence",
                            " because",
                            " they",
                            " are",
                            " the",
                            " foremost",
                            " means",
                            " by",
                            " which",
                            " that",
                            " process",
                            " operates",
                            " in",
                            " free",
                            " societies",
                            ".",
                            " It",
                            " should",
                            " hardly",
                            " surprise",
                            " us",
                            ",",
                            " therefore",
                            ",",
                            " that",
                            " these",
                            " two",
                            " sets",
                            " of",
                            " institutions",
                            " are",
                            " also",
                            " the",
                            " foremost",
                            " targets",
                            " and",
                            " objects",
                            " of",
                            " scorn",
                            " of",
                            " today",
                            "'s"
                        ],
                        "dataIndex": null,
                        "index": "8385",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.867,
                        "maxValueTokenIndex": 10,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.294,
                            0,
                            14.867,
                            6.038,
                            1.103,
                            3.152,
                            0,
                            0,
                            0,
                            0,
                            3.68,
                            7.722,
                            0.22,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.529,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:55:32.909Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 11.894,
                        "binMax": 14.867,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdme3px7ys6i666o2p6pnx3",
                        "tokens": [
                            " before",
                            " coming",
                            " to",
                            " understand",
                            " its",
                            " limitations",
                            ".",
                            "\n",
                            "\n",
                            "Dec",
                            "on",
                            "struct",
                            "ive",
                            " post",
                            "modern",
                            "ism",
                            ",",
                            " their",
                            " critique",
                            " of",
                            " stage",
                            " 4",
                            " modern",
                            "ism",
                            "/",
                            "system",
                            "atic",
                            "ity",
                            "/",
                            "rational",
                            "ity",
                            ",",
                            " is",
                            " the",
                            " basis",
                            " of",
                            " the",
                            " contemporary",
                            " university",
                            " humanities",
                            " curriculum",
                            ".",
                            " This",
                            " is",
                            " a",
                            " disaster",
                            ".",
                            " The",
                            " critique",
                            " is",
                            " largely",
                            " correct",
                            ";",
                            " but",
                            ",",
                            " as",
                            " Ke",
                            "gan",
                            " observed",
                            ",",
                            " to",
                            " teach",
                            " it",
                            " to",
                            " young",
                            " adults",
                            " is",
                            " harmful",
                            ".",
                            " Few",
                            " university",
                            " students",
                            " have",
                            " consolidated",
                            " rationality",
                            ".",
                            " Essentially",
                            " none",
                            " are",
                            " ready",
                            " to",
                            " move",
                            " beyond",
                            " it",
                            ".",
                            " Point",
                            "ing",
                            " out",
                            " its",
                            " defects",
                            " makes",
                            " their",
                            " developmental",
                            " task",
                            " more",
                            " difficult",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " cannot",
                            " understand",
                            " what",
                            " is",
                            " wrong",
                            " with",
                            " rational",
                            "ism",
                            " until",
                            " you",
                            " are",
                            " capable",
                            " of",
                            " being",
                            " rational",
                            ".",
                            " You",
                            " cannot",
                            " go",
                            " beyond",
                            " rationality",
                            " until",
                            " after",
                            " you",
                            " can",
                            " use",
                            " it"
                        ],
                        "dataIndex": null,
                        "index": "8385",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.32,
                        "maxValueTokenIndex": 108,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.32,
                            10.238,
                            6.529,
                            3.316,
                            2.932,
                            1.183,
                            0,
                            0,
                            1.373,
                            0,
                            0,
                            0,
                            0,
                            1.877,
                            1.947,
                            0.137,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:55:32.909Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 14.867,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "20048",
            "description": "dialogue and interactions between individuals",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5745712176220894,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "20048",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:10:26.896Z",
                "maxActApprox": 38.985,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    20048,
                    1932,
                    14602,
                    2160,
                    8952,
                    4250,
                    20003,
                    2225,
                    11031,
                    11017,
                    17879,
                    22378,
                    23018,
                    19453,
                    18285,
                    7319,
                    842,
                    6323,
                    1653,
                    21511,
                    20255,
                    12137,
                    11432,
                    11730,
                    16807
                ],
                "topkCosSimValues": [
                    1,
                    0.5499,
                    0.4886,
                    0.4616,
                    0.4269,
                    0.4107,
                    0.3892,
                    0.387,
                    0.376,
                    0.3744,
                    0.3539,
                    0.35,
                    0.3456,
                    0.3437,
                    0.339,
                    0.33,
                    0.325,
                    0.3224,
                    0.3142,
                    0.3109,
                    0.3098,
                    0.3096,
                    0.3023,
                    0.3019,
                    0.3017
                ],
                "neuron_alignment_indices": [
                    378,
                    721,
                    389
                ],
                "neuron_alignment_values": [
                    0.127,
                    0.113,
                    0.108
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    389,
                    721,
                    243
                ],
                "correlated_neurons_pearson": [
                    0.029,
                    0.023,
                    0.021
                ],
                "correlated_neurons_l1": [
                    0.028,
                    0.021,
                    0.023
                ],
                "correlated_features_indices": [
                    20003,
                    20069,
                    20086
                ],
                "correlated_features_pearson": [
                    0.154,
                    0.005,
                    0.001
                ],
                "correlated_features_l1": [
                    0.154,
                    0.005,
                    0.001
                ],
                "neg_str": [
                    "ounded",
                    "enta",
                    "arted",
                    "Reviewed",
                    "robe",
                    "reated",
                    "aign",
                    "astery",
                    "jit",
                    " embroiled"
                ],
                "neg_values": [
                    -0.773,
                    -0.7,
                    -0.699,
                    -0.688,
                    -0.68,
                    -0.677,
                    -0.669,
                    -0.646,
                    -0.628,
                    -0.625
                ],
                "pos_str": [
                    " sir",
                    " yeah",
                    " Absolutely",
                    " yes",
                    " Exactly",
                    "Absolutely",
                    " YES",
                    " absolutely",
                    "yeah",
                    "YES"
                ],
                "pos_values": [
                    1.146,
                    1.059,
                    1.054,
                    1.015,
                    0.944,
                    0.865,
                    0.841,
                    0.834,
                    0.824,
                    0.807
                ],
                "frac_nonzero": 0.00079,
                "freq_hist_data_bar_heights": [
                    628,
                    406,
                    271,
                    192,
                    141,
                    101,
                    102,
                    98,
                    73,
                    41,
                    44,
                    33,
                    33,
                    35,
                    17,
                    23,
                    16,
                    24,
                    20,
                    6,
                    10,
                    16,
                    18,
                    9,
                    14,
                    7,
                    7,
                    10,
                    11,
                    9,
                    8,
                    5,
                    11,
                    3,
                    5,
                    3,
                    5,
                    4,
                    6,
                    4,
                    7,
                    1,
                    2,
                    1,
                    2,
                    1,
                    0,
                    3,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.39,
                    1.17,
                    1.949,
                    2.729,
                    3.509,
                    4.288,
                    5.068,
                    5.848,
                    6.628,
                    7.407,
                    8.187,
                    8.967,
                    9.746,
                    10.526,
                    11.306,
                    12.085,
                    12.865,
                    13.645,
                    14.424,
                    15.204,
                    15.984,
                    16.763,
                    17.543,
                    18.323,
                    19.103,
                    19.882,
                    20.662,
                    21.442,
                    22.221,
                    23.001,
                    23.781,
                    24.56,
                    25.34,
                    26.12,
                    26.899,
                    27.679,
                    28.459,
                    29.239,
                    30.018,
                    30.798,
                    31.578,
                    32.357,
                    33.137,
                    33.917,
                    34.696,
                    35.476,
                    36.256,
                    37.035,
                    37.815,
                    38.595
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    4,
                    3,
                    13,
                    19,
                    34,
                    63,
                    126,
                    209,
                    344,
                    522,
                    841,
                    1284,
                    1757,
                    2431,
                    3211,
                    3886,
                    4462,
                    4936,
                    5002,
                    4864,
                    4234,
                    3489,
                    2816,
                    2027,
                    1408,
                    987,
                    514,
                    324,
                    182,
                    118,
                    58,
                    26,
                    16,
                    9,
                    8,
                    6,
                    4,
                    3,
                    3,
                    4,
                    2,
                    0,
                    1,
                    0,
                    1,
                    2,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.754,
                    -0.716,
                    -0.677,
                    -0.639,
                    -0.601,
                    -0.562,
                    -0.524,
                    -0.485,
                    -0.447,
                    -0.409,
                    -0.37,
                    -0.332,
                    -0.293,
                    -0.255,
                    -0.217,
                    -0.178,
                    -0.14,
                    -0.101,
                    -0.063,
                    -0.025,
                    0.014,
                    0.052,
                    0.091,
                    0.129,
                    0.167,
                    0.206,
                    0.244,
                    0.283,
                    0.321,
                    0.359,
                    0.398,
                    0.436,
                    0.474,
                    0.513,
                    0.551,
                    0.59,
                    0.628,
                    0.666,
                    0.705,
                    0.743,
                    0.782,
                    0.82,
                    0.858,
                    0.897,
                    0.935,
                    0.974,
                    1.012,
                    1.05,
                    1.089,
                    1.127
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "dialogue and interactions between individuals",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmxdqlj1y6i6661jmoo3mz",
                        "tokens": [
                            " as",
                            " well",
                            "?\"",
                            "\n",
                            "\n",
                            "\"",
                            "Yes",
                            ",",
                            " Ain",
                            "z",
                            "-",
                            "sama",
                            "!\"",
                            " Repl",
                            "ied",
                            " Al",
                            "bed",
                            "o",
                            ",",
                            " turning",
                            " to",
                            " face",
                            " Ain",
                            "z",
                            ".",
                            " \"",
                            "With",
                            " the",
                            " help",
                            " of",
                            " Eight",
                            " F",
                            "ingers",
                            ",",
                            " we",
                            " were",
                            " able",
                            " to",
                            " prop",
                            " up",
                            " a",
                            " worthless",
                            " human",
                            ",",
                            " to",
                            " create",
                            " a",
                            " third",
                            " faction",
                            " in",
                            " the",
                            " kingdom",
                            ".",
                            " Princess",
                            " Ren",
                            "ner",
                            " is",
                            " also",
                            " proving",
                            " to",
                            " be",
                            " a",
                            " useful",
                            " puppet",
                            ".",
                            " Although",
                            ",",
                            " if",
                            " she",
                            " can",
                            " open",
                            " the",
                            " box",
                            " she",
                            " was",
                            " given",
                            ",",
                            " she",
                            " might",
                            " even",
                            " be",
                            " worth",
                            " welcoming",
                            " as",
                            " a",
                            " servant",
                            " of",
                            " the",
                            " great",
                            " tomb",
                            " of",
                            " N",
                            "azz",
                            "ar",
                            "ick",
                            ".\"",
                            "\n",
                            "\n",
                            "I",
                            " still",
                            " don",
                            "'t",
                            " know",
                            " what",
                            " Al",
                            "bed",
                            "o",
                            "'s",
                            " and",
                            " Dem",
                            "i",
                            "ur",
                            "ge",
                            "'s",
                            " plan",
                            " for",
                            " this",
                            " Princess",
                            " is",
                            ".",
                            " But",
                            " is",
                            " letting",
                            " someone",
                            " so",
                            " smart",
                            " near"
                        ],
                        "dataIndex": null,
                        "index": "20048",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.985,
                        "maxValueTokenIndex": 7,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.72,
                            38.985,
                            0,
                            0,
                            0,
                            0,
                            1.885,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:10:32.348Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 38.985,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmxdqlj1y7i666ehqdyzgx",
                        "tokens": [
                            "del",
                            "ayed",
                            ",",
                            " or",
                            " what",
                            " have",
                            " you",
                            ",",
                            " simply",
                            " because",
                            " things",
                            " were",
                            " quiet",
                            " on",
                            " the",
                            " news",
                            " front",
                            ",",
                            " Lo",
                            "eb",
                            " confirms",
                            " that",
                            " this",
                            " is",
                            " not",
                            " the",
                            " case",
                            ":",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "There",
                            " was",
                            " a",
                            " lot",
                            " of",
                            " speculation",
                            " about",
                            " what",
                            " was",
                            " going",
                            " on",
                            " with",
                            " \u00e2\u0122",
                            "\u013a",
                            "Iron",
                            " Fist",
                            ",",
                            "\u00e2\u0122",
                            "\u013b",
                            " because",
                            " [",
                            "f",
                            "ans",
                            "]",
                            " hadn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " heard",
                            " anything",
                            " about",
                            " it",
                            ",",
                            " but",
                            " there",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " never",
                            " been",
                            " any",
                            " change",
                            " at",
                            " all",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "In",
                            " fact",
                            ",",
                            " when",
                            " asked",
                            " if",
                            " fans",
                            " can",
                            " expect",
                            " to",
                            " see",
                            " some",
                            " casting",
                            " announcements",
                            " or",
                            " other",
                            " hard",
                            " news",
                            " sometime",
                            " soon",
                            ",",
                            " Lo",
                            "eb",
                            " said",
                            ":",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "The",
                            " short",
                            " answer",
                            " is",
                            ",",
                            " \u00e2\u0122",
                            "\u013a",
                            "Yes",
                            ",",
                            " there",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " be",
                            " news",
                            ".",
                            "\u00e2\u0122"
                        ],
                        "dataIndex": null,
                        "index": "20048",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 37.349,
                        "maxValueTokenIndex": 118,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.14,
                            0,
                            0,
                            7.978,
                            37.349,
                            10.954,
                            0,
                            0,
                            0,
                            0.794,
                            0,
                            3.965,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:10:32.348Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 38.985,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmxdqlj1y8i666ll4wuz1k",
                        "tokens": [
                            " If",
                            " he",
                            " tells",
                            " you",
                            " you",
                            "'re",
                            " not",
                            " okay",
                            ",",
                            " you",
                            "'re",
                            " not",
                            " okay",
                            " \u2013",
                            " not",
                            " okay",
                            " for",
                            " America",
                            ".",
                            " You",
                            "'re",
                            " destroying",
                            " our",
                            " country",
                            ".'",
                            "\n",
                            "\n",
                            "The",
                            " unnamed",
                            " woman",
                            " described",
                            " the",
                            " One",
                            " Nation",
                            " leader",
                            " as",
                            " '",
                            "since",
                            "re",
                            "'",
                            " and",
                            " '",
                            "straight",
                            "forward",
                            "'",
                            "\n",
                            "\n",
                            "While",
                            " some",
                            " called",
                            " Ms",
                            " Hanson",
                            " (",
                            "pictured",
                            ")",
                            " '",
                            "too",
                            " anti",
                            "-",
                            "everything",
                            "',",
                            " the",
                            " woman",
                            " continued",
                            " to",
                            " compliment",
                            " her",
                            "\n",
                            "\n",
                            "Asked",
                            " if",
                            " she",
                            " would",
                            " like",
                            " to",
                            " hear",
                            " more",
                            " Trump",
                            "-",
                            "inspired",
                            " rhetoric",
                            " in",
                            " Australia",
                            ",",
                            " she",
                            " replied",
                            ":",
                            " '",
                            "Yes",
                            ",",
                            " yes",
                            ".'",
                            "\n",
                            "\n",
                            "She",
                            " added",
                            ":",
                            " '",
                            "See",
                            " like",
                            " that",
                            " speech",
                            " he",
                            " had",
                            " yesterday",
                            ",",
                            " that",
                            " was",
                            " great",
                            ".",
                            " Yes",
                            ",",
                            " it",
                            " sounded",
                            " like",
                            " Hitler",
                            ",",
                            " but",
                            " you",
                            " know",
                            ",",
                            " Hitler",
                            " loved",
                            " Germany",
                            ".'",
                            "\n",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "20048",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 37.11,
                        "maxValueTokenIndex": 89,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.875,
                            4.419,
                            37.11,
                            17.254,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.466,
                            3.659,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:10:32.348Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 38.985,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "32422",
            "description": "two-way interactions or relationships in discussions",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5709060430526733,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "32422",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:11:50.846Z",
                "maxActApprox": 53.083,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    32422,
                    79143,
                    6896,
                    55451,
                    5063,
                    54577,
                    85327,
                    66654,
                    57474,
                    35027,
                    36979,
                    84371,
                    12544,
                    30076,
                    37824,
                    23018,
                    6613,
                    27127,
                    83784,
                    61424,
                    74995,
                    69110,
                    66031,
                    97136,
                    1450
                ],
                "topkCosSimValues": [
                    1,
                    0.8035,
                    0.7618,
                    0.7246,
                    0.658,
                    0.6564,
                    0.6492,
                    0.6473,
                    0.6128,
                    0.5934,
                    0.5903,
                    0.5804,
                    0.5759,
                    0.5758,
                    0.5566,
                    0.5389,
                    0.5292,
                    0.529,
                    0.5267,
                    0.5229,
                    0.5141,
                    0.5129,
                    0.4873,
                    0.4822,
                    0.4793
                ],
                "neuron_alignment_indices": [
                    314,
                    102,
                    680
                ],
                "neuron_alignment_values": [
                    0.115,
                    0.113,
                    0.107
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    425,
                    680,
                    152
                ],
                "correlated_neurons_pearson": [
                    0.032,
                    0.032,
                    0.029
                ],
                "correlated_neurons_l1": [
                    0.032,
                    0.029,
                    0.031
                ],
                "correlated_features_indices": [
                    32508,
                    32422,
                    32372
                ],
                "correlated_features_pearson": [
                    0.002,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0,
                    0
                ],
                "neg_str": [
                    " BDS",
                    " Lovecraft",
                    " Clyde",
                    " Gillespie",
                    " Borders",
                    " Lanka",
                    "\u00e3\u0124\u00bc\u00e3\u0124\u00a6\u00e3\u0124\u00b9",
                    " FANTASY",
                    " Richards",
                    "NEY"
                ],
                "neg_values": [
                    -0.663,
                    -0.638,
                    -0.623,
                    -0.62,
                    -0.62,
                    -0.613,
                    -0.607,
                    -0.601,
                    -0.597,
                    -0.594
                ],
                "pos_str": [
                    "thirds",
                    "sided",
                    "hander",
                    "handed",
                    "legged",
                    "dimensional",
                    "year",
                    "fif",
                    "footed",
                    " thirds"
                ],
                "pos_values": [
                    1.646,
                    1.206,
                    1.203,
                    1.2,
                    1.198,
                    1.172,
                    1.168,
                    1.162,
                    1.161,
                    1.158
                ],
                "frac_nonzero": 0.00023,
                "freq_hist_data_bar_heights": [
                    81,
                    70,
                    50,
                    46,
                    48,
                    48,
                    21,
                    37,
                    14,
                    15,
                    11,
                    13,
                    13,
                    8,
                    10,
                    3,
                    2,
                    0,
                    1,
                    0,
                    1,
                    2,
                    1,
                    1,
                    1,
                    2,
                    0,
                    2,
                    6,
                    3,
                    3,
                    5,
                    7,
                    5,
                    11,
                    7,
                    14,
                    13,
                    12,
                    8,
                    20,
                    28,
                    19,
                    13,
                    13,
                    7,
                    9,
                    4,
                    5,
                    5
                ],
                "freq_hist_data_bar_values": [
                    0.531,
                    1.593,
                    2.654,
                    3.716,
                    4.778,
                    5.839,
                    6.901,
                    7.963,
                    9.024,
                    10.086,
                    11.148,
                    12.209,
                    13.271,
                    14.332,
                    15.394,
                    16.456,
                    17.517,
                    18.579,
                    19.641,
                    20.702,
                    21.764,
                    22.826,
                    23.887,
                    24.949,
                    26.011,
                    27.072,
                    28.134,
                    29.196,
                    30.257,
                    31.319,
                    32.381,
                    33.442,
                    34.504,
                    35.566,
                    36.627,
                    37.689,
                    38.751,
                    39.812,
                    40.874,
                    41.935,
                    42.997,
                    44.059,
                    45.12,
                    46.182,
                    47.244,
                    48.305,
                    49.367,
                    50.429,
                    51.49,
                    52.552
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    13,
                    17,
                    60,
                    139,
                    278,
                    515,
                    1038,
                    1727,
                    2752,
                    3905,
                    4762,
                    5384,
                    5485,
                    4953,
                    4276,
                    3403,
                    2709,
                    2160,
                    1659,
                    1316,
                    1035,
                    780,
                    522,
                    414,
                    297,
                    203,
                    138,
                    82,
                    44,
                    49,
                    53,
                    24,
                    19,
                    10,
                    5,
                    4,
                    5,
                    5,
                    7,
                    4,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.639,
                    -0.593,
                    -0.547,
                    -0.501,
                    -0.455,
                    -0.409,
                    -0.362,
                    -0.316,
                    -0.27,
                    -0.224,
                    -0.178,
                    -0.132,
                    -0.086,
                    -0.039,
                    0.007,
                    0.053,
                    0.099,
                    0.145,
                    0.191,
                    0.238,
                    0.284,
                    0.33,
                    0.376,
                    0.422,
                    0.468,
                    0.515,
                    0.561,
                    0.607,
                    0.653,
                    0.699,
                    0.745,
                    0.792,
                    0.838,
                    0.884,
                    0.93,
                    0.976,
                    1.022,
                    1.069,
                    1.115,
                    1.161,
                    1.207,
                    1.253,
                    1.299,
                    1.346,
                    1.392,
                    1.438,
                    1.484,
                    1.53,
                    1.576,
                    1.623
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "two-way interactions or relationships in discussions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to two-way interactions or relational dynamics",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggfukozv2r10expv0kkona",
                        "tokens": [
                            "'s",
                            " the",
                            " two",
                            "-",
                            "way",
                            " interaction",
                            " that",
                            " matters",
                            " most",
                            ".",
                            " Technology",
                            " that",
                            " facilitates",
                            " that",
                            " back",
                            "-",
                            "and",
                            "-",
                            "forth",
                            ",",
                            " then",
                            ",",
                            " is",
                            " more",
                            " likely",
                            " to",
                            " facilitate",
                            " learning",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " here",
                            "'s",
                            " the",
                            " thing",
                            ":",
                            " Hand",
                            "ing",
                            " a",
                            " 2",
                            "-",
                            "year",
                            "-",
                            "old",
                            " an",
                            " iPad",
                            " and",
                            " walking",
                            " away",
                            " isn",
                            "'t",
                            " going",
                            " to",
                            " cut",
                            " it",
                            ",",
                            " no",
                            " matter",
                            " what",
                            " the",
                            " software",
                            " facilitates",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            " \"",
                            " This",
                            " girl",
                            " watches",
                            " cartoons",
                            " online",
                            " with",
                            " the",
                            " iPad",
                            " tablet",
                            " while",
                            " sitting",
                            " on",
                            " the",
                            " sofa",
                            " at",
                            " home",
                            ".",
                            " Art",
                            "ur",
                            " De",
                            "bat",
                            "/",
                            "Getty",
                            "\n",
                            "\n",
                            "\"",
                            "All",
                            " of",
                            " our",
                            " experts",
                            " indicated",
                            " the",
                            " importance",
                            " of",
                            " co",
                            "-",
                            "eng",
                            "agement",
                            ",\"",
                            " Brown",
                            " says",
                            ".",
                            " Parent",
                            "al",
                            " involvement",
                            " determines",
                            " the",
                            " ultimate",
                            " nature",
                            " of",
                            " screen",
                            " time",
                            ".",
                            " For",
                            " young",
                            " children",
                            " especially",
                            ",",
                            " positive"
                        ],
                        "dataIndex": null,
                        "index": "32422",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 53.083,
                        "maxValueTokenIndex": 3,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            53.083,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.158,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:11:57.562Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 53.083,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggfukozv2s10exxxnfc5hc",
                        "tokens": [
                            " President",
                            " Emmanuel",
                            " Macron",
                            ".",
                            " The",
                            " summit",
                            " marks",
                            " the",
                            " two",
                            "-",
                            "year",
                            " anniversary",
                            " of",
                            " the",
                            " Paris",
                            " Climate",
                            " agreement",
                            ",",
                            " which",
                            " seeks",
                            " to",
                            " limit",
                            " the",
                            " global",
                            " temperature",
                            " rise",
                            " to",
                            " below",
                            " 2",
                            " degrees",
                            " Celsius",
                            " by",
                            " reducing",
                            " greenhouse",
                            " emissions",
                            ".",
                            " President",
                            " Donald",
                            " Trump",
                            " has",
                            " pledged",
                            " to",
                            " pull",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " from",
                            " the",
                            " Paris",
                            " Agreement",
                            ",",
                            " dism",
                            "aying",
                            " climate",
                            " activists",
                            " but",
                            " sp",
                            "urring",
                            " a",
                            " greater",
                            " effort",
                            " from",
                            " the",
                            " private",
                            " sector",
                            " to",
                            " push",
                            " through",
                            " its",
                            " goals",
                            " without",
                            " government",
                            " help",
                            ".",
                            " Ins",
                            "urers",
                            " have",
                            " said",
                            " anything",
                            " higher",
                            " than",
                            " a",
                            " 2",
                            " degree",
                            "-",
                            "tem",
                            "perature",
                            " increase",
                            " would",
                            " make",
                            " the",
                            " world",
                            " un",
                            "ins",
                            "urable",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " case",
                            " you",
                            " missed",
                            " it",
                            ":",
                            " U",
                            ".",
                            "S",
                            ".",
                            " health",
                            " insurers",
                            " are",
                            " in",
                            " a",
                            " state",
                            " of",
                            " denial",
                            " about",
                            " climate",
                            " change",
                            "\n",
                            "\n",
                            "The",
                            " companies",
                            " span",
                            " a"
                        ],
                        "dataIndex": null,
                        "index": "32422",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 52.879,
                        "maxValueTokenIndex": 9,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            52.879,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:11:57.562Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 53.083,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggfukozv2t10ex4u6arojy",
                        "tokens": [
                            " training",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " two",
                            "-",
                            "month",
                            " enlisted",
                            " course",
                            " here",
                            " at",
                            " the",
                            " School",
                            " of",
                            " Infantry",
                            "-",
                            "East",
                            " is",
                            " not",
                            " as",
                            " demanding",
                            " as",
                            " the",
                            " officer",
                            " course",
                            " and",
                            " it",
                            " is",
                            " more",
                            " likely",
                            " at",
                            " least",
                            " some",
                            " women",
                            " will",
                            " complete",
                            " it",
                            ".",
                            " The",
                            " attrition",
                            " rate",
                            " for",
                            " men",
                            " here",
                            " has",
                            " been",
                            " about",
                            " 1",
                            "%.",
                            "\n",
                            "\n",
                            "Even",
                            " if",
                            " they",
                            " do",
                            " pass",
                            " this",
                            " initial",
                            " group",
                            " will",
                            " not",
                            " get",
                            " to",
                            " join",
                            " the",
                            " infantry",
                            ",",
                            " at",
                            " least",
                            " not",
                            " immediately",
                            ",",
                            " since",
                            " it",
                            " remains",
                            " closed",
                            " to",
                            " women",
                            ".",
                            "\n",
                            "\n",
                            "On",
                            " the",
                            " 10",
                            "-",
                            "kil",
                            "ometer",
                            " hike",
                            " two",
                            " men",
                            " and",
                            " two",
                            " women",
                            " dropped",
                            " out",
                            ".",
                            " The",
                            " hikes",
                            " here",
                            " at",
                            " the",
                            " infantry",
                            " school",
                            " get",
                            " longer",
                            ",",
                            " culminating",
                            " with",
                            " a",
                            " 20",
                            "-",
                            "kil",
                            "ometer",
                            " walk",
                            ".",
                            " Officers",
                            " have",
                            " promised",
                            " that",
                            " standards",
                            ",",
                            " hon",
                            "ed",
                            " after",
                            " more",
                            " than"
                        ],
                        "dataIndex": null,
                        "index": "32422",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 52.767,
                        "maxValueTokenIndex": 6,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            52.767,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:11:57.562Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 53.083,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "67437",
            "description": " actions associated with sharing, learning, and creating",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.55608731508255,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "67437",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:55:57.104Z",
                "maxActApprox": 16.775,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    67437,
                    20344,
                    82960,
                    51723,
                    201,
                    30390,
                    66426,
                    34190,
                    2922,
                    72289,
                    53029,
                    66794,
                    94072,
                    32648,
                    3113,
                    10428,
                    53797,
                    91010,
                    41901,
                    93241,
                    16621,
                    65571,
                    91347,
                    46610,
                    68613
                ],
                "topkCosSimValues": [
                    1,
                    0.4554,
                    0.4545,
                    0.4386,
                    0.4101,
                    0.3909,
                    0.3885,
                    0.3818,
                    0.378,
                    0.3769,
                    0.376,
                    0.3759,
                    0.3638,
                    0.3622,
                    0.347,
                    0.3453,
                    0.3425,
                    0.3371,
                    0.3369,
                    0.3363,
                    0.3321,
                    0.3317,
                    0.3299,
                    0.3297,
                    0.3282
                ],
                "neuron_alignment_indices": [
                    602,
                    500,
                    570
                ],
                "neuron_alignment_values": [
                    0.099,
                    0.093,
                    0.09
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    604,
                    738,
                    25
                ],
                "correlated_neurons_pearson": [
                    0.026,
                    0.026,
                    0.023
                ],
                "correlated_neurons_l1": [
                    0.023,
                    0.023,
                    0.021
                ],
                "correlated_features_indices": [
                    67317,
                    67332,
                    67335
                ],
                "correlated_features_pearson": [
                    0.007,
                    0.005,
                    0.002
                ],
                "correlated_features_l1": [
                    0.008,
                    0.005,
                    0.002
                ],
                "neg_str": [
                    " mishand",
                    " Historically",
                    "\u00e9\u00be\u012f\u00e5\u00a5\u0133\u00e5\u00a3\u00ab",
                    "COMPLE",
                    "currently",
                    "urnal",
                    "abama",
                    "\u0123\u0138",
                    "Eastern",
                    "ablished"
                ],
                "neg_values": [
                    -0.623,
                    -0.622,
                    -0.592,
                    -0.588,
                    -0.582,
                    -0.579,
                    -0.576,
                    -0.575,
                    -0.57,
                    -0.569
                ],
                "pos_str": [
                    " yourself",
                    " yourselves",
                    " yours",
                    "anooga",
                    " your",
                    " Yourself",
                    " ya",
                    "!'",
                    " whatever",
                    "oice"
                ],
                "pos_values": [
                    1.079,
                    0.921,
                    0.898,
                    0.798,
                    0.775,
                    0.752,
                    0.751,
                    0.742,
                    0.723,
                    0.721
                ],
                "frac_nonzero": 0.00094,
                "freq_hist_data_bar_heights": [
                    628,
                    432,
                    367,
                    300,
                    227,
                    182,
                    123,
                    110,
                    97,
                    78,
                    71,
                    50,
                    42,
                    39,
                    22,
                    29,
                    23,
                    19,
                    18,
                    13,
                    10,
                    10,
                    8,
                    7,
                    2,
                    7,
                    3,
                    4,
                    3,
                    0,
                    0,
                    1,
                    1,
                    1,
                    3,
                    2,
                    0,
                    2,
                    2,
                    0,
                    0,
                    1,
                    1,
                    0,
                    2,
                    0,
                    2,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.168,
                    0.504,
                    0.839,
                    1.175,
                    1.51,
                    1.846,
                    2.181,
                    2.517,
                    2.852,
                    3.188,
                    3.523,
                    3.859,
                    4.194,
                    4.53,
                    4.865,
                    5.201,
                    5.536,
                    5.872,
                    6.207,
                    6.542,
                    6.878,
                    7.213,
                    7.549,
                    7.884,
                    8.22,
                    8.555,
                    8.891,
                    9.226,
                    9.562,
                    9.897,
                    10.233,
                    10.568,
                    10.904,
                    11.239,
                    11.575,
                    11.91,
                    12.246,
                    12.581,
                    12.917,
                    13.252,
                    13.588,
                    13.923,
                    14.259,
                    14.594,
                    14.93,
                    15.265,
                    15.6,
                    15.936,
                    16.271,
                    16.607
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    8,
                    19,
                    18,
                    41,
                    87,
                    156,
                    290,
                    426,
                    647,
                    1098,
                    1493,
                    2095,
                    2523,
                    3182,
                    3691,
                    4000,
                    4423,
                    4377,
                    4098,
                    3841,
                    3321,
                    2787,
                    2187,
                    1700,
                    1204,
                    826,
                    598,
                    374,
                    270,
                    165,
                    123,
                    66,
                    43,
                    23,
                    20,
                    10,
                    5,
                    6,
                    5,
                    3,
                    2,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.606,
                    -0.572,
                    -0.537,
                    -0.503,
                    -0.469,
                    -0.435,
                    -0.401,
                    -0.367,
                    -0.333,
                    -0.299,
                    -0.265,
                    -0.231,
                    -0.197,
                    -0.163,
                    -0.129,
                    -0.095,
                    -0.061,
                    -0.027,
                    0.007,
                    0.041,
                    0.075,
                    0.109,
                    0.143,
                    0.177,
                    0.211,
                    0.245,
                    0.28,
                    0.314,
                    0.348,
                    0.382,
                    0.416,
                    0.45,
                    0.484,
                    0.518,
                    0.552,
                    0.586,
                    0.62,
                    0.654,
                    0.688,
                    0.722,
                    0.756,
                    0.79,
                    0.824,
                    0.858,
                    0.892,
                    0.926,
                    0.96,
                    0.994,
                    1.028,
                    1.062
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " actions associated with sharing, learning, and creating",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "actions related to sharing and engaging with content",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi0kzjqfos10ex9oe2q0k7",
                        "tokens": [
                            " Rel",
                            "ish",
                            " it",
                            ",",
                            " taste",
                            " it",
                            ",",
                            " roll",
                            " it",
                            " round",
                            " your",
                            " tongue",
                            " and",
                            " chew",
                            " it",
                            " over",
                            ",",
                            " because",
                            " these",
                            " moments",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " come",
                            " around",
                            " that",
                            " often",
                            ".",
                            " Then",
                            " think",
                            " back",
                            " to",
                            " February",
                            " or",
                            " March",
                            " last",
                            " year",
                            " and",
                            " tell",
                            " me",
                            " you",
                            " believed",
                            " that",
                            " was",
                            " possible",
                            ".",
                            " Be",
                            " honest",
                            ".",
                            "\n",
                            "\n",
                            "Yet",
                            " our",
                            " und",
                            "oubted",
                            " achievements",
                            " this",
                            " season",
                            " have",
                            " been",
                            " t",
                            "inged",
                            " with",
                            " regret",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " realistic",
                            " rather",
                            " than",
                            " greedy",
                            " to",
                            " say",
                            " we",
                            " could",
                            " have",
                            " done",
                            " so",
                            " much",
                            " more",
                            ".",
                            " Our",
                            " wo",
                            "eful",
                            " lack",
                            " of",
                            " firepower",
                            " up",
                            " front",
                            " has",
                            " been",
                            " the",
                            " main",
                            " problem",
                            " \u2013",
                            " the",
                            " strikers",
                            " have",
                            " been",
                            " downright",
                            " dreadful",
                            " for",
                            " much",
                            " of",
                            " the",
                            " time",
                            ".",
                            " Cou",
                            "pled",
                            " with",
                            " regular",
                            " disappearing",
                            " acts",
                            " from",
                            " our",
                            " defenders",
                            " and",
                            " keeper",
                            " (",
                            "where",
                            " the",
                            " hell",
                            " did",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "67437",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.775,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            16.775,
                            3.684,
                            1.34,
                            13.908,
                            2.604,
                            0,
                            0,
                            0,
                            0,
                            7.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:56:04.522Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 16.775,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi0kzjqfoy10exm0wixfaq",
                        "tokens": [
                            " Rel",
                            "ish",
                            " it",
                            ",",
                            " taste",
                            " it",
                            ",",
                            " roll",
                            " it",
                            " round",
                            " your",
                            " tongue",
                            " and",
                            " chew",
                            " it",
                            " over",
                            ",",
                            " because",
                            " these",
                            " moments",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " come",
                            " around",
                            " that",
                            " often",
                            ".",
                            " Then",
                            " think",
                            " back",
                            " to",
                            " February",
                            " or",
                            " March",
                            " last",
                            " year",
                            " and",
                            " tell",
                            " me",
                            " you",
                            " believed",
                            " that",
                            " was",
                            " possible",
                            ".",
                            " Be",
                            " honest",
                            ".",
                            "\n",
                            "\n",
                            "Yet",
                            " our",
                            " und",
                            "oubted",
                            " achievements",
                            " this",
                            " season",
                            " have",
                            " been",
                            " t",
                            "inged",
                            " with",
                            " regret",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " realistic",
                            " rather",
                            " than",
                            " greedy",
                            " to",
                            " say",
                            " we",
                            " could",
                            " have",
                            " done",
                            " so",
                            " much",
                            " more",
                            ".",
                            " Our",
                            " wo",
                            "eful",
                            " lack",
                            " of",
                            " firepower",
                            " up",
                            " front",
                            " has",
                            " been",
                            " the",
                            " main",
                            " problem",
                            " \u2013",
                            " the",
                            " strikers",
                            " have",
                            " been",
                            " downright",
                            " dreadful",
                            " for",
                            " much",
                            " of",
                            " the",
                            " time",
                            ".",
                            " Cou",
                            "pled",
                            " with",
                            " regular",
                            " disappearing",
                            " acts",
                            " from",
                            " our",
                            " defenders",
                            " and",
                            " keeper",
                            " (",
                            "where",
                            " the",
                            " hell",
                            " did",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "67437",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.775,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            16.775,
                            3.684,
                            1.34,
                            13.908,
                            2.604,
                            0,
                            0,
                            0,
                            0,
                            7.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:56:04.522Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 16.775,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi0kzlqfpe10exe96je5qi",
                        "tokens": [
                            " Rel",
                            "ish",
                            " it",
                            ",",
                            " taste",
                            " it",
                            ",",
                            " roll",
                            " it",
                            " round",
                            " your",
                            " tongue",
                            " and",
                            " chew",
                            " it",
                            " over",
                            ",",
                            " because",
                            " these",
                            " moments",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " come",
                            " around",
                            " that",
                            " often",
                            ".",
                            " Then",
                            " think",
                            " back",
                            " to",
                            " February",
                            " or",
                            " March",
                            " last",
                            " year",
                            " and",
                            " tell",
                            " me",
                            " you",
                            " believed",
                            " that",
                            " was",
                            " possible",
                            ".",
                            " Be",
                            " honest",
                            ".",
                            "\n",
                            "\n",
                            "Yet",
                            " our",
                            " und",
                            "oubted",
                            " achievements",
                            " this",
                            " season",
                            " have",
                            " been",
                            " t",
                            "inged",
                            " with",
                            " regret",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " realistic",
                            " rather",
                            " than",
                            " greedy",
                            " to",
                            " say",
                            " we",
                            " could",
                            " have",
                            " done",
                            " so",
                            " much",
                            " more",
                            ".",
                            " Our",
                            " wo",
                            "eful",
                            " lack",
                            " of",
                            " firepower",
                            " up",
                            " front",
                            " has",
                            " been",
                            " the",
                            " main",
                            " problem",
                            " \u2013",
                            " the",
                            " strikers",
                            " have",
                            " been",
                            " downright",
                            " dreadful",
                            " for",
                            " much",
                            " of",
                            " the",
                            " time",
                            ".",
                            " Cou",
                            "pled",
                            " with",
                            " regular",
                            " disappearing",
                            " acts",
                            " from",
                            " our",
                            " defenders",
                            " and",
                            " keeper",
                            " (",
                            "where",
                            " the",
                            " hell",
                            " did",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "67437",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.775,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            16.775,
                            3.684,
                            1.34,
                            13.908,
                            2.604,
                            0,
                            0,
                            0,
                            0,
                            7.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:56:04.522Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 13.42,
                        "binMax": 16.775,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "76725",
            "description": " structured dialogue in discussions",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5529372692108154,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "76725",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:05:59.713Z",
                "maxActApprox": 18.706,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    76725,
                    86274,
                    89022,
                    41747,
                    53239,
                    15607,
                    35826,
                    46683,
                    88410,
                    57227,
                    91303,
                    18846,
                    97319,
                    1226,
                    66327,
                    87001,
                    78372,
                    23012,
                    98289,
                    39438,
                    69015,
                    26958,
                    51249,
                    25750,
                    44975
                ],
                "topkCosSimValues": [
                    1,
                    0.6372,
                    0.598,
                    0.5631,
                    0.5284,
                    0.5248,
                    0.4983,
                    0.4969,
                    0.4896,
                    0.4774,
                    0.4771,
                    0.4696,
                    0.4648,
                    0.4616,
                    0.4536,
                    0.4519,
                    0.451,
                    0.4467,
                    0.4443,
                    0.4429,
                    0.4419,
                    0.4415,
                    0.4393,
                    0.4369,
                    0.4367
                ],
                "neuron_alignment_indices": [
                    481,
                    145,
                    679
                ],
                "neuron_alignment_values": [
                    0.145,
                    0.131,
                    0.108
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    6,
                    145,
                    679
                ],
                "correlated_neurons_pearson": [
                    0.068,
                    0.063,
                    0.055
                ],
                "correlated_neurons_l1": [
                    0.074,
                    0.063,
                    0.063
                ],
                "correlated_features_indices": [
                    76676,
                    76606,
                    76645
                ],
                "correlated_features_pearson": [
                    0.008,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.008,
                    0,
                    0.001
                ],
                "neg_str": [
                    " outraged",
                    " unseen",
                    "ascus",
                    " clut",
                    "uer",
                    "\u00e3\u0124\u00bc\u00e3\u0124\u00a6\u00e3\u0124\u00b9",
                    " recess",
                    " grip",
                    "uers",
                    " tantal"
                ],
                "neg_values": [
                    -0.675,
                    -0.666,
                    -0.654,
                    -0.644,
                    -0.642,
                    -0.634,
                    -0.627,
                    -0.626,
                    -0.607,
                    -0.605
                ],
                "pos_str": [
                    " Especially",
                    " Usually",
                    " Firstly",
                    " Personally",
                    " Whenever",
                    " Basically",
                    " Obviously",
                    " Sometimes",
                    " Anyway",
                    " Particularly"
                ],
                "pos_values": [
                    1.346,
                    1.301,
                    1.294,
                    1.284,
                    1.27,
                    1.263,
                    1.253,
                    1.251,
                    1.245,
                    1.222
                ],
                "frac_nonzero": 0.00198,
                "freq_hist_data_bar_heights": [
                    1005,
                    846,
                    663,
                    574,
                    467,
                    402,
                    336,
                    276,
                    213,
                    193,
                    153,
                    140,
                    103,
                    97,
                    92,
                    64,
                    62,
                    62,
                    54,
                    40,
                    45,
                    27,
                    27,
                    27,
                    29,
                    39,
                    18,
                    19,
                    23,
                    14,
                    19,
                    12,
                    10,
                    11,
                    6,
                    8,
                    8,
                    8,
                    6,
                    3,
                    6,
                    2,
                    3,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.187,
                    0.561,
                    0.936,
                    1.31,
                    1.684,
                    2.058,
                    2.432,
                    2.806,
                    3.18,
                    3.554,
                    3.929,
                    4.303,
                    4.677,
                    5.051,
                    5.425,
                    5.799,
                    6.173,
                    6.547,
                    6.922,
                    7.296,
                    7.67,
                    8.044,
                    8.418,
                    8.792,
                    9.166,
                    9.54,
                    9.915,
                    10.289,
                    10.663,
                    11.037,
                    11.411,
                    11.785,
                    12.159,
                    12.533,
                    12.908,
                    13.282,
                    13.656,
                    14.03,
                    14.404,
                    14.778,
                    15.152,
                    15.526,
                    15.901,
                    16.275,
                    16.649,
                    17.023,
                    17.397,
                    17.771,
                    18.145,
                    18.519
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    8,
                    36,
                    61,
                    135,
                    249,
                    487,
                    714,
                    1170,
                    1714,
                    2345,
                    2994,
                    3393,
                    3631,
                    3740,
                    3764,
                    3699,
                    3314,
                    3011,
                    2769,
                    2553,
                    2210,
                    1949,
                    1600,
                    1262,
                    953,
                    676,
                    483,
                    349,
                    247,
                    147,
                    125,
                    98,
                    52,
                    49,
                    62,
                    37,
                    36,
                    24,
                    27,
                    18,
                    17,
                    10,
                    11,
                    6,
                    3,
                    5,
                    4,
                    4,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.655,
                    -0.614,
                    -0.574,
                    -0.533,
                    -0.493,
                    -0.452,
                    -0.412,
                    -0.372,
                    -0.331,
                    -0.291,
                    -0.25,
                    -0.21,
                    -0.17,
                    -0.129,
                    -0.089,
                    -0.048,
                    -0.008,
                    0.032,
                    0.073,
                    0.113,
                    0.154,
                    0.194,
                    0.235,
                    0.275,
                    0.315,
                    0.356,
                    0.396,
                    0.437,
                    0.477,
                    0.517,
                    0.558,
                    0.598,
                    0.639,
                    0.679,
                    0.72,
                    0.76,
                    0.8,
                    0.841,
                    0.881,
                    0.922,
                    0.962,
                    1.002,
                    1.043,
                    1.083,
                    1.124,
                    1.164,
                    1.204,
                    1.245,
                    1.285,
                    1.326
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " structured dialogue in discussions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " statements asserting opinions or perspectives",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " instances of dialogue",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygidijqxi4p10ex9i6qv4wx",
                        "tokens": [
                            " stops",
                            " in",
                            " Mind",
                            " MG",
                            "MT",
                            ",",
                            " the",
                            " rotating",
                            " universes",
                            " of",
                            " Rev",
                            "olver",
                            " and",
                            " even",
                            " the",
                            " psychedelic",
                            " fun",
                            "-",
                            "house",
                            " of",
                            " Marvel",
                            " Knights",
                            ":",
                            " Spider",
                            "-",
                            "Man",
                            ".",
                            " These",
                            " places",
                            " also",
                            " define",
                            " and",
                            " provide",
                            " a",
                            " kind",
                            " of",
                            " relief",
                            " to",
                            " the",
                            " characters",
                            ",",
                            " like",
                            " Henry",
                            " Lyme",
                            " in",
                            " Z",
                            "anz",
                            "ib",
                            "ar",
                            ".",
                            " Now",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " going",
                            " underwater",
                            ".",
                            " What",
                            " attracted",
                            " you",
                            " to",
                            " the",
                            " deep",
                            " blue",
                            " sea",
                            "?",
                            " Does",
                            " it",
                            " reflect",
                            " the",
                            " characters",
                            " in",
                            " some",
                            " way",
                            "?",
                            "\n",
                            "\n",
                            "Kind",
                            "t",
                            ":",
                            " Definitely",
                            ".",
                            " I",
                            " think",
                            " the",
                            " most",
                            " exciting",
                            " thing",
                            " to",
                            " me",
                            ",",
                            " other",
                            " than",
                            " coming",
                            " up",
                            " with",
                            " the",
                            " story",
                            " idea",
                            ",",
                            " is",
                            " where",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " going",
                            " to",
                            " take",
                            " place",
                            ".",
                            " A",
                            " lot",
                            " of",
                            " it",
                            " is",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " going",
                            " to",
                            " have",
                            " to",
                            " draw",
                            " that"
                        ],
                        "dataIndex": null,
                        "index": "76725",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.706,
                        "maxValueTokenIndex": 82,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.584,
                            0,
                            18.706,
                            1.92,
                            0,
                            1.202,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.898,
                            0.476,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.123,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:07.886Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 18.706,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygidijpxi4e10exkcb42qj5",
                        "tokens": [
                            " stops",
                            " in",
                            " Mind",
                            " MG",
                            "MT",
                            ",",
                            " the",
                            " rotating",
                            " universes",
                            " of",
                            " Rev",
                            "olver",
                            " and",
                            " even",
                            " the",
                            " psychedelic",
                            " fun",
                            "-",
                            "house",
                            " of",
                            " Marvel",
                            " Knights",
                            ":",
                            " Spider",
                            "-",
                            "Man",
                            ".",
                            " These",
                            " places",
                            " also",
                            " define",
                            " and",
                            " provide",
                            " a",
                            " kind",
                            " of",
                            " relief",
                            " to",
                            " the",
                            " characters",
                            ",",
                            " like",
                            " Henry",
                            " Lyme",
                            " in",
                            " Z",
                            "anz",
                            "ib",
                            "ar",
                            ".",
                            " Now",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " going",
                            " underwater",
                            ".",
                            " What",
                            " attracted",
                            " you",
                            " to",
                            " the",
                            " deep",
                            " blue",
                            " sea",
                            "?",
                            " Does",
                            " it",
                            " reflect",
                            " the",
                            " characters",
                            " in",
                            " some",
                            " way",
                            "?",
                            "\n",
                            "\n",
                            "Kind",
                            "t",
                            ":",
                            " Definitely",
                            ".",
                            " I",
                            " think",
                            " the",
                            " most",
                            " exciting",
                            " thing",
                            " to",
                            " me",
                            ",",
                            " other",
                            " than",
                            " coming",
                            " up",
                            " with",
                            " the",
                            " story",
                            " idea",
                            ",",
                            " is",
                            " where",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " going",
                            " to",
                            " take",
                            " place",
                            ".",
                            " A",
                            " lot",
                            " of",
                            " it",
                            " is",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " going",
                            " to",
                            " have",
                            " to",
                            " draw",
                            " that"
                        ],
                        "dataIndex": null,
                        "index": "76725",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.706,
                        "maxValueTokenIndex": 82,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.584,
                            0,
                            18.706,
                            1.92,
                            0,
                            1.202,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.898,
                            0.476,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.123,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:07.886Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 18.706,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygidijrxi5110ex77nckfme",
                        "tokens": [
                            " stops",
                            " in",
                            " Mind",
                            " MG",
                            "MT",
                            ",",
                            " the",
                            " rotating",
                            " universes",
                            " of",
                            " Rev",
                            "olver",
                            " and",
                            " even",
                            " the",
                            " psychedelic",
                            " fun",
                            "-",
                            "house",
                            " of",
                            " Marvel",
                            " Knights",
                            ":",
                            " Spider",
                            "-",
                            "Man",
                            ".",
                            " These",
                            " places",
                            " also",
                            " define",
                            " and",
                            " provide",
                            " a",
                            " kind",
                            " of",
                            " relief",
                            " to",
                            " the",
                            " characters",
                            ",",
                            " like",
                            " Henry",
                            " Lyme",
                            " in",
                            " Z",
                            "anz",
                            "ib",
                            "ar",
                            ".",
                            " Now",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " going",
                            " underwater",
                            ".",
                            " What",
                            " attracted",
                            " you",
                            " to",
                            " the",
                            " deep",
                            " blue",
                            " sea",
                            "?",
                            " Does",
                            " it",
                            " reflect",
                            " the",
                            " characters",
                            " in",
                            " some",
                            " way",
                            "?",
                            "\n",
                            "\n",
                            "Kind",
                            "t",
                            ":",
                            " Definitely",
                            ".",
                            " I",
                            " think",
                            " the",
                            " most",
                            " exciting",
                            " thing",
                            " to",
                            " me",
                            ",",
                            " other",
                            " than",
                            " coming",
                            " up",
                            " with",
                            " the",
                            " story",
                            " idea",
                            ",",
                            " is",
                            " where",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " going",
                            " to",
                            " take",
                            " place",
                            ".",
                            " A",
                            " lot",
                            " of",
                            " it",
                            " is",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " going",
                            " to",
                            " have",
                            " to",
                            " draw",
                            " that"
                        ],
                        "dataIndex": null,
                        "index": "76725",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.706,
                        "maxValueTokenIndex": 82,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.584,
                            0,
                            18.706,
                            1.92,
                            0,
                            1.202,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.898,
                            0.476,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.123,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:07.886Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 14.965,
                        "binMax": 18.706,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "94434",
            "description": "instances of interaction and inquiry within community or societal discussions",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5470425430485594,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "94434",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:25:18.253Z",
                "maxActApprox": 10.554,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    94434,
                    42966,
                    58034,
                    2622,
                    66882,
                    6677,
                    52601,
                    6569,
                    81089,
                    40357,
                    26945,
                    1988,
                    70012,
                    97126,
                    67583,
                    98057,
                    13301,
                    56143,
                    36568,
                    73898,
                    14366,
                    91699,
                    80353,
                    42462,
                    82334
                ],
                "topkCosSimValues": [
                    1,
                    0.5113,
                    0.504,
                    0.5009,
                    0.4758,
                    0.4708,
                    0.4692,
                    0.465,
                    0.4602,
                    0.4579,
                    0.4549,
                    0.4526,
                    0.4447,
                    0.4436,
                    0.4416,
                    0.4381,
                    0.438,
                    0.4305,
                    0.4294,
                    0.4257,
                    0.4204,
                    0.4185,
                    0.4164,
                    0.4092,
                    0.4069
                ],
                "neuron_alignment_indices": [
                    447,
                    288,
                    225
                ],
                "neuron_alignment_values": [
                    0.214,
                    0.113,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.01,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    679,
                    225,
                    51
                ],
                "correlated_neurons_pearson": [
                    0.036,
                    0.035,
                    0.031
                ],
                "correlated_neurons_l1": [
                    0.044,
                    0.037,
                    0.033
                ],
                "correlated_features_indices": [
                    94513,
                    94512,
                    94545
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.003,
                    0.003
                ],
                "correlated_features_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "neg_str": [
                    " Tycoon",
                    "awar",
                    "affer",
                    " coordinates",
                    "areth",
                    " Courier",
                    "inates",
                    " constitution",
                    "ieri",
                    "isma"
                ],
                "neg_values": [
                    -0.771,
                    -0.656,
                    -0.636,
                    -0.583,
                    -0.561,
                    -0.56,
                    -0.553,
                    -0.551,
                    -0.55,
                    -0.549
                ],
                "pos_str": [
                    " involving",
                    " ranging",
                    " relating",
                    " devoted",
                    " documenting",
                    " lately",
                    " dedicated",
                    "piring",
                    " linking",
                    " culminating"
                ],
                "pos_values": [
                    0.952,
                    0.878,
                    0.849,
                    0.841,
                    0.839,
                    0.838,
                    0.818,
                    0.816,
                    0.793,
                    0.762
                ],
                "frac_nonzero": 0.00127,
                "freq_hist_data_bar_heights": [
                    520,
                    453,
                    406,
                    319,
                    295,
                    252,
                    196,
                    174,
                    169,
                    153,
                    142,
                    109,
                    98,
                    93,
                    62,
                    64,
                    70,
                    52,
                    46,
                    39,
                    33,
                    37,
                    15,
                    23,
                    28,
                    21,
                    16,
                    15,
                    18,
                    12,
                    5,
                    6,
                    3,
                    8,
                    7,
                    4,
                    2,
                    4,
                    3,
                    1,
                    2,
                    2,
                    2,
                    3,
                    1,
                    0,
                    0,
                    0,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.106,
                    0.317,
                    0.528,
                    0.739,
                    0.95,
                    1.161,
                    1.372,
                    1.583,
                    1.794,
                    2.005,
                    2.216,
                    2.427,
                    2.638,
                    2.849,
                    3.061,
                    3.272,
                    3.483,
                    3.694,
                    3.905,
                    4.116,
                    4.327,
                    4.538,
                    4.749,
                    4.96,
                    5.171,
                    5.382,
                    5.593,
                    5.804,
                    6.016,
                    6.227,
                    6.438,
                    6.649,
                    6.86,
                    7.071,
                    7.282,
                    7.493,
                    7.704,
                    7.915,
                    8.126,
                    8.337,
                    8.548,
                    8.759,
                    8.971,
                    9.182,
                    9.393,
                    9.604,
                    9.815,
                    10.026,
                    10.237,
                    10.448
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    2,
                    0,
                    1,
                    11,
                    16,
                    18,
                    52,
                    110,
                    218,
                    421,
                    588,
                    959,
                    1479,
                    2017,
                    2761,
                    3409,
                    3880,
                    4278,
                    4480,
                    4273,
                    4047,
                    3562,
                    3182,
                    2584,
                    2093,
                    1633,
                    1206,
                    882,
                    589,
                    457,
                    319,
                    219,
                    164,
                    117,
                    83,
                    38,
                    36,
                    22,
                    17,
                    14,
                    7,
                    3,
                    1,
                    6,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.754,
                    -0.719,
                    -0.685,
                    -0.651,
                    -0.616,
                    -0.582,
                    -0.547,
                    -0.513,
                    -0.478,
                    -0.444,
                    -0.409,
                    -0.375,
                    -0.34,
                    -0.306,
                    -0.271,
                    -0.237,
                    -0.202,
                    -0.168,
                    -0.133,
                    -0.099,
                    -0.065,
                    -0.03,
                    0.004,
                    0.039,
                    0.073,
                    0.108,
                    0.142,
                    0.177,
                    0.211,
                    0.246,
                    0.28,
                    0.315,
                    0.349,
                    0.384,
                    0.418,
                    0.453,
                    0.487,
                    0.521,
                    0.556,
                    0.59,
                    0.625,
                    0.659,
                    0.694,
                    0.728,
                    0.763,
                    0.797,
                    0.832,
                    0.866,
                    0.901,
                    0.935
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "instances of interaction and inquiry within community or societal discussions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " references to community engagement and feedback",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygj26pgaw1f10exac9mmnyd",
                        "tokens": [
                            " Dogs",
                            "'",
                            " reveal",
                            " trailer",
                            " and",
                            " yesterday",
                            "'s",
                            " story",
                            " trailer",
                            " have",
                            " been",
                            " an",
                            " extremely",
                            " hot",
                            " topic",
                            ".",
                            " Online",
                            " communities",
                            " are",
                            " filled",
                            " with",
                            " discussions",
                            " about",
                            " the",
                            " game",
                            "'s",
                            " graphics",
                            " being",
                            " \u00e2\u0122",
                            "\u013e",
                            "down",
                            "graded",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " we",
                            "'re",
                            " seeing",
                            " reports",
                            " of",
                            " Ubisoft",
                            "'s",
                            " PR",
                            " working",
                            " to",
                            " handle",
                            " the",
                            " immense",
                            " backlash",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " such",
                            " Ubisoft",
                            " PR",
                            " person",
                            " is",
                            " T",
                            "essa",
                            " V",
                            "ilyn",
                            ",",
                            " Ubisoft",
                            " Ben",
                            "el",
                            "ux",
                            " PR",
                            " and",
                            " events",
                            " manager",
                            ".",
                            " Due",
                            " to",
                            " her",
                            " comments",
                            " supporting",
                            " the",
                            " game",
                            "'s",
                            " visuals",
                            ",",
                            " she",
                            " has",
                            " become",
                            " a",
                            " target",
                            " for",
                            " questions",
                            " from",
                            " the",
                            " distraught",
                            " community",
                            " looking",
                            " for",
                            " answers",
                            ".",
                            "\n",
                            "\n",
                            "Her",
                            " initial",
                            " tweet",
                            " about",
                            " the",
                            " matter",
                            " is",
                            " as",
                            " follows",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "Bit",
                            " bum",
                            "med",
                            " about",
                            " some",
                            " people",
                            " not",
                            " liking",
                            " the",
                            " graphics",
                            " of",
                            " the",
                            " #",
                            "Watch",
                            "dogs",
                            " trailer"
                        ],
                        "dataIndex": null,
                        "index": "94434",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.554,
                        "maxValueTokenIndex": 21,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            10.554,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.386,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.215,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:25:18.910Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 10.554,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygj26phaw1g10ex89r58v4t",
                        "tokens": [
                            " Chief",
                            " of",
                            " Staff",
                            " Y",
                            "ig",
                            "al",
                            " Y",
                            "adin",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " declaration",
                            " in",
                            " the",
                            " 1940",
                            "s",
                            " that",
                            " \u00e2\u0122",
                            "\u013e",
                            "the",
                            " Israeli",
                            " civilian",
                            " is",
                            " a",
                            " soldier",
                            " with",
                            " 11",
                            " months",
                            " leave",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " continues",
                            " with",
                            " Prime",
                            " Minister",
                            " Netanyahu",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " remarks",
                            " that",
                            " Israel",
                            " must",
                            " \u00e2\u0122",
                            "\u013e",
                            "fore",
                            "ver",
                            " live",
                            " by",
                            " the",
                            " sword",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "L",
                            "ap",
                            "id",
                            " vs",
                            ".",
                            " Abbas",
                            " and",
                            " the",
                            " security",
                            " establishment",
                            "\n",
                            "\n",
                            "On",
                            " the",
                            " backdrop",
                            " of",
                            " Israel",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " militar",
                            "ism",
                            ",",
                            " it",
                            " is",
                            " important",
                            " to",
                            " say",
                            " a",
                            " few",
                            " things",
                            " about",
                            " the",
                            " security",
                            " establishment",
                            ".",
                            " This",
                            " past",
                            " month",
                            " has",
                            " seen",
                            " a",
                            " great",
                            " number",
                            " of",
                            " examples",
                            " that",
                            " show",
                            " how",
                            " this",
                            " establishment",
                            ",",
                            " and",
                            " specifically",
                            " the",
                            " IDF",
                            ",",
                            " has",
                            " begun",
                            " to",
                            " be",
                            " viewed",
                            " by",
                            " the",
                            " Israeli",
                            " leadership",
                            " \u2014",
                            " both",
                            " by",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "94434",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.398,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.777,
                            0.578,
                            10.398,
                            3.607,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:25:18.910Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 10.554,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygj26phaw1h10exdldwbqqr",
                        "tokens": [
                            " in",
                            " the",
                            " vicinity",
                            " of",
                            " a",
                            " bus",
                            " when",
                            " the",
                            " vehicle",
                            " is",
                            " making",
                            " a",
                            " turn",
                            ".",
                            " The",
                            " \"",
                            "Safe",
                            " Turn",
                            " Alert",
                            " System",
                            "\"",
                            " pilot",
                            " is",
                            " an",
                            " extension",
                            " of",
                            " the",
                            " Authority",
                            "'s",
                            " distracted",
                            " commuter",
                            " awareness",
                            " program",
                            " and",
                            " designed",
                            " to",
                            " warn",
                            " pedestrians",
                            " -",
                            " specifically",
                            " those",
                            " eng",
                            "ross",
                            "ed",
                            " in",
                            " their",
                            " phone",
                            " calls",
                            ",",
                            " text",
                            " messages",
                            " and",
                            " music",
                            " -",
                            "that",
                            " the",
                            " bus",
                            " is",
                            " turning",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "We",
                            " are",
                            " seeing",
                            " more",
                            " cases",
                            " of",
                            " people",
                            " unaware",
                            " of",
                            " their",
                            " surroundings",
                            ",\"",
                            " said",
                            " Scott",
                            " S",
                            "auer",
                            ",",
                            " SE",
                            "P",
                            "TA",
                            "'s",
                            " Chief",
                            " Officer",
                            " of",
                            " System",
                            " Safety",
                            ".",
                            " \"",
                            "The",
                            " Safe",
                            " Turn",
                            " Alert",
                            " system",
                            " uses",
                            " an",
                            " audio",
                            " warning",
                            " and",
                            " a",
                            " stro",
                            "be",
                            " light",
                            " to",
                            " make",
                            " pedestrians",
                            " aware",
                            " that",
                            " the",
                            " bus",
                            " is",
                            " making",
                            " a",
                            " right",
                            "-",
                            " or",
                            " left",
                            "-",
                            " hand",
                            " turn",
                            ".",
                            " This",
                            " is",
                            " an",
                            " added"
                        ],
                        "dataIndex": null,
                        "index": "94434",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.354,
                        "maxValueTokenIndex": 67,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.354,
                            1.173,
                            2.269,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:25:18.910Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 10.554,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "19571",
            "description": "keywords related to interactive elements and responses in discussions",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5421967506408691,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "19571",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:33:42.498Z",
                "maxActApprox": 29.925,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    19571,
                    6094,
                    48562,
                    5366,
                    211,
                    8161,
                    23912,
                    8916,
                    17189,
                    46966,
                    19869,
                    14405,
                    28252,
                    15170,
                    33524,
                    21952,
                    29162,
                    14094,
                    4007,
                    13736,
                    27120,
                    18357,
                    12540,
                    36159,
                    10709
                ],
                "topkCosSimValues": [
                    1,
                    0.3747,
                    0.3662,
                    0.3391,
                    0.3378,
                    0.3365,
                    0.3285,
                    0.3231,
                    0.3188,
                    0.3151,
                    0.3003,
                    0.2966,
                    0.2954,
                    0.2924,
                    0.292,
                    0.2917,
                    0.2881,
                    0.2843,
                    0.2836,
                    0.2828,
                    0.2825,
                    0.2807,
                    0.2788,
                    0.2787,
                    0.2786
                ],
                "neuron_alignment_indices": [
                    643,
                    22,
                    336
                ],
                "neuron_alignment_values": [
                    0.114,
                    0.099,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    744,
                    531,
                    609
                ],
                "correlated_neurons_pearson": [
                    0.012,
                    0.011,
                    0.01
                ],
                "correlated_neurons_l1": [
                    0.012,
                    0.011,
                    0.011
                ],
                "correlated_features_indices": [
                    19552,
                    19569,
                    19639
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.002,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "ktop",
                    "comed",
                    "leans",
                    "peak",
                    "ounter",
                    "creen",
                    "uba",
                    "cale",
                    " disg",
                    "jer"
                ],
                "neg_values": [
                    -0.88,
                    -0.824,
                    -0.812,
                    -0.766,
                    -0.752,
                    -0.744,
                    -0.725,
                    -0.721,
                    -0.717,
                    -0.707
                ],
                "pos_str": [
                    " Delete",
                    "Favorite",
                    "ership",
                    " Your",
                    " Title",
                    "able",
                    " Builder",
                    " Girl",
                    " Guy",
                    "Reply"
                ],
                "pos_values": [
                    0.988,
                    0.875,
                    0.749,
                    0.726,
                    0.724,
                    0.718,
                    0.694,
                    0.689,
                    0.688,
                    0.681
                ],
                "frac_nonzero": 0.00013,
                "freq_hist_data_bar_heights": [
                    100,
                    61,
                    37,
                    41,
                    29,
                    30,
                    23,
                    15,
                    7,
                    8,
                    6,
                    4,
                    2,
                    1,
                    7,
                    2,
                    5,
                    1,
                    0,
                    1,
                    0,
                    0,
                    1,
                    2,
                    2,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.301,
                    0.9,
                    1.498,
                    2.097,
                    2.695,
                    3.294,
                    3.892,
                    4.491,
                    5.089,
                    5.688,
                    6.286,
                    6.884,
                    7.483,
                    8.081,
                    8.68,
                    9.278,
                    9.877,
                    10.475,
                    11.074,
                    11.672,
                    12.271,
                    12.869,
                    13.468,
                    14.066,
                    14.664,
                    15.263,
                    15.861,
                    16.46,
                    17.058,
                    17.657,
                    18.255,
                    18.854,
                    19.452,
                    20.051,
                    20.649,
                    21.248,
                    21.846,
                    22.444,
                    23.043,
                    23.641,
                    24.24,
                    24.838,
                    25.437,
                    26.035,
                    26.634,
                    27.232,
                    27.831,
                    28.429,
                    29.028,
                    29.626
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    0,
                    3,
                    6,
                    8,
                    6,
                    20,
                    29,
                    62,
                    105,
                    129,
                    257,
                    404,
                    608,
                    973,
                    1357,
                    1908,
                    2476,
                    3125,
                    3538,
                    4022,
                    4366,
                    4132,
                    3980,
                    3771,
                    3274,
                    2858,
                    2376,
                    1868,
                    1481,
                    1090,
                    735,
                    468,
                    299,
                    221,
                    128,
                    82,
                    30,
                    34,
                    13,
                    5,
                    4,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.861,
                    -0.824,
                    -0.786,
                    -0.749,
                    -0.711,
                    -0.674,
                    -0.637,
                    -0.599,
                    -0.562,
                    -0.525,
                    -0.487,
                    -0.45,
                    -0.413,
                    -0.375,
                    -0.338,
                    -0.301,
                    -0.263,
                    -0.226,
                    -0.189,
                    -0.151,
                    -0.114,
                    -0.076,
                    -0.039,
                    -0.002,
                    0.036,
                    0.073,
                    0.11,
                    0.148,
                    0.185,
                    0.222,
                    0.26,
                    0.297,
                    0.334,
                    0.372,
                    0.409,
                    0.446,
                    0.484,
                    0.521,
                    0.558,
                    0.596,
                    0.633,
                    0.671,
                    0.708,
                    0.745,
                    0.783,
                    0.82,
                    0.857,
                    0.895,
                    0.932,
                    0.969
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "keywords related to interactive elements and responses in discussions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk5dt0ntoski666ixwx2z6g",
                        "tokens": [
                            " ;",
                            "'",
                            "><",
                            "p",
                            " style",
                            "='",
                            "font",
                            "-",
                            "size",
                            ":",
                            " 30",
                            "px",
                            ";",
                            " color",
                            ":",
                            " #",
                            "ef",
                            "ef",
                            "ef",
                            ";",
                            " text",
                            "-",
                            "align",
                            ":",
                            " center",
                            ";",
                            "position",
                            ":",
                            " relative",
                            ";",
                            " top",
                            ":",
                            " 50",
                            "%;",
                            "transform",
                            ":",
                            " translate",
                            "Y",
                            "(-",
                            "50",
                            "%);",
                            " opacity",
                            ":",
                            " 0",
                            ".",
                            "5",
                            ";",
                            "'>",
                            "Reply",
                            "</",
                            "p",
                            "></",
                            "div",
                            ">",
                            "\";",
                            " $(",
                            "this",
                            ").",
                            "html",
                            "(",
                            "hover",
                            "string",
                            ").",
                            "css",
                            "(\"",
                            "background",
                            "\",",
                            " \"#",
                            "444",
                            "\");",
                            " console",
                            ".",
                            "log",
                            "(\"",
                            "mouse",
                            " in",
                            "\");",
                            " },",
                            " function",
                            "(){",
                            " $(",
                            "this",
                            ").",
                            "css",
                            "(\"",
                            "background",
                            "\",",
                            " \"#",
                            "ef",
                            "ef",
                            "ef",
                            "\").",
                            "html",
                            "(",
                            "comment",
                            "_",
                            "html",
                            ");",
                            " console",
                            ".",
                            "log",
                            "(\"",
                            "mouse",
                            " out",
                            "\");",
                            " }",
                            " );",
                            "\n",
                            "\n",
                            "As",
                            " you",
                            " can",
                            " see",
                            ",",
                            " Grey",
                            " was",
                            " calling",
                            " an",
                            " event",
                            " on",
                            " hover",
                            " to",
                            " replace",
                            " the",
                            " div",
                            "'s",
                            " contents"
                        ],
                        "dataIndex": null,
                        "index": "19571",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 29.925,
                        "maxValueTokenIndex": 48,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            29.925,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.679,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:33:48.777Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 29.925,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5dt0ptot6i666ghlutb2d",
                        "tokens": [
                            " ;",
                            "'",
                            "><",
                            "p",
                            " style",
                            "='",
                            "font",
                            "-",
                            "size",
                            ":",
                            " 30",
                            "px",
                            ";",
                            " color",
                            ":",
                            " #",
                            "ef",
                            "ef",
                            "ef",
                            ";",
                            " text",
                            "-",
                            "align",
                            ":",
                            " center",
                            ";",
                            "position",
                            ":",
                            " relative",
                            ";",
                            " top",
                            ":",
                            " 50",
                            "%;",
                            "transform",
                            ":",
                            " translate",
                            "Y",
                            "(-",
                            "50",
                            "%);",
                            " opacity",
                            ":",
                            " 0",
                            ".",
                            "5",
                            ";",
                            "'>",
                            "Reply",
                            "</",
                            "p",
                            "></",
                            "div",
                            ">",
                            "\";",
                            " $(",
                            "this",
                            ").",
                            "html",
                            "(",
                            "hover",
                            "string",
                            ").",
                            "css",
                            "(\"",
                            "background",
                            "\",",
                            " \"#",
                            "444",
                            "\");",
                            " console",
                            ".",
                            "log",
                            "(\"",
                            "mouse",
                            " in",
                            "\");",
                            " },",
                            " function",
                            "(){",
                            " $(",
                            "this",
                            ").",
                            "css",
                            "(\"",
                            "background",
                            "\",",
                            " \"#",
                            "ef",
                            "ef",
                            "ef",
                            "\").",
                            "html",
                            "(",
                            "comment",
                            "_",
                            "html",
                            ");",
                            " console",
                            ".",
                            "log",
                            "(\"",
                            "mouse",
                            " out",
                            "\");",
                            " }",
                            " );",
                            "\n",
                            "\n",
                            "As",
                            " you",
                            " can",
                            " see",
                            ",",
                            " Grey",
                            " was",
                            " calling",
                            " an",
                            " event",
                            " on",
                            " hover",
                            " to",
                            " replace",
                            " the",
                            " div",
                            "'s",
                            " contents"
                        ],
                        "dataIndex": null,
                        "index": "19571",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 29.925,
                        "maxValueTokenIndex": 48,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            29.925,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.679,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:33:48.777Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 23.94,
                        "binMax": 29.925,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5dt0ntosli666smivhdb6",
                        "tokens": [
                            " period",
                            ".",
                            "\n",
                            "\n",
                            "2",
                            ")",
                            " Start",
                            " the",
                            " post",
                            " by",
                            " stating",
                            " the",
                            " approximate",
                            " number",
                            " of",
                            " years",
                            " you",
                            " trip",
                            " and",
                            " how",
                            " many",
                            " trips",
                            " you",
                            " estimate",
                            " to",
                            " have",
                            " had",
                            ".",
                            " If",
                            " you",
                            " don",
                            "'t",
                            " do",
                            " this",
                            ",",
                            " your",
                            " post",
                            " may",
                            " be",
                            " removed",
                            " immediately",
                            " as",
                            " we",
                            " do",
                            " not",
                            " want",
                            " speculation",
                            " but",
                            " actual",
                            " veteran",
                            " advice",
                            " from",
                            " actual",
                            " veterans",
                            ".",
                            "\n",
                            "\n",
                            "3",
                            ")",
                            " Proceed",
                            " to",
                            " give",
                            " your",
                            " advice",
                            ".",
                            " You",
                            " may",
                            " make",
                            " multiple",
                            " posts",
                            " throughout",
                            " the",
                            " thread",
                            " if",
                            " you",
                            " have",
                            " more",
                            " advice",
                            " to",
                            " share",
                            ",",
                            " but",
                            " start",
                            " it",
                            " off",
                            " by",
                            " stating",
                            " your",
                            " 2",
                            ")",
                            " experience",
                            " level",
                            " every",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "4",
                            ")",
                            " DO",
                            " NOT",
                            " reply",
                            " to",
                            " posts",
                            ",",
                            " do",
                            " not",
                            " ask",
                            " questions",
                            ",",
                            " simply",
                            " state",
                            " your",
                            " experience",
                            " level",
                            " and",
                            " advice",
                            " -",
                            " or",
                            " stick",
                            " to",
                            " reading",
                            " the",
                            " thread",
                            " only",
                            ".",
                            " Reply"
                        ],
                        "dataIndex": null,
                        "index": "19571",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.59,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.647,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.59
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:33:48.777Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 29.925,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs3072-jb",
            "index": "1666",
            "description": "personal interaction and dialogue between individuals",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5387303829193115,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs3072-jb",
                "index": "1666",
                "sourceSetName": "res_fs3072-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:42:08.960Z",
                "maxActApprox": 40.575,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    1666,
                    2868,
                    1826,
                    2433,
                    48,
                    2759,
                    2900,
                    474,
                    93,
                    975,
                    2785,
                    838,
                    2145,
                    875,
                    2177,
                    3022,
                    0,
                    844,
                    2094,
                    1628,
                    899,
                    2524,
                    2774,
                    1097,
                    3012
                ],
                "topkCosSimValues": [
                    1,
                    0.3954,
                    0.3387,
                    0.331,
                    0.3218,
                    0.2461,
                    0.2448,
                    0.2193,
                    0.209,
                    0.208,
                    0.2046,
                    0.1969,
                    0.1926,
                    0.1882,
                    0.1831,
                    0.1816,
                    0.1756,
                    0.1746,
                    0.1691,
                    0.1663,
                    0.1628,
                    0.1617,
                    0.1604,
                    0.1499,
                    0.1489
                ],
                "neuron_alignment_indices": [
                    223,
                    764,
                    13
                ],
                "neuron_alignment_values": [
                    0.136,
                    0.106,
                    0.104
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    223,
                    279,
                    567
                ],
                "correlated_neurons_pearson": [
                    0.075,
                    0.071,
                    0.064
                ],
                "correlated_neurons_l1": [
                    0.077,
                    0.076,
                    0.056
                ],
                "correlated_features_indices": [
                    1775,
                    1711,
                    1703
                ],
                "correlated_features_pearson": [
                    0.033,
                    0.019,
                    0.018
                ],
                "correlated_features_l1": [
                    0.038,
                    0.025,
                    0.026
                ],
                "neg_str": [
                    "iba",
                    "uffle",
                    "ater",
                    "CHA",
                    "asha",
                    "aten",
                    "aters",
                    "gra",
                    " offend",
                    "taboola"
                ],
                "neg_values": [
                    -0.829,
                    -0.748,
                    -0.707,
                    -0.66,
                    -0.646,
                    -0.637,
                    -0.636,
                    -0.625,
                    -0.622,
                    -0.607
                ],
                "pos_str": [
                    " thumbs",
                    " opportunity",
                    " chance",
                    " permission",
                    " choice",
                    " priority",
                    " pointers",
                    " pause",
                    " assurances",
                    " berth"
                ],
                "pos_values": [
                    0.913,
                    0.889,
                    0.875,
                    0.81,
                    0.783,
                    0.773,
                    0.772,
                    0.764,
                    0.76,
                    0.742
                ],
                "frac_nonzero": 0.00975,
                "freq_hist_data_bar_heights": [
                    8808,
                    5369,
                    3450,
                    2273,
                    1720,
                    1207,
                    923,
                    771,
                    661,
                    558,
                    506,
                    397,
                    353,
                    324,
                    316,
                    272,
                    254,
                    217,
                    197,
                    219,
                    194,
                    157,
                    189,
                    148,
                    160,
                    121,
                    124,
                    86,
                    83,
                    77,
                    82,
                    49,
                    45,
                    46,
                    35,
                    39,
                    27,
                    18,
                    28,
                    24,
                    22,
                    23,
                    18,
                    27,
                    15,
                    14,
                    6,
                    4,
                    4,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.406,
                    1.217,
                    2.029,
                    2.84,
                    3.652,
                    4.463,
                    5.275,
                    6.086,
                    6.898,
                    7.709,
                    8.521,
                    9.332,
                    10.144,
                    10.955,
                    11.767,
                    12.578,
                    13.39,
                    14.201,
                    15.013,
                    15.824,
                    16.636,
                    17.447,
                    18.259,
                    19.07,
                    19.882,
                    20.693,
                    21.505,
                    22.316,
                    23.128,
                    23.94,
                    24.751,
                    25.563,
                    26.374,
                    27.186,
                    27.997,
                    28.809,
                    29.62,
                    30.432,
                    31.243,
                    32.055,
                    32.866,
                    33.678,
                    34.489,
                    35.301,
                    36.112,
                    36.924,
                    37.735,
                    38.547,
                    39.358,
                    40.17
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    1,
                    1,
                    5,
                    4,
                    8,
                    20,
                    29,
                    53,
                    126,
                    179,
                    314,
                    476,
                    790,
                    1111,
                    1645,
                    2249,
                    2954,
                    3521,
                    3921,
                    4457,
                    4580,
                    4506,
                    4157,
                    3658,
                    3100,
                    2420,
                    1717,
                    1309,
                    961,
                    640,
                    450,
                    298,
                    194,
                    140,
                    90,
                    59,
                    44,
                    17,
                    14,
                    13,
                    7,
                    6,
                    6,
                    1,
                    1,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.811,
                    -0.776,
                    -0.742,
                    -0.707,
                    -0.672,
                    -0.637,
                    -0.602,
                    -0.567,
                    -0.533,
                    -0.498,
                    -0.463,
                    -0.428,
                    -0.393,
                    -0.358,
                    -0.324,
                    -0.289,
                    -0.254,
                    -0.219,
                    -0.184,
                    -0.15,
                    -0.115,
                    -0.08,
                    -0.045,
                    -0.01,
                    0.025,
                    0.059,
                    0.094,
                    0.129,
                    0.164,
                    0.199,
                    0.234,
                    0.268,
                    0.303,
                    0.338,
                    0.373,
                    0.408,
                    0.442,
                    0.477,
                    0.512,
                    0.547,
                    0.582,
                    0.617,
                    0.651,
                    0.686,
                    0.721,
                    0.756,
                    0.791,
                    0.825,
                    0.86,
                    0.895
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "personal interaction and dialogue between individuals",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdo21ofr6oji666imz4asb9",
                        "tokens": [
                            " Fol",
                            "ay",
                            "ang",
                            ".",
                            " Terry",
                            " asked",
                            " if",
                            " I",
                            " had",
                            " a",
                            " 155",
                            " l",
                            "ber",
                            " that",
                            " could",
                            " take",
                            " the",
                            " match",
                            ".",
                            " Terry",
                            " asked",
                            " me",
                            " to",
                            " take",
                            " a",
                            " look",
                            " at",
                            " the",
                            " fighter",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " profile",
                            " and",
                            " to",
                            " let",
                            " him",
                            " know",
                            " what",
                            " I",
                            " thought",
                            ",",
                            " and",
                            " if",
                            " I",
                            " could",
                            " give",
                            " him",
                            " a",
                            " name",
                            " of",
                            " wh",
                            "omever",
                            " I",
                            " chose",
                            " to",
                            " take",
                            " this",
                            " fight",
                            ".",
                            " I",
                            " initially",
                            " offered",
                            " Ray",
                            " \"",
                            "Br",
                            "add",
                            "a",
                            "\"",
                            " Cooper",
                            ",",
                            " my",
                            " nephew",
                            ",",
                            " as",
                            " he",
                            " is",
                            " THE",
                            " best",
                            " 155",
                            " l",
                            "ber",
                            " I",
                            " know",
                            " in",
                            " Hawaii",
                            ".",
                            " After",
                            " discussions",
                            " with",
                            " Ray",
                            ",",
                            " it",
                            " seemed",
                            " that",
                            " he",
                            " was",
                            " going",
                            " in",
                            " another",
                            " direction",
                            ".",
                            " I",
                            " then",
                            " called",
                            " Low",
                            "en",
                            " to",
                            " offer",
                            " him",
                            " the",
                            " fight",
                            " as",
                            " this",
                            " opponent",
                            " was",
                            " perfect",
                            " for",
                            " Low",
                            "en",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " style",
                            " and",
                            " the",
                            " opponent"
                        ],
                        "dataIndex": null,
                        "index": "1666",
                        "layer": "8-res_fs3072-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.575,
                        "maxValueTokenIndex": 47,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.372,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.986,
                            0,
                            0,
                            0,
                            3.629,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.548,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.575,
                            24.362,
                            4.524,
                            1.188,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.778,
                            5.741,
                            0,
                            0,
                            0,
                            2.434,
                            3.577,
                            1.592,
                            0,
                            0,
                            4.203,
                            11.385,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            21.106,
                            11.747,
                            3.922,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:42:09.636Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.575,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdo21ofr6oki666ll3z3jb5",
                        "tokens": [
                            " systematic",
                            " bias",
                            " as",
                            " a",
                            " step",
                            " toward",
                            " correcting",
                            " it",
                            ".",
                            "<|endoftext|>",
                            "Shipping",
                            " will",
                            " always",
                            " be",
                            " via",
                            " USPS",
                            ".",
                            " I",
                            " ship",
                            " all",
                            " orders",
                            " to",
                            " the",
                            " address",
                            " listed",
                            " on",
                            " your",
                            " Etsy",
                            " invoice",
                            ".",
                            " If",
                            " you",
                            " give",
                            " me",
                            " an",
                            " incorrect",
                            " ship",
                            "-",
                            "to",
                            " address",
                            ",",
                            " and",
                            " I",
                            " ship",
                            " there",
                            " because",
                            " that",
                            "'s",
                            " where",
                            " you",
                            " told",
                            " me",
                            " to",
                            " ship",
                            " to",
                            ",",
                            " I",
                            " can",
                            "'t",
                            " be",
                            " held",
                            " responsible",
                            " when",
                            " you",
                            " don",
                            "'t",
                            " get",
                            " your",
                            " package",
                            "-",
                            " PLEASE",
                            " double",
                            "-",
                            "check",
                            " your",
                            " address",
                            " before",
                            " submitting",
                            " your",
                            " order",
                            ".",
                            " If",
                            " you",
                            " need",
                            " to",
                            " ship",
                            " an",
                            " order",
                            " elsewhere",
                            ",",
                            " whether",
                            " it",
                            "'s",
                            " as",
                            " a",
                            " gift",
                            " or",
                            " because",
                            " you",
                            "'ve",
                            " moved",
                            ",",
                            " or",
                            " for",
                            " any",
                            " other",
                            " reason",
                            ",",
                            " PLEASE",
                            " let",
                            " me",
                            " know",
                            " with",
                            " an",
                            " Etsy",
                            " conv",
                            "o",
                            " ASAP",
                            ".",
                            " I",
                            " can",
                            " change",
                            " a",
                            " shipping",
                            " address",
                            " with",
                            " no"
                        ],
                        "dataIndex": null,
                        "index": "1666",
                        "layer": "8-res_fs3072-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.272,
                        "maxValueTokenIndex": 33,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.272,
                            25.084,
                            7.275,
                            0,
                            0,
                            0.65,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.606,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.939,
                            1.546,
                            2.142,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:42:09.636Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.575,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdo21ofr6oli666ymo1grdw",
                        "tokens": [
                            "After",
                            " M",
                            "ee",
                            "Go",
                            " 1",
                            ".",
                            "0",
                            ",",
                            " which",
                            " was",
                            " unveiled",
                            " back",
                            " in",
                            " June",
                            " 2010",
                            ",",
                            " you",
                            " can",
                            " now",
                            " welcome",
                            " the",
                            " M",
                            "ee",
                            "Go",
                            " 1",
                            ".",
                            "1",
                            " for",
                            " hands",
                            "ets",
                            ".",
                            " It",
                            " is",
                            " now",
                            " available",
                            " for",
                            " download",
                            " so",
                            " you",
                            " can",
                            " give",
                            " it",
                            " a",
                            " try",
                            " straight",
                            " away",
                            " if",
                            " you",
                            " have",
                            " a",
                            " Nokia",
                            " N",
                            "900",
                            " and",
                            " you",
                            " are",
                            " feeling",
                            " adventurous",
                            " enough",
                            " to",
                            " dual",
                            " boot",
                            " it",
                            " along",
                            " with",
                            " Ma",
                            "emo",
                            ".",
                            " As",
                            " we",
                            " said",
                            " on",
                            " our",
                            " Previous",
                            " Le",
                            "ak",
                            " Here",
                            " ...",
                            " M",
                            "ee",
                            "Go",
                            " 1",
                            ".",
                            "1",
                            " is",
                            " coming",
                            " to",
                            " N",
                            "900",
                            " on",
                            " October",
                            ",",
                            " And",
                            " it",
                            " Does",
                            "!",
                            "\n",
                            "\n",
                            "As",
                            " the",
                            " video",
                            " below",
                            " reveals",
                            ",",
                            " the",
                            " new",
                            " M",
                            "ee",
                            "Go",
                            " 1",
                            ".",
                            "1",
                            " brings",
                            " U",
                            "-",
                            "Boot",
                            " support",
                            " to",
                            " the",
                            " Nokia",
                            " N",
                            "900",
                            ",",
                            " which",
                            " means",
                            " dual",
                            " boot"
                        ],
                        "dataIndex": null,
                        "index": "1666",
                        "layer": "8-res_fs3072-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.268,
                        "maxValueTokenIndex": 41,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.268,
                            24.893,
                            2.51,
                            0.298,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:42:09.636Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.575,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "12693",
            "description": "elements suggesting a collaborative and instructional effort in the context of creative projects",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5362602195894859,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "12693",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:44:02.350Z",
                "maxActApprox": 14.074,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    12693,
                    10044,
                    15734,
                    48442,
                    61492,
                    50031,
                    48229,
                    82726,
                    33207,
                    55651,
                    42413,
                    90090,
                    4905,
                    84872,
                    26760,
                    68213,
                    37118,
                    93706,
                    91416,
                    36251,
                    82457,
                    12726,
                    35892,
                    80034,
                    80003
                ],
                "topkCosSimValues": [
                    1,
                    0.4613,
                    0.4309,
                    0.4161,
                    0.4134,
                    0.3796,
                    0.3731,
                    0.372,
                    0.3719,
                    0.358,
                    0.3567,
                    0.3547,
                    0.3531,
                    0.349,
                    0.3463,
                    0.3383,
                    0.3241,
                    0.3207,
                    0.3184,
                    0.3128,
                    0.3125,
                    0.3106,
                    0.3097,
                    0.3066,
                    0.3035
                ],
                "neuron_alignment_indices": [
                    481,
                    373,
                    598
                ],
                "neuron_alignment_values": [
                    0.156,
                    0.133,
                    0.11
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    49,
                    718,
                    393
                ],
                "correlated_neurons_pearson": [
                    0.029,
                    0.029,
                    0.028
                ],
                "correlated_neurons_l1": [
                    0.035,
                    0.036,
                    0.049
                ],
                "correlated_features_indices": [
                    12726,
                    12676,
                    12752
                ],
                "correlated_features_pearson": [
                    0.029,
                    0.004,
                    0.004
                ],
                "correlated_features_l1": [
                    0.03,
                    0.006,
                    0.004
                ],
                "neg_str": [
                    "ocaust",
                    "forts",
                    "antage",
                    "aund",
                    "reb",
                    " ISIL",
                    "ovych",
                    "\u00e3\u0125\u00a9\u00e3\u0125\u00b3",
                    "ilee",
                    "azeera"
                ],
                "neg_values": [
                    -0.77,
                    -0.641,
                    -0.629,
                    -0.622,
                    -0.616,
                    -0.615,
                    -0.607,
                    -0.606,
                    -0.596,
                    -0.589
                ],
                "pos_str": [
                    " possibilities",
                    " feasibility",
                    " feasible",
                    "earable",
                    " myster",
                    " Wouldn",
                    " needed",
                    "could",
                    " wanted",
                    " hadn"
                ],
                "pos_values": [
                    0.731,
                    0.719,
                    0.707,
                    0.707,
                    0.696,
                    0.696,
                    0.689,
                    0.683,
                    0.682,
                    0.68
                ],
                "frac_nonzero": 0.0034,
                "freq_hist_data_bar_heights": [
                    2306,
                    1781,
                    1380,
                    1117,
                    835,
                    689,
                    503,
                    387,
                    340,
                    263,
                    208,
                    152,
                    131,
                    104,
                    92,
                    81,
                    70,
                    46,
                    44,
                    22,
                    23,
                    19,
                    18,
                    20,
                    10,
                    8,
                    6,
                    6,
                    1,
                    2,
                    2,
                    4,
                    3,
                    0,
                    1,
                    2,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.141,
                    0.422,
                    0.704,
                    0.985,
                    1.267,
                    1.548,
                    1.83,
                    2.111,
                    2.393,
                    2.674,
                    2.956,
                    3.237,
                    3.519,
                    3.8,
                    4.082,
                    4.363,
                    4.645,
                    4.926,
                    5.208,
                    5.489,
                    5.771,
                    6.052,
                    6.334,
                    6.615,
                    6.896,
                    7.178,
                    7.459,
                    7.741,
                    8.022,
                    8.304,
                    8.585,
                    8.867,
                    9.148,
                    9.43,
                    9.711,
                    9.993,
                    10.274,
                    10.556,
                    10.837,
                    11.119,
                    11.4,
                    11.682,
                    11.963,
                    12.245,
                    12.526,
                    12.808,
                    13.089,
                    13.371,
                    13.652,
                    13.934
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    0,
                    3,
                    5,
                    13,
                    25,
                    35,
                    62,
                    89,
                    131,
                    188,
                    301,
                    510,
                    641,
                    861,
                    1295,
                    1575,
                    2025,
                    2347,
                    2776,
                    3188,
                    3498,
                    3626,
                    3685,
                    3477,
                    3357,
                    3104,
                    2674,
                    2318,
                    1926,
                    1618,
                    1262,
                    1030,
                    759,
                    597,
                    371,
                    311,
                    196,
                    141,
                    79,
                    58,
                    36,
                    17,
                    14,
                    8,
                    10,
                    10,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.755,
                    -0.725,
                    -0.695,
                    -0.665,
                    -0.635,
                    -0.605,
                    -0.575,
                    -0.545,
                    -0.515,
                    -0.485,
                    -0.455,
                    -0.425,
                    -0.395,
                    -0.365,
                    -0.335,
                    -0.305,
                    -0.275,
                    -0.245,
                    -0.215,
                    -0.185,
                    -0.155,
                    -0.125,
                    -0.095,
                    -0.065,
                    -0.035,
                    -0.005,
                    0.025,
                    0.055,
                    0.085,
                    0.115,
                    0.145,
                    0.176,
                    0.206,
                    0.236,
                    0.266,
                    0.296,
                    0.326,
                    0.356,
                    0.386,
                    0.416,
                    0.446,
                    0.476,
                    0.506,
                    0.536,
                    0.566,
                    0.596,
                    0.626,
                    0.656,
                    0.686,
                    0.716
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "conversations about collaboration and project planning",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "elements suggesting a collaborative and instructional effort in the context of creative projects",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygffzp0kxtg10ext9g36b9t",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygffzp0kxth10exsiwar37m",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygffzp1kxtk10exyuy3n35l",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "6942",
            "description": "actions involving instruction, support, and guidance",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5351751446723938,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "6942",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:10:29.382Z",
                "maxActApprox": 16.189,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    6942,
                    9712,
                    3555,
                    33822,
                    41728,
                    10474,
                    27246,
                    36496,
                    22388,
                    24424,
                    41567,
                    14585,
                    2438,
                    8064,
                    47617,
                    3536,
                    3862,
                    25244,
                    32675,
                    10493,
                    26277,
                    11447,
                    18245,
                    32948,
                    6308
                ],
                "topkCosSimValues": [
                    1,
                    0.5472,
                    0.5419,
                    0.5224,
                    0.5021,
                    0.5009,
                    0.4805,
                    0.4674,
                    0.46,
                    0.4515,
                    0.4485,
                    0.4481,
                    0.4469,
                    0.4317,
                    0.4303,
                    0.4244,
                    0.4226,
                    0.4221,
                    0.4154,
                    0.4152,
                    0.4093,
                    0.4061,
                    0.4058,
                    0.4052,
                    0.404
                ],
                "neuron_alignment_indices": [
                    458,
                    63,
                    310
                ],
                "neuron_alignment_values": [
                    0.103,
                    0.098,
                    0.096
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    59,
                    282,
                    184
                ],
                "correlated_neurons_pearson": [
                    0.033,
                    0.031,
                    0.031
                ],
                "correlated_neurons_l1": [
                    0.031,
                    0.033,
                    0.023
                ],
                "correlated_features_indices": [
                    7015,
                    7043,
                    6968
                ],
                "correlated_features_pearson": [
                    0.004,
                    0.003,
                    0.003
                ],
                "correlated_features_l1": [
                    0.004,
                    0.004,
                    0.005
                ],
                "neg_str": [
                    "estate",
                    "alde",
                    "\u00dc",
                    "yond",
                    "fman",
                    "Ranked",
                    "abouts",
                    "levard",
                    " outs",
                    "\"},"
                ],
                "neg_values": [
                    -0.681,
                    -0.678,
                    -0.656,
                    -0.649,
                    -0.649,
                    -0.64,
                    -0.637,
                    -0.636,
                    -0.621,
                    -0.619
                ],
                "pos_str": [
                    " him",
                    " us",
                    " me",
                    " himself",
                    " attendees",
                    " viewers",
                    " listeners",
                    " everyone",
                    " passers",
                    " reporters"
                ],
                "pos_values": [
                    1.183,
                    1.125,
                    1.021,
                    1.011,
                    1.006,
                    0.997,
                    0.99,
                    0.927,
                    0.922,
                    0.914
                ],
                "frac_nonzero": 0.00147,
                "freq_hist_data_bar_heights": [
                    761,
                    638,
                    518,
                    425,
                    372,
                    276,
                    238,
                    215,
                    185,
                    133,
                    132,
                    102,
                    106,
                    77,
                    75,
                    57,
                    44,
                    29,
                    37,
                    32,
                    29,
                    24,
                    17,
                    15,
                    16,
                    11,
                    11,
                    9,
                    5,
                    8,
                    9,
                    4,
                    1,
                    3,
                    2,
                    3,
                    2,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.162,
                    0.486,
                    0.809,
                    1.133,
                    1.457,
                    1.781,
                    2.105,
                    2.428,
                    2.752,
                    3.076,
                    3.4,
                    3.723,
                    4.047,
                    4.371,
                    4.695,
                    5.019,
                    5.342,
                    5.666,
                    5.99,
                    6.314,
                    6.637,
                    6.961,
                    7.285,
                    7.609,
                    7.933,
                    8.256,
                    8.58,
                    8.904,
                    9.228,
                    9.551,
                    9.875,
                    10.199,
                    10.523,
                    10.847,
                    11.17,
                    11.494,
                    11.818,
                    12.142,
                    12.465,
                    12.789,
                    13.113,
                    13.437,
                    13.761,
                    14.084,
                    14.408,
                    14.732,
                    15.056,
                    15.379,
                    15.703,
                    16.027
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    9,
                    14,
                    26,
                    50,
                    65,
                    126,
                    268,
                    450,
                    756,
                    1193,
                    1666,
                    2250,
                    2840,
                    3487,
                    3929,
                    4113,
                    4314,
                    4106,
                    3703,
                    3309,
                    2857,
                    2351,
                    1891,
                    1521,
                    1234,
                    976,
                    842,
                    561,
                    425,
                    337,
                    218,
                    161,
                    77,
                    51,
                    24,
                    17,
                    10,
                    5,
                    4,
                    3,
                    0,
                    4,
                    2,
                    1,
                    4,
                    0,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.662,
                    -0.625,
                    -0.588,
                    -0.551,
                    -0.513,
                    -0.476,
                    -0.439,
                    -0.401,
                    -0.364,
                    -0.327,
                    -0.29,
                    -0.252,
                    -0.215,
                    -0.178,
                    -0.141,
                    -0.103,
                    -0.066,
                    -0.029,
                    0.009,
                    0.046,
                    0.083,
                    0.12,
                    0.158,
                    0.195,
                    0.232,
                    0.269,
                    0.307,
                    0.344,
                    0.381,
                    0.419,
                    0.456,
                    0.493,
                    0.53,
                    0.568,
                    0.605,
                    0.642,
                    0.68,
                    0.717,
                    0.754,
                    0.791,
                    0.829,
                    0.866,
                    0.903,
                    0.94,
                    0.978,
                    1.015,
                    1.052,
                    1.09,
                    1.127,
                    1.164
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "actions involving instruction, support, and guidance",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4jus5i1pzi666bn9olf6c",
                        "tokens": [
                            ".",
                            " It",
                            " was",
                            " a",
                            " short",
                            " flight",
                            ".",
                            " In",
                            " one",
                            " and",
                            " a",
                            " half",
                            " hours",
                            ",",
                            " we",
                            " were",
                            " in",
                            " St",
                            ".",
                            " Petersburg",
                            ",",
                            " the",
                            " city",
                            " known",
                            " for",
                            " its",
                            " art",
                            ",",
                            " splendid",
                            " architecture",
                            ",",
                            " beautiful",
                            " gardens",
                            ",",
                            " magnificent",
                            " cat",
                            "hed",
                            "rals",
                            " and",
                            " the",
                            " largest",
                            " museum",
                            " in",
                            " Europe",
                            ",",
                            "\n",
                            "\n",
                            "Ar",
                            "rival",
                            " at",
                            " St",
                            " Petersburg",
                            "\n",
                            "\n",
                            "A",
                            " young",
                            " lady",
                            " named",
                            " Jane",
                            " received",
                            " us",
                            " at",
                            " the",
                            " airport",
                            " at",
                            " St",
                            " Petersburg",
                            " and",
                            " accompanied",
                            " us",
                            " to",
                            " our",
                            " hotel",
                            " in",
                            " the",
                            " van",
                            ".",
                            " On",
                            " the",
                            " way",
                            ",",
                            " she",
                            " briefed",
                            " us",
                            " a",
                            " little",
                            " on",
                            " the",
                            " city",
                            ".",
                            " The",
                            " driver",
                            " spoke",
                            " only",
                            " Russian",
                            " though",
                            ".",
                            " The",
                            " weather",
                            " was",
                            " pleasantly",
                            " warm",
                            ".",
                            " We",
                            " reached",
                            " hotel",
                            " Marco",
                            " Polo",
                            " by",
                            " 1",
                            ".",
                            "30",
                            " pm",
                            " and",
                            " checked",
                            " into",
                            " the",
                            " two",
                            " rooms",
                            " that",
                            " were",
                            " booked",
                            " for",
                            " the",
                            " five",
                            " of",
                            " us"
                        ],
                        "dataIndex": null,
                        "index": "6942",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.189,
                        "maxValueTokenIndex": 82,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.168,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            16.189,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:10:30.874Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 16.189,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4jus7i1qki666uaarn1z0",
                        "tokens": [
                            ".",
                            " It",
                            " was",
                            " a",
                            " short",
                            " flight",
                            ".",
                            " In",
                            " one",
                            " and",
                            " a",
                            " half",
                            " hours",
                            ",",
                            " we",
                            " were",
                            " in",
                            " St",
                            ".",
                            " Petersburg",
                            ",",
                            " the",
                            " city",
                            " known",
                            " for",
                            " its",
                            " art",
                            ",",
                            " splendid",
                            " architecture",
                            ",",
                            " beautiful",
                            " gardens",
                            ",",
                            " magnificent",
                            " cat",
                            "hed",
                            "rals",
                            " and",
                            " the",
                            " largest",
                            " museum",
                            " in",
                            " Europe",
                            ",",
                            "\n",
                            "\n",
                            "Ar",
                            "rival",
                            " at",
                            " St",
                            " Petersburg",
                            "\n",
                            "\n",
                            "A",
                            " young",
                            " lady",
                            " named",
                            " Jane",
                            " received",
                            " us",
                            " at",
                            " the",
                            " airport",
                            " at",
                            " St",
                            " Petersburg",
                            " and",
                            " accompanied",
                            " us",
                            " to",
                            " our",
                            " hotel",
                            " in",
                            " the",
                            " van",
                            ".",
                            " On",
                            " the",
                            " way",
                            ",",
                            " she",
                            " briefed",
                            " us",
                            " a",
                            " little",
                            " on",
                            " the",
                            " city",
                            ".",
                            " The",
                            " driver",
                            " spoke",
                            " only",
                            " Russian",
                            " though",
                            ".",
                            " The",
                            " weather",
                            " was",
                            " pleasantly",
                            " warm",
                            ".",
                            " We",
                            " reached",
                            " hotel",
                            " Marco",
                            " Polo",
                            " by",
                            " 1",
                            ".",
                            "30",
                            " pm",
                            " and",
                            " checked",
                            " into",
                            " the",
                            " two",
                            " rooms",
                            " that",
                            " were",
                            " booked",
                            " for",
                            " the",
                            " five",
                            " of",
                            " us"
                        ],
                        "dataIndex": null,
                        "index": "6942",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.189,
                        "maxValueTokenIndex": 82,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.168,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            16.189,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:10:30.874Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 12.951,
                        "binMax": 16.189,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4jus5i1q0i666egekhvf3",
                        "tokens": [
                            " the",
                            " nice",
                            " list",
                            ",",
                            " when",
                            " every",
                            " human",
                            " being",
                            " is",
                            " totally",
                            " dep",
                            "raved",
                            " from",
                            " birth",
                            "?",
                            "\u00e2\u0122",
                            "\u013f",
                            " St",
                            ".",
                            " Nick",
                            " was",
                            " overheard",
                            " saying",
                            " to",
                            " Mrs",
                            ".",
                            " Claus",
                            " in",
                            " his",
                            " office",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "No",
                            " matter",
                            " what",
                            " filthy",
                            " r",
                            "ags",
                            " of",
                            " righteousness",
                            " they",
                            " bring",
                            " before",
                            " the",
                            " Lord",
                            ",",
                            " they",
                            " are",
                            " condemned",
                            " already",
                            " based",
                            " on",
                            " their",
                            " sin",
                            " nature",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " j",
                            "olly",
                            " gift",
                            "-",
                            "giving",
                            " man",
                            " tasked",
                            " his",
                            " elves",
                            " with",
                            " pur",
                            "ging",
                            " the",
                            " entire",
                            " \u00e2\u0122",
                            "\u013e",
                            "nice",
                            "\u00e2\u0122",
                            "\u013f",
                            " list",
                            " and",
                            " moving",
                            " all",
                            " the",
                            " names",
                            " over",
                            " to",
                            " the",
                            " naughty",
                            " list",
                            " all",
                            " afternoon",
                            ",",
                            " as",
                            " he",
                            " lect",
                            "ured",
                            " them",
                            " about",
                            " their",
                            " need",
                            " for",
                            " a",
                            " Savior",
                            " who",
                            " could",
                            " save",
                            " them",
                            " completely",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "He",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " actually",
                            " getting",
                            " kind",
                            " of",
                            " annoying",
                            " at",
                            " this"
                        ],
                        "dataIndex": null,
                        "index": "6942",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.158,
                        "maxValueTokenIndex": 98,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.633,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.284,
                            0,
                            0,
                            0,
                            0.413,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.118,
                            15.158,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:10:30.874Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 16.189,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "33387",
            "description": "dialogue and questions related to personal experiences and discussions",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5345267057418823,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "33387",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:58:47.137Z",
                "maxActApprox": 23.914,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    33387,
                    46078,
                    1747,
                    16416,
                    15960,
                    7413,
                    5632,
                    17971,
                    36526,
                    38040,
                    15880,
                    33230,
                    29527,
                    37942,
                    1991,
                    7299,
                    47611,
                    2217,
                    1834,
                    33149,
                    12535,
                    15854,
                    11806,
                    44292,
                    18180
                ],
                "topkCosSimValues": [
                    1,
                    0.5974,
                    0.5691,
                    0.5543,
                    0.5039,
                    0.43,
                    0.4229,
                    0.3855,
                    0.382,
                    0.3667,
                    0.3492,
                    0.346,
                    0.3356,
                    0.3119,
                    0.3102,
                    0.3066,
                    0.3026,
                    0.2992,
                    0.2954,
                    0.2741,
                    0.2568,
                    0.2539,
                    0.2499,
                    0.2495,
                    0.2476
                ],
                "neuron_alignment_indices": [
                    655,
                    668,
                    695
                ],
                "neuron_alignment_values": [
                    0.119,
                    0.101,
                    0.1
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    60,
                    449,
                    108
                ],
                "correlated_neurons_pearson": [
                    0.026,
                    0.022,
                    0.022
                ],
                "correlated_neurons_l1": [
                    0.025,
                    0.021,
                    0.021
                ],
                "correlated_features_indices": [
                    33287,
                    33386,
                    33282
                ],
                "correlated_features_pearson": [
                    0.004,
                    0.002,
                    0.001
                ],
                "correlated_features_l1": [
                    0.005,
                    0.003,
                    0.001
                ],
                "neg_str": [
                    "$$$$",
                    "arte",
                    "@@",
                    "$$",
                    "@#&",
                    "ICLE",
                    "wart",
                    "ACC",
                    "+++",
                    " Coup"
                ],
                "neg_values": [
                    -0.781,
                    -0.741,
                    -0.709,
                    -0.708,
                    -0.651,
                    -0.645,
                    -0.636,
                    -0.623,
                    -0.617,
                    -0.614
                ],
                "pos_str": [
                    " Explain",
                    " autobi",
                    " specifically",
                    " foresee",
                    " qualitative",
                    "gard",
                    " guys",
                    " shed",
                    " extensively",
                    " describe"
                ],
                "pos_values": [
                    0.787,
                    0.714,
                    0.709,
                    0.7,
                    0.694,
                    0.689,
                    0.683,
                    0.666,
                    0.666,
                    0.665
                ],
                "frac_nonzero": 0.0008500000000000001,
                "freq_hist_data_bar_heights": [
                    552,
                    430,
                    277,
                    219,
                    185,
                    133,
                    116,
                    94,
                    75,
                    62,
                    52,
                    54,
                    46,
                    36,
                    31,
                    34,
                    30,
                    25,
                    22,
                    26,
                    17,
                    17,
                    10,
                    12,
                    11,
                    16,
                    6,
                    11,
                    10,
                    5,
                    5,
                    11,
                    3,
                    3,
                    2,
                    3,
                    3,
                    4,
                    3,
                    3,
                    1,
                    1,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.239,
                    0.717,
                    1.196,
                    1.674,
                    2.152,
                    2.631,
                    3.109,
                    3.587,
                    4.065,
                    4.544,
                    5.022,
                    5.5,
                    5.979,
                    6.457,
                    6.935,
                    7.413,
                    7.892,
                    8.37,
                    8.848,
                    9.326,
                    9.805,
                    10.283,
                    10.761,
                    11.24,
                    11.718,
                    12.196,
                    12.674,
                    13.153,
                    13.631,
                    14.109,
                    14.588,
                    15.066,
                    15.544,
                    16.022,
                    16.501,
                    16.979,
                    17.457,
                    17.936,
                    18.414,
                    18.892,
                    19.37,
                    19.849,
                    20.327,
                    20.805,
                    21.283,
                    21.762,
                    22.24,
                    22.718,
                    23.197,
                    23.675
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    2,
                    0,
                    3,
                    11,
                    13,
                    25,
                    43,
                    78,
                    107,
                    195,
                    260,
                    404,
                    567,
                    844,
                    1078,
                    1524,
                    1900,
                    2242,
                    2727,
                    3157,
                    3414,
                    3595,
                    3595,
                    3565,
                    3442,
                    3110,
                    2873,
                    2508,
                    2127,
                    1735,
                    1393,
                    1108,
                    861,
                    583,
                    424,
                    269,
                    165,
                    123,
                    70,
                    51,
                    25,
                    10,
                    17,
                    2,
                    5,
                    4,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.766,
                    -0.734,
                    -0.703,
                    -0.672,
                    -0.64,
                    -0.609,
                    -0.577,
                    -0.546,
                    -0.515,
                    -0.483,
                    -0.452,
                    -0.421,
                    -0.389,
                    -0.358,
                    -0.326,
                    -0.295,
                    -0.264,
                    -0.232,
                    -0.201,
                    -0.17,
                    -0.138,
                    -0.107,
                    -0.075,
                    -0.044,
                    -0.013,
                    0.019,
                    0.05,
                    0.081,
                    0.113,
                    0.144,
                    0.176,
                    0.207,
                    0.238,
                    0.27,
                    0.301,
                    0.332,
                    0.364,
                    0.395,
                    0.427,
                    0.458,
                    0.489,
                    0.521,
                    0.552,
                    0.583,
                    0.615,
                    0.646,
                    0.678,
                    0.709,
                    0.74,
                    0.772
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "dialogue and questions related to personal experiences and discussions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk6a4066f4ti6660xd3za5r",
                        "tokens": [
                            " under",
                            "lie",
                            " what",
                            " the",
                            " anthrop",
                            "ologist",
                            " Robin",
                            " Fox",
                            " calls",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "d",
                            "azz",
                            "le",
                            " of",
                            " surface",
                            " appearances",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " writes",
                            " Kak",
                            "ar",
                            " in",
                            " an",
                            " introduction",
                            " to",
                            " The",
                            " Indians",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " this",
                            " interview",
                            " with",
                            " Man",
                            "ish",
                            " Chand",
                            ",",
                            " Kak",
                            "ar",
                            " explains",
                            " how",
                            " the",
                            " land",
                            " of",
                            " the",
                            " Kam",
                            "as",
                            "utra",
                            " that",
                            " fl",
                            "aunts",
                            " erotic",
                            " sculptures",
                            " in",
                            " temples",
                            " of",
                            " Kon",
                            "arak",
                            " and",
                            " Kh",
                            "aj",
                            "ur",
                            "aho",
                            " slipped",
                            " into",
                            " sexual",
                            " repression",
                            " centuries",
                            " ago",
                            " that",
                            " India",
                            " is",
                            " still",
                            " recovering",
                            " from",
                            ".",
                            "\n",
                            "\n",
                            "Ex",
                            "cerpt",
                            "s",
                            " from",
                            " the",
                            " interview",
                            ":",
                            "\n",
                            "\n",
                            "Q",
                            ")",
                            " You",
                            " have",
                            " been",
                            " writing",
                            " on",
                            " the",
                            " Indian",
                            " mind",
                            " and",
                            " Indian",
                            " people",
                            " for",
                            " a",
                            " long",
                            " time",
                            ".",
                            " What",
                            " sets",
                            " this",
                            " book",
                            " apart",
                            " from",
                            " the",
                            " ones",
                            " you",
                            " have",
                            " written",
                            " before",
                            "?",
                            "\n",
                            "\n",
                            "A",
                            ")",
                            " It"
                        ],
                        "dataIndex": null,
                        "index": "33387",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 23.914,
                        "maxValueTokenIndex": 93,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.678,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.003,
                            3.356,
                            23.914,
                            16.334,
                            10.974,
                            6.173,
                            1.213,
                            1.614,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.029,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.733,
                            3.232,
                            1.168,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:58:55.531Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 23.914,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6a4096f5ei666ylb7onsh",
                        "tokens": [
                            " under",
                            "lie",
                            " what",
                            " the",
                            " anthrop",
                            "ologist",
                            " Robin",
                            " Fox",
                            " calls",
                            " the",
                            " \u00e2\u0122",
                            "\u013e",
                            "d",
                            "azz",
                            "le",
                            " of",
                            " surface",
                            " appearances",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " writes",
                            " Kak",
                            "ar",
                            " in",
                            " an",
                            " introduction",
                            " to",
                            " The",
                            " Indians",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " this",
                            " interview",
                            " with",
                            " Man",
                            "ish",
                            " Chand",
                            ",",
                            " Kak",
                            "ar",
                            " explains",
                            " how",
                            " the",
                            " land",
                            " of",
                            " the",
                            " Kam",
                            "as",
                            "utra",
                            " that",
                            " fl",
                            "aunts",
                            " erotic",
                            " sculptures",
                            " in",
                            " temples",
                            " of",
                            " Kon",
                            "arak",
                            " and",
                            " Kh",
                            "aj",
                            "ur",
                            "aho",
                            " slipped",
                            " into",
                            " sexual",
                            " repression",
                            " centuries",
                            " ago",
                            " that",
                            " India",
                            " is",
                            " still",
                            " recovering",
                            " from",
                            ".",
                            "\n",
                            "\n",
                            "Ex",
                            "cerpt",
                            "s",
                            " from",
                            " the",
                            " interview",
                            ":",
                            "\n",
                            "\n",
                            "Q",
                            ")",
                            " You",
                            " have",
                            " been",
                            " writing",
                            " on",
                            " the",
                            " Indian",
                            " mind",
                            " and",
                            " Indian",
                            " people",
                            " for",
                            " a",
                            " long",
                            " time",
                            ".",
                            " What",
                            " sets",
                            " this",
                            " book",
                            " apart",
                            " from",
                            " the",
                            " ones",
                            " you",
                            " have",
                            " written",
                            " before",
                            "?",
                            "\n",
                            "\n",
                            "A",
                            ")",
                            " It"
                        ],
                        "dataIndex": null,
                        "index": "33387",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 23.914,
                        "maxValueTokenIndex": 93,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.678,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.003,
                            3.356,
                            23.914,
                            16.334,
                            10.974,
                            6.173,
                            1.213,
                            1.614,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.029,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.733,
                            3.232,
                            1.168,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:58:55.531Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 19.131,
                        "binMax": 23.914,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6a4076f4ui6661r85zejz",
                        "tokens": [
                            "'t",
                            " have",
                            " the",
                            " capability",
                            " to",
                            " tell",
                            " you",
                            " that",
                            ",",
                            " to",
                            " even",
                            " give",
                            " you",
                            " rough",
                            " estimates",
                            ".",
                            "\n",
                            "\n",
                            "And",
                            " what",
                            " these",
                            " documents",
                            " that",
                            " we",
                            " published",
                            " show",
                            ",",
                            " that",
                            " were",
                            " marked",
                            " \"",
                            "Top",
                            " Secret",
                            "\"",
                            " to",
                            " prevent",
                            " the",
                            " American",
                            " people",
                            " from",
                            " learning",
                            " about",
                            " them",
                            ",",
                            " was",
                            " that",
                            " the",
                            " NSA",
                            " keeps",
                            " extremely",
                            " precise",
                            " statistics",
                            ",",
                            " all",
                            " the",
                            " data",
                            " that",
                            " the",
                            " senators",
                            " have",
                            " asked",
                            " for",
                            " that",
                            " the",
                            " NSA",
                            " has",
                            " falsely",
                            " claimed",
                            " doesn",
                            "'t",
                            " exist",
                            ".",
                            " And",
                            " the",
                            " other",
                            " thing",
                            " that",
                            " it",
                            " does",
                            ",",
                            " as",
                            " you",
                            " said",
                            " is",
                            " it",
                            " indicates",
                            " just",
                            " how",
                            " vast",
                            " and",
                            " massive",
                            " the",
                            " NSA",
                            " is",
                            " in",
                            " terms",
                            " of",
                            " sweeping",
                            " up",
                            " all",
                            " forms",
                            " of",
                            " communication",
                            " around",
                            " the",
                            " globe",
                            ",",
                            " including",
                            " domestically",
                            ".",
                            "\n",
                            "\n",
                            "GS",
                            ":",
                            " You",
                            " also",
                            " drew",
                            " new",
                            " criticism",
                            " yesterday",
                            " from",
                            " the",
                            " Director",
                            " of",
                            " National",
                            " Intelligence",
                            ","
                        ],
                        "dataIndex": null,
                        "index": "33387",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 23.863,
                        "maxValueTokenIndex": 114,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.556,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.992,
                            23.863,
                            13.026,
                            7.603,
                            0.507,
                            0.188,
                            0.543,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:58:55.531Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 23.914,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "96849",
            "description": "instances of communication and engagement in discussions",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5336288213729858,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "96849",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:27:53.982Z",
                "maxActApprox": 15.274,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    96849,
                    94927,
                    92439,
                    81802,
                    8293,
                    76184,
                    20384,
                    98151,
                    17021,
                    90748,
                    76786,
                    58775,
                    14524,
                    16834,
                    69402,
                    68084,
                    41628,
                    3432,
                    15280,
                    60260,
                    68728,
                    65512,
                    81579,
                    37678,
                    10573
                ],
                "topkCosSimValues": [
                    1,
                    0.497,
                    0.4922,
                    0.4392,
                    0.4102,
                    0.399,
                    0.3941,
                    0.3931,
                    0.3845,
                    0.3842,
                    0.383,
                    0.3802,
                    0.3793,
                    0.3789,
                    0.3774,
                    0.3742,
                    0.3623,
                    0.361,
                    0.3563,
                    0.3562,
                    0.3525,
                    0.3524,
                    0.352,
                    0.3501,
                    0.3489
                ],
                "neuron_alignment_indices": [
                    247,
                    88,
                    664
                ],
                "neuron_alignment_values": [
                    0.099,
                    0.098,
                    0.097
                ],
                "neuron_alignment_l1": [
                    0.004,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    411,
                    679,
                    196
                ],
                "correlated_neurons_pearson": [
                    0.029,
                    0.028,
                    0.026
                ],
                "correlated_neurons_l1": [
                    0.028,
                    0.035,
                    0.024
                ],
                "correlated_features_indices": [
                    96856,
                    96850,
                    96829
                ],
                "correlated_features_pearson": [
                    0.026,
                    0.005,
                    0.003
                ],
                "correlated_features_l1": [
                    0.027,
                    0.005,
                    0.003
                ],
                "neg_str": [
                    "CTV",
                    " Falling",
                    " Poverty",
                    " Alone",
                    " rack",
                    "\u00e3\u0125\u013a",
                    "\u00e9\u00be\u012f\u00e5",
                    "apo",
                    "aughters",
                    "alach"
                ],
                "neg_values": [
                    -0.685,
                    -0.646,
                    -0.626,
                    -0.624,
                    -0.602,
                    -0.598,
                    -0.585,
                    -0.584,
                    -0.578,
                    -0.578
                ],
                "pos_str": [
                    " internally",
                    " feasibility",
                    "actionDate",
                    " beforehand",
                    " consultations",
                    " advisors",
                    " consultation",
                    " mediation",
                    " discussions",
                    " enqu"
                ],
                "pos_values": [
                    1.003,
                    0.938,
                    0.935,
                    0.919,
                    0.901,
                    0.888,
                    0.882,
                    0.857,
                    0.853,
                    0.848
                ],
                "frac_nonzero": 0.00109,
                "freq_hist_data_bar_heights": [
                    567,
                    465,
                    410,
                    307,
                    265,
                    243,
                    154,
                    162,
                    121,
                    116,
                    92,
                    65,
                    56,
                    43,
                    34,
                    40,
                    31,
                    33,
                    27,
                    20,
                    19,
                    15,
                    21,
                    21,
                    10,
                    18,
                    11,
                    15,
                    3,
                    6,
                    3,
                    4,
                    10,
                    2,
                    5,
                    5,
                    2,
                    3,
                    2,
                    0,
                    2,
                    2,
                    0,
                    3,
                    1,
                    1,
                    1,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.153,
                    0.458,
                    0.764,
                    1.069,
                    1.375,
                    1.68,
                    1.986,
                    2.291,
                    2.597,
                    2.902,
                    3.208,
                    3.513,
                    3.819,
                    4.124,
                    4.43,
                    4.735,
                    5.041,
                    5.346,
                    5.652,
                    5.957,
                    6.263,
                    6.568,
                    6.874,
                    7.179,
                    7.485,
                    7.79,
                    8.096,
                    8.401,
                    8.706,
                    9.012,
                    9.317,
                    9.623,
                    9.928,
                    10.234,
                    10.539,
                    10.845,
                    11.15,
                    11.456,
                    11.761,
                    12.067,
                    12.372,
                    12.678,
                    12.983,
                    13.289,
                    13.594,
                    13.9,
                    14.205,
                    14.511,
                    14.816,
                    15.122
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    3,
                    3,
                    12,
                    14,
                    42,
                    64,
                    114,
                    223,
                    326,
                    488,
                    772,
                    1194,
                    1666,
                    2083,
                    2707,
                    3186,
                    3707,
                    3984,
                    4197,
                    4140,
                    3888,
                    3582,
                    2977,
                    2574,
                    2063,
                    1594,
                    1216,
                    937,
                    674,
                    554,
                    378,
                    257,
                    197,
                    132,
                    88,
                    73,
                    47,
                    26,
                    18,
                    14,
                    14,
                    5,
                    8,
                    3,
                    5,
                    3,
                    2,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.668,
                    -0.635,
                    -0.601,
                    -0.567,
                    -0.533,
                    -0.5,
                    -0.466,
                    -0.432,
                    -0.398,
                    -0.365,
                    -0.331,
                    -0.297,
                    -0.263,
                    -0.229,
                    -0.196,
                    -0.162,
                    -0.128,
                    -0.094,
                    -0.061,
                    -0.027,
                    0.007,
                    0.041,
                    0.074,
                    0.108,
                    0.142,
                    0.176,
                    0.209,
                    0.243,
                    0.277,
                    0.311,
                    0.344,
                    0.378,
                    0.412,
                    0.446,
                    0.479,
                    0.513,
                    0.547,
                    0.581,
                    0.614,
                    0.648,
                    0.682,
                    0.716,
                    0.749,
                    0.783,
                    0.817,
                    0.851,
                    0.884,
                    0.918,
                    0.952,
                    0.986
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " verbs related to communication and discussions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "instances of communication and engagement in discussions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygj5kkscq4w10exzo7a761a",
                        "tokens": [
                            " coach",
                            " Mike",
                            " Pett",
                            "ine",
                            " saying",
                            " Leon",
                            "hard",
                            " would",
                            " likely",
                            " make",
                            " his",
                            " decision",
                            " in",
                            " the",
                            " offseason",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " very",
                            " happy",
                            " with",
                            " my",
                            " decision",
                            " and",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " looking",
                            " forward",
                            " to",
                            " that",
                            " next",
                            " chapter",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "He",
                            " also",
                            " alluded",
                            " to",
                            " an",
                            " opportunity",
                            " in",
                            " Madison",
                            ",",
                            " which",
                            " has",
                            " led",
                            " to",
                            " rumors",
                            " that",
                            " a",
                            " spot",
                            " on",
                            " new",
                            " Wisconsin",
                            " head",
                            " coach",
                            " Paul",
                            " Ch",
                            "ry",
                            "st",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " staff",
                            " could",
                            " belong",
                            " to",
                            " the",
                            " Wisconsin",
                            " Al",
                            "umn",
                            "us",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "I",
                            " definitely",
                            " want",
                            " to",
                            " get",
                            " out",
                            " and",
                            " travel",
                            " a",
                            " little",
                            " bit",
                            " with",
                            " the",
                            " family",
                            ".",
                            " Outside",
                            " of",
                            " that",
                            ",",
                            " head",
                            " back",
                            " to",
                            " Madison",
                            " (",
                            "W",
                            "isc",
                            ".)",
                            " and",
                            " figure",
                            " it",
                            " out",
                            ".",
                            " I",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " conversations",
                            " with"
                        ],
                        "dataIndex": null,
                        "index": "96849",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.274,
                        "maxValueTokenIndex": 125,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.608,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.274,
                            4.419
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:27:56.860Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.274,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygj5kkucq5h10exiacbpse1",
                        "tokens": [
                            " coach",
                            " Mike",
                            " Pett",
                            "ine",
                            " saying",
                            " Leon",
                            "hard",
                            " would",
                            " likely",
                            " make",
                            " his",
                            " decision",
                            " in",
                            " the",
                            " offseason",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " very",
                            " happy",
                            " with",
                            " my",
                            " decision",
                            " and",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " looking",
                            " forward",
                            " to",
                            " that",
                            " next",
                            " chapter",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "He",
                            " also",
                            " alluded",
                            " to",
                            " an",
                            " opportunity",
                            " in",
                            " Madison",
                            ",",
                            " which",
                            " has",
                            " led",
                            " to",
                            " rumors",
                            " that",
                            " a",
                            " spot",
                            " on",
                            " new",
                            " Wisconsin",
                            " head",
                            " coach",
                            " Paul",
                            " Ch",
                            "ry",
                            "st",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " staff",
                            " could",
                            " belong",
                            " to",
                            " the",
                            " Wisconsin",
                            " Al",
                            "umn",
                            "us",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "I",
                            " definitely",
                            " want",
                            " to",
                            " get",
                            " out",
                            " and",
                            " travel",
                            " a",
                            " little",
                            " bit",
                            " with",
                            " the",
                            " family",
                            ".",
                            " Outside",
                            " of",
                            " that",
                            ",",
                            " head",
                            " back",
                            " to",
                            " Madison",
                            " (",
                            "W",
                            "isc",
                            ".)",
                            " and",
                            " figure",
                            " it",
                            " out",
                            ".",
                            " I",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " conversations",
                            " with"
                        ],
                        "dataIndex": null,
                        "index": "96849",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.274,
                        "maxValueTokenIndex": 125,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.608,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.274,
                            4.419
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:27:56.860Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 12.22,
                        "binMax": 15.274,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygj5kkscq4x10exek09bl8k",
                        "tokens": [
                            " more",
                            " opportunities",
                            " to",
                            " invest",
                            ".\"",
                            "\n",
                            "\n",
                            "Is",
                            " there",
                            " any",
                            " news",
                            " on",
                            " the",
                            " partner",
                            " you",
                            "'re",
                            " looking",
                            " for",
                            " in",
                            " China",
                            "?",
                            " H",
                            "ain",
                            "an",
                            " airlines",
                            " have",
                            " been",
                            " mentioned",
                            ".",
                            " Could",
                            " they",
                            " acquire",
                            " some",
                            " of",
                            " your",
                            " shares",
                            "?",
                            "\n",
                            "\n",
                            "\"",
                            "I",
                            " think",
                            " this",
                            " is",
                            " where",
                            " people",
                            " are",
                            " mistaken",
                            ".",
                            " We",
                            "'re",
                            " looking",
                            " for",
                            " sponsorship",
                            " partners",
                            " globally",
                            " \u2013",
                            " from",
                            " Indonesia",
                            ",",
                            " China",
                            ",",
                            " anywhere",
                            ".",
                            " We",
                            " don",
                            "'t",
                            " have",
                            " any",
                            " airline",
                            " partners",
                            " and",
                            " that",
                            "'s",
                            " why",
                            " some",
                            " people",
                            " have",
                            " mentioned",
                            " Gar",
                            "uda",
                            " before",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "H",
                            "ain",
                            "an",
                            " are",
                            " looking",
                            " for",
                            " sponsorship",
                            " partners",
                            " but",
                            " we",
                            "'ve",
                            " spoken",
                            " to",
                            " other",
                            " airline",
                            " companies",
                            " globally",
                            " too",
                            " about",
                            " becoming",
                            " our",
                            " partners",
                            ".",
                            " Because",
                            " as",
                            " you",
                            " know",
                            ",",
                            " in",
                            " sponsorship",
                            " we",
                            " have",
                            " car",
                            " partners",
                            ",",
                            " airline",
                            " partners",
                            ",",
                            " bank",
                            " partners",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "96849",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.538,
                        "maxValueTokenIndex": 97,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.095,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.538,
                            7.401,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.036,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:27:56.860Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.274,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "5116",
            "description": "conversations involving questioning and dialogue",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5315572898651795,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "5116",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:07:05.556Z",
                "maxActApprox": 15.535,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    5116,
                    20666,
                    45200,
                    24457,
                    18317,
                    3247,
                    14042,
                    11790,
                    996,
                    35125,
                    10429,
                    19621,
                    1932,
                    20344,
                    23740,
                    38826,
                    22830,
                    44598,
                    10341,
                    21374,
                    23173,
                    3592,
                    42555,
                    4702,
                    7600
                ],
                "topkCosSimValues": [
                    1,
                    0.5558,
                    0.4854,
                    0.4738,
                    0.457,
                    0.4342,
                    0.4089,
                    0.3833,
                    0.3738,
                    0.3636,
                    0.3635,
                    0.363,
                    0.3595,
                    0.3587,
                    0.3561,
                    0.3557,
                    0.3555,
                    0.3539,
                    0.3536,
                    0.3532,
                    0.3528,
                    0.3515,
                    0.3511,
                    0.3504,
                    0.3479
                ],
                "neuron_alignment_indices": [
                    373,
                    495,
                    389
                ],
                "neuron_alignment_values": [
                    0.306,
                    0.095,
                    0.094
                ],
                "neuron_alignment_l1": [
                    0.016,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    373,
                    6,
                    107
                ],
                "correlated_neurons_pearson": [
                    0.041,
                    0.039,
                    0.035
                ],
                "correlated_neurons_l1": [
                    -0.015,
                    0.045,
                    0.032
                ],
                "correlated_features_indices": [
                    5044,
                    5102,
                    5029
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.003,
                    0.002,
                    0.001
                ],
                "neg_str": [
                    " confir",
                    " tremend",
                    "avorite",
                    " Manit",
                    " Pigs",
                    " bom",
                    "adelphia",
                    " autobi",
                    " encount",
                    " behavi"
                ],
                "neg_values": [
                    -0.68,
                    -0.674,
                    -0.66,
                    -0.641,
                    -0.636,
                    -0.616,
                    -0.612,
                    -0.594,
                    -0.593,
                    -0.584
                ],
                "pos_str": [
                    "\u00e2\u0136\u0122\u00e2\u0136\u0122",
                    "\u00e8\u00af",
                    " \u00e2\u0122\u0137",
                    "-\"",
                    "\u00e4\u00bd",
                    "\u00e2\u0136\u0122\u00e2\u0136\u0122\u00e2\u0136\u0122\u00e2\u0136\u0122",
                    "\u00e2\u0136\u0122",
                    "\u00e6\u013f",
                    "\u00c2\u00b7\u00c2\u00b7",
                    " \u00e2\u0136"
                ],
                "pos_values": [
                    0.712,
                    0.694,
                    0.641,
                    0.637,
                    0.625,
                    0.623,
                    0.613,
                    0.609,
                    0.603,
                    0.589
                ],
                "frac_nonzero": 0.00131,
                "freq_hist_data_bar_heights": [
                    666,
                    541,
                    397,
                    371,
                    300,
                    237,
                    220,
                    192,
                    154,
                    114,
                    110,
                    97,
                    95,
                    81,
                    67,
                    60,
                    45,
                    53,
                    34,
                    35,
                    31,
                    24,
                    24,
                    25,
                    24,
                    17,
                    7,
                    11,
                    14,
                    14,
                    9,
                    9,
                    5,
                    6,
                    4,
                    8,
                    7,
                    3,
                    6,
                    3,
                    2,
                    0,
                    2,
                    2,
                    0,
                    0,
                    3,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.156,
                    0.466,
                    0.777,
                    1.088,
                    1.398,
                    1.709,
                    2.02,
                    2.331,
                    2.641,
                    2.952,
                    3.263,
                    3.573,
                    3.884,
                    4.195,
                    4.505,
                    4.816,
                    5.127,
                    5.437,
                    5.748,
                    6.059,
                    6.37,
                    6.68,
                    6.991,
                    7.302,
                    7.612,
                    7.923,
                    8.234,
                    8.544,
                    8.855,
                    9.166,
                    9.476,
                    9.787,
                    10.098,
                    10.409,
                    10.719,
                    11.03,
                    11.341,
                    11.651,
                    11.962,
                    12.273,
                    12.583,
                    12.894,
                    13.205,
                    13.515,
                    13.826,
                    14.137,
                    14.448,
                    14.758,
                    15.069,
                    15.38
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    2,
                    2,
                    7,
                    8,
                    14,
                    16,
                    26,
                    42,
                    69,
                    130,
                    183,
                    306,
                    434,
                    632,
                    901,
                    1185,
                    1616,
                    1959,
                    2493,
                    2863,
                    3288,
                    3563,
                    3792,
                    3998,
                    3693,
                    3558,
                    3092,
                    2816,
                    2283,
                    1867,
                    1479,
                    1153,
                    857,
                    582,
                    448,
                    295,
                    219,
                    130,
                    95,
                    72,
                    32,
                    25,
                    12,
                    4,
                    4,
                    5,
                    2,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.666,
                    -0.639,
                    -0.611,
                    -0.583,
                    -0.555,
                    -0.527,
                    -0.499,
                    -0.472,
                    -0.444,
                    -0.416,
                    -0.388,
                    -0.36,
                    -0.332,
                    -0.304,
                    -0.277,
                    -0.249,
                    -0.221,
                    -0.193,
                    -0.165,
                    -0.137,
                    -0.11,
                    -0.082,
                    -0.054,
                    -0.026,
                    0.002,
                    0.03,
                    0.057,
                    0.085,
                    0.113,
                    0.141,
                    0.169,
                    0.197,
                    0.224,
                    0.252,
                    0.28,
                    0.308,
                    0.336,
                    0.364,
                    0.391,
                    0.419,
                    0.447,
                    0.475,
                    0.503,
                    0.531,
                    0.558,
                    0.586,
                    0.614,
                    0.642,
                    0.67,
                    0.698
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "conversations involving questioning and dialogue",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4fmy5gczni6668sgxc774",
                        "tokens": [
                            " it",
                            " over",
                            " a",
                            " few",
                            " times",
                            ".",
                            " His",
                            " face",
                            " took",
                            " on",
                            " that",
                            " serious",
                            ",",
                            " thinking",
                            " expression",
                            " I",
                            " recognized",
                            " meant",
                            " he",
                            " was",
                            " considering",
                            " how",
                            " to",
                            " phrase",
                            " something",
                            " important",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Al",
                            "aya",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "the",
                            " art",
                            " is",
                            " lovely",
                            ".",
                            " The",
                            " image",
                            " and",
                            " everything",
                            " is",
                            " great",
                            ".",
                            " But",
                            " are",
                            " you",
                            " sure",
                            " you",
                            " want",
                            " to",
                            " limit",
                            " yourself",
                            " like",
                            " that",
                            " with",
                            " this",
                            " cover",
                            "?",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Limit",
                            " myself",
                            "?",
                            "\u00e2\u0122",
                            "\u013f",
                            " I",
                            " asked",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "White",
                            " people",
                            " are",
                            " going",
                            " to",
                            " be",
                            " way",
                            " less",
                            " likely",
                            " to",
                            " pick",
                            " up",
                            " a",
                            " book",
                            " with",
                            " a",
                            " cover",
                            " featuring",
                            " a",
                            " brown",
                            " person",
                            ".",
                            " That",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " just",
                            " the",
                            " way",
                            " the",
                            " world",
                            " works",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "I",
                            " told",
                            " my",
                            " dad"
                        ],
                        "dataIndex": null,
                        "index": "5116",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.535,
                        "maxValueTokenIndex": 77,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.613,
                            0,
                            0,
                            0,
                            5.87,
                            7.122,
                            3.576,
                            1.922,
                            3.84,
                            3.85,
                            6.334,
                            0,
                            0,
                            0,
                            0,
                            0.25,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.935,
                            7.427,
                            8.227,
                            4.2,
                            4.932,
                            10.884,
                            9.648,
                            0,
                            0,
                            5.457,
                            15.535,
                            14.305,
                            8.056,
                            3.736,
                            7.114,
                            7.324,
                            9.046,
                            13.316,
                            10.861,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.801,
                            1.653,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.976,
                            6.254,
                            6.289,
                            7.952,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:07:14.640Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 15.535,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4fmy5gczqi666k5gh9ink",
                        "tokens": [
                            " it",
                            " over",
                            " a",
                            " few",
                            " times",
                            ".",
                            " His",
                            " face",
                            " took",
                            " on",
                            " that",
                            " serious",
                            ",",
                            " thinking",
                            " expression",
                            " I",
                            " recognized",
                            " meant",
                            " he",
                            " was",
                            " considering",
                            " how",
                            " to",
                            " phrase",
                            " something",
                            " important",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Al",
                            "aya",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "the",
                            " art",
                            " is",
                            " lovely",
                            ".",
                            " The",
                            " image",
                            " and",
                            " everything",
                            " is",
                            " great",
                            ".",
                            " But",
                            " are",
                            " you",
                            " sure",
                            " you",
                            " want",
                            " to",
                            " limit",
                            " yourself",
                            " like",
                            " that",
                            " with",
                            " this",
                            " cover",
                            "?",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Limit",
                            " myself",
                            "?",
                            "\u00e2\u0122",
                            "\u013f",
                            " I",
                            " asked",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "White",
                            " people",
                            " are",
                            " going",
                            " to",
                            " be",
                            " way",
                            " less",
                            " likely",
                            " to",
                            " pick",
                            " up",
                            " a",
                            " book",
                            " with",
                            " a",
                            " cover",
                            " featuring",
                            " a",
                            " brown",
                            " person",
                            ".",
                            " That",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " just",
                            " the",
                            " way",
                            " the",
                            " world",
                            " works",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "I",
                            " told",
                            " my",
                            " dad"
                        ],
                        "dataIndex": null,
                        "index": "5116",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.535,
                        "maxValueTokenIndex": 77,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.613,
                            0,
                            0,
                            0,
                            5.87,
                            7.122,
                            3.576,
                            1.922,
                            3.84,
                            3.85,
                            6.334,
                            0,
                            0,
                            0,
                            0,
                            0.25,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.935,
                            7.427,
                            8.227,
                            4.2,
                            4.932,
                            10.884,
                            9.648,
                            0,
                            0,
                            5.457,
                            15.535,
                            14.305,
                            8.056,
                            3.736,
                            7.114,
                            7.324,
                            9.046,
                            13.316,
                            10.861,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.801,
                            1.653,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.976,
                            6.254,
                            6.289,
                            7.952,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:07:14.640Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 15.535,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4fmy6gczti666tvdquue3",
                        "tokens": [
                            " it",
                            " over",
                            " a",
                            " few",
                            " times",
                            ".",
                            " His",
                            " face",
                            " took",
                            " on",
                            " that",
                            " serious",
                            ",",
                            " thinking",
                            " expression",
                            " I",
                            " recognized",
                            " meant",
                            " he",
                            " was",
                            " considering",
                            " how",
                            " to",
                            " phrase",
                            " something",
                            " important",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Al",
                            "aya",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "the",
                            " art",
                            " is",
                            " lovely",
                            ".",
                            " The",
                            " image",
                            " and",
                            " everything",
                            " is",
                            " great",
                            ".",
                            " But",
                            " are",
                            " you",
                            " sure",
                            " you",
                            " want",
                            " to",
                            " limit",
                            " yourself",
                            " like",
                            " that",
                            " with",
                            " this",
                            " cover",
                            "?",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Limit",
                            " myself",
                            "?",
                            "\u00e2\u0122",
                            "\u013f",
                            " I",
                            " asked",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "White",
                            " people",
                            " are",
                            " going",
                            " to",
                            " be",
                            " way",
                            " less",
                            " likely",
                            " to",
                            " pick",
                            " up",
                            " a",
                            " book",
                            " with",
                            " a",
                            " cover",
                            " featuring",
                            " a",
                            " brown",
                            " person",
                            ".",
                            " That",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " just",
                            " the",
                            " way",
                            " the",
                            " world",
                            " works",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "I",
                            " told",
                            " my",
                            " dad"
                        ],
                        "dataIndex": null,
                        "index": "5116",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.535,
                        "maxValueTokenIndex": 77,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.613,
                            0,
                            0,
                            0,
                            5.87,
                            7.122,
                            3.576,
                            1.922,
                            3.84,
                            3.85,
                            6.334,
                            0,
                            0,
                            0,
                            0,
                            0.25,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.935,
                            7.427,
                            8.227,
                            4.2,
                            4.932,
                            10.884,
                            9.648,
                            0,
                            0,
                            5.457,
                            15.535,
                            14.305,
                            8.056,
                            3.736,
                            7.114,
                            7.324,
                            9.046,
                            13.316,
                            10.861,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.801,
                            1.653,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.976,
                            6.254,
                            6.289,
                            7.952,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:07:14.640Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 15.535,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "24823",
            "description": "actions and experiences related to interaction and engagement",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5295100492531041,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "24823",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:00:46.281Z",
                "maxActApprox": 33.165,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    24823,
                    71284,
                    33399,
                    88634,
                    37124,
                    30132,
                    56480,
                    61885,
                    67927,
                    27939,
                    54928,
                    45413,
                    14848,
                    12773,
                    63656,
                    78306,
                    68114,
                    72827,
                    13495,
                    57010,
                    31471,
                    93555,
                    21191,
                    9540,
                    46980
                ],
                "topkCosSimValues": [
                    1,
                    0.6577,
                    0.5434,
                    0.5337,
                    0.5018,
                    0.491,
                    0.4718,
                    0.4581,
                    0.4457,
                    0.4432,
                    0.4386,
                    0.4357,
                    0.4347,
                    0.4324,
                    0.4104,
                    0.3995,
                    0.393,
                    0.3897,
                    0.3885,
                    0.3824,
                    0.3696,
                    0.349,
                    0.3484,
                    0.3327,
                    0.3241
                ],
                "neuron_alignment_indices": [
                    157,
                    143,
                    508
                ],
                "neuron_alignment_values": [
                    0.128,
                    0.109,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    157,
                    587,
                    271
                ],
                "correlated_neurons_pearson": [
                    0.013,
                    0.011,
                    0.011
                ],
                "correlated_neurons_l1": [
                    0.013,
                    0.012,
                    0.01
                ],
                "correlated_features_indices": [
                    24932,
                    24839,
                    24882
                ],
                "correlated_features_pearson": [
                    0.001,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0,
                    0
                ],
                "neg_str": [
                    "arily",
                    "ovi",
                    "andre",
                    "RIP",
                    "geries",
                    "aries",
                    "eg",
                    "hip",
                    "ow",
                    "istence"
                ],
                "neg_values": [
                    -0.759,
                    -0.7,
                    -0.659,
                    -0.653,
                    -0.653,
                    -0.652,
                    -0.652,
                    -0.649,
                    -0.649,
                    -0.643
                ],
                "pos_str": [
                    "odox",
                    " town",
                    " brainstorm",
                    "essage",
                    "ILD",
                    " crazy",
                    "bilt",
                    "iliar",
                    " Auckland",
                    "ModLoader"
                ],
                "pos_values": [
                    0.707,
                    0.671,
                    0.655,
                    0.634,
                    0.633,
                    0.631,
                    0.612,
                    0.609,
                    0.602,
                    0.597
                ],
                "frac_nonzero": 8.999999999999999e-05,
                "freq_hist_data_bar_heights": [
                    67,
                    56,
                    37,
                    29,
                    20,
                    17,
                    12,
                    6,
                    5,
                    5,
                    5,
                    6,
                    2,
                    1,
                    1,
                    1,
                    1,
                    3,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    1,
                    2,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.341,
                    1.004,
                    1.667,
                    2.33,
                    2.993,
                    3.656,
                    4.319,
                    4.983,
                    5.646,
                    6.309,
                    6.972,
                    7.635,
                    8.298,
                    8.961,
                    9.624,
                    10.288,
                    10.951,
                    11.614,
                    12.277,
                    12.94,
                    13.603,
                    14.266,
                    14.929,
                    15.592,
                    16.256,
                    16.919,
                    17.582,
                    18.245,
                    18.908,
                    19.571,
                    20.234,
                    20.897,
                    21.56,
                    22.224,
                    22.887,
                    23.55,
                    24.213,
                    24.876,
                    25.539,
                    26.202,
                    26.865,
                    27.529,
                    28.192,
                    28.855,
                    29.518,
                    30.181,
                    30.844,
                    31.507,
                    32.17,
                    32.833
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    8,
                    5,
                    9,
                    16,
                    30,
                    32,
                    66,
                    92,
                    121,
                    214,
                    239,
                    420,
                    564,
                    838,
                    1038,
                    1445,
                    1799,
                    2148,
                    2612,
                    2963,
                    3343,
                    3594,
                    3742,
                    3728,
                    3534,
                    3423,
                    3018,
                    2669,
                    2174,
                    1737,
                    1322,
                    1004,
                    796,
                    504,
                    345,
                    238,
                    163,
                    114,
                    56,
                    30,
                    25,
                    15,
                    12,
                    4,
                    3,
                    2,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.745,
                    -0.715,
                    -0.686,
                    -0.657,
                    -0.627,
                    -0.598,
                    -0.569,
                    -0.539,
                    -0.51,
                    -0.481,
                    -0.451,
                    -0.422,
                    -0.393,
                    -0.363,
                    -0.334,
                    -0.305,
                    -0.275,
                    -0.246,
                    -0.217,
                    -0.187,
                    -0.158,
                    -0.129,
                    -0.099,
                    -0.07,
                    -0.041,
                    -0.011,
                    0.018,
                    0.047,
                    0.077,
                    0.106,
                    0.135,
                    0.165,
                    0.194,
                    0.223,
                    0.253,
                    0.282,
                    0.311,
                    0.341,
                    0.37,
                    0.399,
                    0.429,
                    0.458,
                    0.487,
                    0.517,
                    0.546,
                    0.575,
                    0.605,
                    0.634,
                    0.663,
                    0.693
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "actions and experiences related to interaction and engagement",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "phrases that describe activities or interactions involving playfulness or experimentation",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygg1h6au4i610exkdy25ano",
                        "tokens": [
                            " post",
                            " Dmitry",
                            " (",
                            "aka",
                            " DL",
                            "ed",
                            ")",
                            " is",
                            " inspired",
                            " to",
                            " replicate",
                            " Ruby",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " syntax",
                            " for",
                            " repeating",
                            " actions",
                            ".",
                            " In",
                            " Ruby",
                            " we",
                            " can",
                            " write",
                            ":",
                            "\n",
                            "\n",
                            "42",
                            ".",
                            "times",
                            " do",
                            " ...",
                            "\n",
                            "\n",
                            "Where",
                            " \u00e2\u0122\u00a6",
                            " is",
                            " some",
                            " bit",
                            " of",
                            " code",
                            " to",
                            " be",
                            " repeated",
                            ",",
                            " in",
                            " this",
                            " case",
                            ",",
                            " forty",
                            "-",
                            "two",
                            " times",
                            ".",
                            " Dmitry",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " blog",
                            " shows",
                            " off",
                            " the",
                            " Modern",
                            " C",
                            "++",
                            " feature",
                            " of",
                            " user",
                            "-",
                            "defined",
                            " liter",
                            "als",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " a",
                            " bit",
                            " old",
                            " school",
                            " on",
                            " this",
                            " and",
                            " I",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " care",
                            " for",
                            " that",
                            " syntax",
                            ".",
                            " But",
                            " the",
                            " post",
                            " did",
                            " inspire",
                            " me",
                            " to",
                            " play",
                            " around",
                            " with",
                            " how",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " implement",
                            " this",
                            " with",
                            " a",
                            " more",
                            " traditional",
                            " syntax",
                            ".",
                            " Along",
                            " the",
                            " way",
                            " we",
                            "\u00e2\u0122",
                            "\u013b"
                        ],
                        "dataIndex": null,
                        "index": "24823",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 33.165,
                        "maxValueTokenIndex": 106,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.902,
                            33.165,
                            3.993,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:00:46.968Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 33.165,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygg1h6cu4iq10ex3dsytavv",
                        "tokens": [
                            " post",
                            " Dmitry",
                            " (",
                            "aka",
                            " DL",
                            "ed",
                            ")",
                            " is",
                            " inspired",
                            " to",
                            " replicate",
                            " Ruby",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " syntax",
                            " for",
                            " repeating",
                            " actions",
                            ".",
                            " In",
                            " Ruby",
                            " we",
                            " can",
                            " write",
                            ":",
                            "\n",
                            "\n",
                            "42",
                            ".",
                            "times",
                            " do",
                            " ...",
                            "\n",
                            "\n",
                            "Where",
                            " \u00e2\u0122\u00a6",
                            " is",
                            " some",
                            " bit",
                            " of",
                            " code",
                            " to",
                            " be",
                            " repeated",
                            ",",
                            " in",
                            " this",
                            " case",
                            ",",
                            " forty",
                            "-",
                            "two",
                            " times",
                            ".",
                            " Dmitry",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " blog",
                            " shows",
                            " off",
                            " the",
                            " Modern",
                            " C",
                            "++",
                            " feature",
                            " of",
                            " user",
                            "-",
                            "defined",
                            " liter",
                            "als",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " a",
                            " bit",
                            " old",
                            " school",
                            " on",
                            " this",
                            " and",
                            " I",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " care",
                            " for",
                            " that",
                            " syntax",
                            ".",
                            " But",
                            " the",
                            " post",
                            " did",
                            " inspire",
                            " me",
                            " to",
                            " play",
                            " around",
                            " with",
                            " how",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " implement",
                            " this",
                            " with",
                            " a",
                            " more",
                            " traditional",
                            " syntax",
                            ".",
                            " Along",
                            " the",
                            " way",
                            " we",
                            "\u00e2\u0122",
                            "\u013b"
                        ],
                        "dataIndex": null,
                        "index": "24823",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 33.165,
                        "maxValueTokenIndex": 106,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.902,
                            33.165,
                            3.993,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:00:46.968Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 26.532,
                        "binMax": 33.165,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygg1h6au4i710exv9oyurmx",
                        "tokens": [
                            " tendency",
                            " to",
                            " hesitate",
                            " on",
                            " my",
                            " shot",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " N",
                            "til",
                            "ik",
                            "ina",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Now",
                            " I",
                            " feel",
                            " more",
                            " comfortable",
                            " while",
                            " getting",
                            " a",
                            " lot",
                            " of",
                            " reps",
                            ".",
                            " H",
                            "itting",
                            " shots",
                            " in",
                            " the",
                            " real",
                            " game",
                            " gives",
                            " me",
                            " confidence",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Yeah",
                            ",",
                            " those",
                            " phony",
                            " games",
                            " rarely",
                            " help",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "I",
                            " just",
                            " need",
                            " to",
                            " keep",
                            " working",
                            ",",
                            " keep",
                            " getting",
                            " reps",
                            ",",
                            " keep",
                            " taking",
                            " those",
                            " shots",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "And",
                            " keep",
                            " avoiding",
                            " all",
                            " that",
                            " thinking",
                            ".",
                            "<|endoftext|>",
                            "Last",
                            " weekend",
                            " I",
                            " was",
                            " playing",
                            " around",
                            " with",
                            " a",
                            " way",
                            " to",
                            " represent",
                            " null",
                            "-",
                            "termin",
                            "ated",
                            " UTF",
                            "8",
                            " strings",
                            " in",
                            " Rust",
                            ".",
                            " Rather",
                            " than",
                            " just",
                            " to",
                            "ying",
                            " with",
                            " it",
                            " forever",
                            ",",
                            " I",
                            " decided",
                            " to",
                            " clean",
                            " up",
                            " a",
                            " minimal",
                            " version",
                            " and",
                            " publish"
                        ],
                        "dataIndex": null,
                        "index": "24823",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 31.747,
                        "maxValueTokenIndex": 92,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            31.747,
                            1.415,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:00:46.968Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 33.165,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "13957",
            "description": "discussions around community engagement and shared experiences",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5281933546066284,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "13957",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:45:24.414Z",
                "maxActApprox": 8.67,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    13957,
                    44976,
                    53445,
                    13735,
                    88973,
                    81612,
                    82087,
                    25348,
                    58210,
                    70808,
                    36307,
                    8765,
                    17278,
                    10459,
                    43341,
                    92515,
                    34947,
                    19260,
                    66198,
                    27096,
                    74367,
                    76745,
                    97736,
                    70016,
                    71300
                ],
                "topkCosSimValues": [
                    1,
                    0.4884,
                    0.4883,
                    0.4695,
                    0.4674,
                    0.4667,
                    0.4617,
                    0.4611,
                    0.4579,
                    0.4511,
                    0.4508,
                    0.4459,
                    0.4442,
                    0.4328,
                    0.432,
                    0.4315,
                    0.4282,
                    0.4271,
                    0.4256,
                    0.4251,
                    0.4251,
                    0.4245,
                    0.4242,
                    0.4213,
                    0.4207
                ],
                "neuron_alignment_indices": [
                    87,
                    756,
                    370
                ],
                "neuron_alignment_values": [
                    0.35,
                    0.097,
                    0.08
                ],
                "neuron_alignment_l1": [
                    0.018,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    87,
                    756,
                    393
                ],
                "correlated_neurons_pearson": [
                    0.052,
                    0.032,
                    0.025
                ],
                "correlated_neurons_l1": [
                    -0.008,
                    -0.012,
                    0.049
                ],
                "correlated_features_indices": [
                    13983,
                    13974,
                    13955
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.007,
                    0.004,
                    0.004
                ],
                "neg_str": [
                    " BASE",
                    "icide",
                    " tether",
                    "inventoryQuantity",
                    "aunder",
                    " starve",
                    " destroyer",
                    "AFP",
                    " ILCS",
                    "morrow"
                ],
                "neg_values": [
                    -0.649,
                    -0.641,
                    -0.605,
                    -0.592,
                    -0.589,
                    -0.587,
                    -0.582,
                    -0.579,
                    -0.578,
                    -0.576
                ],
                "pos_str": [
                    " respondents",
                    " varied",
                    " responses",
                    " testim",
                    " unanimous",
                    " insightful",
                    " informative",
                    " answered",
                    " queries",
                    " respondent"
                ],
                "pos_values": [
                    1.007,
                    0.908,
                    0.851,
                    0.828,
                    0.824,
                    0.787,
                    0.772,
                    0.772,
                    0.751,
                    0.747
                ],
                "frac_nonzero": 0.00347,
                "freq_hist_data_bar_heights": [
                    1737,
                    1431,
                    1249,
                    1068,
                    976,
                    725,
                    654,
                    535,
                    429,
                    364,
                    287,
                    275,
                    211,
                    173,
                    142,
                    94,
                    95,
                    75,
                    74,
                    53,
                    45,
                    32,
                    41,
                    33,
                    14,
                    21,
                    18,
                    14,
                    10,
                    9,
                    5,
                    7,
                    6,
                    1,
                    6,
                    3,
                    4,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.087,
                    0.26,
                    0.434,
                    0.607,
                    0.78,
                    0.954,
                    1.127,
                    1.3,
                    1.474,
                    1.647,
                    1.821,
                    1.994,
                    2.167,
                    2.341,
                    2.514,
                    2.688,
                    2.861,
                    3.034,
                    3.208,
                    3.381,
                    3.555,
                    3.728,
                    3.901,
                    4.075,
                    4.248,
                    4.421,
                    4.595,
                    4.768,
                    4.942,
                    5.115,
                    5.288,
                    5.462,
                    5.635,
                    5.809,
                    5.982,
                    6.155,
                    6.329,
                    6.502,
                    6.676,
                    6.849,
                    7.022,
                    7.196,
                    7.369,
                    7.542,
                    7.716,
                    7.889,
                    8.063,
                    8.236,
                    8.409,
                    8.583
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    4,
                    8,
                    14,
                    17,
                    35,
                    75,
                    128,
                    227,
                    378,
                    619,
                    967,
                    1441,
                    2025,
                    2589,
                    3293,
                    3723,
                    4008,
                    4226,
                    4313,
                    3961,
                    3602,
                    3036,
                    2832,
                    2130,
                    1647,
                    1301,
                    981,
                    687,
                    492,
                    402,
                    305,
                    219,
                    165,
                    120,
                    102,
                    63,
                    39,
                    31,
                    17,
                    12,
                    10,
                    5,
                    1,
                    2,
                    1,
                    0,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.633,
                    -0.6,
                    -0.567,
                    -0.533,
                    -0.5,
                    -0.467,
                    -0.434,
                    -0.401,
                    -0.368,
                    -0.335,
                    -0.302,
                    -0.268,
                    -0.235,
                    -0.202,
                    -0.169,
                    -0.136,
                    -0.103,
                    -0.07,
                    -0.037,
                    -0.003,
                    0.03,
                    0.063,
                    0.096,
                    0.129,
                    0.162,
                    0.195,
                    0.228,
                    0.262,
                    0.295,
                    0.328,
                    0.361,
                    0.394,
                    0.427,
                    0.46,
                    0.493,
                    0.526,
                    0.56,
                    0.593,
                    0.626,
                    0.659,
                    0.692,
                    0.725,
                    0.758,
                    0.791,
                    0.825,
                    0.858,
                    0.891,
                    0.924,
                    0.957,
                    0.99
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "quantitative data and responses related to surveys or questions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "discussions around community engagement and shared experiences",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfhso9lvja10exkg85tr9g",
                        "tokens": [
                            ".",
                            " We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " included",
                            " several",
                            " pie",
                            " and",
                            " bar",
                            " graphs",
                            " to",
                            " make",
                            " the",
                            " data",
                            " a",
                            " bit",
                            " easier",
                            " to",
                            " digest",
                            ".",
                            "\n",
                            "\n",
                            "Feel",
                            " free",
                            " to",
                            " browse",
                            " through",
                            " the",
                            " results",
                            " and",
                            " compare",
                            " them",
                            " to",
                            " your",
                            " own",
                            " workout",
                            " experiences",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " may",
                            " be",
                            " shocked",
                            " by",
                            " how",
                            " you",
                            " and",
                            " your",
                            " friends",
                            " stack",
                            " up",
                            " to",
                            " the",
                            " numbers",
                            ".",
                            "\n",
                            "\n",
                            "Big",
                            "gest",
                            " challenges",
                            " when",
                            " working",
                            " out",
                            "\n",
                            "\n",
                            "Let",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " kick",
                            " things",
                            " off",
                            " by",
                            " discussing",
                            " the",
                            " biggest",
                            " challenges",
                            " you",
                            " all",
                            " face",
                            " when",
                            " it",
                            " comes",
                            " to",
                            " working",
                            " out",
                            ".",
                            " This",
                            " question",
                            " was",
                            " an",
                            " open",
                            " ended",
                            " question",
                            " and",
                            " we",
                            " received",
                            " thousands",
                            " of",
                            " replies",
                            ".",
                            " From",
                            " there",
                            ",",
                            " we",
                            " categorized",
                            " them",
                            " into",
                            " the",
                            " following",
                            ":",
                            "\n",
                            "\n",
                            "As",
                            " you",
                            " can",
                            " see",
                            ",",
                            " the",
                            " number",
                            " one",
                            " challenge",
                            " of",
                            " those",
                            " who"
                        ],
                        "dataIndex": null,
                        "index": "13957",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.67,
                        "maxValueTokenIndex": 103,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.008,
                            0,
                            1.717,
                            0,
                            1.594,
                            0.405,
                            0.992,
                            4.39,
                            4.554,
                            6.359,
                            5.46,
                            5.023,
                            8.67,
                            2.001,
                            4.906,
                            3.485,
                            3.667,
                            3.396,
                            2.03,
                            2.027,
                            2.324,
                            4.397,
                            4.955,
                            3.87,
                            4.208,
                            2.058,
                            0,
                            0,
                            4.15,
                            3.891,
                            4.064,
                            3.292,
                            0,
                            0,
                            0.561,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:45:28.754Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 8.669,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfhsoalvje10ex1z5ydakm",
                        "tokens": [
                            ".",
                            " We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " included",
                            " several",
                            " pie",
                            " and",
                            " bar",
                            " graphs",
                            " to",
                            " make",
                            " the",
                            " data",
                            " a",
                            " bit",
                            " easier",
                            " to",
                            " digest",
                            ".",
                            "\n",
                            "\n",
                            "Feel",
                            " free",
                            " to",
                            " browse",
                            " through",
                            " the",
                            " results",
                            " and",
                            " compare",
                            " them",
                            " to",
                            " your",
                            " own",
                            " workout",
                            " experiences",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " may",
                            " be",
                            " shocked",
                            " by",
                            " how",
                            " you",
                            " and",
                            " your",
                            " friends",
                            " stack",
                            " up",
                            " to",
                            " the",
                            " numbers",
                            ".",
                            "\n",
                            "\n",
                            "Big",
                            "gest",
                            " challenges",
                            " when",
                            " working",
                            " out",
                            "\n",
                            "\n",
                            "Let",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " kick",
                            " things",
                            " off",
                            " by",
                            " discussing",
                            " the",
                            " biggest",
                            " challenges",
                            " you",
                            " all",
                            " face",
                            " when",
                            " it",
                            " comes",
                            " to",
                            " working",
                            " out",
                            ".",
                            " This",
                            " question",
                            " was",
                            " an",
                            " open",
                            " ended",
                            " question",
                            " and",
                            " we",
                            " received",
                            " thousands",
                            " of",
                            " replies",
                            ".",
                            " From",
                            " there",
                            ",",
                            " we",
                            " categorized",
                            " them",
                            " into",
                            " the",
                            " following",
                            ":",
                            "\n",
                            "\n",
                            "As",
                            " you",
                            " can",
                            " see",
                            ",",
                            " the",
                            " number",
                            " one",
                            " challenge",
                            " of",
                            " those",
                            " who"
                        ],
                        "dataIndex": null,
                        "index": "13957",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.67,
                        "maxValueTokenIndex": 103,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.008,
                            0,
                            1.717,
                            0,
                            1.594,
                            0.405,
                            0.992,
                            4.39,
                            4.554,
                            6.359,
                            5.46,
                            5.023,
                            8.67,
                            2.001,
                            4.906,
                            3.485,
                            3.667,
                            3.396,
                            2.03,
                            2.027,
                            2.324,
                            4.397,
                            4.955,
                            3.87,
                            4.208,
                            2.058,
                            0,
                            0,
                            4.15,
                            3.891,
                            4.064,
                            3.292,
                            0,
                            0,
                            0.561,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:45:28.754Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 8.669,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfhsoblvju10exidlqx6ng",
                        "tokens": [
                            ".",
                            " We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " included",
                            " several",
                            " pie",
                            " and",
                            " bar",
                            " graphs",
                            " to",
                            " make",
                            " the",
                            " data",
                            " a",
                            " bit",
                            " easier",
                            " to",
                            " digest",
                            ".",
                            "\n",
                            "\n",
                            "Feel",
                            " free",
                            " to",
                            " browse",
                            " through",
                            " the",
                            " results",
                            " and",
                            " compare",
                            " them",
                            " to",
                            " your",
                            " own",
                            " workout",
                            " experiences",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " may",
                            " be",
                            " shocked",
                            " by",
                            " how",
                            " you",
                            " and",
                            " your",
                            " friends",
                            " stack",
                            " up",
                            " to",
                            " the",
                            " numbers",
                            ".",
                            "\n",
                            "\n",
                            "Big",
                            "gest",
                            " challenges",
                            " when",
                            " working",
                            " out",
                            "\n",
                            "\n",
                            "Let",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " kick",
                            " things",
                            " off",
                            " by",
                            " discussing",
                            " the",
                            " biggest",
                            " challenges",
                            " you",
                            " all",
                            " face",
                            " when",
                            " it",
                            " comes",
                            " to",
                            " working",
                            " out",
                            ".",
                            " This",
                            " question",
                            " was",
                            " an",
                            " open",
                            " ended",
                            " question",
                            " and",
                            " we",
                            " received",
                            " thousands",
                            " of",
                            " replies",
                            ".",
                            " From",
                            " there",
                            ",",
                            " we",
                            " categorized",
                            " them",
                            " into",
                            " the",
                            " following",
                            ":",
                            "\n",
                            "\n",
                            "As",
                            " you",
                            " can",
                            " see",
                            ",",
                            " the",
                            " number",
                            " one",
                            " challenge",
                            " of",
                            " those",
                            " who"
                        ],
                        "dataIndex": null,
                        "index": "13957",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.67,
                        "maxValueTokenIndex": 103,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.008,
                            0,
                            1.717,
                            0,
                            1.594,
                            0.405,
                            0.992,
                            4.39,
                            4.554,
                            6.359,
                            5.46,
                            5.023,
                            8.67,
                            2.001,
                            4.906,
                            3.485,
                            3.667,
                            3.396,
                            2.03,
                            2.027,
                            2.324,
                            4.397,
                            4.955,
                            3.87,
                            4.208,
                            2.058,
                            0,
                            0,
                            4.15,
                            3.891,
                            4.064,
                            3.292,
                            0,
                            0,
                            0.561,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:45:28.754Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 6.936,
                        "binMax": 8.669,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}