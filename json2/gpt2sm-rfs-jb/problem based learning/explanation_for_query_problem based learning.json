{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "problem based learning"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "44599",
            "description": "questions and statements related to understanding, acquiring knowledge, and programming",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5560880899429321,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "44599",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:30:01.882Z",
                "maxActApprox": 8.711,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    44599,
                    93059,
                    76518,
                    21927,
                    1262,
                    89190,
                    61505,
                    15981,
                    10384,
                    82742,
                    13268,
                    62988,
                    20625,
                    98181,
                    43341,
                    24843,
                    77132,
                    41738,
                    96369,
                    72975,
                    8608,
                    19771,
                    48954,
                    69702,
                    96180
                ],
                "topkCosSimValues": [
                    1,
                    0.5121,
                    0.5104,
                    0.5036,
                    0.5032,
                    0.5002,
                    0.4851,
                    0.4733,
                    0.4663,
                    0.4619,
                    0.4595,
                    0.4516,
                    0.4416,
                    0.4385,
                    0.4338,
                    0.4313,
                    0.4309,
                    0.4286,
                    0.4281,
                    0.4272,
                    0.424,
                    0.4234,
                    0.4196,
                    0.4181,
                    0.4167
                ],
                "neuron_alignment_indices": [
                    87,
                    481,
                    246
                ],
                "neuron_alignment_values": [
                    0.297,
                    0.132,
                    0.117
                ],
                "neuron_alignment_l1": [
                    0.015,
                    0.007,
                    0.006
                ],
                "correlated_neurons_indices": [
                    87,
                    570,
                    184
                ],
                "correlated_neurons_pearson": [
                    0.051,
                    0.047,
                    0.038
                ],
                "correlated_neurons_l1": [
                    -0.018,
                    0.02,
                    0.022
                ],
                "correlated_features_indices": [
                    44646,
                    44607,
                    44617
                ],
                "correlated_features_pearson": [
                    0.02,
                    0.013,
                    0.007
                ],
                "correlated_features_l1": [
                    0.022,
                    0.014,
                    0.009
                ],
                "neg_str": [
                    "taboola",
                    "Tip",
                    "iatus",
                    "Writer",
                    "ieu",
                    "\u00e9\u00be\u012f",
                    "idelines",
                    "herty",
                    "\u00c4\u0141",
                    "Prep"
                ],
                "neg_values": [
                    -0.593,
                    -0.545,
                    -0.52,
                    -0.501,
                    -0.498,
                    -0.496,
                    -0.495,
                    -0.493,
                    -0.484,
                    -0.469
                ],
                "pos_str": [
                    " oneself",
                    " yourself",
                    "ntil",
                    " anymore",
                    " meaningful",
                    " these",
                    " difference",
                    " anytime",
                    "ivably",
                    " such"
                ],
                "pos_values": [
                    0.757,
                    0.676,
                    0.627,
                    0.623,
                    0.619,
                    0.618,
                    0.609,
                    0.605,
                    0.599,
                    0.582
                ],
                "frac_nonzero": 0.005500000000000001,
                "freq_hist_data_bar_heights": [
                    2532,
                    2202,
                    1892,
                    1648,
                    1434,
                    1193,
                    1009,
                    832,
                    752,
                    665,
                    556,
                    453,
                    366,
                    293,
                    265,
                    217,
                    182,
                    144,
                    125,
                    100,
                    66,
                    64,
                    65,
                    48,
                    31,
                    36,
                    29,
                    21,
                    20,
                    9,
                    8,
                    4,
                    9,
                    2,
                    7,
                    3,
                    1,
                    0,
                    1,
                    2,
                    0,
                    0,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.087,
                    0.261,
                    0.436,
                    0.61,
                    0.784,
                    0.958,
                    1.132,
                    1.307,
                    1.481,
                    1.655,
                    1.829,
                    2.004,
                    2.178,
                    2.352,
                    2.526,
                    2.7,
                    2.875,
                    3.049,
                    3.223,
                    3.397,
                    3.571,
                    3.746,
                    3.92,
                    4.094,
                    4.268,
                    4.443,
                    4.617,
                    4.791,
                    4.965,
                    5.139,
                    5.314,
                    5.488,
                    5.662,
                    5.836,
                    6.01,
                    6.185,
                    6.359,
                    6.533,
                    6.707,
                    6.882,
                    7.056,
                    7.23,
                    7.404,
                    7.578,
                    7.753,
                    7.927,
                    8.101,
                    8.275,
                    8.449,
                    8.624
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    1,
                    5,
                    3,
                    10,
                    18,
                    33,
                    46,
                    113,
                    169,
                    277,
                    462,
                    742,
                    1081,
                    1539,
                    2092,
                    2803,
                    3350,
                    3971,
                    4372,
                    4585,
                    4400,
                    4249,
                    3752,
                    3198,
                    2492,
                    1869,
                    1449,
                    1044,
                    716,
                    509,
                    292,
                    200,
                    142,
                    88,
                    56,
                    48,
                    28,
                    16,
                    10,
                    7,
                    5,
                    4,
                    5,
                    2,
                    0,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.58,
                    -0.553,
                    -0.526,
                    -0.499,
                    -0.472,
                    -0.445,
                    -0.418,
                    -0.391,
                    -0.364,
                    -0.337,
                    -0.31,
                    -0.283,
                    -0.256,
                    -0.229,
                    -0.202,
                    -0.175,
                    -0.148,
                    -0.121,
                    -0.094,
                    -0.067,
                    -0.04,
                    -0.013,
                    0.014,
                    0.041,
                    0.068,
                    0.095,
                    0.122,
                    0.149,
                    0.176,
                    0.203,
                    0.23,
                    0.257,
                    0.284,
                    0.311,
                    0.338,
                    0.365,
                    0.392,
                    0.419,
                    0.446,
                    0.473,
                    0.5,
                    0.527,
                    0.554,
                    0.581,
                    0.608,
                    0.635,
                    0.662,
                    0.689,
                    0.716,
                    0.743
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions and statements related to understanding, acquiring knowledge, and programming",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " inquiries about understanding and learning complex concepts or skills",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygh36m492w610exhlvwy49b",
                        "tokens": [
                            " personal",
                            " too",
                            ",",
                            " and",
                            " it",
                            " is",
                            " impossible",
                            " to",
                            " convey",
                            " the",
                            " nature",
                            " and",
                            " impact",
                            " of",
                            " any",
                            " neurological",
                            " condition",
                            " without",
                            " entering",
                            " and",
                            " describing",
                            " the",
                            " lives",
                            " of",
                            " individual",
                            " patients",
                            ".\"",
                            "\n",
                            "\n",
                            "Case",
                            " histories",
                            " are",
                            " the",
                            " only",
                            " place",
                            " in",
                            " the",
                            " medical",
                            " literature",
                            " where",
                            " we",
                            " see",
                            ",",
                            " if",
                            " not",
                            " the",
                            " whole",
                            " patient",
                            ",",
                            " at",
                            " least",
                            " enough",
                            " to",
                            " get",
                            " a",
                            " picture",
                            " of",
                            " a",
                            " living",
                            " human",
                            " being",
                            ".",
                            "\n",
                            "\n",
                            "Case",
                            " histories",
                            " can",
                            " make",
                            " hundreds",
                            " of",
                            " observations",
                            " about",
                            " a",
                            " few",
                            " people",
                            ",",
                            " and",
                            " thus",
                            " may",
                            " not",
                            " be",
                            " representative",
                            " of",
                            " the",
                            " larger",
                            " population",
                            ";",
                            " group",
                            " studies",
                            " on",
                            " the",
                            " other",
                            " hand",
                            ",",
                            " make",
                            " a",
                            " few",
                            " observations",
                            " about",
                            " many",
                            " people",
                            ".",
                            " The",
                            " question",
                            " is",
                            ":",
                            " Is",
                            " it",
                            " possible",
                            " to",
                            " understand",
                            " a",
                            " person",
                            " with",
                            " a",
                            " brain",
                            " illness",
                            ",",
                            " by",
                            " describing",
                            " him",
                            " or",
                            " her",
                            " in",
                            " bits",
                            " and",
                            " pieces"
                        ],
                        "dataIndex": null,
                        "index": "44599",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.711,
                        "maxValueTokenIndex": 110,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.746,
                            0.774,
                            0.672,
                            3.146,
                            8.711,
                            6.245,
                            5.608,
                            4.561,
                            1.279,
                            0,
                            0,
                            0.858,
                            1.861,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:30:06.240Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 8.711,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh36m492we10exqx0ptlno",
                        "tokens": [
                            " personal",
                            " too",
                            ",",
                            " and",
                            " it",
                            " is",
                            " impossible",
                            " to",
                            " convey",
                            " the",
                            " nature",
                            " and",
                            " impact",
                            " of",
                            " any",
                            " neurological",
                            " condition",
                            " without",
                            " entering",
                            " and",
                            " describing",
                            " the",
                            " lives",
                            " of",
                            " individual",
                            " patients",
                            ".\"",
                            "\n",
                            "\n",
                            "Case",
                            " histories",
                            " are",
                            " the",
                            " only",
                            " place",
                            " in",
                            " the",
                            " medical",
                            " literature",
                            " where",
                            " we",
                            " see",
                            ",",
                            " if",
                            " not",
                            " the",
                            " whole",
                            " patient",
                            ",",
                            " at",
                            " least",
                            " enough",
                            " to",
                            " get",
                            " a",
                            " picture",
                            " of",
                            " a",
                            " living",
                            " human",
                            " being",
                            ".",
                            "\n",
                            "\n",
                            "Case",
                            " histories",
                            " can",
                            " make",
                            " hundreds",
                            " of",
                            " observations",
                            " about",
                            " a",
                            " few",
                            " people",
                            ",",
                            " and",
                            " thus",
                            " may",
                            " not",
                            " be",
                            " representative",
                            " of",
                            " the",
                            " larger",
                            " population",
                            ";",
                            " group",
                            " studies",
                            " on",
                            " the",
                            " other",
                            " hand",
                            ",",
                            " make",
                            " a",
                            " few",
                            " observations",
                            " about",
                            " many",
                            " people",
                            ".",
                            " The",
                            " question",
                            " is",
                            ":",
                            " Is",
                            " it",
                            " possible",
                            " to",
                            " understand",
                            " a",
                            " person",
                            " with",
                            " a",
                            " brain",
                            " illness",
                            ",",
                            " by",
                            " describing",
                            " him",
                            " or",
                            " her",
                            " in",
                            " bits",
                            " and",
                            " pieces"
                        ],
                        "dataIndex": null,
                        "index": "44599",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.711,
                        "maxValueTokenIndex": 110,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.746,
                            0.774,
                            0.672,
                            3.146,
                            8.711,
                            6.245,
                            5.608,
                            4.561,
                            1.279,
                            0,
                            0,
                            0.858,
                            1.861,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:30:06.240Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 8.711,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh36m692wt10ex3nt41hdw",
                        "tokens": [
                            " personal",
                            " too",
                            ",",
                            " and",
                            " it",
                            " is",
                            " impossible",
                            " to",
                            " convey",
                            " the",
                            " nature",
                            " and",
                            " impact",
                            " of",
                            " any",
                            " neurological",
                            " condition",
                            " without",
                            " entering",
                            " and",
                            " describing",
                            " the",
                            " lives",
                            " of",
                            " individual",
                            " patients",
                            ".\"",
                            "\n",
                            "\n",
                            "Case",
                            " histories",
                            " are",
                            " the",
                            " only",
                            " place",
                            " in",
                            " the",
                            " medical",
                            " literature",
                            " where",
                            " we",
                            " see",
                            ",",
                            " if",
                            " not",
                            " the",
                            " whole",
                            " patient",
                            ",",
                            " at",
                            " least",
                            " enough",
                            " to",
                            " get",
                            " a",
                            " picture",
                            " of",
                            " a",
                            " living",
                            " human",
                            " being",
                            ".",
                            "\n",
                            "\n",
                            "Case",
                            " histories",
                            " can",
                            " make",
                            " hundreds",
                            " of",
                            " observations",
                            " about",
                            " a",
                            " few",
                            " people",
                            ",",
                            " and",
                            " thus",
                            " may",
                            " not",
                            " be",
                            " representative",
                            " of",
                            " the",
                            " larger",
                            " population",
                            ";",
                            " group",
                            " studies",
                            " on",
                            " the",
                            " other",
                            " hand",
                            ",",
                            " make",
                            " a",
                            " few",
                            " observations",
                            " about",
                            " many",
                            " people",
                            ".",
                            " The",
                            " question",
                            " is",
                            ":",
                            " Is",
                            " it",
                            " possible",
                            " to",
                            " understand",
                            " a",
                            " person",
                            " with",
                            " a",
                            " brain",
                            " illness",
                            ",",
                            " by",
                            " describing",
                            " him",
                            " or",
                            " her",
                            " in",
                            " bits",
                            " and",
                            " pieces"
                        ],
                        "dataIndex": null,
                        "index": "44599",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.711,
                        "maxValueTokenIndex": 110,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.746,
                            0.774,
                            0.672,
                            3.146,
                            8.711,
                            6.245,
                            5.608,
                            4.561,
                            1.279,
                            0,
                            0,
                            0.858,
                            1.861,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:30:06.240Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 6.969,
                        "binMax": 8.711,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "32952",
            "description": " discussions around problem-solving scenarios and challenges",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5556324389199959,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "32952",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:12:28.279Z",
                "maxActApprox": 15.952,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    32952,
                    67995,
                    71050,
                    32858,
                    52761,
                    24216,
                    6520,
                    46523,
                    74700,
                    89982,
                    60369,
                    61022,
                    41357,
                    20524,
                    38596,
                    64273,
                    12163,
                    16344,
                    73106,
                    20185,
                    16430,
                    24206,
                    2527,
                    81728,
                    66993
                ],
                "topkCosSimValues": [
                    1,
                    0.6008,
                    0.5658,
                    0.5277,
                    0.5148,
                    0.4974,
                    0.4605,
                    0.4519,
                    0.4517,
                    0.4494,
                    0.4493,
                    0.4458,
                    0.4252,
                    0.4196,
                    0.3918,
                    0.3877,
                    0.3871,
                    0.3862,
                    0.3805,
                    0.3764,
                    0.3652,
                    0.364,
                    0.3528,
                    0.3494,
                    0.3492
                ],
                "neuron_alignment_indices": [
                    756,
                    458,
                    546
                ],
                "neuron_alignment_values": [
                    0.146,
                    0.119,
                    0.109
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    546,
                    458,
                    334
                ],
                "correlated_neurons_pearson": [
                    0.024,
                    0.02,
                    0.02
                ],
                "correlated_neurons_l1": [
                    0.023,
                    0.021,
                    0.017
                ],
                "correlated_features_indices": [
                    32858,
                    32917,
                    32846
                ],
                "correlated_features_pearson": [
                    0.126,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.127,
                    0.003,
                    0.003
                ],
                "neg_str": [
                    "throp",
                    "robe",
                    " nods",
                    " ceremonies",
                    "eston",
                    " ceremony",
                    " snippets",
                    " commissions",
                    "amins",
                    " oath"
                ],
                "neg_values": [
                    -0.798,
                    -0.748,
                    -0.735,
                    -0.724,
                    -0.722,
                    -0.71,
                    -0.71,
                    -0.707,
                    -0.701,
                    -0.675
                ],
                "pos_str": [
                    " plag",
                    " unsolved",
                    " solved",
                    " arise",
                    " arises",
                    " plague",
                    " arising",
                    " worsened",
                    "vable",
                    "Solution"
                ],
                "pos_values": [
                    1.075,
                    1.024,
                    1.009,
                    0.991,
                    0.954,
                    0.911,
                    0.884,
                    0.868,
                    0.863,
                    0.848
                ],
                "frac_nonzero": 0.00122,
                "freq_hist_data_bar_heights": [
                    789,
                    589,
                    485,
                    347,
                    282,
                    234,
                    186,
                    145,
                    131,
                    100,
                    75,
                    70,
                    64,
                    37,
                    55,
                    43,
                    33,
                    26,
                    25,
                    8,
                    15,
                    16,
                    6,
                    15,
                    9,
                    7,
                    4,
                    1,
                    2,
                    4,
                    5,
                    3,
                    3,
                    2,
                    1,
                    1,
                    4,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.16,
                    0.479,
                    0.798,
                    1.117,
                    1.436,
                    1.755,
                    2.074,
                    2.393,
                    2.712,
                    3.031,
                    3.35,
                    3.669,
                    3.988,
                    4.307,
                    4.626,
                    4.945,
                    5.264,
                    5.583,
                    5.902,
                    6.221,
                    6.54,
                    6.859,
                    7.179,
                    7.498,
                    7.817,
                    8.136,
                    8.455,
                    8.774,
                    9.093,
                    9.412,
                    9.731,
                    10.05,
                    10.369,
                    10.688,
                    11.007,
                    11.326,
                    11.645,
                    11.964,
                    12.283,
                    12.602,
                    12.921,
                    13.24,
                    13.559,
                    13.878,
                    14.197,
                    14.516,
                    14.836,
                    15.155,
                    15.474,
                    15.793
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    3,
                    5,
                    3,
                    11,
                    22,
                    32,
                    55,
                    115,
                    152,
                    319,
                    456,
                    716,
                    981,
                    1431,
                    1841,
                    2503,
                    3073,
                    3544,
                    4146,
                    4289,
                    4538,
                    4372,
                    3922,
                    3441,
                    2770,
                    2265,
                    1608,
                    1219,
                    810,
                    581,
                    390,
                    230,
                    155,
                    98,
                    58,
                    31,
                    23,
                    13,
                    11,
                    6,
                    1,
                    5,
                    3,
                    3,
                    1,
                    1,
                    1,
                    2,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.779,
                    -0.742,
                    -0.704,
                    -0.667,
                    -0.629,
                    -0.592,
                    -0.555,
                    -0.517,
                    -0.48,
                    -0.442,
                    -0.405,
                    -0.367,
                    -0.33,
                    -0.292,
                    -0.255,
                    -0.217,
                    -0.18,
                    -0.142,
                    -0.105,
                    -0.068,
                    -0.03,
                    0.007,
                    0.045,
                    0.082,
                    0.12,
                    0.157,
                    0.195,
                    0.232,
                    0.27,
                    0.307,
                    0.344,
                    0.382,
                    0.419,
                    0.457,
                    0.494,
                    0.532,
                    0.569,
                    0.607,
                    0.644,
                    0.682,
                    0.719,
                    0.756,
                    0.794,
                    0.831,
                    0.869,
                    0.906,
                    0.944,
                    0.981,
                    1.019,
                    1.056
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terminology related to problems and challenges",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " discussions around problem-solving scenarios and challenges",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygggp1n097c10ex7je6o8ek",
                        "tokens": [
                            " but",
                            " the",
                            " subtle",
                            " ways",
                            " that",
                            " teachers",
                            " and",
                            " parents",
                            " reinforce",
                            " that",
                            " gender",
                            " stereotype",
                            " can",
                            " harm",
                            " boys",
                            ",",
                            " who",
                            " need",
                            " to",
                            " learn",
                            " empathy",
                            " as",
                            " an",
                            " important",
                            " life",
                            " skill",
                            " for",
                            " connecting",
                            " with",
                            " others",
                            ",",
                            " problem",
                            "-",
                            "s",
                            "olving",
                            " and",
                            " developing",
                            " moral",
                            " courage",
                            ".",
                            " Many",
                            " of",
                            " these",
                            " interpersonal",
                            " skills",
                            " develop",
                            " naturally",
                            " when",
                            " children",
                            " have",
                            " the",
                            " opportunity",
                            " to",
                            " play",
                            " together",
                            " in",
                            " un",
                            "struct",
                            "ured",
                            " environments",
                            ",",
                            " but",
                            " free",
                            " play",
                            " is",
                            " on",
                            " the",
                            " decline",
                            " both",
                            " in",
                            " schools",
                            " and",
                            " at",
                            " home",
                            ".",
                            " Researchers",
                            " are",
                            " now",
                            " even",
                            " questioning",
                            " if",
                            " lack",
                            " of",
                            " free",
                            " play",
                            " in",
                            " students",
                            "\u00e2\u0122",
                            "\u013b",
                            " lives",
                            " could",
                            " be",
                            " partly",
                            " responsible",
                            " for",
                            " rising",
                            " rates",
                            " of",
                            " depression",
                            " among",
                            " youth",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " way",
                            " to",
                            " help",
                            " students",
                            " develop",
                            " social",
                            " and",
                            " emotional",
                            " skills",
                            " is",
                            " by",
                            " helping",
                            " them",
                            " develop",
                            " the",
                            " part",
                            " of",
                            " their",
                            " brain",
                            " that",
                            " governs",
                            " self"
                        ],
                        "dataIndex": null,
                        "index": "32952",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.952,
                        "maxValueTokenIndex": 33,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.171,
                            15.952,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:12:37.028Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.952,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygggp1o097f10exp2hfkttn",
                        "tokens": [
                            " but",
                            " the",
                            " subtle",
                            " ways",
                            " that",
                            " teachers",
                            " and",
                            " parents",
                            " reinforce",
                            " that",
                            " gender",
                            " stereotype",
                            " can",
                            " harm",
                            " boys",
                            ",",
                            " who",
                            " need",
                            " to",
                            " learn",
                            " empathy",
                            " as",
                            " an",
                            " important",
                            " life",
                            " skill",
                            " for",
                            " connecting",
                            " with",
                            " others",
                            ",",
                            " problem",
                            "-",
                            "s",
                            "olving",
                            " and",
                            " developing",
                            " moral",
                            " courage",
                            ".",
                            " Many",
                            " of",
                            " these",
                            " interpersonal",
                            " skills",
                            " develop",
                            " naturally",
                            " when",
                            " children",
                            " have",
                            " the",
                            " opportunity",
                            " to",
                            " play",
                            " together",
                            " in",
                            " un",
                            "struct",
                            "ured",
                            " environments",
                            ",",
                            " but",
                            " free",
                            " play",
                            " is",
                            " on",
                            " the",
                            " decline",
                            " both",
                            " in",
                            " schools",
                            " and",
                            " at",
                            " home",
                            ".",
                            " Researchers",
                            " are",
                            " now",
                            " even",
                            " questioning",
                            " if",
                            " lack",
                            " of",
                            " free",
                            " play",
                            " in",
                            " students",
                            "\u00e2\u0122",
                            "\u013b",
                            " lives",
                            " could",
                            " be",
                            " partly",
                            " responsible",
                            " for",
                            " rising",
                            " rates",
                            " of",
                            " depression",
                            " among",
                            " youth",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " way",
                            " to",
                            " help",
                            " students",
                            " develop",
                            " social",
                            " and",
                            " emotional",
                            " skills",
                            " is",
                            " by",
                            " helping",
                            " them",
                            " develop",
                            " the",
                            " part",
                            " of",
                            " their",
                            " brain",
                            " that",
                            " governs",
                            " self"
                        ],
                        "dataIndex": null,
                        "index": "32952",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.952,
                        "maxValueTokenIndex": 33,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.171,
                            15.952,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:12:37.028Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.952,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygggp1q097z10ex85vlboin",
                        "tokens": [
                            " but",
                            " the",
                            " subtle",
                            " ways",
                            " that",
                            " teachers",
                            " and",
                            " parents",
                            " reinforce",
                            " that",
                            " gender",
                            " stereotype",
                            " can",
                            " harm",
                            " boys",
                            ",",
                            " who",
                            " need",
                            " to",
                            " learn",
                            " empathy",
                            " as",
                            " an",
                            " important",
                            " life",
                            " skill",
                            " for",
                            " connecting",
                            " with",
                            " others",
                            ",",
                            " problem",
                            "-",
                            "s",
                            "olving",
                            " and",
                            " developing",
                            " moral",
                            " courage",
                            ".",
                            " Many",
                            " of",
                            " these",
                            " interpersonal",
                            " skills",
                            " develop",
                            " naturally",
                            " when",
                            " children",
                            " have",
                            " the",
                            " opportunity",
                            " to",
                            " play",
                            " together",
                            " in",
                            " un",
                            "struct",
                            "ured",
                            " environments",
                            ",",
                            " but",
                            " free",
                            " play",
                            " is",
                            " on",
                            " the",
                            " decline",
                            " both",
                            " in",
                            " schools",
                            " and",
                            " at",
                            " home",
                            ".",
                            " Researchers",
                            " are",
                            " now",
                            " even",
                            " questioning",
                            " if",
                            " lack",
                            " of",
                            " free",
                            " play",
                            " in",
                            " students",
                            "\u00e2\u0122",
                            "\u013b",
                            " lives",
                            " could",
                            " be",
                            " partly",
                            " responsible",
                            " for",
                            " rising",
                            " rates",
                            " of",
                            " depression",
                            " among",
                            " youth",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " way",
                            " to",
                            " help",
                            " students",
                            " develop",
                            " social",
                            " and",
                            " emotional",
                            " skills",
                            " is",
                            " by",
                            " helping",
                            " them",
                            " develop",
                            " the",
                            " part",
                            " of",
                            " their",
                            " brain",
                            " that",
                            " governs",
                            " self"
                        ],
                        "dataIndex": null,
                        "index": "32952",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.952,
                        "maxValueTokenIndex": 33,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.171,
                            15.952,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:12:37.028Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 12.762,
                        "binMax": 15.952,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "11",
            "description": " questions and statements related to learning processes and methodologies",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5388641357421875,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "11",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:28:31.021Z",
                "maxActApprox": 39.394,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    11,
                    21306,
                    29674,
                    5418,
                    24863,
                    59028,
                    63520,
                    60147,
                    38758,
                    90284,
                    42965,
                    23492,
                    62741,
                    97707,
                    5228,
                    2086,
                    78040,
                    58522,
                    29326,
                    23145,
                    2430,
                    28390,
                    25084,
                    28472,
                    69877
                ],
                "topkCosSimValues": [
                    1,
                    0.7454,
                    0.7111,
                    0.7028,
                    0.6897,
                    0.6778,
                    0.6541,
                    0.6504,
                    0.6484,
                    0.6384,
                    0.6347,
                    0.6211,
                    0.6082,
                    0.5782,
                    0.5764,
                    0.5566,
                    0.5289,
                    0.5175,
                    0.4836,
                    0.4809,
                    0.4673,
                    0.4652,
                    0.4393,
                    0.4262,
                    0.4102
                ],
                "neuron_alignment_indices": [
                    534,
                    483,
                    60
                ],
                "neuron_alignment_values": [
                    0.104,
                    0.103,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    60,
                    483,
                    236
                ],
                "correlated_neurons_pearson": [
                    0.032,
                    0.03,
                    0.029
                ],
                "correlated_neurons_l1": [
                    0.031,
                    0.029,
                    0.031
                ],
                "correlated_features_indices": [
                    26,
                    113,
                    59
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.006,
                    0.003,
                    0.002
                ],
                "neg_str": [
                    "vertisement",
                    "holder",
                    "enture",
                    "Rum",
                    "UX",
                    "EStream",
                    "oubted",
                    "idon",
                    "Reader",
                    "Guest"
                ],
                "neg_values": [
                    -0.745,
                    -0.663,
                    -0.62,
                    -0.599,
                    -0.59,
                    -0.585,
                    -0.584,
                    -0.576,
                    -0.57,
                    -0.569
                ],
                "pos_str": [
                    "soever",
                    "ls",
                    "itzer",
                    "olds",
                    "ells",
                    " efficiently",
                    " messed",
                    "ards",
                    "lers",
                    "ling"
                ],
                "pos_values": [
                    0.802,
                    0.747,
                    0.735,
                    0.721,
                    0.719,
                    0.708,
                    0.695,
                    0.69,
                    0.676,
                    0.662
                ],
                "frac_nonzero": 0.0004,
                "freq_hist_data_bar_heights": [
                    157,
                    114,
                    108,
                    92,
                    83,
                    60,
                    61,
                    39,
                    55,
                    50,
                    30,
                    37,
                    23,
                    20,
                    18,
                    21,
                    15,
                    20,
                    18,
                    13,
                    20,
                    10,
                    16,
                    8,
                    9,
                    6,
                    8,
                    12,
                    8,
                    8,
                    3,
                    13,
                    9,
                    4,
                    6,
                    8,
                    3,
                    6,
                    7,
                    5,
                    10,
                    4,
                    3,
                    5,
                    7,
                    8,
                    0,
                    0,
                    1,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.401,
                    1.189,
                    1.976,
                    2.764,
                    3.552,
                    4.34,
                    5.127,
                    5.915,
                    6.703,
                    7.491,
                    8.278,
                    9.066,
                    9.854,
                    10.642,
                    11.429,
                    12.217,
                    13.005,
                    13.792,
                    14.58,
                    15.368,
                    16.156,
                    16.943,
                    17.731,
                    18.519,
                    19.307,
                    20.094,
                    20.882,
                    21.67,
                    22.458,
                    23.245,
                    24.033,
                    24.821,
                    25.609,
                    26.396,
                    27.184,
                    27.972,
                    28.76,
                    29.547,
                    30.335,
                    31.123,
                    31.911,
                    32.698,
                    33.486,
                    34.274,
                    35.062,
                    35.849,
                    36.637,
                    37.425,
                    38.213,
                    39
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    0,
                    2,
                    11,
                    8,
                    26,
                    50,
                    72,
                    116,
                    180,
                    259,
                    445,
                    709,
                    939,
                    1172,
                    1661,
                    2194,
                    2718,
                    3093,
                    3631,
                    3844,
                    3854,
                    4054,
                    3855,
                    3516,
                    3096,
                    2505,
                    2137,
                    1630,
                    1318,
                    961,
                    720,
                    518,
                    348,
                    222,
                    132,
                    101,
                    61,
                    37,
                    23,
                    15,
                    8,
                    3,
                    3,
                    3,
                    3,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.73,
                    -0.699,
                    -0.668,
                    -0.637,
                    -0.606,
                    -0.575,
                    -0.544,
                    -0.513,
                    -0.482,
                    -0.451,
                    -0.42,
                    -0.389,
                    -0.358,
                    -0.327,
                    -0.296,
                    -0.265,
                    -0.234,
                    -0.204,
                    -0.173,
                    -0.142,
                    -0.111,
                    -0.08,
                    -0.049,
                    -0.018,
                    0.013,
                    0.044,
                    0.075,
                    0.106,
                    0.137,
                    0.168,
                    0.199,
                    0.23,
                    0.261,
                    0.292,
                    0.323,
                    0.354,
                    0.385,
                    0.415,
                    0.446,
                    0.477,
                    0.508,
                    0.539,
                    0.57,
                    0.601,
                    0.632,
                    0.663,
                    0.694,
                    0.725,
                    0.756,
                    0.787
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions and phrases that express \"how to\" achieve something or perform an action",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " questions and statements related to learning processes and methodologies",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygew0ixbceo10exrqgsclg9",
                        "tokens": [
                            " commentary",
                            " on",
                            " the",
                            " failure",
                            " by",
                            " one",
                            " or",
                            " more",
                            " members",
                            " of",
                            " that",
                            " family",
                            " to",
                            " live",
                            " up",
                            " to",
                            " their",
                            " duties",
                            ",",
                            " not",
                            " of",
                            " the",
                            " family",
                            " itself",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " family",
                            " is",
                            " the",
                            " basis",
                            " of",
                            " any",
                            " decent",
                            " society",
                            " because",
                            " only",
                            " in",
                            " it",
                            " do",
                            " children",
                            " learn",
                            " how",
                            " to",
                            " be",
                            " decent",
                            " adults",
                            ".",
                            " They",
                            " are",
                            " taught",
                            " virtue",
                            " in",
                            " families",
                            ",",
                            " or",
                            " nowhere",
                            ",",
                            " because",
                            " it",
                            " is",
                            " only",
                            " in",
                            " the",
                            " home",
                            " that",
                            " the",
                            " kind",
                            " of",
                            " intensive",
                            ",",
                            " round",
                            "-",
                            "the",
                            "-",
                            "clock",
                            " nurturing",
                            " and",
                            " acc",
                            "ult",
                            "uration",
                            " necessary",
                            " for",
                            " character",
                            " formation",
                            " can",
                            " occur",
                            ".",
                            " And",
                            ",",
                            " while",
                            " it",
                            " may",
                            " be",
                            " nice",
                            " to",
                            " talk",
                            " about",
                            " how",
                            " common",
                            " emotions",
                            " and",
                            " dedication",
                            " to",
                            " abstract",
                            " ideals",
                            " like",
                            " justice",
                            " or",
                            " tolerance",
                            " or",
                            " love",
                            " are",
                            " what",
                            " really",
                            " matter",
                            ",",
                            " those",
                            " emotions",
                            " and",
                            " ideals",
                            " only",
                            " become",
                            " real",
                            " when",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.394,
                        "maxValueTokenIndex": 43,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.394,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew0ixbcep10ex8drtvb0k",
                        "tokens": [
                            " sexuality",
                            ".",
                            " No",
                            " long",
                            ",",
                            " complex",
                            " process",
                            " of",
                            " re",
                            "acqu",
                            "ain",
                            "ting",
                            " yourself",
                            " with",
                            " new",
                            " genital",
                            "ia",
                            " and",
                            " learning",
                            " to",
                            " understand",
                            " them",
                            ".",
                            " No",
                            " learning",
                            " what",
                            " you",
                            " are",
                            " and",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " comfortable",
                            " wearing",
                            ".",
                            " No",
                            " getting",
                            " nail",
                            " polish",
                            " all",
                            " over",
                            " your",
                            " fingers",
                            " and",
                            " eyel",
                            "iner",
                            " in",
                            " your",
                            " eyeb",
                            "all",
                            " because",
                            " you",
                            " never",
                            " got",
                            " a",
                            " chance",
                            " to",
                            " learn",
                            " how",
                            " to",
                            " do",
                            " that",
                            " stuff",
                            " as",
                            " a",
                            " little",
                            " girl",
                            ".",
                            " No",
                            " coming",
                            " out",
                            ".",
                            " No",
                            " losing",
                            " friends",
                            ".",
                            " No",
                            " being",
                            " dis",
                            "owned",
                            " by",
                            " family",
                            ".",
                            " No",
                            " growing",
                            " closer",
                            " to",
                            " the",
                            " people",
                            " who",
                            " supported",
                            " you",
                            ".",
                            " No",
                            " adapting",
                            " to",
                            " the",
                            " loss",
                            " of",
                            " male",
                            " privilege",
                            " and",
                            " learning",
                            " how",
                            " to",
                            " deal",
                            " with",
                            " cat",
                            " calls",
                            ".",
                            " No",
                            " nothing",
                            ".",
                            "\n",
                            "\n",
                            "Basically",
                            "?",
                            " No",
                            " transition",
                            ".",
                            " None",
                            " of",
                            " any",
                            " of",
                            " the",
                            " stuff"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.371,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.818,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.371,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew0iybcf410exd6leeuku",
                        "tokens": [
                            " sexuality",
                            ".",
                            " No",
                            " long",
                            ",",
                            " complex",
                            " process",
                            " of",
                            " re",
                            "acqu",
                            "ain",
                            "ting",
                            " yourself",
                            " with",
                            " new",
                            " genital",
                            "ia",
                            " and",
                            " learning",
                            " to",
                            " understand",
                            " them",
                            ".",
                            " No",
                            " learning",
                            " what",
                            " you",
                            " are",
                            " and",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " comfortable",
                            " wearing",
                            ".",
                            " No",
                            " getting",
                            " nail",
                            " polish",
                            " all",
                            " over",
                            " your",
                            " fingers",
                            " and",
                            " eyel",
                            "iner",
                            " in",
                            " your",
                            " eyeb",
                            "all",
                            " because",
                            " you",
                            " never",
                            " got",
                            " a",
                            " chance",
                            " to",
                            " learn",
                            " how",
                            " to",
                            " do",
                            " that",
                            " stuff",
                            " as",
                            " a",
                            " little",
                            " girl",
                            ".",
                            " No",
                            " coming",
                            " out",
                            ".",
                            " No",
                            " losing",
                            " friends",
                            ".",
                            " No",
                            " being",
                            " dis",
                            "owned",
                            " by",
                            " family",
                            ".",
                            " No",
                            " growing",
                            " closer",
                            " to",
                            " the",
                            " people",
                            " who",
                            " supported",
                            " you",
                            ".",
                            " No",
                            " adapting",
                            " to",
                            " the",
                            " loss",
                            " of",
                            " male",
                            " privilege",
                            " and",
                            " learning",
                            " how",
                            " to",
                            " deal",
                            " with",
                            " cat",
                            " calls",
                            ".",
                            " No",
                            " nothing",
                            ".",
                            "\n",
                            "\n",
                            "Basically",
                            "?",
                            " No",
                            " transition",
                            ".",
                            " None",
                            " of",
                            " any",
                            " of",
                            " the",
                            " stuff"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.371,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.818,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.371,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "21740",
            "description": "personal anecdotes involving experiences related to knowledge acquisition and critical thinking",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5354755201652346,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "21740",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:12:34.087Z",
                "maxActApprox": 36.416,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    21740,
                    3088,
                    21487,
                    12947,
                    16697,
                    2946,
                    20433,
                    251,
                    4001,
                    17235,
                    4407,
                    4717,
                    23503,
                    14215,
                    6124,
                    13657,
                    2197,
                    12026,
                    13434,
                    12886,
                    7963,
                    17224,
                    6857,
                    13339,
                    10095
                ],
                "topkCosSimValues": [
                    1,
                    0.5718,
                    0.5358,
                    0.419,
                    0.4171,
                    0.4083,
                    0.3814,
                    0.3811,
                    0.37,
                    0.3452,
                    0.3149,
                    0.3122,
                    0.3097,
                    0.3061,
                    0.3036,
                    0.2992,
                    0.298,
                    0.295,
                    0.2895,
                    0.2846,
                    0.2834,
                    0.283,
                    0.2741,
                    0.2639,
                    0.2629
                ],
                "neuron_alignment_indices": [
                    502,
                    363,
                    741
                ],
                "neuron_alignment_values": [
                    0.128,
                    0.109,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    502,
                    566,
                    718
                ],
                "correlated_neurons_pearson": [
                    0.06,
                    0.05,
                    0.036
                ],
                "correlated_neurons_l1": [
                    0.058,
                    0.051,
                    0.041
                ],
                "correlated_features_indices": [
                    21711,
                    21727,
                    21757
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.004,
                    0.003
                ],
                "correlated_features_l1": [
                    0.009,
                    0.006,
                    0.004
                ],
                "neg_str": [
                    "umption",
                    " completion",
                    " Proced",
                    " Squid",
                    " sorcery",
                    " summary",
                    "allo",
                    " Volcano",
                    " Spur",
                    " Biology"
                ],
                "neg_values": [
                    -0.638,
                    -0.622,
                    -0.612,
                    -0.611,
                    -0.607,
                    -0.6,
                    -0.596,
                    -0.584,
                    -0.584,
                    -0.582
                ],
                "pos_str": [
                    " adore",
                    " admire",
                    " trusts",
                    " trusted",
                    " sidx",
                    " affection",
                    " befriend",
                    "igl",
                    "assadors",
                    " interviewed"
                ],
                "pos_values": [
                    0.954,
                    0.9,
                    0.865,
                    0.854,
                    0.8,
                    0.797,
                    0.796,
                    0.789,
                    0.779,
                    0.778
                ],
                "frac_nonzero": 0.00222,
                "freq_hist_data_bar_heights": [
                    1873,
                    1215,
                    804,
                    548,
                    393,
                    305,
                    251,
                    190,
                    178,
                    120,
                    116,
                    96,
                    84,
                    68,
                    67,
                    58,
                    59,
                    45,
                    49,
                    47,
                    27,
                    30,
                    25,
                    25,
                    21,
                    26,
                    20,
                    20,
                    19,
                    23,
                    12,
                    21,
                    13,
                    21,
                    16,
                    14,
                    15,
                    7,
                    9,
                    9,
                    12,
                    9,
                    9,
                    1,
                    3,
                    3,
                    3,
                    2,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.364,
                    1.093,
                    1.821,
                    2.549,
                    3.278,
                    4.006,
                    4.734,
                    5.463,
                    6.191,
                    6.919,
                    7.648,
                    8.376,
                    9.104,
                    9.833,
                    10.561,
                    11.289,
                    12.018,
                    12.746,
                    13.474,
                    14.203,
                    14.931,
                    15.659,
                    16.388,
                    17.116,
                    17.844,
                    18.572,
                    19.301,
                    20.029,
                    20.757,
                    21.486,
                    22.214,
                    22.942,
                    23.671,
                    24.399,
                    25.127,
                    25.856,
                    26.584,
                    27.312,
                    28.041,
                    28.769,
                    29.497,
                    30.226,
                    30.954,
                    31.682,
                    32.411,
                    33.139,
                    33.867,
                    34.596,
                    35.324,
                    36.052
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    7,
                    13,
                    15,
                    32,
                    79,
                    124,
                    226,
                    344,
                    526,
                    743,
                    1006,
                    1395,
                    1826,
                    2448,
                    2769,
                    3259,
                    3635,
                    3664,
                    3840,
                    3742,
                    3509,
                    3114,
                    2826,
                    2268,
                    1971,
                    1604,
                    1381,
                    1003,
                    819,
                    556,
                    424,
                    284,
                    218,
                    176,
                    129,
                    84,
                    61,
                    50,
                    26,
                    13,
                    14,
                    9,
                    7,
                    6,
                    3,
                    1,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.622,
                    -0.59,
                    -0.558,
                    -0.526,
                    -0.494,
                    -0.463,
                    -0.431,
                    -0.399,
                    -0.367,
                    -0.335,
                    -0.303,
                    -0.272,
                    -0.24,
                    -0.208,
                    -0.176,
                    -0.144,
                    -0.112,
                    -0.081,
                    -0.049,
                    -0.017,
                    0.015,
                    0.047,
                    0.078,
                    0.11,
                    0.142,
                    0.174,
                    0.206,
                    0.238,
                    0.269,
                    0.301,
                    0.333,
                    0.365,
                    0.397,
                    0.429,
                    0.46,
                    0.492,
                    0.524,
                    0.556,
                    0.588,
                    0.62,
                    0.651,
                    0.683,
                    0.715,
                    0.747,
                    0.779,
                    0.811,
                    0.842,
                    0.874,
                    0.906,
                    0.938
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "personal anecdotes involving experiences related to knowledge acquisition and critical thinking",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdn050nknwui666bug7k88o",
                        "tokens": [
                            " months",
                            " into",
                            " learning",
                            " a",
                            " language",
                            " with",
                            " a",
                            " terrible",
                            " syntax",
                            " in",
                            " order",
                            " to",
                            " understand",
                            " obscure",
                            " features",
                            " that",
                            " had",
                            " no",
                            " useful",
                            " examples",
                            ".",
                            " My",
                            " time",
                            " has",
                            " not",
                            " yet",
                            " come",
                            ".",
                            "\n",
                            "\n",
                            "For",
                            " many",
                            " months",
                            " the",
                            " Lisp",
                            " advocates",
                            " pressed",
                            " on",
                            ".",
                            " I",
                            " was",
                            " baffled",
                            ".",
                            " Many",
                            " extremely",
                            " intelligent",
                            " people",
                            " I",
                            " knew",
                            " and",
                            " had",
                            " much",
                            " respect",
                            " for",
                            " were",
                            " praising",
                            " Lisp",
                            " with",
                            " almost",
                            " religious",
                            " dedication",
                            ".",
                            " There",
                            " had",
                            " to",
                            " be",
                            " something",
                            " there",
                            ",",
                            " something",
                            " I",
                            " couldn",
                            "'t",
                            " afford",
                            " not",
                            " to",
                            " get",
                            " my",
                            " hands",
                            " on",
                            "!",
                            " Eventually",
                            " my",
                            " thirst",
                            " for",
                            " knowledge",
                            " won",
                            " me",
                            " over",
                            ".",
                            " I",
                            " took",
                            " the",
                            " plunge",
                            ",",
                            " bit",
                            " the",
                            " bullet",
                            ",",
                            " got",
                            " my",
                            " hands",
                            " dirty",
                            ",",
                            " and",
                            " began",
                            " months",
                            " of",
                            " mind",
                            " bending",
                            " exercises",
                            ".",
                            " It",
                            " was",
                            " a",
                            " journey",
                            " on",
                            " an",
                            " endless",
                            " lake",
                            " of",
                            " frustration",
                            ".",
                            " I",
                            " turned",
                            " my",
                            " mind"
                        ],
                        "dataIndex": null,
                        "index": "21740",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.416,
                        "maxValueTokenIndex": 47,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            36.416,
                            5.618,
                            10.899,
                            9.726,
                            0,
                            0.543,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:12:40.999Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.416,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn050pknxhi6668it3dmdq",
                        "tokens": [
                            " months",
                            " into",
                            " learning",
                            " a",
                            " language",
                            " with",
                            " a",
                            " terrible",
                            " syntax",
                            " in",
                            " order",
                            " to",
                            " understand",
                            " obscure",
                            " features",
                            " that",
                            " had",
                            " no",
                            " useful",
                            " examples",
                            ".",
                            " My",
                            " time",
                            " has",
                            " not",
                            " yet",
                            " come",
                            ".",
                            "\n",
                            "\n",
                            "For",
                            " many",
                            " months",
                            " the",
                            " Lisp",
                            " advocates",
                            " pressed",
                            " on",
                            ".",
                            " I",
                            " was",
                            " baffled",
                            ".",
                            " Many",
                            " extremely",
                            " intelligent",
                            " people",
                            " I",
                            " knew",
                            " and",
                            " had",
                            " much",
                            " respect",
                            " for",
                            " were",
                            " praising",
                            " Lisp",
                            " with",
                            " almost",
                            " religious",
                            " dedication",
                            ".",
                            " There",
                            " had",
                            " to",
                            " be",
                            " something",
                            " there",
                            ",",
                            " something",
                            " I",
                            " couldn",
                            "'t",
                            " afford",
                            " not",
                            " to",
                            " get",
                            " my",
                            " hands",
                            " on",
                            "!",
                            " Eventually",
                            " my",
                            " thirst",
                            " for",
                            " knowledge",
                            " won",
                            " me",
                            " over",
                            ".",
                            " I",
                            " took",
                            " the",
                            " plunge",
                            ",",
                            " bit",
                            " the",
                            " bullet",
                            ",",
                            " got",
                            " my",
                            " hands",
                            " dirty",
                            ",",
                            " and",
                            " began",
                            " months",
                            " of",
                            " mind",
                            " bending",
                            " exercises",
                            ".",
                            " It",
                            " was",
                            " a",
                            " journey",
                            " on",
                            " an",
                            " endless",
                            " lake",
                            " of",
                            " frustration",
                            ".",
                            " I",
                            " turned",
                            " my",
                            " mind"
                        ],
                        "dataIndex": null,
                        "index": "21740",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.416,
                        "maxValueTokenIndex": 47,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            36.416,
                            5.618,
                            10.899,
                            9.726,
                            0,
                            0.543,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:12:40.999Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 29.133,
                        "binMax": 36.416,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn050nknwvi666w5dxgs5u",
                        "tokens": [
                            "'s",
                            " just",
                            " b",
                            "oll",
                            "ocks",
                            ".",
                            " Its",
                            " not",
                            " a",
                            " lot",
                            " of",
                            " sugar",
                            " in",
                            " the",
                            " scheme",
                            " of",
                            " things",
                            " at",
                            " all",
                            ",",
                            " and",
                            " the",
                            " stuff",
                            " about",
                            " processed",
                            " meat",
                            " is",
                            " badly",
                            " reported",
                            " and",
                            " misunderstood",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " and",
                            " everyone",
                            " I",
                            " know",
                            " was",
                            " raised",
                            " on",
                            " beans",
                            " on",
                            " toast",
                            " and",
                            " the",
                            " kind",
                            " of",
                            " food",
                            " people",
                            " sne",
                            "er",
                            " about",
                            " on",
                            " here",
                            ".",
                            " Never",
                            " did",
                            " any",
                            " of",
                            " us",
                            " any",
                            " harm",
                            ".",
                            " In",
                            " fact",
                            " its",
                            " now",
                            " that",
                            " everything",
                            " is",
                            " reduced",
                            " sugar",
                            " this",
                            " and",
                            " reduced",
                            " fat",
                            " that",
                            " that",
                            " the",
                            " kids",
                            " are",
                            " all",
                            " getting",
                            " obese",
                            " and",
                            " diabetes",
                            ".",
                            " Everyone",
                            " talks",
                            " about",
                            " kale",
                            " and",
                            " qu",
                            "inoa",
                            " but",
                            " they",
                            " are",
                            " less",
                            " healthy",
                            " than",
                            " those",
                            " of",
                            " us",
                            " raised",
                            " on",
                            " beans",
                            " and",
                            " turkey",
                            " drum",
                            "mers",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            "'s",
                            " fine",
                            " OP",
                            ",",
                            " its",
                            " food",
                            ".",
                            " Nothing",
                            " even",
                            " slightly",
                            " wrong"
                        ],
                        "dataIndex": null,
                        "index": "21740",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 35.455,
                        "maxValueTokenIndex": 37,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.455,
                            0.145,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.332,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.209,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:12:40.999Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.416,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "83399",
            "description": "discussions about motivation and collaborative learning in educational settings",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5329590757464822,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "83399",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:13:16.516Z",
                "maxActApprox": 7.105,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    83399,
                    45264,
                    37869,
                    26707,
                    49613,
                    65325,
                    83479,
                    40522,
                    1730,
                    71574,
                    26774,
                    15189,
                    8445,
                    76152,
                    4199,
                    30861,
                    4334,
                    24950,
                    67841,
                    85418,
                    45803,
                    95922,
                    44877,
                    81076,
                    83568
                ],
                "topkCosSimValues": [
                    1,
                    0.5039,
                    0.5011,
                    0.4889,
                    0.4861,
                    0.4776,
                    0.4733,
                    0.4715,
                    0.4699,
                    0.4595,
                    0.4582,
                    0.4582,
                    0.4557,
                    0.4449,
                    0.4443,
                    0.441,
                    0.4396,
                    0.4357,
                    0.4338,
                    0.4315,
                    0.427,
                    0.4257,
                    0.4253,
                    0.4252,
                    0.4244
                ],
                "neuron_alignment_indices": [
                    480,
                    192,
                    654
                ],
                "neuron_alignment_values": [
                    0.414,
                    0.107,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.021,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    480,
                    351,
                    266
                ],
                "correlated_neurons_pearson": [
                    0.057,
                    0.054,
                    0.045
                ],
                "correlated_neurons_l1": [
                    0.002,
                    0.045,
                    0.071
                ],
                "correlated_features_indices": [
                    83479,
                    83475,
                    83421
                ],
                "correlated_features_pearson": [
                    0.056,
                    0.007,
                    0.005
                ],
                "correlated_features_l1": [
                    0.059,
                    0.008,
                    0.005
                ],
                "neg_str": [
                    "\u00d9\u012c",
                    "Nev",
                    "north",
                    " Belg",
                    " 1961",
                    "warning",
                    " Coulter",
                    " outlawed",
                    "upt",
                    "ahon"
                ],
                "neg_values": [
                    -0.651,
                    -0.613,
                    -0.611,
                    -0.61,
                    -0.607,
                    -0.599,
                    -0.598,
                    -0.595,
                    -0.593,
                    -0.589
                ],
                "pos_str": [
                    " iter",
                    " collabor",
                    " feedback",
                    " workflow",
                    " deadlines",
                    " improv",
                    " collaborate",
                    " interact",
                    " timelines",
                    " creatively"
                ],
                "pos_values": [
                    0.908,
                    0.883,
                    0.869,
                    0.814,
                    0.785,
                    0.773,
                    0.769,
                    0.759,
                    0.759,
                    0.752
                ],
                "frac_nonzero": 0.006979999999999999,
                "freq_hist_data_bar_heights": [
                    2675,
                    2416,
                    2115,
                    1934,
                    1638,
                    1462,
                    1297,
                    1172,
                    995,
                    800,
                    746,
                    676,
                    542,
                    498,
                    460,
                    405,
                    330,
                    308,
                    214,
                    218,
                    152,
                    137,
                    116,
                    129,
                    74,
                    87,
                    52,
                    58,
                    45,
                    40,
                    30,
                    21,
                    18,
                    24,
                    13,
                    10,
                    8,
                    4,
                    5,
                    4,
                    3,
                    5,
                    5,
                    2,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.071,
                    0.213,
                    0.355,
                    0.497,
                    0.639,
                    0.782,
                    0.924,
                    1.066,
                    1.208,
                    1.35,
                    1.492,
                    1.634,
                    1.776,
                    1.918,
                    2.06,
                    2.203,
                    2.345,
                    2.487,
                    2.629,
                    2.771,
                    2.913,
                    3.055,
                    3.197,
                    3.339,
                    3.481,
                    3.623,
                    3.766,
                    3.908,
                    4.05,
                    4.192,
                    4.334,
                    4.476,
                    4.618,
                    4.76,
                    4.902,
                    5.044,
                    5.187,
                    5.329,
                    5.471,
                    5.613,
                    5.755,
                    5.897,
                    6.039,
                    6.181,
                    6.323,
                    6.465,
                    6.608,
                    6.75,
                    6.892,
                    7.034
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    9,
                    21,
                    27,
                    51,
                    86,
                    140,
                    246,
                    355,
                    577,
                    788,
                    1031,
                    1405,
                    1766,
                    2058,
                    2479,
                    2811,
                    3138,
                    3048,
                    3278,
                    3248,
                    3107,
                    3001,
                    2767,
                    2493,
                    2272,
                    1891,
                    1700,
                    1327,
                    1190,
                    946,
                    702,
                    594,
                    483,
                    340,
                    273,
                    179,
                    137,
                    102,
                    63,
                    45,
                    23,
                    28,
                    16,
                    5,
                    5,
                    2,
                    0,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.636,
                    -0.605,
                    -0.573,
                    -0.542,
                    -0.511,
                    -0.48,
                    -0.449,
                    -0.418,
                    -0.386,
                    -0.355,
                    -0.324,
                    -0.293,
                    -0.262,
                    -0.23,
                    -0.199,
                    -0.168,
                    -0.137,
                    -0.106,
                    -0.074,
                    -0.043,
                    -0.012,
                    0.019,
                    0.05,
                    0.082,
                    0.113,
                    0.144,
                    0.175,
                    0.206,
                    0.238,
                    0.269,
                    0.3,
                    0.331,
                    0.362,
                    0.394,
                    0.425,
                    0.456,
                    0.487,
                    0.518,
                    0.549,
                    0.581,
                    0.612,
                    0.643,
                    0.674,
                    0.705,
                    0.737,
                    0.768,
                    0.799,
                    0.83,
                    0.861,
                    0.893
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " concepts related to project management and effective teamwork",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "discussions about motivation and collaborative learning in educational settings",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygimqez2jaj10exclclhntq",
                        "tokens": [
                            "\u013f",
                            " grants",
                            " whose",
                            " informational",
                            " value",
                            " comes",
                            " from",
                            " (",
                            "a",
                            ")",
                            " following",
                            " through",
                            " on",
                            " initial",
                            " expressions",
                            " of",
                            " interest",
                            ";",
                            " (",
                            "b",
                            ")",
                            " signaling",
                            " our",
                            " further",
                            " interests",
                            ";",
                            " and",
                            " (",
                            "c",
                            ")",
                            " giving",
                            " us",
                            " opportunities",
                            " to",
                            " follow",
                            " up",
                            " over",
                            " time",
                            " and",
                            " learn",
                            " about",
                            " the",
                            " relevant",
                            " people",
                            " and",
                            " organizations",
                            " and",
                            " their",
                            " progress",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " a",
                            " few",
                            " comments",
                            " that",
                            " we",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " seem",
                            " to",
                            " place",
                            " much",
                            " value",
                            " on",
                            " \u00e2\u0122",
                            "\u013e",
                            "value",
                            " of",
                            " information",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " since",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " primarily",
                            " funding",
                            " direct",
                            " work",
                            " of",
                            " various",
                            " kinds",
                            " rather",
                            " than",
                            " research",
                            " projects",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ".",
                            " I",
                            " disagree",
                            " with",
                            " comments",
                            " along",
                            " these",
                            " lines",
                            ".",
                            " Our",
                            " work",
                            " is",
                            " a",
                            " research",
                            " project",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ",",
                            " and",
                            " funding",
                            " projects"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.105,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            3.344,
                            1.85,
                            3.61,
                            2.098,
                            2.933,
                            2.859,
                            2.916,
                            3.892,
                            4.399,
                            7.105,
                            4.183,
                            3.765,
                            2.972,
                            1.324,
                            0,
                            1.929,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.105,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygimqf22jb410exu9dxomnj",
                        "tokens": [
                            "\u013f",
                            " grants",
                            " whose",
                            " informational",
                            " value",
                            " comes",
                            " from",
                            " (",
                            "a",
                            ")",
                            " following",
                            " through",
                            " on",
                            " initial",
                            " expressions",
                            " of",
                            " interest",
                            ";",
                            " (",
                            "b",
                            ")",
                            " signaling",
                            " our",
                            " further",
                            " interests",
                            ";",
                            " and",
                            " (",
                            "c",
                            ")",
                            " giving",
                            " us",
                            " opportunities",
                            " to",
                            " follow",
                            " up",
                            " over",
                            " time",
                            " and",
                            " learn",
                            " about",
                            " the",
                            " relevant",
                            " people",
                            " and",
                            " organizations",
                            " and",
                            " their",
                            " progress",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " a",
                            " few",
                            " comments",
                            " that",
                            " we",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " seem",
                            " to",
                            " place",
                            " much",
                            " value",
                            " on",
                            " \u00e2\u0122",
                            "\u013e",
                            "value",
                            " of",
                            " information",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " since",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " primarily",
                            " funding",
                            " direct",
                            " work",
                            " of",
                            " various",
                            " kinds",
                            " rather",
                            " than",
                            " research",
                            " projects",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ".",
                            " I",
                            " disagree",
                            " with",
                            " comments",
                            " along",
                            " these",
                            " lines",
                            ".",
                            " Our",
                            " work",
                            " is",
                            " a",
                            " research",
                            " project",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ",",
                            " and",
                            " funding",
                            " projects"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.105,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            3.344,
                            1.85,
                            3.61,
                            2.098,
                            2.933,
                            2.859,
                            2.916,
                            3.892,
                            4.399,
                            7.105,
                            4.183,
                            3.765,
                            2.972,
                            1.324,
                            0,
                            1.929,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 5.684,
                        "binMax": 7.105,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygimqez2jak10ex3wiuo4gq",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " the",
                            " end",
                            ",",
                            " doing",
                            " it",
                            " yourself",
                            " is",
                            " great",
                            ",",
                            " but",
                            " it",
                            "'s",
                            " also",
                            " good",
                            " to",
                            " know",
                            " when",
                            " a",
                            " project",
                            " is",
                            " over",
                            " your",
                            " head",
                            " and",
                            " it",
                            "'s",
                            " time",
                            " to",
                            " call",
                            " someone",
                            " else",
                            ".",
                            " In",
                            " addition",
                            ",",
                            " sometimes",
                            " it",
                            " actually",
                            " is",
                            " better",
                            " to",
                            " replace",
                            " your",
                            " gear",
                            " instead",
                            " of",
                            " fix",
                            " it",
                            ",",
                            " so",
                            " make",
                            " sure",
                            " you",
                            " aren",
                            "'t",
                            " on",
                            " a",
                            " fool",
                            "'s",
                            " err",
                            "and",
                            " trying",
                            " to",
                            " fix",
                            " a",
                            " gadget",
                            " that",
                            "'s",
                            " just",
                            " reached",
                            " its",
                            " time",
                            " to",
                            " die",
                            ".",
                            " Got",
                            " your",
                            " own",
                            " favorite",
                            " repair",
                            " project",
                            " that",
                            " you",
                            " did",
                            " on",
                            " your",
                            " own",
                            ",",
                            " or",
                            " a",
                            " skill",
                            " any",
                            " DIY",
                            "er",
                            " should",
                            " know",
                            " how",
                            " to",
                            " do",
                            "?",
                            " Share",
                            " it",
                            " with",
                            " us",
                            " in",
                            " the",
                            " comments",
                            ".",
                            "<|endoftext|>",
                            "So",
                            " i",
                            " opened",
                            " up",
                            " my",
                            " gift",
                            " that",
                            " came",
                            " earlier",
                            " on",
                            " tonight",
                            ".",
                            " The",
                            " post"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 6.744,
                        "maxValueTokenIndex": 20,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.37,
                            1.73,
                            6.744,
                            4.1,
                            0.725,
                            2.35,
                            1.713,
                            0.702,
                            0.523,
                            0.642,
                            2.552,
                            1.152,
                            1.972,
                            2.65,
                            1.368,
                            1.601,
                            0.519,
                            0,
                            0,
                            0,
                            0,
                            0.865,
                            0,
                            0,
                            0,
                            0,
                            0.551,
                            0,
                            0.336,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.089,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.105,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "72667",
            "description": " concepts and practices related to effective problem-solving and guidance in various contexts",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5286853909492493,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "72667",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:01:37.146Z",
                "maxActApprox": 15.129,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    72667,
                    36998,
                    75538,
                    36196,
                    40231,
                    53922,
                    75805,
                    93941,
                    59336,
                    5602,
                    94940,
                    91699,
                    12163,
                    48398,
                    74797,
                    2254,
                    83229,
                    60241,
                    79719,
                    79966,
                    70155,
                    40880,
                    66882,
                    6297,
                    47582
                ],
                "topkCosSimValues": [
                    1,
                    0.5596,
                    0.5202,
                    0.4707,
                    0.4702,
                    0.4607,
                    0.4371,
                    0.4352,
                    0.4276,
                    0.4272,
                    0.4225,
                    0.42,
                    0.4199,
                    0.419,
                    0.414,
                    0.4121,
                    0.412,
                    0.4113,
                    0.4071,
                    0.4056,
                    0.403,
                    0.4016,
                    0.394,
                    0.391,
                    0.3871
                ],
                "neuron_alignment_indices": [
                    447,
                    318,
                    497
                ],
                "neuron_alignment_values": [
                    0.171,
                    0.087,
                    0.085
                ],
                "neuron_alignment_l1": [
                    0.008,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    679,
                    575,
                    324
                ],
                "correlated_neurons_pearson": [
                    0.038,
                    0.032,
                    0.029
                ],
                "correlated_neurons_l1": [
                    0.045,
                    0.038,
                    0.029
                ],
                "correlated_features_indices": [
                    72589,
                    72603,
                    72562
                ],
                "correlated_features_pearson": [
                    0.003,
                    0.002,
                    0.001
                ],
                "correlated_features_l1": [
                    0.003,
                    0.002,
                    0.001
                ],
                "neg_str": [
                    "enegger",
                    "ocaust",
                    "Asia",
                    "Office",
                    "erity",
                    " Alive",
                    "artisan",
                    "EVA",
                    " Brotherhood",
                    "tch"
                ],
                "neg_values": [
                    -0.759,
                    -0.667,
                    -0.651,
                    -0.649,
                    -0.642,
                    -0.64,
                    -0.626,
                    -0.62,
                    -0.608,
                    -0.606
                ],
                "pos_str": [
                    "hooting",
                    " pitfalls",
                    " ranging",
                    " whereby",
                    " misconceptions",
                    " pertaining",
                    " strategies",
                    " explan",
                    " relating",
                    " regarding"
                ],
                "pos_values": [
                    0.917,
                    0.907,
                    0.893,
                    0.89,
                    0.833,
                    0.809,
                    0.798,
                    0.784,
                    0.758,
                    0.754
                ],
                "frac_nonzero": 0.00123,
                "freq_hist_data_bar_heights": [
                    652,
                    526,
                    417,
                    332,
                    299,
                    236,
                    246,
                    168,
                    148,
                    119,
                    115,
                    92,
                    81,
                    74,
                    57,
                    56,
                    39,
                    26,
                    25,
                    20,
                    25,
                    20,
                    21,
                    13,
                    6,
                    9,
                    9,
                    5,
                    6,
                    7,
                    3,
                    2,
                    4,
                    2,
                    1,
                    2,
                    3,
                    1,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.151,
                    0.454,
                    0.757,
                    1.059,
                    1.362,
                    1.664,
                    1.967,
                    2.269,
                    2.572,
                    2.875,
                    3.177,
                    3.48,
                    3.782,
                    4.085,
                    4.387,
                    4.69,
                    4.993,
                    5.295,
                    5.598,
                    5.9,
                    6.203,
                    6.505,
                    6.808,
                    7.111,
                    7.413,
                    7.716,
                    8.018,
                    8.321,
                    8.623,
                    8.926,
                    9.229,
                    9.531,
                    9.834,
                    10.136,
                    10.439,
                    10.741,
                    11.044,
                    11.347,
                    11.649,
                    11.952,
                    12.254,
                    12.557,
                    12.859,
                    13.162,
                    13.465,
                    13.767,
                    14.07,
                    14.372,
                    14.675,
                    14.977
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    5,
                    5,
                    12,
                    35,
                    24,
                    82,
                    123,
                    186,
                    342,
                    490,
                    728,
                    1074,
                    1542,
                    1943,
                    2483,
                    2999,
                    3519,
                    3832,
                    3916,
                    3998,
                    3894,
                    3551,
                    3144,
                    2703,
                    2299,
                    1832,
                    1478,
                    1083,
                    828,
                    637,
                    450,
                    280,
                    222,
                    171,
                    120,
                    88,
                    53,
                    30,
                    15,
                    14,
                    11,
                    4,
                    2,
                    3,
                    1,
                    0,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.742,
                    -0.708,
                    -0.675,
                    -0.641,
                    -0.608,
                    -0.574,
                    -0.541,
                    -0.507,
                    -0.474,
                    -0.44,
                    -0.407,
                    -0.373,
                    -0.34,
                    -0.306,
                    -0.273,
                    -0.239,
                    -0.206,
                    -0.172,
                    -0.139,
                    -0.105,
                    -0.072,
                    -0.038,
                    -0.005,
                    0.029,
                    0.062,
                    0.096,
                    0.129,
                    0.163,
                    0.197,
                    0.23,
                    0.264,
                    0.297,
                    0.331,
                    0.364,
                    0.398,
                    0.431,
                    0.465,
                    0.498,
                    0.532,
                    0.565,
                    0.599,
                    0.632,
                    0.666,
                    0.699,
                    0.733,
                    0.766,
                    0.8,
                    0.833,
                    0.867,
                    0.9
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " practical advice and guidelines for problem-solving",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " concepts and practices related to effective problem-solving and guidance in various contexts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi7uy9ueq710exukk8wop6",
                        "tokens": [
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Watch",
                            " (",
                            "Part",
                            " 2",
                            "):",
                            "\n",
                            "\n",
                            "Follow",
                            " Pam",
                            " Key",
                            " on",
                            " Twitter",
                            " @",
                            "p",
                            "am",
                            "key",
                            "N",
                            "EN",
                            "<|endoftext|>",
                            "C",
                            "oding",
                            " Contest",
                            " Byte",
                            ":",
                            " The",
                            " Square",
                            " Root",
                            " Trick",
                            "\n",
                            "\n",
                            "Cos",
                            "min",
                            " Neg",
                            "r",
                            "user",
                            "i",
                            "\n",
                            "\n",
                            "20",
                            " i",
                            "ul",
                            "ie",
                            " 2012",
                            " 20",
                            " i",
                            "ul",
                            "ie",
                            " 2012",
                            "\n",
                            "\n",
                            "We",
                            "'re",
                            " starting",
                            " a",
                            " series",
                            " of",
                            " articles",
                            " describing",
                            " tricks",
                            " useful",
                            " in",
                            " programming",
                            " contests",
                            ".",
                            " Please",
                            " keep",
                            " the",
                            " comments",
                            " in",
                            " English",
                            ".",
                            "\n",
                            "\n",
                            "Being",
                            " flexible",
                            " and",
                            " easy",
                            " to",
                            " code",
                            ",",
                            " the",
                            " square",
                            " root",
                            " trick",
                            " is",
                            " pretty",
                            " popular",
                            " in",
                            " the",
                            " Romanian",
                            " programming",
                            " contests",
                            " community",
                            ".",
                            " It",
                            " even",
                            " has",
                            " a",
                            " name",
                            ":",
                            " \"",
                            "j",
                            "men",
                            "ul",
                            " l",
                            "u",
                            " Bat",
                            "og",
                            "\"",
                            " which",
                            " means",
                            " Bat",
                            "og",
                            "'s",
                            " trick",
                            " :",
                            ").",
                            " Bog",
                            "dan",
                            " Bat",
                            "og",
                            " introduced"
                        ],
                        "dataIndex": null,
                        "index": "72667",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.129,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.129,
                            7.349,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:01:44.027Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.129,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi7uybueqt10exiq7558ct",
                        "tokens": [
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Watch",
                            " (",
                            "Part",
                            " 2",
                            "):",
                            "\n",
                            "\n",
                            "Follow",
                            " Pam",
                            " Key",
                            " on",
                            " Twitter",
                            " @",
                            "p",
                            "am",
                            "key",
                            "N",
                            "EN",
                            "<|endoftext|>",
                            "C",
                            "oding",
                            " Contest",
                            " Byte",
                            ":",
                            " The",
                            " Square",
                            " Root",
                            " Trick",
                            "\n",
                            "\n",
                            "Cos",
                            "min",
                            " Neg",
                            "r",
                            "user",
                            "i",
                            "\n",
                            "\n",
                            "20",
                            " i",
                            "ul",
                            "ie",
                            " 2012",
                            " 20",
                            " i",
                            "ul",
                            "ie",
                            " 2012",
                            "\n",
                            "\n",
                            "We",
                            "'re",
                            " starting",
                            " a",
                            " series",
                            " of",
                            " articles",
                            " describing",
                            " tricks",
                            " useful",
                            " in",
                            " programming",
                            " contests",
                            ".",
                            " Please",
                            " keep",
                            " the",
                            " comments",
                            " in",
                            " English",
                            ".",
                            "\n",
                            "\n",
                            "Being",
                            " flexible",
                            " and",
                            " easy",
                            " to",
                            " code",
                            ",",
                            " the",
                            " square",
                            " root",
                            " trick",
                            " is",
                            " pretty",
                            " popular",
                            " in",
                            " the",
                            " Romanian",
                            " programming",
                            " contests",
                            " community",
                            ".",
                            " It",
                            " even",
                            " has",
                            " a",
                            " name",
                            ":",
                            " \"",
                            "j",
                            "men",
                            "ul",
                            " l",
                            "u",
                            " Bat",
                            "og",
                            "\"",
                            " which",
                            " means",
                            " Bat",
                            "og",
                            "'s",
                            " trick",
                            " :",
                            ").",
                            " Bog",
                            "dan",
                            " Bat",
                            "og",
                            " introduced"
                        ],
                        "dataIndex": null,
                        "index": "72667",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.129,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.129,
                            7.349,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:01:44.027Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 12.103,
                        "binMax": 15.129,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi7uy9ueq810exva6h6ksb",
                        "tokens": [
                            " future",
                            ".",
                            " Pearson",
                            " was",
                            " a",
                            " subcontract",
                            "or",
                            " for",
                            " Apple",
                            " in",
                            " the",
                            " deal",
                            " between",
                            " the",
                            " tech",
                            " giant",
                            " and",
                            " LA",
                            "USD",
                            ".",
                            "\n",
                            "\n",
                            "On",
                            " Thursday",
                            ",",
                            " District",
                            " officials",
                            " told",
                            " the",
                            " LA",
                            " Times",
                            " that",
                            " \u00e2\u0122",
                            "\u013e",
                            "they",
                            " were",
                            " optimistic",
                            " that",
                            " they",
                            " had",
                            " addressed",
                            " the",
                            " SEC",
                            " concerns",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            " The",
                            " LA",
                            " Times",
                            " also",
                            " reported",
                            " that",
                            " LA",
                            "USD",
                            " had",
                            " prepared",
                            " a",
                            " presentation",
                            " in",
                            " March",
                            " that",
                            " \u00e2\u0122",
                            "\u013e",
                            "out",
                            "lined",
                            " measures",
                            " it",
                            " took",
                            " to",
                            " inform",
                            " the",
                            " public",
                            " and",
                            " potential",
                            " investors",
                            " about",
                            " how",
                            " bond",
                            " funds",
                            " [",
                            "for",
                            " the",
                            " iPad",
                            " program",
                            "]",
                            " would",
                            " be",
                            " spent",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " school",
                            " district",
                            " reportedly",
                            " told",
                            " the",
                            " SEC",
                            " that",
                            " the",
                            " bonds",
                            " used",
                            " to",
                            " fund",
                            " the",
                            " iPad",
                            " program",
                            " were",
                            " general",
                            " obligation",
                            " bonds",
                            " that",
                            " were",
                            " not",
                            " meant",
                            " to",
                            " generate",
                            " revenue",
                            " for",
                            " investors",
                            ".",
                            " It",
                            " also",
                            " maintained"
                        ],
                        "dataIndex": null,
                        "index": "72667",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 12.659,
                        "maxValueTokenIndex": 66,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.659,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:01:44.027Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.129,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "53579",
            "description": " concepts related to problem-solving and discussion",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5238773822784424,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "53579",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:40:57.670Z",
                "maxActApprox": 15.825,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    53579,
                    94538,
                    70172,
                    66118,
                    33713,
                    19869,
                    74061,
                    48596,
                    25270,
                    77794,
                    15338,
                    92499,
                    79662,
                    32022,
                    79342,
                    2957,
                    85320,
                    87634,
                    49758,
                    75658,
                    93072,
                    84230,
                    88411,
                    85468,
                    81607
                ],
                "topkCosSimValues": [
                    1,
                    0.542,
                    0.5123,
                    0.494,
                    0.4682,
                    0.4605,
                    0.4332,
                    0.4124,
                    0.3981,
                    0.3964,
                    0.3958,
                    0.3941,
                    0.3939,
                    0.3908,
                    0.3901,
                    0.3878,
                    0.3857,
                    0.3853,
                    0.3836,
                    0.3831,
                    0.3821,
                    0.3819,
                    0.381,
                    0.3801,
                    0.3758
                ],
                "neuron_alignment_indices": [
                    408,
                    737,
                    288
                ],
                "neuron_alignment_values": [
                    0.131,
                    0.107,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    247,
                    408,
                    641
                ],
                "correlated_neurons_pearson": [
                    0.018,
                    0.018,
                    0.018
                ],
                "correlated_neurons_l1": [
                    0.017,
                    0.021,
                    0.02
                ],
                "correlated_features_indices": [
                    53547,
                    53641,
                    53560
                ],
                "correlated_features_pearson": [
                    0.001,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "ospons",
                    "iaries",
                    "arus",
                    "rams",
                    "agar",
                    "ewitness",
                    "cott",
                    "ancies",
                    "cow",
                    "sels"
                ],
                "neg_values": [
                    -0.761,
                    -0.727,
                    -0.721,
                    -0.681,
                    -0.67,
                    -0.651,
                    -0.628,
                    -0.626,
                    -0.613,
                    -0.601
                ],
                "pos_str": [
                    " equation",
                    "-----",
                    "osphere",
                    "iest",
                    " unfolding",
                    "\u00e2\u0136\u0122\u00e2\u0136\u0122",
                    "=-=-=-=-",
                    " continuum",
                    "\u0123\u0138",
                    "elight"
                ],
                "pos_values": [
                    0.933,
                    0.807,
                    0.785,
                    0.705,
                    0.683,
                    0.666,
                    0.657,
                    0.654,
                    0.648,
                    0.647
                ],
                "frac_nonzero": 0.00032,
                "freq_hist_data_bar_heights": [
                    140,
                    112,
                    112,
                    85,
                    84,
                    55,
                    53,
                    55,
                    34,
                    42,
                    33,
                    24,
                    19,
                    13,
                    23,
                    16,
                    12,
                    8,
                    10,
                    11,
                    8,
                    9,
                    9,
                    4,
                    7,
                    2,
                    5,
                    2,
                    5,
                    4,
                    2,
                    2,
                    0,
                    1,
                    0,
                    2,
                    1,
                    3,
                    2,
                    0,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.161,
                    0.477,
                    0.794,
                    1.11,
                    1.427,
                    1.743,
                    2.06,
                    2.376,
                    2.692,
                    3.009,
                    3.325,
                    3.642,
                    3.958,
                    4.275,
                    4.591,
                    4.908,
                    5.224,
                    5.54,
                    5.857,
                    6.173,
                    6.49,
                    6.806,
                    7.123,
                    7.439,
                    7.756,
                    8.072,
                    8.388,
                    8.705,
                    9.021,
                    9.338,
                    9.654,
                    9.971,
                    10.287,
                    10.603,
                    10.92,
                    11.236,
                    11.553,
                    11.869,
                    12.186,
                    12.502,
                    12.819,
                    13.135,
                    13.451,
                    13.768,
                    14.084,
                    14.401,
                    14.717,
                    15.034,
                    15.35,
                    15.666
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    2,
                    2,
                    6,
                    7,
                    19,
                    34,
                    48,
                    101,
                    183,
                    259,
                    426,
                    638,
                    937,
                    1411,
                    1883,
                    2446,
                    3103,
                    3573,
                    3957,
                    4341,
                    4304,
                    4074,
                    3933,
                    3440,
                    2933,
                    2365,
                    1781,
                    1282,
                    925,
                    631,
                    437,
                    293,
                    169,
                    122,
                    72,
                    42,
                    31,
                    17,
                    12,
                    9,
                    2,
                    1,
                    0,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.744,
                    -0.711,
                    -0.677,
                    -0.643,
                    -0.609,
                    -0.575,
                    -0.541,
                    -0.507,
                    -0.473,
                    -0.439,
                    -0.406,
                    -0.372,
                    -0.338,
                    -0.304,
                    -0.27,
                    -0.236,
                    -0.202,
                    -0.168,
                    -0.134,
                    -0.1,
                    -0.067,
                    -0.033,
                    0.001,
                    0.035,
                    0.069,
                    0.103,
                    0.137,
                    0.171,
                    0.205,
                    0.238,
                    0.272,
                    0.306,
                    0.34,
                    0.374,
                    0.408,
                    0.442,
                    0.476,
                    0.51,
                    0.544,
                    0.577,
                    0.611,
                    0.645,
                    0.679,
                    0.713,
                    0.747,
                    0.781,
                    0.815,
                    0.849,
                    0.882,
                    0.916
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " references to problem-solving and systemic challenges",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " concepts related to problem-solving and discussion",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghh7jvfwdy10exoproffkn",
                        "tokens": [
                            " play",
                            " six",
                            " times",
                            " in",
                            " years",
                            " the",
                            " NL",
                            " East",
                            " plays",
                            " the",
                            " AL",
                            " East",
                            ".",
                            "\n",
                            "\n",
                            "Base",
                            "ball",
                            "'s",
                            " new",
                            " labor",
                            " contract",
                            " says",
                            " teams",
                            " will",
                            " play",
                            " up",
                            " to",
                            " 20",
                            " inter",
                            "league",
                            " games",
                            " a",
                            " year",
                            ".",
                            " Weiner",
                            " says",
                            " the",
                            " total",
                            " is",
                            " likely",
                            " to",
                            " be",
                            " close",
                            " to",
                            " the",
                            " maximum",
                            ".",
                            " \"",
                            "It",
                            " may",
                            " be",
                            " that",
                            " you",
                            " can",
                            " come",
                            " up",
                            " with",
                            " a",
                            " more",
                            " work",
                            "able",
                            " schedule",
                            " by",
                            " moving",
                            " up",
                            " to",
                            " the",
                            " higher",
                            " end",
                            " of",
                            " the",
                            " inter",
                            "league",
                            " play",
                            " range",
                            " as",
                            " opposed",
                            " to",
                            " the",
                            " lower",
                            " end",
                            ",\"",
                            " he",
                            " said",
                            ".",
                            " \"",
                            "So",
                            " it",
                            "'s",
                            " not",
                            " a",
                            " question",
                            " that",
                            " 19",
                            " or",
                            " 20",
                            " is",
                            " much",
                            " better",
                            " than",
                            " 18",
                            " in",
                            " terms",
                            " of",
                            " inter",
                            "league",
                            " play",
                            ",",
                            " it",
                            "'s",
                            " a",
                            " question",
                            " of",
                            " how",
                            " to",
                            " put",
                            " the",
                            " pieces",
                            " of",
                            " the",
                            " puzzle",
                            " together",
                            ".\"",
                            "\n",
                            "\n",
                            "A",
                            " draft"
                        ],
                        "dataIndex": null,
                        "index": "53579",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.825,
                        "maxValueTokenIndex": 120,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.825,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:41:00.623Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.825,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghh7jvfwdz10ex2r4t6gvl",
                        "tokens": [
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " mention",
                            " Trump",
                            " by",
                            " name",
                            ",",
                            " but",
                            " asked",
                            " why",
                            " school",
                            " lun",
                            "ches",
                            " had",
                            " become",
                            " a",
                            " partisan",
                            " issue",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "You",
                            " have",
                            " to",
                            " stop",
                            " and",
                            " think",
                            ",",
                            " \u00e2\u0122",
                            "\u013a",
                            "Why",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " you",
                            " want",
                            " our",
                            " kids",
                            " to",
                            " have",
                            " good",
                            " food",
                            " at",
                            " school",
                            "?",
                            " What",
                            " is",
                            " wrong",
                            " with",
                            " you",
                            "?",
                            "\u00e2\u0122",
                            "\u013b",
                            " And",
                            " why",
                            " is",
                            " that",
                            " a",
                            " partisan",
                            " issue",
                            "?",
                            "\u00e2\u0122",
                            "\u013f",
                            " Obama",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "M",
                            "oms",
                            ",",
                            " think",
                            " about",
                            " this",
                            ":",
                            " I",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " care",
                            " what",
                            " state",
                            " you",
                            " live",
                            " in",
                            ",",
                            " take",
                            " me",
                            " out",
                            " of",
                            " the",
                            " equation",
                            " \u00e2\u0122\u0137",
                            " like",
                            " me",
                            ",",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " like",
                            " me",
                            " \u00e2\u0122\u0137",
                            " but",
                            " think",
                            " about",
                            " why",
                            " someone",
                            " is",
                            " OK",
                            " with",
                            " your",
                            " kids",
                            " eating",
                            " crap",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Ag",
                            "ric"
                        ],
                        "dataIndex": null,
                        "index": "53579",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.311,
                        "maxValueTokenIndex": 96,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.311,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:41:00.623Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.825,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghh7jxfwei10ex4xwwtfit",
                        "tokens": [
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " mention",
                            " Trump",
                            " by",
                            " name",
                            ",",
                            " but",
                            " asked",
                            " why",
                            " school",
                            " lun",
                            "ches",
                            " had",
                            " become",
                            " a",
                            " partisan",
                            " issue",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "You",
                            " have",
                            " to",
                            " stop",
                            " and",
                            " think",
                            ",",
                            " \u00e2\u0122",
                            "\u013a",
                            "Why",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " you",
                            " want",
                            " our",
                            " kids",
                            " to",
                            " have",
                            " good",
                            " food",
                            " at",
                            " school",
                            "?",
                            " What",
                            " is",
                            " wrong",
                            " with",
                            " you",
                            "?",
                            "\u00e2\u0122",
                            "\u013b",
                            " And",
                            " why",
                            " is",
                            " that",
                            " a",
                            " partisan",
                            " issue",
                            "?",
                            "\u00e2\u0122",
                            "\u013f",
                            " Obama",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "M",
                            "oms",
                            ",",
                            " think",
                            " about",
                            " this",
                            ":",
                            " I",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " care",
                            " what",
                            " state",
                            " you",
                            " live",
                            " in",
                            ",",
                            " take",
                            " me",
                            " out",
                            " of",
                            " the",
                            " equation",
                            " \u00e2\u0122\u0137",
                            " like",
                            " me",
                            ",",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " like",
                            " me",
                            " \u00e2\u0122\u0137",
                            " but",
                            " think",
                            " about",
                            " why",
                            " someone",
                            " is",
                            " OK",
                            " with",
                            " your",
                            " kids",
                            " eating",
                            " crap",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Ag",
                            "ric"
                        ],
                        "dataIndex": null,
                        "index": "53579",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.311,
                        "maxValueTokenIndex": 96,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.311,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:41:00.623Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 12.66,
                        "binMax": 15.825,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "14559",
            "description": "discussions related to educational achievement and challenges faced by students, particularly boys",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5189639329910278,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "14559",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:46:06.235Z",
                "maxActApprox": 10.489,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    14559,
                    79875,
                    36119,
                    20928,
                    75739,
                    64264,
                    26789,
                    18105,
                    61837,
                    14066,
                    4065,
                    94660,
                    58881,
                    14825,
                    85431,
                    51711,
                    5909,
                    78790,
                    37808,
                    42150,
                    88366,
                    78467,
                    74433,
                    57450,
                    79364
                ],
                "topkCosSimValues": [
                    1,
                    0.4831,
                    0.4476,
                    0.4124,
                    0.4114,
                    0.4032,
                    0.4024,
                    0.382,
                    0.3789,
                    0.3778,
                    0.365,
                    0.3647,
                    0.3543,
                    0.3502,
                    0.3419,
                    0.3391,
                    0.334,
                    0.3306,
                    0.3295,
                    0.3257,
                    0.3203,
                    0.32,
                    0.3186,
                    0.3178,
                    0.3176
                ],
                "neuron_alignment_indices": [
                    738,
                    215,
                    235
                ],
                "neuron_alignment_values": [
                    0.11,
                    0.109,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    738,
                    252,
                    641
                ],
                "correlated_neurons_pearson": [
                    0.031,
                    0.03,
                    0.029
                ],
                "correlated_neurons_l1": [
                    0.026,
                    0.034,
                    0.036
                ],
                "correlated_features_indices": [
                    14583,
                    14556,
                    14533
                ],
                "correlated_features_pearson": [
                    0.028,
                    0.009,
                    0.009
                ],
                "correlated_features_l1": [
                    0.028,
                    0.012,
                    0.01
                ],
                "neg_str": [
                    " eBay",
                    " Shipping",
                    " Canary",
                    " shipping",
                    "soType",
                    " hiber",
                    " Carnage",
                    "NetMessage",
                    " Hydra",
                    " franch"
                ],
                "neg_values": [
                    -0.805,
                    -0.783,
                    -0.753,
                    -0.721,
                    -0.718,
                    -0.708,
                    -0.697,
                    -0.687,
                    -0.685,
                    -0.684
                ],
                "pos_str": [
                    " literacy",
                    " classroom",
                    " curriculum",
                    " curric",
                    " proficiency",
                    " learners",
                    " homework",
                    " exams",
                    " vocational",
                    " kindergarten"
                ],
                "pos_values": [
                    1.505,
                    1.378,
                    1.367,
                    1.329,
                    1.322,
                    1.27,
                    1.268,
                    1.191,
                    1.138,
                    1.137
                ],
                "frac_nonzero": 0.00333,
                "freq_hist_data_bar_heights": [
                    1577,
                    1394,
                    1160,
                    998,
                    835,
                    687,
                    578,
                    467,
                    396,
                    374,
                    315,
                    248,
                    203,
                    184,
                    158,
                    126,
                    109,
                    95,
                    77,
                    69,
                    60,
                    72,
                    34,
                    47,
                    31,
                    28,
                    26,
                    23,
                    22,
                    10,
                    14,
                    12,
                    8,
                    5,
                    4,
                    5,
                    6,
                    5,
                    7,
                    1,
                    1,
                    2,
                    3,
                    1,
                    2,
                    0,
                    0,
                    3,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.105,
                    0.315,
                    0.525,
                    0.734,
                    0.944,
                    1.154,
                    1.364,
                    1.573,
                    1.783,
                    1.993,
                    2.203,
                    2.413,
                    2.622,
                    2.832,
                    3.042,
                    3.252,
                    3.462,
                    3.671,
                    3.881,
                    4.091,
                    4.301,
                    4.51,
                    4.72,
                    4.93,
                    5.14,
                    5.35,
                    5.559,
                    5.769,
                    5.979,
                    6.189,
                    6.399,
                    6.608,
                    6.818,
                    7.028,
                    7.238,
                    7.447,
                    7.657,
                    7.867,
                    8.077,
                    8.287,
                    8.496,
                    8.706,
                    8.916,
                    9.126,
                    9.336,
                    9.545,
                    9.755,
                    9.965,
                    10.175,
                    10.384
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    3,
                    9,
                    27,
                    53,
                    99,
                    154,
                    272,
                    468,
                    745,
                    1246,
                    1772,
                    2354,
                    3147,
                    4039,
                    4723,
                    5027,
                    5090,
                    4501,
                    4138,
                    3153,
                    2538,
                    1883,
                    1326,
                    991,
                    722,
                    516,
                    344,
                    234,
                    188,
                    118,
                    83,
                    69,
                    56,
                    34,
                    33,
                    22,
                    15,
                    20,
                    11,
                    10,
                    10,
                    4,
                    1,
                    2,
                    0,
                    2,
                    2,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.782,
                    -0.736,
                    -0.689,
                    -0.643,
                    -0.597,
                    -0.551,
                    -0.505,
                    -0.458,
                    -0.412,
                    -0.366,
                    -0.32,
                    -0.274,
                    -0.227,
                    -0.181,
                    -0.135,
                    -0.089,
                    -0.042,
                    0.004,
                    0.05,
                    0.096,
                    0.142,
                    0.189,
                    0.235,
                    0.281,
                    0.327,
                    0.373,
                    0.42,
                    0.466,
                    0.512,
                    0.558,
                    0.604,
                    0.651,
                    0.697,
                    0.743,
                    0.789,
                    0.835,
                    0.882,
                    0.928,
                    0.974,
                    1.02,
                    1.067,
                    1.113,
                    1.159,
                    1.205,
                    1.251,
                    1.298,
                    1.344,
                    1.39,
                    1.436,
                    1.482
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "discussions related to educational achievement and challenges faced by students, particularly boys",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfipfkmc3910exq7nl1603",
                        "tokens": [
                            " said",
                            " universities",
                            " were",
                            " working",
                            " \"",
                            "hell",
                            " for",
                            " leather",
                            "\"",
                            " to",
                            " rect",
                            "ify",
                            " the",
                            " situation",
                            " in",
                            " terms",
                            " of",
                            " places",
                            " for",
                            " students",
                            " from",
                            " disadvantaged",
                            " backgrounds",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " told",
                            " BBC",
                            " Radio",
                            " Scotland",
                            " many",
                            " of",
                            " the",
                            " inequalities",
                            " in",
                            " education",
                            " begin",
                            " much",
                            " earlier",
                            ",",
                            " in",
                            " school",
                            " or",
                            " even",
                            " pre",
                            "-",
                            "school",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " added",
                            ":",
                            " \"",
                            "If",
                            " you",
                            " look",
                            " at",
                            " the",
                            " attainment",
                            " of",
                            " five",
                            "-",
                            "year",
                            "-",
                            "olds",
                            ",",
                            " you",
                            " find",
                            " some",
                            " absolutely",
                            " shocking",
                            " differences",
                            " according",
                            " to",
                            " whether",
                            " they",
                            "'re",
                            " from",
                            " a",
                            " challenged",
                            " background",
                            " of",
                            " not",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "There",
                            "'s",
                            " an",
                            " 18",
                            " month",
                            " attainment",
                            " gap",
                            " in",
                            " verbal",
                            " skills",
                            " between",
                            " five",
                            "-",
                            "year",
                            "-",
                            "olds",
                            " from",
                            " the",
                            " most",
                            " privileged",
                            " backgrounds",
                            " and",
                            " the",
                            " most",
                            " challenged",
                            " backgrounds",
                            ",",
                            " so",
                            " there",
                            "'s",
                            " a",
                            " huge",
                            " systemic",
                            " issue",
                            " for",
                            " Scotland",
                            " about",
                            " making"
                        ],
                        "dataIndex": null,
                        "index": "14559",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.489,
                        "maxValueTokenIndex": 97,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.265,
                            0,
                            2.403,
                            3.438,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.616,
                            1.676,
                            2.849,
                            1.458,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.183,
                            3.543,
                            0,
                            0.358,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.343,
                            10.489,
                            5.592,
                            4.355,
                            2.994,
                            5.517,
                            2.602,
                            0.935,
                            1.258,
                            0,
                            3.796,
                            1.634,
                            0,
                            0,
                            0,
                            1.9,
                            0,
                            0.242,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:11.240Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 8.392,
                        "binMax": 10.489,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfipfhmc2n10exj5gcpbn6",
                        "tokens": [
                            " said",
                            " universities",
                            " were",
                            " working",
                            " \"",
                            "hell",
                            " for",
                            " leather",
                            "\"",
                            " to",
                            " rect",
                            "ify",
                            " the",
                            " situation",
                            " in",
                            " terms",
                            " of",
                            " places",
                            " for",
                            " students",
                            " from",
                            " disadvantaged",
                            " backgrounds",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " told",
                            " BBC",
                            " Radio",
                            " Scotland",
                            " many",
                            " of",
                            " the",
                            " inequalities",
                            " in",
                            " education",
                            " begin",
                            " much",
                            " earlier",
                            ",",
                            " in",
                            " school",
                            " or",
                            " even",
                            " pre",
                            "-",
                            "school",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " added",
                            ":",
                            " \"",
                            "If",
                            " you",
                            " look",
                            " at",
                            " the",
                            " attainment",
                            " of",
                            " five",
                            "-",
                            "year",
                            "-",
                            "olds",
                            ",",
                            " you",
                            " find",
                            " some",
                            " absolutely",
                            " shocking",
                            " differences",
                            " according",
                            " to",
                            " whether",
                            " they",
                            "'re",
                            " from",
                            " a",
                            " challenged",
                            " background",
                            " of",
                            " not",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "There",
                            "'s",
                            " an",
                            " 18",
                            " month",
                            " attainment",
                            " gap",
                            " in",
                            " verbal",
                            " skills",
                            " between",
                            " five",
                            "-",
                            "year",
                            "-",
                            "olds",
                            " from",
                            " the",
                            " most",
                            " privileged",
                            " backgrounds",
                            " and",
                            " the",
                            " most",
                            " challenged",
                            " backgrounds",
                            ",",
                            " so",
                            " there",
                            "'s",
                            " a",
                            " huge",
                            " systemic",
                            " issue",
                            " for",
                            " Scotland",
                            " about",
                            " making"
                        ],
                        "dataIndex": null,
                        "index": "14559",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.489,
                        "maxValueTokenIndex": 97,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.265,
                            0,
                            2.403,
                            3.438,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.616,
                            1.676,
                            2.849,
                            1.458,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.183,
                            3.543,
                            0,
                            0.358,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.343,
                            10.489,
                            5.592,
                            4.355,
                            2.994,
                            5.517,
                            2.602,
                            0.935,
                            1.258,
                            0,
                            3.796,
                            1.634,
                            0,
                            0,
                            0,
                            1.9,
                            0,
                            0.242,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:11.240Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 10.489,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfipfhmc2o10exc7emu0os",
                        "tokens": [
                            " out",
                            ".",
                            " Steve",
                            " Compar",
                            "ato",
                            ",",
                            " the",
                            " principal",
                            " of",
                            " Com",
                            "bee",
                            " Elementary",
                            " School",
                            ",",
                            " worried",
                            " at",
                            " how",
                            " he",
                            " was",
                            " going",
                            " to",
                            " provide",
                            " essential",
                            " supplies",
                            " for",
                            " his",
                            " students",
                            " when",
                            " his",
                            " budget",
                            " was",
                            " cut",
                            " by",
                            " a",
                            " third",
                            " this",
                            " year",
                            ",",
                            " was",
                            " delighted",
                            " when",
                            " the",
                            " First",
                            " Baptist",
                            " Church",
                            " at",
                            " the",
                            " Mall",
                            " \u00e2\u0122",
                            "\u013e",
                            "ad",
                            "opted",
                            "\u00e2\u0122",
                            "\u013f",
                            " his",
                            " school",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " result",
                            "?",
                            " The",
                            " church",
                            " filled",
                            " the",
                            " school",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " resource",
                            " room",
                            " with",
                            " $",
                            "5000",
                            " worth",
                            " of",
                            " supplies",
                            ";",
                            " it",
                            " also",
                            " c",
                            "atered",
                            " spaghetti",
                            " dinners",
                            " at",
                            " evening",
                            " school",
                            " events",
                            ",",
                            " bought",
                            " sneakers",
                            " for",
                            " needy",
                            " kids",
                            ",",
                            " and",
                            " provided",
                            " math",
                            " and",
                            " English",
                            " tut",
                            "ors",
                            ".",
                            "\n",
                            "\n",
                            "And",
                            " in",
                            " exchange",
                            "?",
                            " \u00e2\u0122",
                            "\u013e",
                            "We",
                            " have",
                            " in",
                            "roads",
                            " into",
                            " public",
                            " schools",
                            " that",
                            " we",
                            " had",
                            " not",
                            " had",
                            " before",
                            ",",
                            "\u00e2\u0122"
                        ],
                        "dataIndex": null,
                        "index": "14559",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.369,
                        "maxValueTokenIndex": 99,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.62,
                            10.369,
                            5.965,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:11.240Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 10.489,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "34472",
            "description": "concepts related to understanding and knowledge acquisition",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.516589879989624,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "34472",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:00:49.061Z",
                "maxActApprox": 8.652,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    34472,
                    40351,
                    19229,
                    26183,
                    12737,
                    36064,
                    34171,
                    26658,
                    23624,
                    41598,
                    27830,
                    27472,
                    38013,
                    15624,
                    46100,
                    36221,
                    26314,
                    4131,
                    46711,
                    20780,
                    47822,
                    14572,
                    44650,
                    48515,
                    47098
                ],
                "topkCosSimValues": [
                    1,
                    0.3966,
                    0.388,
                    0.3679,
                    0.3668,
                    0.3552,
                    0.3503,
                    0.3493,
                    0.3418,
                    0.3404,
                    0.3306,
                    0.3274,
                    0.3259,
                    0.3161,
                    0.3135,
                    0.312,
                    0.312,
                    0.3072,
                    0.3071,
                    0.3064,
                    0.3064,
                    0.304,
                    0.3024,
                    0.3023,
                    0.3002
                ],
                "neuron_alignment_indices": [
                    481,
                    373,
                    568
                ],
                "neuron_alignment_values": [
                    0.189,
                    0.114,
                    0.11
                ],
                "neuron_alignment_l1": [
                    0.009,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    568,
                    39,
                    285
                ],
                "correlated_neurons_pearson": [
                    0.038,
                    0.035,
                    0.035
                ],
                "correlated_neurons_l1": [
                    0.031,
                    0.039,
                    0.022
                ],
                "correlated_features_indices": [
                    34494,
                    34511,
                    34429
                ],
                "correlated_features_pearson": [
                    0.013,
                    0.007,
                    0.004
                ],
                "correlated_features_l1": [
                    0.014,
                    0.008,
                    0.006
                ],
                "neg_str": [
                    " vetoed",
                    " Supporters",
                    " ransom",
                    " veto",
                    " Corker",
                    " billboard",
                    "dor",
                    " Shelter",
                    " billboards",
                    "onement"
                ],
                "neg_values": [
                    -0.742,
                    -0.717,
                    -0.704,
                    -0.698,
                    -0.694,
                    -0.694,
                    -0.694,
                    -0.693,
                    -0.692,
                    -0.691
                ],
                "pos_str": [
                    " learning",
                    "learning",
                    "Learning",
                    " comprehension",
                    " understanding",
                    " knowledge",
                    " beginner",
                    " lear",
                    " learners",
                    " tutorials"
                ],
                "pos_values": [
                    1.364,
                    1.301,
                    1.221,
                    1.201,
                    1.157,
                    1.13,
                    1.127,
                    1.121,
                    1.119,
                    1.109
                ],
                "frac_nonzero": 0.00534,
                "freq_hist_data_bar_heights": [
                    2388,
                    2143,
                    1780,
                    1557,
                    1352,
                    1134,
                    1001,
                    811,
                    720,
                    617,
                    532,
                    427,
                    374,
                    295,
                    278,
                    231,
                    186,
                    136,
                    144,
                    100,
                    95,
                    83,
                    65,
                    55,
                    46,
                    40,
                    37,
                    32,
                    24,
                    14,
                    14,
                    14,
                    8,
                    9,
                    10,
                    7,
                    3,
                    8,
                    6,
                    4,
                    1,
                    2,
                    1,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.087,
                    0.26,
                    0.433,
                    0.606,
                    0.779,
                    0.952,
                    1.125,
                    1.298,
                    1.471,
                    1.644,
                    1.817,
                    1.99,
                    2.163,
                    2.336,
                    2.509,
                    2.682,
                    2.855,
                    3.028,
                    3.201,
                    3.374,
                    3.547,
                    3.72,
                    3.893,
                    4.066,
                    4.239,
                    4.412,
                    4.585,
                    4.758,
                    4.931,
                    5.104,
                    5.278,
                    5.451,
                    5.624,
                    5.797,
                    5.97,
                    6.143,
                    6.316,
                    6.489,
                    6.662,
                    6.835,
                    7.008,
                    7.181,
                    7.354,
                    7.527,
                    7.7,
                    7.873,
                    8.046,
                    8.219,
                    8.392,
                    8.565
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    13,
                    22,
                    46,
                    79,
                    149,
                    319,
                    493,
                    781,
                    1055,
                    1569,
                    2054,
                    2627,
                    3087,
                    3557,
                    3951,
                    4165,
                    4099,
                    3820,
                    3504,
                    3093,
                    2620,
                    2123,
                    1640,
                    1280,
                    999,
                    764,
                    621,
                    435,
                    346,
                    225,
                    194,
                    142,
                    99,
                    80,
                    52,
                    39,
                    39,
                    16,
                    20,
                    12,
                    9,
                    2,
                    5,
                    4,
                    1,
                    2,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.721,
                    -0.679,
                    -0.636,
                    -0.594,
                    -0.552,
                    -0.51,
                    -0.468,
                    -0.426,
                    -0.384,
                    -0.342,
                    -0.299,
                    -0.257,
                    -0.215,
                    -0.173,
                    -0.131,
                    -0.089,
                    -0.047,
                    -0.005,
                    0.038,
                    0.08,
                    0.122,
                    0.164,
                    0.206,
                    0.248,
                    0.29,
                    0.332,
                    0.375,
                    0.417,
                    0.459,
                    0.501,
                    0.543,
                    0.585,
                    0.627,
                    0.669,
                    0.712,
                    0.754,
                    0.796,
                    0.838,
                    0.88,
                    0.922,
                    0.964,
                    1.006,
                    1.048,
                    1.091,
                    1.133,
                    1.175,
                    1.217,
                    1.259,
                    1.301,
                    1.343
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "concepts related to understanding and knowledge acquisition",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk6cn2k7f0yi6663jp2hsi8",
                        "tokens": [
                            " currently",
                            " mapping",
                            " over",
                            " so",
                            " we",
                            " can",
                            " make",
                            " any",
                            " transformations",
                            " or",
                            " calculations",
                            " that",
                            " we",
                            " need",
                            ".",
                            " After",
                            " we",
                            " go",
                            " through",
                            " each",
                            " element",
                            ",",
                            " map",
                            " will",
                            " return",
                            " a",
                            " new",
                            " array",
                            " containing",
                            " the",
                            " result",
                            " of",
                            " the",
                            " mapping",
                            ".",
                            "\n",
                            "\n",
                            "Map",
                            " can",
                            " be",
                            " a",
                            " bit",
                            " misleading",
                            " at",
                            " first",
                            ",",
                            " but",
                            " once",
                            " you",
                            " get",
                            " used",
                            " to",
                            " it",
                            " you",
                            " will",
                            " always",
                            " prefer",
                            " it",
                            " to",
                            " loops",
                            ".",
                            " This",
                            " is",
                            " the",
                            " same",
                            " example",
                            " that",
                            " we",
                            " had",
                            " earlier",
                            " in",
                            " the",
                            " article",
                            " but",
                            " written",
                            " with",
                            " a",
                            " single",
                            " line",
                            " of",
                            " code",
                            ".",
                            " We",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " taking",
                            " advantage",
                            " of",
                            " ES",
                            "6",
                            " arrow",
                            " functions",
                            " to",
                            " simplify",
                            " our",
                            " code",
                            " as",
                            " much",
                            " as",
                            " possible",
                            ".",
                            " We",
                            " omit",
                            " parentheses",
                            " around",
                            " the",
                            " input",
                            " x",
                            ",",
                            " because",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " single",
                            " input",
                            " and",
                            " we",
                            " can",
                            " also",
                            " omit",
                            " the",
                            " return",
                            " statement",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "34472",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.652,
                        "maxValueTokenIndex": 53,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.767,
                            5.725,
                            5.528,
                            5.926,
                            3.845,
                            3.948,
                            8.652,
                            8.593,
                            0.942,
                            0,
                            0.589,
                            1.641,
                            0,
                            0,
                            0,
                            0,
                            1.041,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.96,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.704,
                            0.782,
                            0,
                            0.144,
                            1.727,
                            0,
                            0.541,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:00:54.044Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 8.652,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6cn2k7f0zi666dlgoplz8",
                        "tokens": [
                            " currently",
                            " mapping",
                            " over",
                            " so",
                            " we",
                            " can",
                            " make",
                            " any",
                            " transformations",
                            " or",
                            " calculations",
                            " that",
                            " we",
                            " need",
                            ".",
                            " After",
                            " we",
                            " go",
                            " through",
                            " each",
                            " element",
                            ",",
                            " map",
                            " will",
                            " return",
                            " a",
                            " new",
                            " array",
                            " containing",
                            " the",
                            " result",
                            " of",
                            " the",
                            " mapping",
                            ".",
                            "\n",
                            "\n",
                            "Map",
                            " can",
                            " be",
                            " a",
                            " bit",
                            " misleading",
                            " at",
                            " first",
                            ",",
                            " but",
                            " once",
                            " you",
                            " get",
                            " used",
                            " to",
                            " it",
                            " you",
                            " will",
                            " always",
                            " prefer",
                            " it",
                            " to",
                            " loops",
                            ".",
                            " This",
                            " is",
                            " the",
                            " same",
                            " example",
                            " that",
                            " we",
                            " had",
                            " earlier",
                            " in",
                            " the",
                            " article",
                            " but",
                            " written",
                            " with",
                            " a",
                            " single",
                            " line",
                            " of",
                            " code",
                            ".",
                            " We",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " taking",
                            " advantage",
                            " of",
                            " ES",
                            "6",
                            " arrow",
                            " functions",
                            " to",
                            " simplify",
                            " our",
                            " code",
                            " as",
                            " much",
                            " as",
                            " possible",
                            ".",
                            " We",
                            " omit",
                            " parentheses",
                            " around",
                            " the",
                            " input",
                            " x",
                            ",",
                            " because",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " single",
                            " input",
                            " and",
                            " we",
                            " can",
                            " also",
                            " omit",
                            " the",
                            " return",
                            " statement",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "34472",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.652,
                        "maxValueTokenIndex": 53,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.767,
                            5.725,
                            5.528,
                            5.926,
                            3.845,
                            3.948,
                            8.652,
                            8.593,
                            0.942,
                            0,
                            0.589,
                            1.641,
                            0,
                            0,
                            0,
                            0,
                            1.041,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.96,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.704,
                            0.782,
                            0,
                            0.144,
                            1.727,
                            0,
                            0.541,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:00:54.044Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 8.652,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6cn2m7f1ii666sp15qxku",
                        "tokens": [
                            " currently",
                            " mapping",
                            " over",
                            " so",
                            " we",
                            " can",
                            " make",
                            " any",
                            " transformations",
                            " or",
                            " calculations",
                            " that",
                            " we",
                            " need",
                            ".",
                            " After",
                            " we",
                            " go",
                            " through",
                            " each",
                            " element",
                            ",",
                            " map",
                            " will",
                            " return",
                            " a",
                            " new",
                            " array",
                            " containing",
                            " the",
                            " result",
                            " of",
                            " the",
                            " mapping",
                            ".",
                            "\n",
                            "\n",
                            "Map",
                            " can",
                            " be",
                            " a",
                            " bit",
                            " misleading",
                            " at",
                            " first",
                            ",",
                            " but",
                            " once",
                            " you",
                            " get",
                            " used",
                            " to",
                            " it",
                            " you",
                            " will",
                            " always",
                            " prefer",
                            " it",
                            " to",
                            " loops",
                            ".",
                            " This",
                            " is",
                            " the",
                            " same",
                            " example",
                            " that",
                            " we",
                            " had",
                            " earlier",
                            " in",
                            " the",
                            " article",
                            " but",
                            " written",
                            " with",
                            " a",
                            " single",
                            " line",
                            " of",
                            " code",
                            ".",
                            " We",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " taking",
                            " advantage",
                            " of",
                            " ES",
                            "6",
                            " arrow",
                            " functions",
                            " to",
                            " simplify",
                            " our",
                            " code",
                            " as",
                            " much",
                            " as",
                            " possible",
                            ".",
                            " We",
                            " omit",
                            " parentheses",
                            " around",
                            " the",
                            " input",
                            " x",
                            ",",
                            " because",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " single",
                            " input",
                            " and",
                            " we",
                            " can",
                            " also",
                            " omit",
                            " the",
                            " return",
                            " statement",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "34472",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.652,
                        "maxValueTokenIndex": 53,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.767,
                            5.725,
                            5.528,
                            5.926,
                            3.845,
                            3.948,
                            8.652,
                            8.593,
                            0.942,
                            0,
                            0.589,
                            1.641,
                            0,
                            0,
                            0,
                            0,
                            1.041,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.96,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.704,
                            0.782,
                            0,
                            0.144,
                            1.727,
                            0,
                            0.541,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:00:54.044Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 6.921,
                        "binMax": 8.652,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "37298",
            "description": " statements related to teaching and learning experiences",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5164009024857946,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "37298",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:18:08.931Z",
                "maxActApprox": 9.544,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    37298,
                    90447,
                    44148,
                    93599,
                    2714,
                    82087,
                    36307,
                    18136,
                    17278,
                    70016,
                    71300,
                    59012,
                    23643,
                    97518,
                    40768,
                    70808,
                    98181,
                    78615,
                    85101,
                    21925,
                    40309,
                    53445,
                    26319,
                    42245,
                    49591
                ],
                "topkCosSimValues": [
                    1,
                    0.5543,
                    0.5408,
                    0.5356,
                    0.517,
                    0.516,
                    0.5119,
                    0.5118,
                    0.4883,
                    0.4736,
                    0.4733,
                    0.4704,
                    0.4662,
                    0.4625,
                    0.4608,
                    0.4595,
                    0.4592,
                    0.4577,
                    0.4546,
                    0.4544,
                    0.4533,
                    0.4516,
                    0.4492,
                    0.448,
                    0.4464
                ],
                "neuron_alignment_indices": [
                    87,
                    373,
                    218
                ],
                "neuron_alignment_values": [
                    0.264,
                    0.118,
                    0.085
                ],
                "neuron_alignment_l1": [
                    0.013,
                    0.006,
                    0.004
                ],
                "correlated_neurons_indices": [
                    8,
                    566,
                    87
                ],
                "correlated_neurons_pearson": [
                    0.053,
                    0.037,
                    0.036
                ],
                "correlated_neurons_l1": [
                    0.056,
                    0.039,
                    -0.014
                ],
                "correlated_features_indices": [
                    37301,
                    37309,
                    37397
                ],
                "correlated_features_pearson": [
                    0.003,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.004,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "rete",
                    "aucas",
                    "atile",
                    " Unique",
                    "ciating",
                    " oval",
                    " exceeds",
                    " ambul",
                    "nexus",
                    "yth"
                ],
                "neg_values": [
                    -0.555,
                    -0.545,
                    -0.534,
                    -0.529,
                    -0.502,
                    -0.495,
                    -0.492,
                    -0.474,
                    -0.474,
                    -0.474
                ],
                "pos_str": [
                    " nonetheless",
                    " nevertheless",
                    " apologies",
                    " caveats",
                    " caution",
                    "endix",
                    " doubtless",
                    " gladly",
                    "warning",
                    " caveat"
                ],
                "pos_values": [
                    0.872,
                    0.768,
                    0.758,
                    0.707,
                    0.683,
                    0.641,
                    0.638,
                    0.63,
                    0.624,
                    0.624
                ],
                "frac_nonzero": 0.00287,
                "freq_hist_data_bar_heights": [
                    1368,
                    1126,
                    971,
                    817,
                    720,
                    624,
                    563,
                    441,
                    389,
                    346,
                    262,
                    219,
                    176,
                    182,
                    137,
                    119,
                    96,
                    87,
                    54,
                    60,
                    58,
                    36,
                    34,
                    32,
                    21,
                    19,
                    13,
                    11,
                    12,
                    9,
                    6,
                    3,
                    7,
                    2,
                    6,
                    0,
                    1,
                    3,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.096,
                    0.286,
                    0.477,
                    0.668,
                    0.859,
                    1.05,
                    1.241,
                    1.432,
                    1.623,
                    1.813,
                    2.004,
                    2.195,
                    2.386,
                    2.577,
                    2.768,
                    2.959,
                    3.149,
                    3.34,
                    3.531,
                    3.722,
                    3.913,
                    4.104,
                    4.295,
                    4.486,
                    4.676,
                    4.867,
                    5.058,
                    5.249,
                    5.44,
                    5.631,
                    5.822,
                    6.012,
                    6.203,
                    6.394,
                    6.585,
                    6.776,
                    6.967,
                    7.158,
                    7.349,
                    7.539,
                    7.73,
                    7.921,
                    8.112,
                    8.303,
                    8.494,
                    8.685,
                    8.875,
                    9.066,
                    9.257,
                    9.448
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    1,
                    7,
                    14,
                    28,
                    58,
                    117,
                    184,
                    319,
                    492,
                    788,
                    1177,
                    1627,
                    2113,
                    2641,
                    3121,
                    3628,
                    3919,
                    3956,
                    3942,
                    3876,
                    3556,
                    3014,
                    2683,
                    2153,
                    1739,
                    1406,
                    1057,
                    774,
                    568,
                    356,
                    295,
                    209,
                    159,
                    95,
                    63,
                    47,
                    20,
                    20,
                    13,
                    5,
                    8,
                    0,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.541,
                    -0.512,
                    -0.484,
                    -0.455,
                    -0.426,
                    -0.398,
                    -0.369,
                    -0.341,
                    -0.312,
                    -0.284,
                    -0.255,
                    -0.227,
                    -0.198,
                    -0.17,
                    -0.141,
                    -0.113,
                    -0.084,
                    -0.055,
                    -0.027,
                    0.002,
                    0.03,
                    0.059,
                    0.087,
                    0.116,
                    0.144,
                    0.173,
                    0.201,
                    0.23,
                    0.259,
                    0.287,
                    0.316,
                    0.344,
                    0.373,
                    0.401,
                    0.43,
                    0.458,
                    0.487,
                    0.515,
                    0.544,
                    0.573,
                    0.601,
                    0.63,
                    0.658,
                    0.687,
                    0.715,
                    0.744,
                    0.772,
                    0.801,
                    0.829,
                    0.858
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " statements related to teaching and learning experiences",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "phrases expressing advice or suggestions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggntmh3k9e10ex8zq32xmy",
                        "tokens": [
                            " the",
                            " k",
                            "ua",
                            " works",
                            " and",
                            " why",
                            ".",
                            " They",
                            " know",
                            " that",
                            " the",
                            " muscles",
                            " that",
                            " run",
                            " through",
                            " the",
                            " K",
                            "ua",
                            " tie",
                            " directly",
                            " to",
                            " the",
                            " lower",
                            " spine",
                            " and",
                            " pel",
                            "vis",
                            ",",
                            " providing",
                            " a",
                            " strong",
                            " path",
                            " for",
                            " force",
                            " generated",
                            " from",
                            " the",
                            " core",
                            " to",
                            " travel",
                            " to",
                            " the",
                            " ground",
                            " and",
                            " back",
                            ".",
                            " They",
                            " can",
                            " also",
                            " provide",
                            " a",
                            " plethora",
                            " of",
                            " smaller",
                            " exercises",
                            " to",
                            " develop",
                            " this",
                            " area",
                            " and",
                            " can",
                            " easily",
                            " explain",
                            " the",
                            " concept",
                            " without",
                            " using",
                            " a",
                            " slew",
                            " of",
                            " esoteric",
                            " terms",
                            " that",
                            " the",
                            " student",
                            " doesn",
                            "'t",
                            " understand",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " could",
                            " go",
                            " on",
                            " and",
                            " on",
                            " with",
                            " different",
                            " examples",
                            " of",
                            " how",
                            " lineage",
                            " provides",
                            " a",
                            " great",
                            " indicator",
                            " of",
                            " the",
                            " quality",
                            " of",
                            " both",
                            " the",
                            " art",
                            " and",
                            " the",
                            " teacher",
                            " but",
                            ",",
                            " instead",
                            ",",
                            " I",
                            " would",
                            " like",
                            " to",
                            " provide",
                            " some",
                            " thoughts",
                            " or",
                            " ideas",
                            " from",
                            " other",
                            " teachers",
                            ".",
                            " Here",
                            " is",
                            " what"
                        ],
                        "dataIndex": null,
                        "index": "37298",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.544,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.784,
                            1.902,
                            1.846,
                            0.61,
                            4.242,
                            9.544,
                            6.063,
                            3.335,
                            1.801,
                            1.801,
                            0,
                            1.76,
                            1.163,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:18:09.575Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.543,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggntmj3k9y10exc6tmgsm1",
                        "tokens": [
                            " the",
                            " k",
                            "ua",
                            " works",
                            " and",
                            " why",
                            ".",
                            " They",
                            " know",
                            " that",
                            " the",
                            " muscles",
                            " that",
                            " run",
                            " through",
                            " the",
                            " K",
                            "ua",
                            " tie",
                            " directly",
                            " to",
                            " the",
                            " lower",
                            " spine",
                            " and",
                            " pel",
                            "vis",
                            ",",
                            " providing",
                            " a",
                            " strong",
                            " path",
                            " for",
                            " force",
                            " generated",
                            " from",
                            " the",
                            " core",
                            " to",
                            " travel",
                            " to",
                            " the",
                            " ground",
                            " and",
                            " back",
                            ".",
                            " They",
                            " can",
                            " also",
                            " provide",
                            " a",
                            " plethora",
                            " of",
                            " smaller",
                            " exercises",
                            " to",
                            " develop",
                            " this",
                            " area",
                            " and",
                            " can",
                            " easily",
                            " explain",
                            " the",
                            " concept",
                            " without",
                            " using",
                            " a",
                            " slew",
                            " of",
                            " esoteric",
                            " terms",
                            " that",
                            " the",
                            " student",
                            " doesn",
                            "'t",
                            " understand",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " could",
                            " go",
                            " on",
                            " and",
                            " on",
                            " with",
                            " different",
                            " examples",
                            " of",
                            " how",
                            " lineage",
                            " provides",
                            " a",
                            " great",
                            " indicator",
                            " of",
                            " the",
                            " quality",
                            " of",
                            " both",
                            " the",
                            " art",
                            " and",
                            " the",
                            " teacher",
                            " but",
                            ",",
                            " instead",
                            ",",
                            " I",
                            " would",
                            " like",
                            " to",
                            " provide",
                            " some",
                            " thoughts",
                            " or",
                            " ideas",
                            " from",
                            " other",
                            " teachers",
                            ".",
                            " Here",
                            " is",
                            " what"
                        ],
                        "dataIndex": null,
                        "index": "37298",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.544,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.784,
                            1.902,
                            1.846,
                            0.61,
                            4.242,
                            9.544,
                            6.063,
                            3.335,
                            1.801,
                            1.801,
                            0,
                            1.76,
                            1.163,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:18:09.575Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 7.635,
                        "binMax": 9.543,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggntmh3k9f10exukem1fpm",
                        "tokens": [
                            " this",
                            " console",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "Now",
                            " N",
                            "aughty",
                            " Dog",
                            " returns",
                            " to",
                            " the",
                            " spotlight",
                            " with",
                            " Uncharted",
                            " 2",
                            ":",
                            " Among",
                            " Thieves",
                            ".",
                            " Both",
                            " expected",
                            "ly",
                            " and",
                            " amazingly",
                            ",",
                            " N",
                            "aughty",
                            " Dog",
                            " has",
                            " indeed",
                            " best",
                            "ed",
                            " Nate",
                            "'s",
                            " first",
                            " adventure",
                            " and",
                            " has",
                            " created",
                            " a",
                            " sequel",
                            " that",
                            " is",
                            " not",
                            " only",
                            " bigger",
                            " and",
                            " better",
                            " in",
                            " practically",
                            " every",
                            " way",
                            ",",
                            " but",
                            " also",
                            " packs",
                            " a",
                            " multiplayer",
                            " component",
                            " that",
                            " could",
                            " be",
                            " released",
                            " as",
                            " its",
                            " own",
                            " separate",
                            ",",
                            " full",
                            "-",
                            "priced",
                            " game",
                            " and",
                            " people",
                            " would",
                            " stand",
                            " in",
                            " line",
                            " to",
                            " hand",
                            " over",
                            " their",
                            " cash",
                            ".",
                            "\n",
                            "\n",
                            "Yes",
                            ",",
                            " Uncharted",
                            " 2",
                            ":",
                            " Among",
                            " Thieves",
                            " is",
                            " fantastic",
                            ".",
                            "\n",
                            "\n",
                            "Click",
                            " the",
                            " image",
                            " to",
                            " watch",
                            " our",
                            " in",
                            "-",
                            "depth",
                            " video",
                            " review",
                            ".",
                            "\n",
                            "\n",
                            "T",
                            "rying",
                            " to",
                            " remain",
                            " as",
                            " spoiler",
                            "-",
                            "free",
                            " as",
                            " possible",
                            ",",
                            " I",
                            "'ll"
                        ],
                        "dataIndex": null,
                        "index": "37298",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.545,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.14,
                            7.545
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:18:09.575Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.543,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "44599",
            "description": " inquiries about understanding and learning complex concepts or skills",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5076311230659485,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "44599",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:30:01.882Z",
                "maxActApprox": 8.711,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    44599,
                    93059,
                    76518,
                    21927,
                    1262,
                    89190,
                    61505,
                    15981,
                    10384,
                    82742,
                    13268,
                    62988,
                    20625,
                    98181,
                    43341,
                    24843,
                    77132,
                    41738,
                    96369,
                    72975,
                    8608,
                    19771,
                    48954,
                    69702,
                    96180
                ],
                "topkCosSimValues": [
                    1,
                    0.5121,
                    0.5104,
                    0.5036,
                    0.5032,
                    0.5002,
                    0.4851,
                    0.4733,
                    0.4663,
                    0.4619,
                    0.4595,
                    0.4516,
                    0.4416,
                    0.4385,
                    0.4338,
                    0.4313,
                    0.4309,
                    0.4286,
                    0.4281,
                    0.4272,
                    0.424,
                    0.4234,
                    0.4196,
                    0.4181,
                    0.4167
                ],
                "neuron_alignment_indices": [
                    87,
                    481,
                    246
                ],
                "neuron_alignment_values": [
                    0.297,
                    0.132,
                    0.117
                ],
                "neuron_alignment_l1": [
                    0.015,
                    0.007,
                    0.006
                ],
                "correlated_neurons_indices": [
                    87,
                    570,
                    184
                ],
                "correlated_neurons_pearson": [
                    0.051,
                    0.047,
                    0.038
                ],
                "correlated_neurons_l1": [
                    -0.018,
                    0.02,
                    0.022
                ],
                "correlated_features_indices": [
                    44646,
                    44607,
                    44617
                ],
                "correlated_features_pearson": [
                    0.02,
                    0.013,
                    0.007
                ],
                "correlated_features_l1": [
                    0.022,
                    0.014,
                    0.009
                ],
                "neg_str": [
                    "taboola",
                    "Tip",
                    "iatus",
                    "Writer",
                    "ieu",
                    "\u00e9\u00be\u012f",
                    "idelines",
                    "herty",
                    "\u00c4\u0141",
                    "Prep"
                ],
                "neg_values": [
                    -0.593,
                    -0.545,
                    -0.52,
                    -0.501,
                    -0.498,
                    -0.496,
                    -0.495,
                    -0.493,
                    -0.484,
                    -0.469
                ],
                "pos_str": [
                    " oneself",
                    " yourself",
                    "ntil",
                    " anymore",
                    " meaningful",
                    " these",
                    " difference",
                    " anytime",
                    "ivably",
                    " such"
                ],
                "pos_values": [
                    0.757,
                    0.676,
                    0.627,
                    0.623,
                    0.619,
                    0.618,
                    0.609,
                    0.605,
                    0.599,
                    0.582
                ],
                "frac_nonzero": 0.005500000000000001,
                "freq_hist_data_bar_heights": [
                    2532,
                    2202,
                    1892,
                    1648,
                    1434,
                    1193,
                    1009,
                    832,
                    752,
                    665,
                    556,
                    453,
                    366,
                    293,
                    265,
                    217,
                    182,
                    144,
                    125,
                    100,
                    66,
                    64,
                    65,
                    48,
                    31,
                    36,
                    29,
                    21,
                    20,
                    9,
                    8,
                    4,
                    9,
                    2,
                    7,
                    3,
                    1,
                    0,
                    1,
                    2,
                    0,
                    0,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.087,
                    0.261,
                    0.436,
                    0.61,
                    0.784,
                    0.958,
                    1.132,
                    1.307,
                    1.481,
                    1.655,
                    1.829,
                    2.004,
                    2.178,
                    2.352,
                    2.526,
                    2.7,
                    2.875,
                    3.049,
                    3.223,
                    3.397,
                    3.571,
                    3.746,
                    3.92,
                    4.094,
                    4.268,
                    4.443,
                    4.617,
                    4.791,
                    4.965,
                    5.139,
                    5.314,
                    5.488,
                    5.662,
                    5.836,
                    6.01,
                    6.185,
                    6.359,
                    6.533,
                    6.707,
                    6.882,
                    7.056,
                    7.23,
                    7.404,
                    7.578,
                    7.753,
                    7.927,
                    8.101,
                    8.275,
                    8.449,
                    8.624
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    1,
                    5,
                    3,
                    10,
                    18,
                    33,
                    46,
                    113,
                    169,
                    277,
                    462,
                    742,
                    1081,
                    1539,
                    2092,
                    2803,
                    3350,
                    3971,
                    4372,
                    4585,
                    4400,
                    4249,
                    3752,
                    3198,
                    2492,
                    1869,
                    1449,
                    1044,
                    716,
                    509,
                    292,
                    200,
                    142,
                    88,
                    56,
                    48,
                    28,
                    16,
                    10,
                    7,
                    5,
                    4,
                    5,
                    2,
                    0,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.58,
                    -0.553,
                    -0.526,
                    -0.499,
                    -0.472,
                    -0.445,
                    -0.418,
                    -0.391,
                    -0.364,
                    -0.337,
                    -0.31,
                    -0.283,
                    -0.256,
                    -0.229,
                    -0.202,
                    -0.175,
                    -0.148,
                    -0.121,
                    -0.094,
                    -0.067,
                    -0.04,
                    -0.013,
                    0.014,
                    0.041,
                    0.068,
                    0.095,
                    0.122,
                    0.149,
                    0.176,
                    0.203,
                    0.23,
                    0.257,
                    0.284,
                    0.311,
                    0.338,
                    0.365,
                    0.392,
                    0.419,
                    0.446,
                    0.473,
                    0.5,
                    0.527,
                    0.554,
                    0.581,
                    0.608,
                    0.635,
                    0.662,
                    0.689,
                    0.716,
                    0.743
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions and statements related to understanding, acquiring knowledge, and programming",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " inquiries about understanding and learning complex concepts or skills",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygh36m492w610exhlvwy49b",
                        "tokens": [
                            " personal",
                            " too",
                            ",",
                            " and",
                            " it",
                            " is",
                            " impossible",
                            " to",
                            " convey",
                            " the",
                            " nature",
                            " and",
                            " impact",
                            " of",
                            " any",
                            " neurological",
                            " condition",
                            " without",
                            " entering",
                            " and",
                            " describing",
                            " the",
                            " lives",
                            " of",
                            " individual",
                            " patients",
                            ".\"",
                            "\n",
                            "\n",
                            "Case",
                            " histories",
                            " are",
                            " the",
                            " only",
                            " place",
                            " in",
                            " the",
                            " medical",
                            " literature",
                            " where",
                            " we",
                            " see",
                            ",",
                            " if",
                            " not",
                            " the",
                            " whole",
                            " patient",
                            ",",
                            " at",
                            " least",
                            " enough",
                            " to",
                            " get",
                            " a",
                            " picture",
                            " of",
                            " a",
                            " living",
                            " human",
                            " being",
                            ".",
                            "\n",
                            "\n",
                            "Case",
                            " histories",
                            " can",
                            " make",
                            " hundreds",
                            " of",
                            " observations",
                            " about",
                            " a",
                            " few",
                            " people",
                            ",",
                            " and",
                            " thus",
                            " may",
                            " not",
                            " be",
                            " representative",
                            " of",
                            " the",
                            " larger",
                            " population",
                            ";",
                            " group",
                            " studies",
                            " on",
                            " the",
                            " other",
                            " hand",
                            ",",
                            " make",
                            " a",
                            " few",
                            " observations",
                            " about",
                            " many",
                            " people",
                            ".",
                            " The",
                            " question",
                            " is",
                            ":",
                            " Is",
                            " it",
                            " possible",
                            " to",
                            " understand",
                            " a",
                            " person",
                            " with",
                            " a",
                            " brain",
                            " illness",
                            ",",
                            " by",
                            " describing",
                            " him",
                            " or",
                            " her",
                            " in",
                            " bits",
                            " and",
                            " pieces"
                        ],
                        "dataIndex": null,
                        "index": "44599",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.711,
                        "maxValueTokenIndex": 110,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.746,
                            0.774,
                            0.672,
                            3.146,
                            8.711,
                            6.245,
                            5.608,
                            4.561,
                            1.279,
                            0,
                            0,
                            0.858,
                            1.861,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:30:06.240Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 8.711,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh36m492we10exqx0ptlno",
                        "tokens": [
                            " personal",
                            " too",
                            ",",
                            " and",
                            " it",
                            " is",
                            " impossible",
                            " to",
                            " convey",
                            " the",
                            " nature",
                            " and",
                            " impact",
                            " of",
                            " any",
                            " neurological",
                            " condition",
                            " without",
                            " entering",
                            " and",
                            " describing",
                            " the",
                            " lives",
                            " of",
                            " individual",
                            " patients",
                            ".\"",
                            "\n",
                            "\n",
                            "Case",
                            " histories",
                            " are",
                            " the",
                            " only",
                            " place",
                            " in",
                            " the",
                            " medical",
                            " literature",
                            " where",
                            " we",
                            " see",
                            ",",
                            " if",
                            " not",
                            " the",
                            " whole",
                            " patient",
                            ",",
                            " at",
                            " least",
                            " enough",
                            " to",
                            " get",
                            " a",
                            " picture",
                            " of",
                            " a",
                            " living",
                            " human",
                            " being",
                            ".",
                            "\n",
                            "\n",
                            "Case",
                            " histories",
                            " can",
                            " make",
                            " hundreds",
                            " of",
                            " observations",
                            " about",
                            " a",
                            " few",
                            " people",
                            ",",
                            " and",
                            " thus",
                            " may",
                            " not",
                            " be",
                            " representative",
                            " of",
                            " the",
                            " larger",
                            " population",
                            ";",
                            " group",
                            " studies",
                            " on",
                            " the",
                            " other",
                            " hand",
                            ",",
                            " make",
                            " a",
                            " few",
                            " observations",
                            " about",
                            " many",
                            " people",
                            ".",
                            " The",
                            " question",
                            " is",
                            ":",
                            " Is",
                            " it",
                            " possible",
                            " to",
                            " understand",
                            " a",
                            " person",
                            " with",
                            " a",
                            " brain",
                            " illness",
                            ",",
                            " by",
                            " describing",
                            " him",
                            " or",
                            " her",
                            " in",
                            " bits",
                            " and",
                            " pieces"
                        ],
                        "dataIndex": null,
                        "index": "44599",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.711,
                        "maxValueTokenIndex": 110,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.746,
                            0.774,
                            0.672,
                            3.146,
                            8.711,
                            6.245,
                            5.608,
                            4.561,
                            1.279,
                            0,
                            0,
                            0.858,
                            1.861,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:30:06.240Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 8.711,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh36m692wt10ex3nt41hdw",
                        "tokens": [
                            " personal",
                            " too",
                            ",",
                            " and",
                            " it",
                            " is",
                            " impossible",
                            " to",
                            " convey",
                            " the",
                            " nature",
                            " and",
                            " impact",
                            " of",
                            " any",
                            " neurological",
                            " condition",
                            " without",
                            " entering",
                            " and",
                            " describing",
                            " the",
                            " lives",
                            " of",
                            " individual",
                            " patients",
                            ".\"",
                            "\n",
                            "\n",
                            "Case",
                            " histories",
                            " are",
                            " the",
                            " only",
                            " place",
                            " in",
                            " the",
                            " medical",
                            " literature",
                            " where",
                            " we",
                            " see",
                            ",",
                            " if",
                            " not",
                            " the",
                            " whole",
                            " patient",
                            ",",
                            " at",
                            " least",
                            " enough",
                            " to",
                            " get",
                            " a",
                            " picture",
                            " of",
                            " a",
                            " living",
                            " human",
                            " being",
                            ".",
                            "\n",
                            "\n",
                            "Case",
                            " histories",
                            " can",
                            " make",
                            " hundreds",
                            " of",
                            " observations",
                            " about",
                            " a",
                            " few",
                            " people",
                            ",",
                            " and",
                            " thus",
                            " may",
                            " not",
                            " be",
                            " representative",
                            " of",
                            " the",
                            " larger",
                            " population",
                            ";",
                            " group",
                            " studies",
                            " on",
                            " the",
                            " other",
                            " hand",
                            ",",
                            " make",
                            " a",
                            " few",
                            " observations",
                            " about",
                            " many",
                            " people",
                            ".",
                            " The",
                            " question",
                            " is",
                            ":",
                            " Is",
                            " it",
                            " possible",
                            " to",
                            " understand",
                            " a",
                            " person",
                            " with",
                            " a",
                            " brain",
                            " illness",
                            ",",
                            " by",
                            " describing",
                            " him",
                            " or",
                            " her",
                            " in",
                            " bits",
                            " and",
                            " pieces"
                        ],
                        "dataIndex": null,
                        "index": "44599",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.711,
                        "maxValueTokenIndex": 110,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.746,
                            0.774,
                            0.672,
                            3.146,
                            8.711,
                            6.245,
                            5.608,
                            4.561,
                            1.279,
                            0,
                            0,
                            0.858,
                            1.861,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:30:06.240Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 6.969,
                        "binMax": 8.711,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "3427",
            "description": "concepts related to teaching and learning processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.50750333070755,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "3427",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:32:27.928Z",
                "maxActApprox": 15.943,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    3427,
                    77561,
                    60325,
                    73728,
                    50077,
                    33640,
                    55572,
                    46187,
                    52346,
                    44237,
                    71908,
                    41600,
                    11,
                    70412,
                    53181,
                    83314,
                    42965,
                    79098,
                    21161,
                    23492,
                    28490,
                    42202,
                    93440,
                    42300,
                    59028
                ],
                "topkCosSimValues": [
                    1,
                    0.5752,
                    0.5313,
                    0.518,
                    0.4759,
                    0.4686,
                    0.4422,
                    0.3923,
                    0.391,
                    0.3864,
                    0.3785,
                    0.3768,
                    0.3757,
                    0.3679,
                    0.367,
                    0.367,
                    0.3629,
                    0.3589,
                    0.3481,
                    0.3475,
                    0.3419,
                    0.3416,
                    0.3379,
                    0.3346,
                    0.3338
                ],
                "neuron_alignment_indices": [
                    635,
                    603,
                    263
                ],
                "neuron_alignment_values": [
                    0.096,
                    0.094,
                    0.09
                ],
                "neuron_alignment_l1": [
                    0.004,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    263,
                    236,
                    60
                ],
                "correlated_neurons_pearson": [
                    0.023,
                    0.02,
                    0.018
                ],
                "correlated_neurons_l1": [
                    0.022,
                    0.022,
                    0.017
                ],
                "correlated_features_indices": [
                    3457,
                    3415,
                    3391
                ],
                "correlated_features_pearson": [
                    0.054,
                    0.008,
                    0.001
                ],
                "correlated_features_l1": [
                    0.054,
                    0.009,
                    0.001
                ],
                "neg_str": [
                    "Rum",
                    "storm",
                    "inqu",
                    " Inqu",
                    "estate",
                    "luster",
                    " inquiries",
                    " Noel",
                    " Bellev",
                    " Graves"
                ],
                "neg_values": [
                    -0.653,
                    -0.639,
                    -0.636,
                    -0.612,
                    -0.604,
                    -0.598,
                    -0.595,
                    -0.589,
                    -0.588,
                    -0.586
                ],
                "pos_str": [
                    " versatility",
                    " ropes",
                    " prowess",
                    "agy",
                    " horizont",
                    " ingenuity",
                    "alore",
                    "emade",
                    " vectors",
                    " flexibility"
                ],
                "pos_values": [
                    0.9,
                    0.817,
                    0.79,
                    0.753,
                    0.746,
                    0.734,
                    0.699,
                    0.698,
                    0.692,
                    0.687
                ],
                "frac_nonzero": 0.00055,
                "freq_hist_data_bar_heights": [
                    266,
                    194,
                    153,
                    123,
                    145,
                    105,
                    91,
                    85,
                    57,
                    50,
                    46,
                    43,
                    51,
                    29,
                    23,
                    30,
                    31,
                    15,
                    26,
                    22,
                    20,
                    8,
                    9,
                    10,
                    12,
                    7,
                    6,
                    6,
                    6,
                    6,
                    7,
                    8,
                    4,
                    6,
                    0,
                    3,
                    2,
                    7,
                    2,
                    4,
                    2,
                    2,
                    1,
                    1,
                    3,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.164,
                    0.483,
                    0.802,
                    1.121,
                    1.439,
                    1.758,
                    2.077,
                    2.396,
                    2.715,
                    3.033,
                    3.352,
                    3.671,
                    3.99,
                    4.308,
                    4.627,
                    4.946,
                    5.265,
                    5.583,
                    5.902,
                    6.221,
                    6.54,
                    6.858,
                    7.177,
                    7.496,
                    7.815,
                    8.133,
                    8.452,
                    8.771,
                    9.09,
                    9.408,
                    9.727,
                    10.046,
                    10.365,
                    10.683,
                    11.002,
                    11.321,
                    11.64,
                    11.958,
                    12.277,
                    12.596,
                    12.915,
                    13.233,
                    13.552,
                    13.871,
                    14.19,
                    14.508,
                    14.827,
                    15.146,
                    15.465,
                    15.784
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    4,
                    6,
                    21,
                    29,
                    57,
                    67,
                    144,
                    219,
                    332,
                    505,
                    720,
                    983,
                    1366,
                    1739,
                    2245,
                    2684,
                    3097,
                    3501,
                    3914,
                    3820,
                    3809,
                    3646,
                    3331,
                    2951,
                    2520,
                    2074,
                    1696,
                    1302,
                    1023,
                    739,
                    528,
                    402,
                    246,
                    194,
                    117,
                    80,
                    50,
                    29,
                    18,
                    14,
                    10,
                    10,
                    6,
                    1,
                    2,
                    1,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.638,
                    -0.606,
                    -0.575,
                    -0.544,
                    -0.513,
                    -0.482,
                    -0.451,
                    -0.42,
                    -0.389,
                    -0.358,
                    -0.327,
                    -0.296,
                    -0.265,
                    -0.234,
                    -0.203,
                    -0.172,
                    -0.141,
                    -0.11,
                    -0.079,
                    -0.048,
                    -0.016,
                    0.015,
                    0.046,
                    0.077,
                    0.108,
                    0.139,
                    0.17,
                    0.201,
                    0.232,
                    0.263,
                    0.294,
                    0.325,
                    0.356,
                    0.387,
                    0.418,
                    0.449,
                    0.48,
                    0.511,
                    0.542,
                    0.574,
                    0.605,
                    0.636,
                    0.667,
                    0.698,
                    0.729,
                    0.76,
                    0.791,
                    0.822,
                    0.853,
                    0.884
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions and instructions related to methods and processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "concepts related to teaching and learning processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygf154kdwgm10ex7gzz8956",
                        "tokens": [
                            " Al",
                            "inea",
                            " outside",
                            " Chicago",
                            ",",
                            " it",
                            "'s",
                            " a",
                            " chance",
                            " to",
                            " present",
                            " their",
                            " cooking",
                            " in",
                            " the",
                            " world",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " most",
                            " disc",
                            "erning",
                            " food",
                            " city",
                            " without",
                            " the",
                            " full",
                            "-",
                            "time",
                            " commitment",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "I",
                            " can",
                            "'t",
                            " tell",
                            " you",
                            " how",
                            " many",
                            " chefs",
                            " have",
                            " said",
                            " to",
                            " me",
                            ",",
                            " '",
                            "Yeah",
                            ",",
                            " you",
                            "'re",
                            " a",
                            " big",
                            " fish",
                            " in",
                            " a",
                            " small",
                            " pond",
                            ".",
                            " The",
                            " only",
                            " reason",
                            " you",
                            "'re",
                            " so",
                            " popular",
                            " is",
                            " because",
                            " you",
                            "'re",
                            " in",
                            " the",
                            " Midwest",
                            ".",
                            "\u00e2\u0122",
                            "\u013b",
                            " In",
                            " a",
                            " way",
                            ",",
                            " we",
                            "'re",
                            " am",
                            "ped",
                            " up",
                            ",\"",
                            " A",
                            "chat",
                            "z",
                            " said",
                            ".",
                            " \"",
                            "I",
                            " want",
                            " to",
                            " introduce",
                            " Al",
                            "inea",
                            " food",
                            " to",
                            " the",
                            " j",
                            "aded",
                            " New",
                            " Yorker",
                            ".",
                            " We",
                            "'re",
                            " going",
                            " to",
                            " show",
                            " New",
                            " Yorkers",
                            " what",
                            " Chicago",
                            " food",
                            " is",
                            " all",
                            " about",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " collaboration"
                        ],
                        "dataIndex": null,
                        "index": "3427",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.943,
                        "maxValueTokenIndex": 114,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.267,
                            1.683,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.943,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:31.739Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.943,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf154kdwgn10exy3t5v2tt",
                        "tokens": [
                            " has",
                            " come",
                            " to",
                            " this",
                            " particular",
                            " point",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " says",
                            ".",
                            "\n",
                            "\n",
                            "Load",
                            " third",
                            " party",
                            " embed",
                            "\n",
                            "\n",
                            "As",
                            " an",
                            " avid",
                            " bike",
                            ",",
                            " parks",
                            " and",
                            " neighborhood",
                            " advocate",
                            ",",
                            " Ford",
                            " has",
                            " been",
                            " fighting",
                            " the",
                            " decline",
                            " of",
                            " Detroit",
                            " for",
                            " years",
                            ".",
                            " To",
                            " see",
                            " his",
                            " hometown",
                            " become",
                            " trendy",
                            " with",
                            " everyone",
                            " from",
                            " tech",
                            " developers",
                            " to",
                            " hip",
                            "ster",
                            " craft",
                            "-",
                            "l",
                            "iqu",
                            "or",
                            " dist",
                            "ill",
                            "ers",
                            " makes",
                            " him",
                            " laugh",
                            " with",
                            " joy",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Being",
                            " a",
                            " unique",
                            " individual",
                            " showcasing",
                            " your",
                            " talent",
                            " is",
                            " like",
                            " the",
                            " new",
                            " hot",
                            " thing",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " says",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Everybody",
                            " wants",
                            " to",
                            " show",
                            " us",
                            " what",
                            " they",
                            " can",
                            " do",
                            ".",
                            " People",
                            " are",
                            " coming",
                            " here",
                            " from",
                            " all",
                            " over",
                            " the",
                            " country",
                            ",",
                            " because",
                            " of",
                            " the",
                            " access",
                            " to",
                            " material",
                            ",",
                            " talent",
                            " and",
                            " overall",
                            " attitude",
                            " to",
                            " get"
                        ],
                        "dataIndex": null,
                        "index": "3427",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.881,
                        "maxValueTokenIndex": 99,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.746,
                            1.82,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.881,
                            4.034,
                            4.12,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:31.739Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.943,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf154kdwgo10exkj0oeyt1",
                        "tokens": [
                            " I",
                            " would",
                            " love",
                            " to",
                            " show",
                            " how",
                            " the",
                            " card",
                            " handle",
                            " but",
                            " I",
                            "'m",
                            " not",
                            " really",
                            " good",
                            " a",
                            " that",
                            ",",
                            " this",
                            " video",
                            " is",
                            " the",
                            " best",
                            " i",
                            " could",
                            " do",
                            "...",
                            " Sorry",
                            " :(",
                            " https",
                            "://",
                            "www",
                            ".",
                            "youtube",
                            ".",
                            "com",
                            "/",
                            "watch",
                            "?",
                            "v",
                            "=",
                            "U",
                            "An",
                            "8",
                            "g",
                            "U",
                            "5",
                            "r",
                            "61",
                            "s",
                            " ***",
                            " #",
                            "Le",
                            " Website",
                            " To",
                            " make",
                            " all",
                            " this",
                            " a",
                            " little",
                            " less",
                            " complicated",
                            " i",
                            " set",
                            " up",
                            " a",
                            " website",
                            " with",
                            " the",
                            " very",
                            " original",
                            " and",
                            " thought",
                            "-",
                            "through",
                            " name",
                            " [",
                            "L",
                            "OL",
                            "Playing",
                            "C",
                            "ards",
                            ".",
                            "com",
                            "](",
                            "http",
                            "://",
                            "www",
                            ".",
                            "lol",
                            "playing",
                            "cards",
                            ".",
                            "com",
                            "/",
                            ").",
                            " here",
                            " are",
                            " some",
                            " screenshots",
                            ":",
                            " Front",
                            " page",
                            " with",
                            " the",
                            " story",
                            " and",
                            " stuff",
                            "s",
                            ":",
                            " http",
                            "://",
                            "i",
                            ".",
                            "imgur",
                            ".",
                            "com",
                            "/",
                            "q",
                            "fy",
                            "B",
                            "10",
                            "Z",
                            ".",
                            "png",
                            " A",
                            " page"
                        ],
                        "dataIndex": null,
                        "index": "3427",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.408,
                        "maxValueTokenIndex": 5,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.408,
                            1.211,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:32:31.739Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.943,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "9965",
            "description": "questions or topics related to learning or being curious about a specific subject",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5068191885948181,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "9965",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:29:39.026Z",
                "maxActApprox": 46.528,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    9965,
                    1397,
                    6983,
                    3824,
                    5476,
                    7623,
                    10267,
                    4161,
                    5753,
                    3508,
                    4988,
                    2082,
                    138,
                    7353,
                    10494,
                    2608,
                    2769,
                    3585,
                    10700,
                    7671,
                    620,
                    3796,
                    6317,
                    4491,
                    6724
                ],
                "topkCosSimValues": [
                    1,
                    0.6912,
                    0.6698,
                    0.64,
                    0.6037,
                    0.5688,
                    0.5677,
                    0.5594,
                    0.5315,
                    0.5275,
                    0.5239,
                    0.5052,
                    0.5035,
                    0.5032,
                    0.4992,
                    0.4811,
                    0.4699,
                    0.4601,
                    0.456,
                    0.4535,
                    0.4529,
                    0.4519,
                    0.4464,
                    0.4368,
                    0.4341
                ],
                "neuron_alignment_indices": [
                    665,
                    105,
                    718
                ],
                "neuron_alignment_values": [
                    0.131,
                    0.114,
                    0.112
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    49,
                    665,
                    105
                ],
                "correlated_neurons_pearson": [
                    0.074,
                    0.07,
                    0.057
                ],
                "correlated_neurons_l1": [
                    0.077,
                    0.075,
                    0.055
                ],
                "correlated_features_indices": [
                    9860,
                    9877,
                    9943
                ],
                "correlated_features_pearson": [
                    0.009,
                    0.007,
                    0.003
                ],
                "correlated_features_l1": [
                    0.012,
                    0.008,
                    0.005
                ],
                "neg_str": [
                    "rising",
                    " Kinnikuman",
                    "soDeliveryDate",
                    "soever",
                    " Lag",
                    " Stru",
                    " Rising",
                    "packing",
                    "ById",
                    " Returning"
                ],
                "neg_values": [
                    -0.755,
                    -0.681,
                    -0.663,
                    -0.662,
                    -0.639,
                    -0.621,
                    -0.614,
                    -0.61,
                    -0.599,
                    -0.599
                ],
                "pos_str": [
                    " emulate",
                    " hear",
                    " maximize",
                    " keep",
                    " recreate",
                    " avoid",
                    " know",
                    " replicate",
                    " see",
                    " pursue"
                ],
                "pos_values": [
                    1.323,
                    1.205,
                    1.161,
                    1.095,
                    1.082,
                    1.081,
                    1.076,
                    1.071,
                    1.069,
                    1.05
                ],
                "frac_nonzero": 0.00174,
                "freq_hist_data_bar_heights": [
                    879,
                    590,
                    480,
                    333,
                    289,
                    183,
                    187,
                    164,
                    137,
                    101,
                    79,
                    55,
                    70,
                    49,
                    69,
                    54,
                    63,
                    57,
                    61,
                    67,
                    78,
                    87,
                    56,
                    70,
                    61,
                    75,
                    54,
                    63,
                    51,
                    62,
                    56,
                    51,
                    54,
                    65,
                    78,
                    71,
                    67,
                    53,
                    57,
                    56,
                    62,
                    47,
                    37,
                    28,
                    23,
                    12,
                    6,
                    5,
                    2,
                    6
                ],
                "freq_hist_data_bar_values": [
                    0.465,
                    1.396,
                    2.327,
                    3.257,
                    4.188,
                    5.118,
                    6.049,
                    6.979,
                    7.91,
                    8.84,
                    9.771,
                    10.702,
                    11.632,
                    12.563,
                    13.493,
                    14.424,
                    15.354,
                    16.285,
                    17.216,
                    18.146,
                    19.077,
                    20.007,
                    20.938,
                    21.868,
                    22.799,
                    23.73,
                    24.66,
                    25.591,
                    26.521,
                    27.452,
                    28.382,
                    29.313,
                    30.244,
                    31.174,
                    32.105,
                    33.035,
                    33.966,
                    34.896,
                    35.827,
                    36.758,
                    37.688,
                    38.619,
                    39.549,
                    40.48,
                    41.41,
                    42.341,
                    43.271,
                    44.202,
                    45.133,
                    46.063
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    3,
                    10,
                    19,
                    29,
                    71,
                    132,
                    263,
                    506,
                    861,
                    1411,
                    2106,
                    3091,
                    3961,
                    4560,
                    4932,
                    4944,
                    4614,
                    4093,
                    3321,
                    2716,
                    2023,
                    1607,
                    1152,
                    895,
                    638,
                    441,
                    358,
                    289,
                    227,
                    191,
                    167,
                    137,
                    113,
                    89,
                    84,
                    59,
                    50,
                    34,
                    18,
                    17,
                    11,
                    5,
                    4,
                    0,
                    1,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.734,
                    -0.692,
                    -0.651,
                    -0.609,
                    -0.568,
                    -0.526,
                    -0.485,
                    -0.443,
                    -0.402,
                    -0.36,
                    -0.318,
                    -0.277,
                    -0.235,
                    -0.194,
                    -0.152,
                    -0.111,
                    -0.069,
                    -0.028,
                    0.014,
                    0.056,
                    0.097,
                    0.139,
                    0.18,
                    0.222,
                    0.263,
                    0.305,
                    0.346,
                    0.388,
                    0.43,
                    0.471,
                    0.513,
                    0.554,
                    0.596,
                    0.637,
                    0.679,
                    0.72,
                    0.762,
                    0.804,
                    0.845,
                    0.887,
                    0.928,
                    0.97,
                    1.011,
                    1.053,
                    1.094,
                    1.136,
                    1.178,
                    1.219,
                    1.261,
                    1.302
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions or topics related to learning or being curious about a specific subject",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdu1mfh80uri666ulbypfae",
                        "tokens": [
                            "umbledore",
                            " had",
                            " wanted",
                            " to",
                            " discuss",
                            " more",
                            " with",
                            " him",
                            ",",
                            " if",
                            " he",
                            " had",
                            " nothing",
                            " better",
                            " to",
                            " do",
                            ".",
                            "\n",
                            "\n",
                            "List",
                            " of",
                            " things",
                            " to",
                            " ask",
                            " Dumbledore",
                            ":",
                            "\n",
                            "\n",
                            "1",
                            ".",
                            " How",
                            " are",
                            " spells",
                            " really",
                            " made",
                            "?",
                            "\n",
                            "\n",
                            "2",
                            ".",
                            " How",
                            " does",
                            " magical",
                            " power",
                            " work",
                            "?",
                            " Why",
                            " aren",
                            "'t",
                            " I",
                            " as",
                            " powerful",
                            " as",
                            " Voldemort",
                            " was",
                            "?",
                            "\n",
                            "\n",
                            "3",
                            ".",
                            " Where",
                            " does",
                            " magic",
                            " come",
                            " from",
                            "?",
                            "\n",
                            "\n",
                            "He",
                            " needed",
                            " to",
                            " contact",
                            " Professor",
                            " Qu",
                            "ir",
                            "rell",
                            ",",
                            " as",
                            " soon",
                            " as",
                            " possible",
                            ".",
                            " They",
                            " needed",
                            " the",
                            " Stone",
                            ".",
                            " Harry",
                            " reached",
                            " for",
                            " his",
                            " wand",
                            "-",
                            "\n",
                            "\n",
                            "\"",
                            "Hello",
                            " again",
                            ",",
                            " Mr",
                            ".",
                            " Potter",
                            ".\"",
                            "\n",
                            "\n",
                            "Harry",
                            " spun",
                            " around",
                            ",",
                            " almost",
                            " falling",
                            " off",
                            " his",
                            " chair",
                            ".",
                            "\n",
                            "\n",
                            "Professor",
                            " Qu",
                            "ir",
                            "rell",
                            " was",
                            " not",
                            " leaning",
                            " against",
                            " a",
                            " wall"
                        ],
                        "dataIndex": null,
                        "index": "9965",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.528,
                        "maxValueTokenIndex": 3,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            46.528,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.411,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:29:47.576Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 46.528,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdu1mfh80usi666ktgkncrn",
                        "tokens": [
                            "'s",
                            " hard",
                            " to",
                            " see",
                            " how",
                            " the",
                            " Republicans",
                            " would",
                            " ever",
                            " win",
                            " another",
                            " presidential",
                            " election",
                            " .\"",
                            "Everything",
                            " we",
                            " know",
                            " about",
                            " the",
                            " political",
                            " opinions",
                            " of",
                            " new",
                            " immigrants",
                            ",",
                            " including",
                            " Hispanics",
                            " and",
                            " non",
                            "-",
                            "His",
                            "pan",
                            "ics",
                            ",",
                            " are",
                            " that",
                            " they",
                            " tend",
                            " to",
                            " favor",
                            " the",
                            " Democratic",
                            " Party",
                            " because",
                            " the",
                            " Democrats",
                            " favor",
                            " expansive",
                            " government",
                            ",",
                            " and",
                            " immigrants",
                            " are",
                            " in",
                            " favor",
                            " of",
                            " that",
                            ".\"",
                            "Cam",
                            "ar",
                            "ota",
                            " \u2014",
                            " whose",
                            " nonpartisan",
                            ",",
                            " research",
                            " group",
                            " advocates",
                            " immigration",
                            " reduction",
                            " \u2014",
                            " said",
                            " a",
                            " \"",
                            "very",
                            " large",
                            " fraction",
                            "\"",
                            " of",
                            " Republicans",
                            " feel",
                            " they",
                            " must",
                            " support",
                            " the",
                            " bill",
                            ",",
                            " a",
                            " bipartisan",
                            " effort",
                            " of",
                            " four",
                            " Republican",
                            " and",
                            " four",
                            " Democratic",
                            " lawmakers",
                            " known",
                            " as",
                            " the",
                            " \"",
                            "G",
                            "ang",
                            " of",
                            " Eight",
                            ".\"",
                            "\"[",
                            "They",
                            "]",
                            " want",
                            " to",
                            " vote",
                            " for",
                            " something",
                            " so",
                            " that",
                            " they",
                            " can",
                            " say",
                            " they",
                            " did",
                            " something",
                            ".",
                            " Whether",
                            " the",
                            " bill",
                            " has"
                        ],
                        "dataIndex": null,
                        "index": "9965",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.501,
                        "maxValueTokenIndex": 110,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.501,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:29:47.576Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 46.528,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdu1mfh80uti66680m63wgs",
                        "tokens": [
                            " Bl",
                            "of",
                            "e",
                            "ld",
                            " starts",
                            " closing",
                            " in",
                            " on",
                            " them",
                            ".",
                            " Not",
                            " only",
                            " do",
                            " the",
                            " bad",
                            " guys",
                            " want",
                            " to",
                            " manipulate",
                            " M",
                            "iki",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " rage",
                            " for",
                            " their",
                            " own",
                            " benefit",
                            ",",
                            " they",
                            " hope",
                            " to",
                            " extract",
                            " the",
                            " wolf",
                            " guy",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " blood",
                            " to",
                            " create",
                            " a",
                            " wolf",
                            " guy",
                            " of",
                            " their",
                            " own",
                            " (",
                            "\u00e2\u0122",
                            "\u013e",
                            "I",
                            " received",
                            " a",
                            " transf",
                            "usion",
                            " of",
                            " your",
                            " blood",
                            " and",
                            " became",
                            " a",
                            " wolf",
                            " man",
                            ",",
                            " too",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " is",
                            " one",
                            " of",
                            " my",
                            " favorite",
                            " lines",
                            " of",
                            " the",
                            " script",
                            ").",
                            "\n",
                            "\n",
                            "Ak",
                            "ira",
                            " encounters",
                            " many",
                            " other",
                            " women",
                            " in",
                            " his",
                            " attempts",
                            " to",
                            " rescue",
                            " M",
                            "iki",
                            " from",
                            " her",
                            " strange",
                            " fate",
                            ".",
                            " And",
                            " all",
                            " of",
                            " these",
                            " women",
                            " want",
                            " to",
                            " get",
                            " naked",
                            " with",
                            " him",
                            " almost",
                            " immediately",
                            ".",
                            " At",
                            " first",
                            ",",
                            " it",
                            " just",
                            " seems",
                            " like",
                            " the",
                            " film",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " attempt"
                        ],
                        "dataIndex": null,
                        "index": "9965",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.348,
                        "maxValueTokenIndex": 106,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.862,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.34,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.348,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:29:47.576Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 46.528,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "17442",
            "description": "discussions and debates related to decision-making and problem-solving in various contexts",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.49761489033699036,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "17442",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:07:11.232Z",
                "maxActApprox": 18.22,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    17442,
                    22675,
                    12863,
                    11450,
                    22839,
                    22333,
                    13361,
                    11070,
                    3712,
                    989,
                    15688,
                    13129,
                    2258,
                    3882,
                    6005,
                    3658,
                    5626,
                    1217,
                    1412,
                    11099,
                    4110,
                    21797,
                    12442,
                    21732,
                    1087
                ],
                "topkCosSimValues": [
                    1,
                    0.5452,
                    0.5327,
                    0.5303,
                    0.5089,
                    0.5027,
                    0.4966,
                    0.4902,
                    0.4688,
                    0.4645,
                    0.4575,
                    0.4549,
                    0.4519,
                    0.4484,
                    0.439,
                    0.4378,
                    0.4315,
                    0.4305,
                    0.4279,
                    0.4237,
                    0.4103,
                    0.41,
                    0.395,
                    0.3901,
                    0.3733
                ],
                "neuron_alignment_indices": [
                    447,
                    157,
                    485
                ],
                "neuron_alignment_values": [
                    0.214,
                    0.134,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.01,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    157,
                    540,
                    288
                ],
                "correlated_neurons_pearson": [
                    0.041,
                    0.038,
                    0.037
                ],
                "correlated_neurons_l1": [
                    0.047,
                    0.048,
                    0.053
                ],
                "correlated_features_indices": [
                    17462,
                    17427,
                    17498
                ],
                "correlated_features_pearson": [
                    0.125,
                    0.015,
                    0.014
                ],
                "correlated_features_l1": [
                    0.127,
                    0.017,
                    0.016
                ],
                "neg_str": [
                    "cause",
                    "\":\"/",
                    "unless",
                    "$.",
                    "Area",
                    "Weight",
                    "AME",
                    "York",
                    "anguages",
                    "Anything"
                ],
                "neg_values": [
                    -0.747,
                    -0.691,
                    -0.683,
                    -0.652,
                    -0.625,
                    -0.599,
                    -0.597,
                    -0.594,
                    -0.568,
                    -0.556
                ],
                "pos_str": [
                    " setbacks",
                    " setback",
                    " debacle",
                    " fiasco",
                    " precautions",
                    ",",
                    " Canter",
                    " foregoing",
                    " successes",
                    "hower"
                ],
                "pos_values": [
                    0.729,
                    0.669,
                    0.668,
                    0.654,
                    0.604,
                    0.584,
                    0.565,
                    0.552,
                    0.55,
                    0.548
                ],
                "frac_nonzero": 0.00294,
                "freq_hist_data_bar_heights": [
                    1530,
                    1152,
                    1023,
                    814,
                    655,
                    553,
                    455,
                    428,
                    376,
                    292,
                    267,
                    201,
                    204,
                    170,
                    149,
                    121,
                    113,
                    109,
                    77,
                    85,
                    75,
                    61,
                    47,
                    41,
                    36,
                    28,
                    22,
                    18,
                    26,
                    21,
                    10,
                    13,
                    15,
                    9,
                    14,
                    7,
                    6,
                    6,
                    3,
                    3,
                    1,
                    4,
                    2,
                    2,
                    0,
                    1,
                    0,
                    1,
                    3,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.182,
                    0.547,
                    0.911,
                    1.276,
                    1.64,
                    2.004,
                    2.369,
                    2.733,
                    3.097,
                    3.462,
                    3.826,
                    4.191,
                    4.555,
                    4.919,
                    5.284,
                    5.648,
                    6.013,
                    6.377,
                    6.741,
                    7.106,
                    7.47,
                    7.835,
                    8.199,
                    8.563,
                    8.928,
                    9.292,
                    9.656,
                    10.021,
                    10.385,
                    10.75,
                    11.114,
                    11.478,
                    11.843,
                    12.207,
                    12.572,
                    12.936,
                    13.3,
                    13.665,
                    14.029,
                    14.394,
                    14.758,
                    15.122,
                    15.487,
                    15.851,
                    16.215,
                    16.58,
                    16.944,
                    17.309,
                    17.673,
                    18.037
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    1,
                    1,
                    1,
                    3,
                    4,
                    18,
                    25,
                    31,
                    57,
                    100,
                    184,
                    265,
                    391,
                    545,
                    717,
                    1103,
                    1456,
                    1884,
                    2348,
                    2863,
                    3534,
                    3870,
                    4128,
                    4297,
                    4131,
                    3777,
                    3450,
                    2907,
                    2339,
                    1804,
                    1304,
                    963,
                    690,
                    409,
                    264,
                    159,
                    89,
                    65,
                    31,
                    16,
                    13,
                    10,
                    2,
                    2,
                    0,
                    3,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.732,
                    -0.702,
                    -0.673,
                    -0.643,
                    -0.614,
                    -0.584,
                    -0.555,
                    -0.525,
                    -0.496,
                    -0.466,
                    -0.437,
                    -0.407,
                    -0.378,
                    -0.348,
                    -0.319,
                    -0.289,
                    -0.26,
                    -0.23,
                    -0.201,
                    -0.171,
                    -0.142,
                    -0.112,
                    -0.083,
                    -0.053,
                    -0.024,
                    0.006,
                    0.035,
                    0.065,
                    0.094,
                    0.124,
                    0.153,
                    0.183,
                    0.212,
                    0.242,
                    0.272,
                    0.301,
                    0.331,
                    0.36,
                    0.39,
                    0.419,
                    0.449,
                    0.478,
                    0.508,
                    0.537,
                    0.567,
                    0.596,
                    0.626,
                    0.655,
                    0.685,
                    0.714
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "discussions and debates related to decision-making and problem-solving in various contexts",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmt4a0gktui666s8b9l94t",
                        "tokens": [
                            " here",
                            " and",
                            " there",
                            ",",
                            " but",
                            " none",
                            " of",
                            " these",
                            " builds",
                            " had",
                            " the",
                            " potential",
                            " to",
                            " be",
                            " part",
                            " of",
                            " the",
                            " met",
                            "agame",
                            ",",
                            " mostly",
                            " because",
                            " the",
                            " monks",
                            " spot",
                            " is",
                            " the",
                            " only",
                            " viable",
                            " spot",
                            " to",
                            " be",
                            " replaced",
                            " by",
                            " the",
                            ".",
                            " Thus",
                            ",",
                            " I",
                            " came",
                            " up",
                            " with",
                            " a",
                            " Crusader",
                            " build",
                            " able",
                            " to",
                            " replace",
                            " the",
                            " Monk",
                            " and",
                            " capable",
                            " of",
                            " GR",
                            "120",
                            "+.",
                            "\n",
                            "\n",
                            "After",
                            " alot",
                            " of",
                            " brainstorm",
                            "ing",
                            " I",
                            " finally",
                            " found",
                            " a",
                            " build",
                            " that",
                            " was",
                            " actually",
                            " worth",
                            " to",
                            " try",
                            " a",
                            " few",
                            " weeks",
                            " ago",
                            ".",
                            " So",
                            " we",
                            " made",
                            " a",
                            " few",
                            " tries",
                            " and",
                            " cleared",
                            " GR",
                            "115",
                            " pretty",
                            " easily",
                            " (",
                            "You",
                            " can",
                            " see",
                            " it",
                            " here",
                            ").",
                            " After",
                            " some",
                            " more",
                            " tests",
                            " in",
                            " GR",
                            "119",
                            "/",
                            "120",
                            " and",
                            " some",
                            " builds",
                            " adjust",
                            "ements",
                            " with",
                            " my",
                            " mates",
                            " Lou",
                            "Lou",
                            ",",
                            " Hust",
                            "le",
                            " and",
                            " S",
                            "0",
                            "R",
                            "RY",
                            ",",
                            " we"
                        ],
                        "dataIndex": null,
                        "index": "17442",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.22,
                        "maxValueTokenIndex": 62,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.643,
                            3.272,
                            12.5,
                            18.22,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.857,
                            12.394,
                            3.569,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.419,
                            0,
                            5.325,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:13.453Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 18.22,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmt4a0gktvi666fps5zqr7",
                        "tokens": [
                            " Audi",
                            " had",
                            " a",
                            " leak",
                            " coming",
                            " from",
                            " the",
                            " firewall",
                            ",",
                            " causing",
                            " the",
                            " drivers",
                            " side",
                            " floor",
                            " to",
                            " be",
                            " soaked",
                            ".",
                            " It",
                            " was",
                            " put",
                            " away",
                            " in",
                            " a",
                            " garage",
                            " for",
                            " about",
                            " 4",
                            " months",
                            " or",
                            " so",
                            " for",
                            " the",
                            " winter",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " what",
                            " does",
                            " 4",
                            " months",
                            " of",
                            " wet",
                            " car",
                            " interior",
                            " look",
                            " like",
                            "...",
                            ":",
                            "s",
                            "ick",
                            "1",
                            ":",
                            "\n",
                            "\n",
                            "After",
                            " some",
                            " discussion",
                            ",",
                            " and",
                            " research",
                            ",",
                            " I",
                            " decided",
                            " to",
                            " use",
                            " an",
                            " En",
                            "zyme",
                            " Mold",
                            " Clean",
                            "er",
                            " called",
                            " sp",
                            "oric",
                            "id",
                            "in",
                            ".",
                            " I",
                            " knew",
                            " this",
                            " would",
                            " be",
                            " a",
                            " two",
                            " day",
                            " project",
                            ".",
                            " I",
                            " suited",
                            " up",
                            ",",
                            " using",
                            " a",
                            " mask",
                            ",",
                            " gloves",
                            ",",
                            " long",
                            " sleeve",
                            " shirt",
                            " tucked",
                            " into",
                            " the",
                            " glove",
                            ",",
                            " and",
                            " some",
                            " old",
                            " pants",
                            ".",
                            " I",
                            " was",
                            " going",
                            " to",
                            " throw",
                            " away",
                            " everything",
                            " I",
                            " was",
                            " wearing",
                            " so",
                            " I",
                            " looked",
                            " like",
                            " pretty"
                        ],
                        "dataIndex": null,
                        "index": "17442",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.712,
                        "maxValueTokenIndex": 58,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.589,
                            17.712,
                            0.868,
                            2.774,
                            11.811,
                            3.748,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:13.453Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 18.22,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmt4a2gkuei666sismhoa9",
                        "tokens": [
                            " Audi",
                            " had",
                            " a",
                            " leak",
                            " coming",
                            " from",
                            " the",
                            " firewall",
                            ",",
                            " causing",
                            " the",
                            " drivers",
                            " side",
                            " floor",
                            " to",
                            " be",
                            " soaked",
                            ".",
                            " It",
                            " was",
                            " put",
                            " away",
                            " in",
                            " a",
                            " garage",
                            " for",
                            " about",
                            " 4",
                            " months",
                            " or",
                            " so",
                            " for",
                            " the",
                            " winter",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " what",
                            " does",
                            " 4",
                            " months",
                            " of",
                            " wet",
                            " car",
                            " interior",
                            " look",
                            " like",
                            "...",
                            ":",
                            "s",
                            "ick",
                            "1",
                            ":",
                            "\n",
                            "\n",
                            "After",
                            " some",
                            " discussion",
                            ",",
                            " and",
                            " research",
                            ",",
                            " I",
                            " decided",
                            " to",
                            " use",
                            " an",
                            " En",
                            "zyme",
                            " Mold",
                            " Clean",
                            "er",
                            " called",
                            " sp",
                            "oric",
                            "id",
                            "in",
                            ".",
                            " I",
                            " knew",
                            " this",
                            " would",
                            " be",
                            " a",
                            " two",
                            " day",
                            " project",
                            ".",
                            " I",
                            " suited",
                            " up",
                            ",",
                            " using",
                            " a",
                            " mask",
                            ",",
                            " gloves",
                            ",",
                            " long",
                            " sleeve",
                            " shirt",
                            " tucked",
                            " into",
                            " the",
                            " glove",
                            ",",
                            " and",
                            " some",
                            " old",
                            " pants",
                            ".",
                            " I",
                            " was",
                            " going",
                            " to",
                            " throw",
                            " away",
                            " everything",
                            " I",
                            " was",
                            " wearing",
                            " so",
                            " I",
                            " looked",
                            " like",
                            " pretty"
                        ],
                        "dataIndex": null,
                        "index": "17442",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.712,
                        "maxValueTokenIndex": 58,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.589,
                            17.712,
                            0.868,
                            2.774,
                            11.811,
                            3.748,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:13.453Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 14.576,
                        "binMax": 18.22,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "20497",
            "description": "concepts involving ideas, questions, and problems",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4972616432465111,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "20497",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:35:20.302Z",
                "maxActApprox": 24.822,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    20497,
                    11984,
                    17493,
                    10803,
                    34382,
                    19219,
                    20182,
                    2305,
                    17026,
                    41809,
                    13960,
                    13218,
                    9371,
                    25443,
                    23205,
                    5670,
                    27350,
                    32293,
                    64,
                    41700,
                    29602,
                    26737,
                    47380,
                    48183,
                    1034
                ],
                "topkCosSimValues": [
                    1,
                    0.7918,
                    0.7657,
                    0.7544,
                    0.7524,
                    0.7512,
                    0.7389,
                    0.721,
                    0.7126,
                    0.7117,
                    0.7072,
                    0.7049,
                    0.6991,
                    0.695,
                    0.6934,
                    0.6876,
                    0.6759,
                    0.6667,
                    0.6645,
                    0.6582,
                    0.6543,
                    0.6452,
                    0.6426,
                    0.6402,
                    0.6374
                ],
                "neuron_alignment_indices": [
                    480,
                    481,
                    87
                ],
                "neuron_alignment_values": [
                    0.259,
                    0.24,
                    0.138
                ],
                "neuron_alignment_l1": [
                    0.012,
                    0.012,
                    0.007
                ],
                "correlated_neurons_indices": [
                    464,
                    52,
                    85
                ],
                "correlated_neurons_pearson": [
                    0.044,
                    0.035,
                    0.033
                ],
                "correlated_neurons_l1": [
                    0.045,
                    0.036,
                    0.034
                ],
                "correlated_features_indices": [
                    20511,
                    20503,
                    20443
                ],
                "correlated_features_pearson": [
                    0.006,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.006,
                    0.002,
                    0.001
                ],
                "neg_str": [
                    " challeng",
                    " Clarkson",
                    " arrang",
                    " Seym",
                    " contrace",
                    " helicop",
                    "iterranean",
                    " territ",
                    " Peb",
                    " submar"
                ],
                "neg_values": [
                    -0.701,
                    -0.666,
                    -0.661,
                    -0.656,
                    -0.643,
                    -0.64,
                    -0.624,
                    -0.613,
                    -0.606,
                    -0.587
                ],
                "pos_str": [
                    " ]",
                    " ][",
                    "\u00c2\u00b6",
                    "\"]=>",
                    "Joined",
                    "imon",
                    "yp",
                    " ):",
                    "cloud",
                    "=\""
                ],
                "pos_values": [
                    0.735,
                    0.652,
                    0.643,
                    0.641,
                    0.64,
                    0.587,
                    0.584,
                    0.577,
                    0.576,
                    0.573
                ],
                "frac_nonzero": 0.00104,
                "freq_hist_data_bar_heights": [
                    534,
                    532,
                    315,
                    246,
                    215,
                    150,
                    179,
                    123,
                    116,
                    109,
                    115,
                    71,
                    85,
                    48,
                    69,
                    47,
                    39,
                    35,
                    16,
                    36,
                    11,
                    32,
                    31,
                    11,
                    8,
                    15,
                    3,
                    21,
                    15,
                    3,
                    8,
                    5,
                    7,
                    0,
                    15,
                    0,
                    0,
                    0,
                    0,
                    0,
                    6,
                    0,
                    0,
                    0,
                    0,
                    5,
                    0,
                    0,
                    0,
                    5
                ],
                "freq_hist_data_bar_values": [
                    0.251,
                    0.748,
                    1.244,
                    1.74,
                    2.237,
                    2.733,
                    3.229,
                    3.726,
                    4.222,
                    4.719,
                    5.215,
                    5.711,
                    6.208,
                    6.704,
                    7.201,
                    7.697,
                    8.193,
                    8.69,
                    9.186,
                    9.682,
                    10.179,
                    10.675,
                    11.172,
                    11.668,
                    12.164,
                    12.661,
                    13.157,
                    13.654,
                    14.15,
                    14.646,
                    15.143,
                    15.639,
                    16.135,
                    16.632,
                    17.128,
                    17.625,
                    18.121,
                    18.617,
                    19.114,
                    19.61,
                    20.106,
                    20.603,
                    21.099,
                    21.596,
                    22.092,
                    22.588,
                    23.085,
                    23.581,
                    24.078,
                    24.574
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    3,
                    3,
                    3,
                    7,
                    6,
                    20,
                    11,
                    36,
                    65,
                    75,
                    141,
                    223,
                    328,
                    491,
                    750,
                    1019,
                    1420,
                    1920,
                    2457,
                    2923,
                    3378,
                    3926,
                    4169,
                    4161,
                    4164,
                    3844,
                    3373,
                    2976,
                    2264,
                    1820,
                    1377,
                    947,
                    678,
                    445,
                    293,
                    225,
                    126,
                    66,
                    46,
                    26,
                    17,
                    14,
                    8,
                    7,
                    0,
                    3,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.686,
                    -0.658,
                    -0.629,
                    -0.6,
                    -0.571,
                    -0.543,
                    -0.514,
                    -0.485,
                    -0.457,
                    -0.428,
                    -0.399,
                    -0.37,
                    -0.342,
                    -0.313,
                    -0.284,
                    -0.256,
                    -0.227,
                    -0.198,
                    -0.169,
                    -0.141,
                    -0.112,
                    -0.083,
                    -0.055,
                    -0.026,
                    0.003,
                    0.031,
                    0.06,
                    0.089,
                    0.118,
                    0.146,
                    0.175,
                    0.204,
                    0.232,
                    0.261,
                    0.29,
                    0.319,
                    0.347,
                    0.376,
                    0.405,
                    0.433,
                    0.462,
                    0.491,
                    0.519,
                    0.548,
                    0.577,
                    0.606,
                    0.634,
                    0.663,
                    0.692,
                    0.72
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "concepts involving ideas, questions, and problems",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk5fw1rujewi666rf84kov8",
                        "tokens": [
                            " question",
                            " for",
                            " lower",
                            "-",
                            "income",
                            " families",
                            ",",
                            " the",
                            " East",
                            "side",
                            " is",
                            " becoming",
                            " unaff",
                            "ordable",
                            " as",
                            " well",
                            ".",
                            " Neigh",
                            "\u00c2\u0143",
                            "bor",
                            "hood",
                            " Scout",
                            " weighs",
                            " in",
                            " with",
                            " its",
                            " statistics",
                            " to",
                            " illustrate",
                            " this",
                            " widening",
                            " ch",
                            "asm",
                            ":",
                            " the",
                            " East",
                            " C",
                            "esar",
                            " Chavez",
                            " \"",
                            "med",
                            "ian",
                            " real",
                            " estate",
                            " price",
                            " is",
                            " $",
                            "314",
                            ",",
                            "236",
                            ",",
                            " which",
                            " is",
                            " more",
                            " expensive",
                            " than",
                            " 91",
                            ".",
                            "7",
                            "%",
                            " of",
                            " the",
                            " neighborhoods",
                            " in",
                            " Texas",
                            " and",
                            " 76",
                            ".",
                            "3",
                            "%",
                            " of",
                            " the",
                            " neighborhoods",
                            " in",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".\"",
                            "\n",
                            "\n",
                            "An",
                            " earlier",
                            " study",
                            " by",
                            " UT",
                            "-",
                            "Austin",
                            "'s",
                            " Institute",
                            " for",
                            " Urban",
                            " Policy",
                            " Research",
                            " and",
                            " Analysis",
                            " showed",
                            " a",
                            " 5",
                            ".",
                            "4",
                            "%",
                            " decline",
                            " in",
                            " the",
                            " city",
                            "'s",
                            " African",
                            "-",
                            "American",
                            " population",
                            " between",
                            " 2000",
                            " and",
                            " 2010",
                            " \u2013",
                            " a",
                            " trend",
                            " partially",
                            " attributable",
                            " to",
                            " gent",
                            "rification",
                            ".",
                            " Austin",
                            " earned",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "20497",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 24.822,
                        "maxValueTokenIndex": 0,
                        "minValue": 0,
                        "values": [
                            24.822,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:35:25.517Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 24.822,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5fw1rujevi666z6r1mwcg",
                        "tokens": [
                            " question",
                            " remains",
                            " as",
                            " to",
                            " how",
                            " supportive",
                            " the",
                            " Obama",
                            " administration",
                            " will",
                            " be",
                            " if",
                            " Israel",
                            "'s",
                            " defense",
                            " forces",
                            " strike",
                            " Syrian",
                            " territory",
                            " --",
                            " again",
                            ",",
                            " possibly",
                            " widening",
                            " the",
                            " Middle",
                            " East",
                            " conflict",
                            ".",
                            "\n",
                            "\n",
                            "At",
                            " a",
                            " recent",
                            " conference",
                            " in",
                            " Jerusalem",
                            ",",
                            " Jonathan",
                            " Sp",
                            "yer",
                            ",",
                            " a",
                            " senior",
                            " researcher",
                            " at",
                            " the",
                            " Inter",
                            "-",
                            "Dis",
                            "ciplinary",
                            " Center",
                            " in",
                            " Herz",
                            "li",
                            "ya",
                            " (",
                            "ID",
                            "C",
                            "),",
                            " explained",
                            " that",
                            " prior",
                            " to",
                            " the",
                            " Arab",
                            " Spring",
                            ",",
                            " the",
                            " region",
                            " faced",
                            " two",
                            " bloc",
                            "s",
                            " --",
                            " a",
                            " U",
                            ".",
                            "S",
                            ".",
                            " bloc",
                            " and",
                            " an",
                            " Iranian",
                            " bloc",
                            ".",
                            " \"",
                            "Today",
                            ",",
                            " I",
                            " would",
                            " argue",
                            " that",
                            " the",
                            " Iran",
                            "-",
                            "led",
                            " Shiite",
                            " bloc",
                            " still",
                            " exists",
                            ",",
                            " but",
                            " there",
                            " is",
                            " no",
                            " longer",
                            " a",
                            " coherent",
                            " western",
                            " bloc",
                            " in",
                            " the",
                            " region",
                            ".\"",
                            "\n",
                            "\n",
                            "Sp",
                            "yer",
                            " concluded",
                            " that",
                            " one",
                            " of",
                            " the",
                            " central",
                            " reasons",
                            " for"
                        ],
                        "dataIndex": null,
                        "index": "20497",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 24.822,
                        "maxValueTokenIndex": 0,
                        "minValue": 0,
                        "values": [
                            24.822,
                            0.546,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:35:25.517Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 24.822,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5fw1rujexi666kbb9z2ew",
                        "tokens": [
                            " question",
                            " we",
                            " might",
                            " ask",
                            "\n",
                            "\n",
                            "Except",
                            " for",
                            " one",
                            "\n",
                            "\n",
                            "The",
                            " one",
                            " we",
                            " thirst",
                            " for",
                            "\n",
                            "\n",
                            "The",
                            " one",
                            " that",
                            " leads",
                            " to",
                            " understanding",
                            "\n",
                            "\n",
                            "Our",
                            " world",
                            "\n",
                            "\n",
                            "Our",
                            " choices",
                            "\n",
                            "\n",
                            "Our",
                            "selves",
                            "\n",
                            "\n",
                            "The",
                            " question",
                            " that",
                            " lies",
                            " at",
                            " the",
                            " intersection",
                            " of",
                            " technology",
                            " and",
                            " spirituality",
                            "\n",
                            "\n",
                            "Advertisement",
                            " Who",
                            " am",
                            " I",
                            "?",
                            "\n",
                            "\n",
                            "And",
                            " some",
                            " reactions",
                            "\u00e2\u0122\u00a6",
                            "\n",
                            "\n",
                            "\u2014\u2014\u2014\u2014",
                            "\u2014\u2014",
                            "\u2013",
                            "\n",
                            "\n",
                            "Posted",
                            " by",
                            " Tony",
                            " Or",
                            "te",
                            "ga",
                            " on",
                            " February",
                            " 7",
                            ",",
                            " 2016",
                            " at",
                            " 20",
                            ":",
                            "20",
                            "\n",
                            "\n",
                            "E",
                            "-",
                            "mail",
                            " tips",
                            " and",
                            " story",
                            " ideas",
                            " to",
                            " t",
                            "ony",
                            "o",
                            "94",
                            " AT",
                            " g",
                            "mail",
                            " DOT",
                            " com",
                            " or",
                            " follow",
                            " us",
                            " on",
                            " Twitter",
                            ".",
                            " We",
                            " post",
                            " behind",
                            "-",
                            "the",
                            "-",
                            "scenes",
                            " updates",
                            " at",
                            " our",
                            " Facebook",
                            " author",
                            " page",
                            ".",
                            " After",
                            " every",
                            " new",
                            " story"
                        ],
                        "dataIndex": null,
                        "index": "20497",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 24.822,
                        "maxValueTokenIndex": 0,
                        "minValue": 0,
                        "values": [
                            24.822,
                            3.314,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:35:25.517Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 24.822,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "21306",
            "description": "questions about understanding or learning processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4952148199081421,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "21306",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:55:08.250Z",
                "maxActApprox": 46.771,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    21306,
                    11,
                    59028,
                    24863,
                    97707,
                    62741,
                    63520,
                    60147,
                    38758,
                    90284,
                    2430,
                    23492,
                    5418,
                    42965,
                    29326,
                    29674,
                    5228,
                    58522,
                    2086,
                    15009,
                    78040,
                    23145,
                    69877,
                    2372,
                    81898
                ],
                "topkCosSimValues": [
                    1,
                    0.7454,
                    0.7336,
                    0.6773,
                    0.6355,
                    0.6096,
                    0.608,
                    0.606,
                    0.5991,
                    0.5956,
                    0.5951,
                    0.5894,
                    0.5793,
                    0.5581,
                    0.5506,
                    0.5474,
                    0.5369,
                    0.5271,
                    0.5197,
                    0.4772,
                    0.4568,
                    0.4391,
                    0.4388,
                    0.3822,
                    0.3546
                ],
                "neuron_alignment_indices": [
                    243,
                    373,
                    350
                ],
                "neuron_alignment_values": [
                    0.119,
                    0.095,
                    0.093
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    243,
                    60,
                    350
                ],
                "correlated_neurons_pearson": [
                    0.023,
                    0.02,
                    0.019
                ],
                "correlated_neurons_l1": [
                    0.024,
                    0.019,
                    0.019
                ],
                "correlated_features_indices": [
                    21352,
                    21266,
                    21244
                ],
                "correlated_features_pearson": [
                    0.011,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.012,
                    0,
                    0
                ],
                "neg_str": [
                    "phant",
                    "UA",
                    "iture",
                    "hammad",
                    "anship",
                    "aber",
                    " Issue",
                    "reporting",
                    "aredevil",
                    "idered"
                ],
                "neg_values": [
                    -0.701,
                    -0.654,
                    -0.627,
                    -0.615,
                    -0.612,
                    -0.591,
                    -0.585,
                    -0.584,
                    -0.583,
                    -0.582
                ],
                "pos_str": [
                    " lucky",
                    "ls",
                    " much",
                    " messed",
                    "beit",
                    " hard",
                    "itzer",
                    " thankful",
                    " frustrating",
                    " grateful"
                ],
                "pos_values": [
                    0.765,
                    0.753,
                    0.752,
                    0.747,
                    0.736,
                    0.715,
                    0.71,
                    0.709,
                    0.694,
                    0.694
                ],
                "frac_nonzero": 0.0002,
                "freq_hist_data_bar_heights": [
                    104,
                    77,
                    59,
                    45,
                    42,
                    38,
                    30,
                    28,
                    19,
                    23,
                    13,
                    8,
                    17,
                    13,
                    12,
                    7,
                    7,
                    9,
                    4,
                    2,
                    2,
                    3,
                    6,
                    3,
                    3,
                    1,
                    2,
                    0,
                    2,
                    2,
                    2,
                    0,
                    3,
                    3,
                    3,
                    5,
                    2,
                    2,
                    3,
                    2,
                    2,
                    2,
                    2,
                    2,
                    2,
                    2,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.48,
                    1.415,
                    2.351,
                    3.286,
                    4.221,
                    5.156,
                    6.091,
                    7.026,
                    7.962,
                    8.897,
                    9.832,
                    10.767,
                    11.702,
                    12.637,
                    13.573,
                    14.508,
                    15.443,
                    16.378,
                    17.313,
                    18.248,
                    19.184,
                    20.119,
                    21.054,
                    21.989,
                    22.924,
                    23.859,
                    24.795,
                    25.73,
                    26.665,
                    27.6,
                    28.535,
                    29.47,
                    30.406,
                    31.341,
                    32.276,
                    33.211,
                    34.146,
                    35.081,
                    36.017,
                    36.952,
                    37.887,
                    38.822,
                    39.757,
                    40.692,
                    41.628,
                    42.563,
                    43.498,
                    44.433,
                    45.368,
                    46.303
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    2,
                    4,
                    7,
                    19,
                    21,
                    28,
                    70,
                    109,
                    155,
                    248,
                    378,
                    484,
                    743,
                    1087,
                    1356,
                    1818,
                    2190,
                    2719,
                    3255,
                    3665,
                    3743,
                    3945,
                    3934,
                    3657,
                    3266,
                    2861,
                    2350,
                    1925,
                    1529,
                    1195,
                    882,
                    680,
                    493,
                    380,
                    291,
                    222,
                    148,
                    132,
                    99,
                    67,
                    32,
                    23,
                    16,
                    13,
                    4,
                    2,
                    3,
                    5
                ],
                "logits_hist_data_bar_values": [
                    -0.686,
                    -0.657,
                    -0.628,
                    -0.598,
                    -0.569,
                    -0.54,
                    -0.51,
                    -0.481,
                    -0.452,
                    -0.422,
                    -0.393,
                    -0.364,
                    -0.334,
                    -0.305,
                    -0.276,
                    -0.247,
                    -0.217,
                    -0.188,
                    -0.159,
                    -0.129,
                    -0.1,
                    -0.071,
                    -0.041,
                    -0.012,
                    0.017,
                    0.047,
                    0.076,
                    0.105,
                    0.135,
                    0.164,
                    0.193,
                    0.223,
                    0.252,
                    0.281,
                    0.311,
                    0.34,
                    0.369,
                    0.399,
                    0.428,
                    0.457,
                    0.486,
                    0.516,
                    0.545,
                    0.574,
                    0.604,
                    0.633,
                    0.662,
                    0.692,
                    0.721,
                    0.75
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions about understanding or learning processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfubx4rgf010exsjeyoxom",
                        "tokens": [
                            " President",
                            " Enrique",
                            " Pe",
                            "\u00c3\u00b1a",
                            " Nieto",
                            " on",
                            " Jan",
                            ".",
                            " 27",
                            ",",
                            " according",
                            " to",
                            " a",
                            " transcript",
                            " published",
                            " Thursday",
                            " by",
                            " The",
                            " Washington",
                            " Post",
                            ".",
                            "\n",
                            "\n",
                            "[",
                            "Trump",
                            " urged",
                            " Mexican",
                            " president",
                            " to",
                            " end",
                            " his",
                            " public",
                            " defiance",
                            " on",
                            " border",
                            " wall",
                            ",",
                            " transcript",
                            " reveals",
                            "]",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Listen",
                            ",",
                            " I",
                            " know",
                            " how",
                            " tough",
                            " these",
                            " guys",
                            " are",
                            " \u2014",
                            " our",
                            " military",
                            " will",
                            " knock",
                            " them",
                            " out",
                            " like",
                            " you",
                            " never",
                            " thought",
                            " of",
                            ",",
                            " we",
                            " will",
                            " work",
                            " to",
                            " help",
                            " you",
                            " knock",
                            " them",
                            " out",
                            " because",
                            " your",
                            " country",
                            " does",
                            " not",
                            " want",
                            " that",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Trump",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " can",
                            " Trump",
                            " actually",
                            " do",
                            " that",
                            "?",
                            "\n",
                            "\n",
                            "Republican",
                            " presidential",
                            " nominee",
                            " Donald",
                            " Trump",
                            " discussed",
                            " border",
                            " security",
                            " at",
                            " the",
                            " third",
                            " and",
                            " final",
                            " presidential",
                            " debate",
                            ",",
                            " Oct",
                            ".",
                            " 19",
                            ",",
                            " in",
                            " Las",
                            " Vegas",
                            ".",
                            " (",
                            "The",
                            " Washington",
                            " Post"
                        ],
                        "dataIndex": null,
                        "index": "21306",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.771,
                        "maxValueTokenIndex": 48,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.771,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:55:13.567Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 46.771,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfubx5rgf110ex2b7evkpk",
                        "tokens": [
                            " because",
                            " you",
                            " did",
                            " that",
                            " on",
                            " the",
                            " blind",
                            " faith",
                            " that",
                            " life",
                            " might",
                            " be",
                            " better",
                            " on",
                            " the",
                            " other",
                            " side",
                            ".",
                            " You",
                            " did",
                            " that",
                            " on",
                            " hope",
                            " alone",
                            ".",
                            " You",
                            " didn",
                            "'t",
                            " know",
                            " what",
                            " you",
                            " do",
                            " now",
                            ".",
                            " That",
                            "'s",
                            " so",
                            " brave",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " are",
                            " so",
                            " brave",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " know",
                            " how",
                            " scared",
                            " you",
                            " are",
                            ".",
                            " I",
                            " still",
                            " get",
                            " scared",
                            ".",
                            " My",
                            " year",
                            " of",
                            " recovery",
                            " has",
                            " been",
                            " the",
                            " most",
                            " challenging",
                            " and",
                            " rewarding",
                            " of",
                            " my",
                            " life",
                            ".",
                            " It",
                            "'s",
                            " not",
                            " perfect",
                            " and",
                            " I",
                            " don",
                            "'t",
                            " think",
                            " it",
                            " ever",
                            " will",
                            " be",
                            ".",
                            " I",
                            " get",
                            " lonely",
                            " and",
                            " restless",
                            ".",
                            " I",
                            " live",
                            " with",
                            " those",
                            " feelings",
                            ".",
                            " Actually",
                            ",",
                            " I",
                            " try",
                            " to",
                            " understand",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " day",
                            ",",
                            " your",
                            " life",
                            " will",
                            " look",
                            " like",
                            " a",
                            " version",
                            " of",
                            " mine",
                            ".",
                            " Things",
                            " will",
                            " keep"
                        ],
                        "dataIndex": null,
                        "index": "21306",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.978,
                        "maxValueTokenIndex": 50,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.978,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:55:13.567Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 46.771,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfubx7rgfm10exporrr5nf",
                        "tokens": [
                            " because",
                            " you",
                            " did",
                            " that",
                            " on",
                            " the",
                            " blind",
                            " faith",
                            " that",
                            " life",
                            " might",
                            " be",
                            " better",
                            " on",
                            " the",
                            " other",
                            " side",
                            ".",
                            " You",
                            " did",
                            " that",
                            " on",
                            " hope",
                            " alone",
                            ".",
                            " You",
                            " didn",
                            "'t",
                            " know",
                            " what",
                            " you",
                            " do",
                            " now",
                            ".",
                            " That",
                            "'s",
                            " so",
                            " brave",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " are",
                            " so",
                            " brave",
                            ".",
                            "\n",
                            "\n",
                            "I",
                            " know",
                            " how",
                            " scared",
                            " you",
                            " are",
                            ".",
                            " I",
                            " still",
                            " get",
                            " scared",
                            ".",
                            " My",
                            " year",
                            " of",
                            " recovery",
                            " has",
                            " been",
                            " the",
                            " most",
                            " challenging",
                            " and",
                            " rewarding",
                            " of",
                            " my",
                            " life",
                            ".",
                            " It",
                            "'s",
                            " not",
                            " perfect",
                            " and",
                            " I",
                            " don",
                            "'t",
                            " think",
                            " it",
                            " ever",
                            " will",
                            " be",
                            ".",
                            " I",
                            " get",
                            " lonely",
                            " and",
                            " restless",
                            ".",
                            " I",
                            " live",
                            " with",
                            " those",
                            " feelings",
                            ".",
                            " Actually",
                            ",",
                            " I",
                            " try",
                            " to",
                            " understand",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " day",
                            ",",
                            " your",
                            " life",
                            " will",
                            " look",
                            " like",
                            " a",
                            " version",
                            " of",
                            " mine",
                            ".",
                            " Things",
                            " will",
                            " keep"
                        ],
                        "dataIndex": null,
                        "index": "21306",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.978,
                        "maxValueTokenIndex": 50,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.978,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:55:13.567Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 37.417,
                        "binMax": 46.771,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "7119",
            "description": "questions or prompts for inquiry",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4944324044714097,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "7119",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:10:42.057Z",
                "maxActApprox": 39.099,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    7119,
                    27620,
                    41554,
                    22388,
                    20034,
                    27390,
                    2982,
                    46150,
                    14536,
                    28056,
                    42079,
                    33506,
                    27675,
                    2113,
                    11076,
                    36644,
                    14958,
                    4007,
                    24424,
                    1128,
                    10162,
                    38447,
                    49146,
                    30287,
                    1273
                ],
                "topkCosSimValues": [
                    1,
                    0.8224,
                    0.7732,
                    0.7545,
                    0.7212,
                    0.6714,
                    0.6018,
                    0.5986,
                    0.49,
                    0.4899,
                    0.4792,
                    0.4781,
                    0.4647,
                    0.4631,
                    0.4492,
                    0.441,
                    0.4344,
                    0.4283,
                    0.4238,
                    0.4163,
                    0.4135,
                    0.4093,
                    0.392,
                    0.3872,
                    0.3791
                ],
                "neuron_alignment_indices": [
                    321,
                    213,
                    610
                ],
                "neuron_alignment_values": [
                    0.113,
                    0.113,
                    0.1
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    184,
                    213,
                    321
                ],
                "correlated_neurons_pearson": [
                    0.031,
                    0.031,
                    0.028
                ],
                "correlated_neurons_l1": [
                    0.027,
                    0.027,
                    0.028
                ],
                "correlated_features_indices": [
                    7104,
                    7084,
                    7119
                ],
                "correlated_features_pearson": [
                    0.015,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.016,
                    0,
                    0
                ],
                "neg_str": [
                    "zinski",
                    "undo",
                    "luaj",
                    "rongh",
                    "cutting",
                    "pite",
                    "\u0124\u00ac",
                    "lim",
                    "ccording",
                    "ovie"
                ],
                "neg_values": [
                    -0.683,
                    -0.661,
                    -0.659,
                    -0.642,
                    -0.635,
                    -0.631,
                    -0.62,
                    -0.614,
                    -0.589,
                    -0.584
                ],
                "pos_str": [
                    " questions",
                    " probing",
                    " rhet",
                    "wered",
                    " forgiveness",
                    " Questions",
                    " answered",
                    " permission",
                    " question",
                    "govtrack"
                ],
                "pos_values": [
                    1.081,
                    1.023,
                    1.004,
                    0.914,
                    0.886,
                    0.838,
                    0.82,
                    0.82,
                    0.809,
                    0.796
                ],
                "frac_nonzero": 0.00025,
                "freq_hist_data_bar_heights": [
                    93,
                    58,
                    36,
                    34,
                    39,
                    26,
                    30,
                    31,
                    20,
                    20,
                    23,
                    26,
                    23,
                    23,
                    23,
                    17,
                    25,
                    25,
                    15,
                    13,
                    14,
                    9,
                    11,
                    12,
                    6,
                    10,
                    7,
                    5,
                    12,
                    14,
                    13,
                    9,
                    4,
                    6,
                    6,
                    9,
                    8,
                    7,
                    7,
                    7,
                    3,
                    1,
                    2,
                    3,
                    0,
                    3,
                    0,
                    1,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.394,
                    1.176,
                    1.958,
                    2.739,
                    3.521,
                    4.303,
                    5.085,
                    5.867,
                    6.649,
                    7.431,
                    8.213,
                    8.995,
                    9.777,
                    10.559,
                    11.341,
                    12.123,
                    12.905,
                    13.686,
                    14.468,
                    15.25,
                    16.032,
                    16.814,
                    17.596,
                    18.378,
                    19.16,
                    19.942,
                    20.724,
                    21.506,
                    22.288,
                    23.07,
                    23.852,
                    24.634,
                    25.415,
                    26.197,
                    26.979,
                    27.761,
                    28.543,
                    29.325,
                    30.107,
                    30.889,
                    31.671,
                    32.453,
                    33.235,
                    34.017,
                    34.799,
                    35.581,
                    36.362,
                    37.144,
                    37.926,
                    38.708
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    5,
                    2,
                    10,
                    19,
                    40,
                    59,
                    126,
                    206,
                    328,
                    524,
                    819,
                    1288,
                    1862,
                    2475,
                    3186,
                    3687,
                    4332,
                    4706,
                    4727,
                    4523,
                    4092,
                    3499,
                    2839,
                    2149,
                    1580,
                    1079,
                    758,
                    498,
                    289,
                    206,
                    119,
                    85,
                    38,
                    27,
                    19,
                    14,
                    5,
                    11,
                    5,
                    6,
                    3,
                    3,
                    1,
                    1,
                    1,
                    0,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.665,
                    -0.63,
                    -0.595,
                    -0.559,
                    -0.524,
                    -0.489,
                    -0.454,
                    -0.418,
                    -0.383,
                    -0.348,
                    -0.312,
                    -0.277,
                    -0.242,
                    -0.207,
                    -0.171,
                    -0.136,
                    -0.101,
                    -0.066,
                    -0.03,
                    0.005,
                    0.04,
                    0.076,
                    0.111,
                    0.146,
                    0.181,
                    0.217,
                    0.252,
                    0.287,
                    0.322,
                    0.358,
                    0.393,
                    0.428,
                    0.464,
                    0.499,
                    0.534,
                    0.569,
                    0.605,
                    0.64,
                    0.675,
                    0.71,
                    0.746,
                    0.781,
                    0.816,
                    0.851,
                    0.887,
                    0.922,
                    0.957,
                    0.993,
                    1.028,
                    1.063
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions or prompts for inquiry",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4k75ki7kri6667u1y7bck",
                        "tokens": [
                            " question",
                            " we",
                            " might",
                            " ask",
                            "\n",
                            "\n",
                            "Except",
                            " for",
                            " one",
                            "\n",
                            "\n",
                            "The",
                            " one",
                            " we",
                            " thirst",
                            " for",
                            "\n",
                            "\n",
                            "The",
                            " one",
                            " that",
                            " leads",
                            " to",
                            " understanding",
                            "\n",
                            "\n",
                            "Our",
                            " world",
                            "\n",
                            "\n",
                            "Our",
                            " choices",
                            "\n",
                            "\n",
                            "Our",
                            "selves",
                            "\n",
                            "\n",
                            "The",
                            " question",
                            " that",
                            " lies",
                            " at",
                            " the",
                            " intersection",
                            " of",
                            " technology",
                            " and",
                            " spirituality",
                            "\n",
                            "\n",
                            "Advertisement",
                            " Who",
                            " am",
                            " I",
                            "?",
                            "\n",
                            "\n",
                            "And",
                            " some",
                            " reactions",
                            "\u00e2\u0122\u00a6",
                            "\n",
                            "\n",
                            "\u2014\u2014\u2014\u2014",
                            "\u2014\u2014",
                            "\u2013",
                            "\n",
                            "\n",
                            "Posted",
                            " by",
                            " Tony",
                            " Or",
                            "te",
                            "ga",
                            " on",
                            " February",
                            " 7",
                            ",",
                            " 2016",
                            " at",
                            " 20",
                            ":",
                            "20",
                            "\n",
                            "\n",
                            "E",
                            "-",
                            "mail",
                            " tips",
                            " and",
                            " story",
                            " ideas",
                            " to",
                            " t",
                            "ony",
                            "o",
                            "94",
                            " AT",
                            " g",
                            "mail",
                            " DOT",
                            " com",
                            " or",
                            " follow",
                            " us",
                            " on",
                            " Twitter",
                            ".",
                            " We",
                            " post",
                            " behind",
                            "-",
                            "the",
                            "-",
                            "scenes",
                            " updates",
                            " at",
                            " our",
                            " Facebook",
                            " author",
                            " page",
                            ".",
                            " After",
                            " every",
                            " new",
                            " story"
                        ],
                        "dataIndex": null,
                        "index": "7119",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.099,
                        "maxValueTokenIndex": 3,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            39.099,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:10:46.926Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 39.099,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4k75ki7ksi666m0gmcfuz",
                        "tokens": [
                            " are",
                            " benefiting",
                            " our",
                            " society",
                            " or",
                            " causing",
                            " more",
                            " harm",
                            " than",
                            " good",
                            "?",
                            "\n",
                            "\n",
                            "We",
                            " need",
                            " to",
                            " ask",
                            ":",
                            " does",
                            " cannabis",
                            " prohibition",
                            " work",
                            "?",
                            " The",
                            " simple",
                            " answer",
                            " is",
                            " no",
                            ".",
                            " We",
                            " only",
                            " have",
                            " to",
                            " look",
                            " back",
                            " in",
                            " history",
                            " to",
                            " the",
                            " era",
                            " of",
                            " Prohibition",
                            " in",
                            " the",
                            " 1920",
                            "s",
                            " to",
                            " understand",
                            " why",
                            ".",
                            " Al",
                            " Cap",
                            "one",
                            " and",
                            " his",
                            " violent",
                            " mob",
                            " made",
                            " millions",
                            " of",
                            " dollars",
                            " from",
                            " the",
                            " illegal",
                            " sale",
                            " of",
                            " alcohol",
                            ".",
                            " Today",
                            " we",
                            " are",
                            " witnessing",
                            " a",
                            " similar",
                            " trend",
                            " in",
                            " Ireland",
                            ",",
                            " with",
                            " ruthless",
                            " criminal",
                            " gangs",
                            " making",
                            " a",
                            " fortune",
                            " (",
                            "tax",
                            "-",
                            "free",
                            " of",
                            " course",
                            ")",
                            " from",
                            " the",
                            " sale",
                            " of",
                            " cannabis",
                            ".",
                            " Sadly",
                            ",",
                            " the",
                            " mon",
                            "ies",
                            " raised",
                            " often",
                            " go",
                            " on",
                            " to",
                            " fuel",
                            " much",
                            " more",
                            " serious",
                            " crimes",
                            " such",
                            " as",
                            " gun",
                            " crime",
                            ",",
                            " hard",
                            " drugs",
                            " and",
                            " prostitution",
                            ".",
                            "\n",
                            "\n",
                            "Legal",
                            "ising"
                        ],
                        "dataIndex": null,
                        "index": "7119",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.498,
                        "maxValueTokenIndex": 16,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            38.498,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:10:46.926Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 39.099,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4k75ki7kti6667mpf4onl",
                        "tokens": [
                            " other",
                            " places",
                            " and",
                            " many",
                            " of",
                            " them",
                            " do",
                            " not",
                            " share",
                            " the",
                            " same",
                            " values",
                            " of",
                            " tolerance",
                            " and",
                            " fair",
                            " play",
                            " that",
                            " we",
                            " grew",
                            " up",
                            " with",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            " is",
                            " simply",
                            " a",
                            " numbers",
                            " game",
                            ".",
                            "\n",
                            "\n",
                            "And",
                            " speaking",
                            " of",
                            " numbers",
                            " it",
                            "'s",
                            " time",
                            " to",
                            " ask",
                            " the",
                            " government",
                            " about",
                            " where",
                            " the",
                            " 170",
                            ",",
                            "000",
                            " new",
                            " jobs",
                            " promised",
                            " in",
                            " the",
                            " Budget",
                            " are",
                            " coming",
                            " from",
                            ".",
                            "\n",
                            "\n",
                            "That",
                            "'s",
                            " right",
                            " \u2013",
                            " 170",
                            ",",
                            "000",
                            " new",
                            " jobs",
                            " over",
                            " the",
                            " next",
                            " four",
                            " years",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            " was",
                            " simply",
                            " part",
                            " of",
                            " the",
                            " giant",
                            " con",
                            " job",
                            " these",
                            " people",
                            " special",
                            "ise",
                            " in",
                            ".",
                            "\n",
                            "\n",
                            "Since",
                            " Budget",
                            " day",
                            " last",
                            " month",
                            " thousands",
                            " of",
                            " people",
                            " have",
                            " been",
                            " given",
                            " their",
                            " marching",
                            " orders",
                            ",",
                            " from",
                            " railway",
                            " shop",
                            " workers",
                            " to",
                            " hundreds",
                            " in",
                            " our",
                            " defence",
                            " force",
                            " announced",
                            " just",
                            " yesterday",
                            ".",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "7119",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 37.013,
                        "maxValueTokenIndex": 42,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            37.013,
                            3.1,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:10:46.926Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 39.099,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "15971",
            "description": "questions related to personal experiences or knowledge",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.49091191562747727,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "15971",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:05:11.242Z",
                "maxActApprox": 32.685,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    15971,
                    3251,
                    16640,
                    7129,
                    15548,
                    136,
                    20655,
                    9275,
                    1079,
                    19912,
                    19871,
                    16466,
                    15974,
                    172,
                    16601,
                    10447,
                    10976,
                    12534,
                    18718,
                    23027,
                    2069,
                    19837,
                    22504,
                    17798,
                    18778
                ],
                "topkCosSimValues": [
                    1,
                    0.5125,
                    0.4829,
                    0.4028,
                    0.3953,
                    0.3742,
                    0.3481,
                    0.3365,
                    0.3355,
                    0.3341,
                    0.3214,
                    0.3199,
                    0.3195,
                    0.2999,
                    0.2906,
                    0.2886,
                    0.2852,
                    0.2766,
                    0.275,
                    0.2709,
                    0.2703,
                    0.2698,
                    0.2667,
                    0.2648,
                    0.2636
                ],
                "neuron_alignment_indices": [
                    368,
                    43,
                    450
                ],
                "neuron_alignment_values": [
                    0.108,
                    0.092,
                    0.091
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    665,
                    368,
                    699
                ],
                "correlated_neurons_pearson": [
                    0.039,
                    0.036,
                    0.03
                ],
                "correlated_neurons_l1": [
                    0.045,
                    0.039,
                    0.022
                ],
                "correlated_features_indices": [
                    15940,
                    15974,
                    15875
                ],
                "correlated_features_pearson": [
                    0.073,
                    0.048,
                    0.04
                ],
                "correlated_features_l1": [
                    0.075,
                    0.05,
                    0.04
                ],
                "neg_str": [
                    "illation",
                    "elli",
                    " balcon",
                    "arer",
                    "auer",
                    " fixme",
                    "cour",
                    "inder",
                    "rored",
                    "lication"
                ],
                "neg_values": [
                    -0.691,
                    -0.646,
                    -0.629,
                    -0.628,
                    -0.626,
                    -0.604,
                    -0.59,
                    -0.589,
                    -0.587,
                    -0.576
                ],
                "pos_str": [
                    " existence",
                    "oslov",
                    " genesis",
                    "olas",
                    "agascar",
                    "ename",
                    " fateful",
                    " fixation",
                    " conception",
                    " forged"
                ],
                "pos_values": [
                    0.725,
                    0.702,
                    0.674,
                    0.635,
                    0.633,
                    0.624,
                    0.62,
                    0.615,
                    0.593,
                    0.587
                ],
                "frac_nonzero": 0.00247,
                "freq_hist_data_bar_heights": [
                    2206,
                    1482,
                    1042,
                    750,
                    517,
                    371,
                    261,
                    206,
                    149,
                    122,
                    92,
                    70,
                    65,
                    59,
                    41,
                    46,
                    44,
                    31,
                    18,
                    19,
                    22,
                    13,
                    12,
                    9,
                    10,
                    10,
                    14,
                    8,
                    7,
                    4,
                    4,
                    9,
                    4,
                    4,
                    3,
                    3,
                    2,
                    4,
                    5,
                    5,
                    4,
                    2,
                    5,
                    3,
                    3,
                    4,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.327,
                    0.981,
                    1.634,
                    2.288,
                    2.942,
                    3.595,
                    4.249,
                    4.903,
                    5.557,
                    6.21,
                    6.864,
                    7.518,
                    8.171,
                    8.825,
                    9.479,
                    10.132,
                    10.786,
                    11.44,
                    12.093,
                    12.747,
                    13.401,
                    14.055,
                    14.708,
                    15.362,
                    16.016,
                    16.669,
                    17.323,
                    17.977,
                    18.63,
                    19.284,
                    19.938,
                    20.592,
                    21.245,
                    21.899,
                    22.553,
                    23.206,
                    23.86,
                    24.514,
                    25.167,
                    25.821,
                    26.475,
                    27.128,
                    27.782,
                    28.436,
                    29.09,
                    29.743,
                    30.397,
                    31.051,
                    31.704,
                    32.358
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    3,
                    4,
                    9,
                    10,
                    36,
                    45,
                    59,
                    72,
                    151,
                    226,
                    313,
                    472,
                    664,
                    966,
                    1180,
                    1567,
                    2056,
                    2455,
                    2900,
                    3243,
                    3589,
                    3686,
                    3798,
                    3587,
                    3501,
                    3209,
                    2750,
                    2271,
                    1956,
                    1501,
                    1106,
                    885,
                    626,
                    439,
                    324,
                    200,
                    146,
                    103,
                    51,
                    44,
                    20,
                    12,
                    9,
                    3,
                    5,
                    0,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.677,
                    -0.649,
                    -0.62,
                    -0.592,
                    -0.564,
                    -0.535,
                    -0.507,
                    -0.479,
                    -0.45,
                    -0.422,
                    -0.394,
                    -0.365,
                    -0.337,
                    -0.309,
                    -0.28,
                    -0.252,
                    -0.224,
                    -0.195,
                    -0.167,
                    -0.139,
                    -0.11,
                    -0.082,
                    -0.054,
                    -0.025,
                    0.003,
                    0.031,
                    0.06,
                    0.088,
                    0.116,
                    0.145,
                    0.173,
                    0.201,
                    0.23,
                    0.258,
                    0.286,
                    0.315,
                    0.343,
                    0.371,
                    0.4,
                    0.428,
                    0.456,
                    0.485,
                    0.513,
                    0.541,
                    0.569,
                    0.598,
                    0.626,
                    0.654,
                    0.683,
                    0.711
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions related to personal experiences or knowledge",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmqnb6f6idi666gwztqkz2",
                        "tokens": [
                            " Visit",
                            " discourse",
                            ".",
                            "python",
                            "podcast",
                            ".",
                            "com",
                            " for",
                            " your",
                            " opportunity",
                            " to",
                            " find",
                            " out",
                            " about",
                            " upcoming",
                            " guests",
                            ",",
                            " suggest",
                            " questions",
                            ",",
                            " and",
                            " propose",
                            " show",
                            " ideas",
                            ".",
                            "\n",
                            "\n",
                            "Your",
                            " host",
                            " as",
                            " usual",
                            " is",
                            " Tobias",
                            " M",
                            "acey",
                            " and",
                            " today",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " interviewing",
                            " Dave",
                            " Vand",
                            "en",
                            "b",
                            "out",
                            " about",
                            " SK",
                            "ID",
                            "L",
                            ",",
                            " a",
                            " library",
                            " for",
                            " designing",
                            " and",
                            " valid",
                            "ating",
                            " circuit",
                            " layouts",
                            ".",
                            "\n",
                            "\n",
                            "Interview",
                            "\n",
                            "\n",
                            "Introdu",
                            "ctions",
                            "\n",
                            "\n",
                            "How",
                            " did",
                            " you",
                            " get",
                            " introduced",
                            " to",
                            " Python",
                            "?",
                            "\n",
                            "\n",
                            "Can",
                            " you",
                            " describe",
                            " what",
                            " SK",
                            "ID",
                            "L",
                            " is",
                            " and",
                            " the",
                            " problem",
                            " that",
                            " you",
                            " were",
                            " trying",
                            " to",
                            " solve",
                            " when",
                            " you",
                            " first",
                            " started",
                            " it",
                            "?",
                            "\n",
                            "\n",
                            "Most",
                            " of",
                            " my",
                            " experience",
                            " designing",
                            " circuits",
                            " has",
                            " been",
                            " done",
                            " using",
                            " a",
                            " graphical",
                            " tool",
                            ".",
                            " If",
                            " you",
                            " are",
                            " using",
                            " Python",
                            " for",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "15971",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 32.685,
                        "maxValueTokenIndex": 74,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.763,
                            12.829,
                            32.685,
                            12.362,
                            9.937,
                            0,
                            0.346,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.382,
                            0.602,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.986,
                            0,
                            2.182,
                            7.157,
                            0.137,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:05:18.181Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 32.685,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmqnb9f6jfi6666zb8pcx8",
                        "tokens": [
                            " Visit",
                            " discourse",
                            ".",
                            "python",
                            "podcast",
                            ".",
                            "com",
                            " for",
                            " your",
                            " opportunity",
                            " to",
                            " find",
                            " out",
                            " about",
                            " upcoming",
                            " guests",
                            ",",
                            " suggest",
                            " questions",
                            ",",
                            " and",
                            " propose",
                            " show",
                            " ideas",
                            ".",
                            "\n",
                            "\n",
                            "Your",
                            " host",
                            " as",
                            " usual",
                            " is",
                            " Tobias",
                            " M",
                            "acey",
                            " and",
                            " today",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " interviewing",
                            " Dave",
                            " Vand",
                            "en",
                            "b",
                            "out",
                            " about",
                            " SK",
                            "ID",
                            "L",
                            ",",
                            " a",
                            " library",
                            " for",
                            " designing",
                            " and",
                            " valid",
                            "ating",
                            " circuit",
                            " layouts",
                            ".",
                            "\n",
                            "\n",
                            "Interview",
                            "\n",
                            "\n",
                            "Introdu",
                            "ctions",
                            "\n",
                            "\n",
                            "How",
                            " did",
                            " you",
                            " get",
                            " introduced",
                            " to",
                            " Python",
                            "?",
                            "\n",
                            "\n",
                            "Can",
                            " you",
                            " describe",
                            " what",
                            " SK",
                            "ID",
                            "L",
                            " is",
                            " and",
                            " the",
                            " problem",
                            " that",
                            " you",
                            " were",
                            " trying",
                            " to",
                            " solve",
                            " when",
                            " you",
                            " first",
                            " started",
                            " it",
                            "?",
                            "\n",
                            "\n",
                            "Most",
                            " of",
                            " my",
                            " experience",
                            " designing",
                            " circuits",
                            " has",
                            " been",
                            " done",
                            " using",
                            " a",
                            " graphical",
                            " tool",
                            ".",
                            " If",
                            " you",
                            " are",
                            " using",
                            " Python",
                            " for",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "15971",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 32.685,
                        "maxValueTokenIndex": 74,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.763,
                            12.829,
                            32.685,
                            12.362,
                            9.937,
                            0,
                            0.346,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.382,
                            0.602,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.986,
                            0,
                            2.182,
                            7.157,
                            0.137,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:05:18.181Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 6.537,
                        "binMax": 13.074,
                        "binContains": 0.00015,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmqnb6f6iei666yiv1hbkh",
                        "tokens": [
                            ",",
                            " and",
                            " by",
                            " a",
                            " complex",
                            " inter",
                            "play",
                            " of",
                            " forces",
                            " of",
                            " gravity",
                            " was",
                            " brought",
                            " within",
                            " a",
                            " ge",
                            "oc",
                            "entric",
                            " orbit",
                            ",",
                            " very",
                            " close",
                            " to",
                            " circular",
                            ".",
                            " But",
                            " a",
                            " catch",
                            " of",
                            " this",
                            " kind",
                            " is",
                            " virtually",
                            " impossible",
                            ".",
                            "In",
                            " fact",
                            ",",
                            " scientists",
                            " studying",
                            " the",
                            " origin",
                            " of",
                            " the",
                            " Universe",
                            " today",
                            " have",
                            " no",
                            " acceptable",
                            " theory",
                            " to",
                            " explain",
                            " how",
                            " the",
                            " Earth",
                            "-",
                            "Moon",
                            " system",
                            " came",
                            " into",
                            " being",
                            ".",
                            "We",
                            " refuse",
                            " to",
                            " engage",
                            " in",
                            " speculation",
                            " about",
                            " who",
                            " exactly",
                            " staged",
                            " this",
                            " unique",
                            " experiment",
                            ",",
                            " which",
                            " only",
                            " a",
                            " highly",
                            " developed",
                            " civilization",
                            " was",
                            " capable",
                            " of",
                            ".",
                            "If",
                            " you",
                            " are",
                            " going",
                            " to",
                            " launch",
                            " an",
                            " artificial",
                            " sp",
                            "ut",
                            "nik",
                            ",",
                            " then",
                            " it",
                            " is",
                            " advisable",
                            " to",
                            " make",
                            " it",
                            " hollow",
                            ".",
                            "At",
                            " the",
                            " same",
                            " time",
                            " it",
                            " would",
                            " be",
                            " naive",
                            " to",
                            " imagine",
                            " that",
                            " anyone",
                            " capable",
                            " of",
                            " such",
                            " a",
                            " tremendous",
                            " space",
                            " project",
                            " would"
                        ],
                        "dataIndex": null,
                        "index": "15971",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 30.411,
                        "maxValueTokenIndex": 58,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.048,
                            2.008,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.78,
                            1.133,
                            1.218,
                            0,
                            0,
                            2.451,
                            30.411,
                            22.942,
                            20.934,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.469,
                            10.098,
                            2.184,
                            2.34,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:05:18.181Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 32.685,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "806",
            "description": "concepts related to problem-solving and handling difficult situations",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4885690219063159,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "806",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T07:58:40.733Z",
                "maxActApprox": 17.022,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    806,
                    38288,
                    35654,
                    43832,
                    22436,
                    9067,
                    2707,
                    16853,
                    4623,
                    16251,
                    38804,
                    19447,
                    5874,
                    31617,
                    30225,
                    3829,
                    43657,
                    33139,
                    17043,
                    23610,
                    14402,
                    32719,
                    31180,
                    35386,
                    40383
                ],
                "topkCosSimValues": [
                    1,
                    0.523,
                    0.5017,
                    0.4261,
                    0.3926,
                    0.3917,
                    0.3828,
                    0.3808,
                    0.3605,
                    0.356,
                    0.3551,
                    0.3492,
                    0.349,
                    0.3469,
                    0.3416,
                    0.3399,
                    0.3319,
                    0.3241,
                    0.3235,
                    0.3189,
                    0.3145,
                    0.3124,
                    0.3114,
                    0.3109,
                    0.3102
                ],
                "neuron_alignment_indices": [
                    157,
                    698,
                    298
                ],
                "neuron_alignment_values": [
                    0.125,
                    0.113,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    298,
                    163,
                    698
                ],
                "correlated_neurons_pearson": [
                    0.026,
                    0.021,
                    0.019
                ],
                "correlated_neurons_l1": [
                    0.025,
                    0.019,
                    0.02
                ],
                "correlated_features_indices": [
                    829,
                    892,
                    863
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.005,
                    0.002
                ],
                "correlated_features_l1": [
                    0.006,
                    0.005,
                    0.002
                ],
                "neg_str": [
                    "SPONSORED",
                    "saf",
                    "ortium",
                    "osponsors",
                    " Designs",
                    "racuse",
                    "\u0123\u0138",
                    "cham",
                    "uart",
                    " Newsp"
                ],
                "neg_values": [
                    -0.889,
                    -0.841,
                    -0.757,
                    -0.727,
                    -0.714,
                    -0.703,
                    -0.687,
                    -0.681,
                    -0.677,
                    -0.66
                ],
                "pos_str": [
                    " fallout",
                    " adversity",
                    " complexities",
                    " backlog",
                    " brunt",
                    " responsibilities",
                    " aftermath",
                    " emergencies",
                    " differently",
                    " burdens"
                ],
                "pos_values": [
                    1.052,
                    1.026,
                    1.001,
                    0.998,
                    0.983,
                    0.979,
                    0.959,
                    0.951,
                    0.949,
                    0.916
                ],
                "frac_nonzero": 0.00126,
                "freq_hist_data_bar_heights": [
                    703,
                    521,
                    441,
                    348,
                    257,
                    224,
                    196,
                    156,
                    126,
                    99,
                    98,
                    88,
                    64,
                    64,
                    56,
                    50,
                    66,
                    51,
                    41,
                    49,
                    32,
                    27,
                    33,
                    25,
                    15,
                    15,
                    16,
                    12,
                    16,
                    10,
                    6,
                    10,
                    6,
                    7,
                    5,
                    5,
                    3,
                    4,
                    0,
                    4,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.171,
                    0.511,
                    0.851,
                    1.192,
                    1.532,
                    1.873,
                    2.213,
                    2.554,
                    2.894,
                    3.234,
                    3.575,
                    3.915,
                    4.256,
                    4.596,
                    4.937,
                    5.277,
                    5.617,
                    5.958,
                    6.298,
                    6.639,
                    6.979,
                    7.32,
                    7.66,
                    8,
                    8.341,
                    8.681,
                    9.022,
                    9.362,
                    9.703,
                    10.043,
                    10.383,
                    10.724,
                    11.064,
                    11.405,
                    11.745,
                    12.086,
                    12.426,
                    12.766,
                    13.107,
                    13.447,
                    13.788,
                    14.128,
                    14.469,
                    14.809,
                    15.149,
                    15.49,
                    15.83,
                    16.171,
                    16.511,
                    16.852
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    0,
                    1,
                    3,
                    4,
                    13,
                    16,
                    29,
                    58,
                    115,
                    250,
                    376,
                    571,
                    921,
                    1263,
                    1772,
                    2407,
                    2928,
                    3419,
                    3913,
                    4159,
                    4244,
                    4111,
                    3788,
                    3444,
                    2828,
                    2342,
                    1908,
                    1483,
                    1055,
                    812,
                    570,
                    435,
                    252,
                    217,
                    150,
                    134,
                    64,
                    67,
                    37,
                    30,
                    23,
                    16,
                    10,
                    7,
                    1,
                    3,
                    4,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.87,
                    -0.831,
                    -0.792,
                    -0.754,
                    -0.715,
                    -0.676,
                    -0.637,
                    -0.598,
                    -0.559,
                    -0.521,
                    -0.482,
                    -0.443,
                    -0.404,
                    -0.365,
                    -0.326,
                    -0.288,
                    -0.249,
                    -0.21,
                    -0.171,
                    -0.132,
                    -0.093,
                    -0.055,
                    -0.016,
                    0.023,
                    0.062,
                    0.101,
                    0.14,
                    0.178,
                    0.217,
                    0.256,
                    0.295,
                    0.334,
                    0.373,
                    0.411,
                    0.45,
                    0.489,
                    0.528,
                    0.567,
                    0.606,
                    0.644,
                    0.683,
                    0.722,
                    0.761,
                    0.8,
                    0.839,
                    0.877,
                    0.916,
                    0.955,
                    0.994,
                    1.033
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "concepts related to problem-solving and handling difficult situations",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk44p8gcdvai666h3ebvevg",
                        "tokens": [
                            " built",
                            " and",
                            " maintains",
                            " a",
                            " hydro",
                            "electric",
                            " power",
                            " plant",
                            ",",
                            " roads",
                            ",",
                            " schools",
                            ",",
                            " a",
                            " telephone",
                            " system",
                            "\u00e2\u0122\u00a6",
                            " But",
                            " the",
                            " enhanced",
                            " living",
                            " conditions",
                            " are",
                            " only",
                            " part",
                            " of",
                            " why",
                            " Fire",
                            "stone",
                            " succeeded",
                            " with",
                            " Ebola",
                            " where",
                            " so",
                            " many",
                            " governments",
                            " have",
                            " failed",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " first",
                            " case",
                            " arrived",
                            " on",
                            " the",
                            " company",
                            " doorstep",
                            " on",
                            " Sunday",
                            ",",
                            " March",
                            " 30",
                            ".",
                            " The",
                            " wife",
                            " of",
                            " an",
                            " employee",
                            " was",
                            " diagnosed",
                            ".",
                            " The",
                            " managing",
                            " director",
                            ",",
                            " Ed",
                            " Garcia",
                            ",",
                            " tried",
                            " to",
                            " find",
                            " a",
                            " hospital",
                            " that",
                            " would",
                            " take",
                            " the",
                            " woman",
                            " but",
                            " none",
                            " would",
                            " accept",
                            " her",
                            ".",
                            " As",
                            " he",
                            " said",
                            ",",
                            " \"[",
                            "W",
                            "]",
                            "e",
                            " quickly",
                            " realized",
                            " that",
                            " we",
                            " had",
                            " to",
                            " handle",
                            " the",
                            " situation",
                            " ourselves",
                            ".\"",
                            " By",
                            " the",
                            " next",
                            " day",
                            ",",
                            " the",
                            " company",
                            "'s",
                            " medical",
                            " team",
                            " had",
                            " set",
                            " up",
                            " a",
                            " primitive",
                            " but",
                            " effective",
                            " clinic",
                            " using",
                            " storage",
                            " containers",
                            " for"
                        ],
                        "dataIndex": null,
                        "index": "806",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.022,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.858,
                            17.022,
                            2.938,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T07:58:43.798Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 17.022,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk44p8hcdvji666g3otr05h",
                        "tokens": [
                            " built",
                            " and",
                            " maintains",
                            " a",
                            " hydro",
                            "electric",
                            " power",
                            " plant",
                            ",",
                            " roads",
                            ",",
                            " schools",
                            ",",
                            " a",
                            " telephone",
                            " system",
                            "\u00e2\u0122\u00a6",
                            " But",
                            " the",
                            " enhanced",
                            " living",
                            " conditions",
                            " are",
                            " only",
                            " part",
                            " of",
                            " why",
                            " Fire",
                            "stone",
                            " succeeded",
                            " with",
                            " Ebola",
                            " where",
                            " so",
                            " many",
                            " governments",
                            " have",
                            " failed",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " first",
                            " case",
                            " arrived",
                            " on",
                            " the",
                            " company",
                            " doorstep",
                            " on",
                            " Sunday",
                            ",",
                            " March",
                            " 30",
                            ".",
                            " The",
                            " wife",
                            " of",
                            " an",
                            " employee",
                            " was",
                            " diagnosed",
                            ".",
                            " The",
                            " managing",
                            " director",
                            ",",
                            " Ed",
                            " Garcia",
                            ",",
                            " tried",
                            " to",
                            " find",
                            " a",
                            " hospital",
                            " that",
                            " would",
                            " take",
                            " the",
                            " woman",
                            " but",
                            " none",
                            " would",
                            " accept",
                            " her",
                            ".",
                            " As",
                            " he",
                            " said",
                            ",",
                            " \"[",
                            "W",
                            "]",
                            "e",
                            " quickly",
                            " realized",
                            " that",
                            " we",
                            " had",
                            " to",
                            " handle",
                            " the",
                            " situation",
                            " ourselves",
                            ".\"",
                            " By",
                            " the",
                            " next",
                            " day",
                            ",",
                            " the",
                            " company",
                            "'s",
                            " medical",
                            " team",
                            " had",
                            " set",
                            " up",
                            " a",
                            " primitive",
                            " but",
                            " effective",
                            " clinic",
                            " using",
                            " storage",
                            " containers",
                            " for"
                        ],
                        "dataIndex": null,
                        "index": "806",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.022,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.858,
                            17.022,
                            2.938,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T07:58:43.798Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 17.022,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk44p8icdvvi666vt8nzfle",
                        "tokens": [
                            " built",
                            " and",
                            " maintains",
                            " a",
                            " hydro",
                            "electric",
                            " power",
                            " plant",
                            ",",
                            " roads",
                            ",",
                            " schools",
                            ",",
                            " a",
                            " telephone",
                            " system",
                            "\u00e2\u0122\u00a6",
                            " But",
                            " the",
                            " enhanced",
                            " living",
                            " conditions",
                            " are",
                            " only",
                            " part",
                            " of",
                            " why",
                            " Fire",
                            "stone",
                            " succeeded",
                            " with",
                            " Ebola",
                            " where",
                            " so",
                            " many",
                            " governments",
                            " have",
                            " failed",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " first",
                            " case",
                            " arrived",
                            " on",
                            " the",
                            " company",
                            " doorstep",
                            " on",
                            " Sunday",
                            ",",
                            " March",
                            " 30",
                            ".",
                            " The",
                            " wife",
                            " of",
                            " an",
                            " employee",
                            " was",
                            " diagnosed",
                            ".",
                            " The",
                            " managing",
                            " director",
                            ",",
                            " Ed",
                            " Garcia",
                            ",",
                            " tried",
                            " to",
                            " find",
                            " a",
                            " hospital",
                            " that",
                            " would",
                            " take",
                            " the",
                            " woman",
                            " but",
                            " none",
                            " would",
                            " accept",
                            " her",
                            ".",
                            " As",
                            " he",
                            " said",
                            ",",
                            " \"[",
                            "W",
                            "]",
                            "e",
                            " quickly",
                            " realized",
                            " that",
                            " we",
                            " had",
                            " to",
                            " handle",
                            " the",
                            " situation",
                            " ourselves",
                            ".\"",
                            " By",
                            " the",
                            " next",
                            " day",
                            ",",
                            " the",
                            " company",
                            "'s",
                            " medical",
                            " team",
                            " had",
                            " set",
                            " up",
                            " a",
                            " primitive",
                            " but",
                            " effective",
                            " clinic",
                            " using",
                            " storage",
                            " containers",
                            " for"
                        ],
                        "dataIndex": null,
                        "index": "806",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 17.022,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.858,
                            17.022,
                            2.938,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T07:58:43.798Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 13.617,
                        "binMax": 17.022,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "17003",
            "description": "questions and prompts related to inquiry and communication",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4875068955127544,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "17003",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:49:01.229Z",
                "maxActApprox": 25.968,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    17003,
                    49820,
                    68065,
                    66330,
                    8359,
                    51806,
                    36840,
                    72646,
                    81621,
                    77577,
                    95384,
                    21404,
                    22066,
                    28334,
                    90043,
                    95445,
                    45475,
                    96172,
                    39493,
                    60288,
                    43865,
                    20524,
                    43966,
                    35570,
                    20901
                ],
                "topkCosSimValues": [
                    1,
                    0.5874,
                    0.4958,
                    0.4928,
                    0.4911,
                    0.4824,
                    0.4603,
                    0.4415,
                    0.4385,
                    0.4366,
                    0.4337,
                    0.4225,
                    0.4208,
                    0.4094,
                    0.405,
                    0.4012,
                    0.3889,
                    0.3867,
                    0.3825,
                    0.3763,
                    0.3732,
                    0.3724,
                    0.3697,
                    0.3664,
                    0.352
                ],
                "neuron_alignment_indices": [
                    179,
                    386,
                    96
                ],
                "neuron_alignment_values": [
                    0.122,
                    0.111,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    111,
                    179,
                    560
                ],
                "correlated_neurons_pearson": [
                    0.014,
                    0.014,
                    0.014
                ],
                "correlated_neurons_l1": [
                    0.012,
                    0.014,
                    0.012
                ],
                "correlated_features_indices": [
                    16885,
                    16893,
                    16896
                ],
                "correlated_features_pearson": [
                    0.037,
                    0.005,
                    0.005
                ],
                "correlated_features_l1": [
                    0.037,
                    0.006,
                    0.006
                ],
                "neg_str": [
                    "ufact",
                    " Tycoon",
                    "\u00e3\u0124\u00bc\u00e3\u0124\u00a6\u00e3\u0124\u00b9",
                    "ourning",
                    "stead",
                    "acca",
                    "edition",
                    " Dock",
                    "layout",
                    "\u00e5\u00a3\u00ab"
                ],
                "neg_values": [
                    -0.923,
                    -0.826,
                    -0.731,
                    -0.674,
                    -0.673,
                    -0.672,
                    -0.668,
                    -0.654,
                    -0.643,
                    -0.628
                ],
                "pos_str": [
                    " questions",
                    " probing",
                    " Questions",
                    " QUEST",
                    " rhet",
                    " question",
                    " unanswered",
                    " answ",
                    " plaint",
                    "answered"
                ],
                "pos_values": [
                    1.188,
                    1.092,
                    1.029,
                    1.008,
                    0.986,
                    0.984,
                    0.969,
                    0.878,
                    0.873,
                    0.864
                ],
                "frac_nonzero": 0.00039,
                "freq_hist_data_bar_heights": [
                    313,
                    183,
                    160,
                    114,
                    92,
                    49,
                    61,
                    41,
                    24,
                    31,
                    23,
                    25,
                    10,
                    13,
                    17,
                    15,
                    14,
                    11,
                    11,
                    8,
                    2,
                    4,
                    4,
                    4,
                    3,
                    2,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.262,
                    0.781,
                    1.301,
                    1.82,
                    2.339,
                    2.858,
                    3.378,
                    3.897,
                    4.416,
                    4.936,
                    5.455,
                    5.974,
                    6.494,
                    7.013,
                    7.532,
                    8.052,
                    8.571,
                    9.09,
                    9.609,
                    10.129,
                    10.648,
                    11.167,
                    11.687,
                    12.206,
                    12.725,
                    13.245,
                    13.764,
                    14.283,
                    14.802,
                    15.322,
                    15.841,
                    16.36,
                    16.88,
                    17.399,
                    17.918,
                    18.438,
                    18.957,
                    19.476,
                    19.995,
                    20.515,
                    21.034,
                    21.553,
                    22.073,
                    22.592,
                    23.111,
                    23.631,
                    24.15,
                    24.669,
                    25.189,
                    25.708
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    0,
                    1,
                    3,
                    5,
                    10,
                    24,
                    38,
                    73,
                    150,
                    272,
                    497,
                    812,
                    1298,
                    2010,
                    2772,
                    3718,
                    4472,
                    5039,
                    5063,
                    4895,
                    4708,
                    4059,
                    3243,
                    2361,
                    1677,
                    1136,
                    758,
                    469,
                    275,
                    160,
                    98,
                    61,
                    33,
                    22,
                    8,
                    11,
                    10,
                    3,
                    0,
                    4,
                    0,
                    1,
                    3,
                    1,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.902,
                    -0.859,
                    -0.817,
                    -0.775,
                    -0.733,
                    -0.691,
                    -0.648,
                    -0.606,
                    -0.564,
                    -0.522,
                    -0.48,
                    -0.437,
                    -0.395,
                    -0.353,
                    -0.311,
                    -0.268,
                    -0.226,
                    -0.184,
                    -0.142,
                    -0.1,
                    -0.057,
                    -0.015,
                    0.027,
                    0.069,
                    0.111,
                    0.154,
                    0.196,
                    0.238,
                    0.28,
                    0.323,
                    0.365,
                    0.407,
                    0.449,
                    0.491,
                    0.534,
                    0.576,
                    0.618,
                    0.66,
                    0.702,
                    0.745,
                    0.787,
                    0.829,
                    0.871,
                    0.914,
                    0.956,
                    0.998,
                    1.04,
                    1.082,
                    1.125,
                    1.167
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions and prompts related to inquiry and communication",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases related to inquiries and questions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfmj38o70f10ex09actll2",
                        "tokens": [
                            ",",
                            " click",
                            " the",
                            " Ask",
                            " a",
                            " Question",
                            " button",
                            " below",
                            ".",
                            " For",
                            " post",
                            "-",
                            "p",
                            "urchase",
                            " inquiries",
                            ",",
                            " please",
                            " contact",
                            " Group",
                            "on",
                            " customer",
                            " support",
                            ".",
                            "\n",
                            "\n",
                            "Good",
                            "s",
                            " sold",
                            " by",
                            " Group",
                            "on",
                            " Goods",
                            ".",
                            " View",
                            " the",
                            " Group",
                            "on",
                            " Goods",
                            " FAQ",
                            " to",
                            " learn",
                            " more",
                            ".",
                            "<|endoftext|>",
                            "A",
                            "head",
                            " of",
                            " her",
                            " meeting",
                            " with",
                            " Trump",
                            " tomorrow",
                            ",",
                            " British",
                            " Prime",
                            " Minister",
                            " Theresa",
                            " May",
                            " joked",
                            " that",
                            " \"",
                            "opp",
                            "os",
                            "ites",
                            " attract",
                            "\"",
                            " and",
                            " called",
                            " on",
                            " the",
                            " US",
                            " President",
                            " to",
                            " renew",
                            " the",
                            " \"",
                            "special",
                            " relationship",
                            "\"",
                            " between",
                            " Britain",
                            " and",
                            " the",
                            " United",
                            " States",
                            " and",
                            " lead",
                            " in",
                            " a",
                            " new",
                            ",",
                            " changed",
                            " world",
                            ".",
                            " In",
                            " the",
                            " United",
                            " States",
                            " for",
                            " what",
                            " will",
                            " be",
                            " Trump",
                            "'s",
                            " first",
                            " meeting",
                            " with",
                            " a",
                            " foreign",
                            " leader",
                            " since",
                            " he",
                            " took",
                            " office",
                            " last",
                            " week",
                            ",",
                            " May",
                            " signaled",
                            " a",
                            " shift",
                            " in",
                            " foreign",
                            " policy",
                            ",",
                            " bringing",
                            " her"
                        ],
                        "dataIndex": null,
                        "index": "17003",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.968,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            1.842,
                            25.968,
                            10.373,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.844,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:49:09.631Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 25.967,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfmj3ao71210exkfh08ma7",
                        "tokens": [
                            ",",
                            " click",
                            " the",
                            " Ask",
                            " a",
                            " Question",
                            " button",
                            " below",
                            ".",
                            " For",
                            " post",
                            "-",
                            "p",
                            "urchase",
                            " inquiries",
                            ",",
                            " please",
                            " contact",
                            " Group",
                            "on",
                            " customer",
                            " support",
                            ".",
                            "\n",
                            "\n",
                            "Good",
                            "s",
                            " sold",
                            " by",
                            " Group",
                            "on",
                            " Goods",
                            ".",
                            " View",
                            " the",
                            " Group",
                            "on",
                            " Goods",
                            " FAQ",
                            " to",
                            " learn",
                            " more",
                            ".",
                            "<|endoftext|>",
                            "A",
                            "head",
                            " of",
                            " her",
                            " meeting",
                            " with",
                            " Trump",
                            " tomorrow",
                            ",",
                            " British",
                            " Prime",
                            " Minister",
                            " Theresa",
                            " May",
                            " joked",
                            " that",
                            " \"",
                            "opp",
                            "os",
                            "ites",
                            " attract",
                            "\"",
                            " and",
                            " called",
                            " on",
                            " the",
                            " US",
                            " President",
                            " to",
                            " renew",
                            " the",
                            " \"",
                            "special",
                            " relationship",
                            "\"",
                            " between",
                            " Britain",
                            " and",
                            " the",
                            " United",
                            " States",
                            " and",
                            " lead",
                            " in",
                            " a",
                            " new",
                            ",",
                            " changed",
                            " world",
                            ".",
                            " In",
                            " the",
                            " United",
                            " States",
                            " for",
                            " what",
                            " will",
                            " be",
                            " Trump",
                            "'s",
                            " first",
                            " meeting",
                            " with",
                            " a",
                            " foreign",
                            " leader",
                            " since",
                            " he",
                            " took",
                            " office",
                            " last",
                            " week",
                            ",",
                            " May",
                            " signaled",
                            " a",
                            " shift",
                            " in",
                            " foreign",
                            " policy",
                            ",",
                            " bringing",
                            " her"
                        ],
                        "dataIndex": null,
                        "index": "17003",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.968,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            1.842,
                            25.968,
                            10.373,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.844,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:49:09.631Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 20.774,
                        "binMax": 25.967,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfmj38o70g10exfalzo7hd",
                        "tokens": [
                            " &",
                            " $",
                            "10",
                            " children",
                            " at",
                            " the",
                            " door",
                            ".",
                            " Not",
                            " Available",
                            " Location",
                            " San",
                            " Jose",
                            " Sk",
                            "ate",
                            "\n",
                            "\n",
                            "397",
                            " Blossom",
                            " Hill",
                            " Road",
                            "\n",
                            "\n",
                            "San",
                            " Jose",
                            ",",
                            " CA",
                            " 95",
                            "123",
                            "\n",
                            "\n",
                            "United",
                            " States",
                            "\n",
                            "\n",
                            "C",
                            "ategories",
                            " Sports",
                            " >",
                            " Roller",
                            " Derby",
                            "\n",
                            "\n",
                            "Kid",
                            " Friendly",
                            ":",
                            " Yes",
                            "!",
                            " Dog",
                            " Friendly",
                            ":",
                            " No",
                            " Non",
                            "-",
                            "Sm",
                            "oking",
                            ":",
                            " Yes",
                            "!",
                            " Wheel",
                            "chair",
                            " Access",
                            "ible",
                            ":",
                            " Yes",
                            "!",
                            " Contact",
                            " Owner",
                            ":",
                            " Silicon",
                            " Valley",
                            " Roller",
                            " Girls",
                            " On",
                            " B",
                            "PT",
                            " Since",
                            ":",
                            " Jun",
                            " 19",
                            ",",
                            " 2008",
                            " S",
                            "VR",
                            "G",
                            " Bout",
                            " Production",
                            " Production",
                            "@",
                            "sv",
                            "roll",
                            "erg",
                            "irl",
                            "s",
                            ".",
                            "com",
                            " www",
                            ".",
                            "sv",
                            "roll",
                            "erg",
                            "irl",
                            "s",
                            ".",
                            "com",
                            "\n",
                            "\n",
                            "Ask",
                            " a",
                            " question",
                            "...",
                            " Ask",
                            "!",
                            "<|endoftext|>",
                            "The",
                            " proposal",
                            ":",
                            " Brown",
                            " has",
                            " proposed",
                            " generating",
                            " $",
                            "12",
                            " billion",
                            " in",
                            " new",
                            " revenue"
                        ],
                        "dataIndex": null,
                        "index": "17003",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 23.339,
                        "maxValueTokenIndex": 108,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            23.339,
                            3.238,
                            5.409,
                            0.815,
                            9.665,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:49:09.631Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 25.967,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}