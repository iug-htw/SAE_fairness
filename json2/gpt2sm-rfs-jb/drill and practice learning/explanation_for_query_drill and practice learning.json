{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "drill and practice learning"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "7283",
            "description": "verbs related to learning or acquiring new skills",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5586410427903518,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "7283",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:25:47.675Z",
                "maxActApprox": 54.917,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    7283,
                    4647,
                    2769,
                    695,
                    7481,
                    10075,
                    8159,
                    620,
                    7496,
                    6878,
                    4161,
                    10494,
                    315,
                    4454,
                    8052,
                    10344,
                    2795,
                    5646,
                    5753,
                    11334,
                    1070,
                    9109,
                    2082,
                    7766,
                    8961
                ],
                "topkCosSimValues": [
                    1,
                    0.5407,
                    0.4572,
                    0.444,
                    0.4403,
                    0.4161,
                    0.416,
                    0.4155,
                    0.4032,
                    0.3849,
                    0.3846,
                    0.3815,
                    0.3785,
                    0.3771,
                    0.3764,
                    0.3744,
                    0.3627,
                    0.3593,
                    0.3541,
                    0.3512,
                    0.3488,
                    0.3484,
                    0.3471,
                    0.3452,
                    0.3449
                ],
                "neuron_alignment_indices": [
                    665,
                    718,
                    608
                ],
                "neuron_alignment_values": [
                    0.113,
                    0.107,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    665,
                    718,
                    49
                ],
                "correlated_neurons_pearson": [
                    0.039,
                    0.034,
                    0.034
                ],
                "correlated_neurons_l1": [
                    0.042,
                    0.037,
                    0.037
                ],
                "correlated_features_indices": [
                    7173,
                    7289,
                    7172
                ],
                "correlated_features_pearson": [
                    0.013,
                    0.01,
                    0.004
                ],
                "correlated_features_l1": [
                    0.013,
                    0.01,
                    0.006
                ],
                "neg_str": [
                    "lights",
                    "listed",
                    "teen",
                    "holder",
                    "termination",
                    " Hartford",
                    " Appears",
                    "hra",
                    "nces",
                    " revelations"
                ],
                "neg_values": [
                    -0.834,
                    -0.725,
                    -0.705,
                    -0.68,
                    -0.666,
                    -0.653,
                    -0.647,
                    -0.645,
                    -0.632,
                    -0.624
                ],
                "pos_str": [
                    " behave",
                    " cope",
                    " differentiate",
                    " recognize",
                    " wrestle",
                    " manipulate",
                    " tolerate",
                    " imitate",
                    " navigate",
                    " cultivate"
                ],
                "pos_values": [
                    1.222,
                    1.208,
                    1.162,
                    1.156,
                    1.149,
                    1.125,
                    1.108,
                    1.069,
                    1.034,
                    1.019
                ],
                "frac_nonzero": 0.00163,
                "freq_hist_data_bar_heights": [
                    2067,
                    1175,
                    651,
                    405,
                    205,
                    156,
                    86,
                    68,
                    32,
                    43,
                    27,
                    16,
                    9,
                    15,
                    16,
                    16,
                    8,
                    6,
                    7,
                    9,
                    10,
                    9,
                    7,
                    4,
                    5,
                    7,
                    5,
                    2,
                    6,
                    4,
                    0,
                    3,
                    5,
                    3,
                    1,
                    2,
                    3,
                    1,
                    2,
                    5,
                    2,
                    3,
                    1,
                    7,
                    5,
                    4,
                    0,
                    0,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.549,
                    1.648,
                    2.746,
                    3.844,
                    4.943,
                    6.041,
                    7.139,
                    8.238,
                    9.336,
                    10.434,
                    11.533,
                    12.631,
                    13.729,
                    14.828,
                    15.926,
                    17.024,
                    18.123,
                    19.221,
                    20.319,
                    21.418,
                    22.516,
                    23.614,
                    24.713,
                    25.811,
                    26.909,
                    28.008,
                    29.106,
                    30.204,
                    31.303,
                    32.401,
                    33.499,
                    34.598,
                    35.696,
                    36.794,
                    37.893,
                    38.991,
                    40.089,
                    41.188,
                    42.286,
                    43.384,
                    44.483,
                    45.581,
                    46.679,
                    47.778,
                    48.876,
                    49.974,
                    51.073,
                    52.171,
                    53.269,
                    54.368
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    2,
                    5,
                    11,
                    26,
                    57,
                    108,
                    227,
                    362,
                    669,
                    1120,
                    1588,
                    2133,
                    2988,
                    3680,
                    4005,
                    4280,
                    4366,
                    4259,
                    3818,
                    3478,
                    2955,
                    2411,
                    1844,
                    1477,
                    1106,
                    831,
                    605,
                    457,
                    294,
                    237,
                    179,
                    155,
                    135,
                    100,
                    74,
                    59,
                    50,
                    32,
                    24,
                    19,
                    9,
                    10,
                    2,
                    1,
                    2,
                    3,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.813,
                    -0.772,
                    -0.731,
                    -0.69,
                    -0.649,
                    -0.608,
                    -0.567,
                    -0.526,
                    -0.485,
                    -0.443,
                    -0.402,
                    -0.361,
                    -0.32,
                    -0.279,
                    -0.238,
                    -0.197,
                    -0.156,
                    -0.114,
                    -0.073,
                    -0.032,
                    0.009,
                    0.05,
                    0.091,
                    0.132,
                    0.173,
                    0.214,
                    0.256,
                    0.297,
                    0.338,
                    0.379,
                    0.42,
                    0.461,
                    0.502,
                    0.543,
                    0.584,
                    0.626,
                    0.667,
                    0.708,
                    0.749,
                    0.79,
                    0.831,
                    0.872,
                    0.913,
                    0.955,
                    0.996,
                    1.037,
                    1.078,
                    1.119,
                    1.16,
                    1.201
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "verbs related to learning or acquiring new skills",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtwn415g53i6668wz8rpmc",
                        "tokens": [
                            "When",
                            " we",
                            " enter",
                            " the",
                            " political",
                            " debate",
                            " sphere",
                            " of",
                            " the",
                            " online",
                            " world",
                            ",",
                            " I",
                            " think",
                            " we",
                            " consider",
                            " people",
                            " holding",
                            " these",
                            " beliefs",
                            " to",
                            " be",
                            " unreal",
                            ".",
                            " The",
                            " information",
                            " age",
                            " means",
                            " almost",
                            " anybody",
                            " can",
                            " become",
                            " informed",
                            " about",
                            " any",
                            " topic",
                            ",",
                            " right",
                            "?",
                            " Someone",
                            " who",
                            " believes",
                            " in",
                            " these",
                            " conspir",
                            "acies",
                            " has",
                            " got",
                            " to",
                            " be",
                            " a",
                            " troll",
                            " or",
                            " using",
                            " their",
                            " anonymity",
                            " to",
                            " esp",
                            "ouse",
                            " harmful",
                            " beliefs",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " never",
                            " talk",
                            " about",
                            " in",
                            "-",
                            "person",
                            ".",
                            " They",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " an",
                            " ed",
                            "gy",
                            " teenager",
                            ",",
                            " a",
                            " kid",
                            " who",
                            " hasn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " learned",
                            " to",
                            " navigate",
                            " the",
                            " harmful",
                            " tra",
                            "ppings",
                            " of",
                            " the",
                            " internet",
                            ";",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " an",
                            " old",
                            " cod",
                            "ger",
                            ",",
                            " still",
                            " holding",
                            " onto",
                            " the",
                            " good",
                            " old",
                            " days",
                            " where",
                            " they",
                            " had",
                            " all",
                            " the",
                            " privilege",
                            ";",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " just"
                        ],
                        "dataIndex": null,
                        "index": "7283",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 54.917,
                        "maxValueTokenIndex": 89,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            54.917,
                            0.521,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:25:55.074Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 54.917,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtwn415g54i666ao9t8r0t",
                        "tokens": [
                            "\u013b",
                            "t",
                            " reapp",
                            "ear",
                            " for",
                            " about",
                            " 20",
                            " years",
                            ".",
                            " Compos",
                            "ers",
                            " or",
                            " performers",
                            " of",
                            " concert",
                            "os",
                            " could",
                            " hire",
                            " theater",
                            " orchestr",
                            "as",
                            " in",
                            " Vienna",
                            ",",
                            " but",
                            " they",
                            " played",
                            " badly",
                            ".",
                            "\n",
                            "\n",
                            "No",
                            " other",
                            " cities",
                            " in",
                            " Europe",
                            " had",
                            " enough",
                            " influence",
                            " to",
                            " put",
                            " their",
                            " resident",
                            " compos",
                            "ers",
                            " on",
                            " the",
                            " international",
                            " stage",
                            ".",
                            "\n",
                            "\n",
                            "By",
                            " the",
                            " time",
                            " concert",
                            " life",
                            " revived",
                            " in",
                            " these",
                            " capitals",
                            ",",
                            " Hay",
                            "dn",
                            " and",
                            " Moz",
                            "art",
                            " were",
                            " dead",
                            ".",
                            " There",
                            " was",
                            " no",
                            " logical",
                            " successor",
                            " to",
                            " Be",
                            "eth",
                            "oven",
                            ".",
                            " After",
                            " all",
                            ",",
                            " why",
                            " would",
                            " anyone",
                            " learn",
                            " to",
                            " compose",
                            " that",
                            " kind",
                            " of",
                            " music",
                            "?",
                            " They",
                            " couldn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " get",
                            " it",
                            " heard",
                            " with",
                            " no",
                            " concert",
                            " life",
                            ".",
                            "\n",
                            "\n",
                            "Twenty",
                            " years",
                            " later",
                            ",",
                            " mass",
                            " audiences",
                            " no",
                            " longer",
                            " remembered",
                            " how",
                            " to",
                            " listen",
                            " to",
                            " that",
                            " music",
                            ".",
                            "\n",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "7283",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 53.496,
                        "maxValueTokenIndex": 87,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            53.496,
                            2.579,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.06,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:25:55.074Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 54.917,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtwn415g55i6665qwdc36q",
                        "tokens": [
                            "The",
                            " gold",
                            "il",
                            "ocks",
                            " economy",
                            " Buffett",
                            " describes",
                            ",",
                            " in",
                            " which",
                            " we",
                            " can",
                            " have",
                            " \u00e2\u0122",
                            "\u013e",
                            "re",
                            "co",
                            "very",
                            "\u00e2\u0122",
                            "\u013f",
                            " without",
                            " increasing",
                            " debt",
                            ",",
                            " is",
                            " a",
                            " fantasy",
                            ".",
                            "\n",
                            "\n",
                            "My",
                            " point",
                            " is",
                            " that",
                            " in",
                            " order",
                            " to",
                            " reduce",
                            " debt",
                            " we",
                            " have",
                            " to",
                            " endure",
                            " some",
                            " sort",
                            " of",
                            " deflation",
                            "ary",
                            " recession",
                            ".",
                            " The",
                            " alternative",
                            " is",
                            " to",
                            " spend",
                            " and",
                            " print",
                            " perpetually",
                            ",",
                            " which",
                            " Buffett",
                            " points",
                            " out",
                            " is",
                            " the",
                            " worse",
                            " option",
                            ".",
                            "\n",
                            "\n",
                            "What",
                            " Buffett",
                            " should",
                            " have",
                            " said",
                            "?",
                            " S",
                            "uck",
                            " it",
                            " up",
                            " folks",
                            ",",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " no",
                            " choice",
                            " but",
                            " to",
                            " learn",
                            " to",
                            " live",
                            " with",
                            " less",
                            ".",
                            "\n",
                            "\n",
                            "\u2014\u2014",
                            "\n",
                            "\n",
                            "P",
                            ".",
                            "s",
                            ".:",
                            " I",
                            " think",
                            " Buffett",
                            " actually",
                            " knows",
                            " this",
                            ",",
                            " but",
                            " being",
                            " asset",
                            "-",
                            "rich",
                            ",",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " boxed",
                            " in",
                            ".",
                            " Def",
                            "lation"
                        ],
                        "dataIndex": null,
                        "index": "7283",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 50.432,
                        "maxValueTokenIndex": 91,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            50.432,
                            15.167,
                            1.96,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:25:55.074Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 54.917,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "36759",
            "description": " actions related to learning and practicing skills",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5551533102989197,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "36759",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:17:20.863Z",
                "maxActApprox": 13.291,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    36759,
                    80530,
                    6057,
                    64733,
                    34954,
                    14052,
                    96770,
                    33115,
                    29063,
                    11105,
                    55382,
                    59850,
                    97527,
                    84712,
                    15165,
                    57852,
                    52248,
                    22083,
                    50986,
                    6850,
                    76062,
                    26071,
                    49673,
                    7364,
                    10485
                ],
                "topkCosSimValues": [
                    1,
                    0.5951,
                    0.5934,
                    0.5701,
                    0.5328,
                    0.4929,
                    0.4908,
                    0.4778,
                    0.4684,
                    0.4549,
                    0.4378,
                    0.4362,
                    0.4357,
                    0.4286,
                    0.428,
                    0.4258,
                    0.4207,
                    0.4182,
                    0.4174,
                    0.417,
                    0.4154,
                    0.4034,
                    0.4003,
                    0.3977,
                    0.396
                ],
                "neuron_alignment_indices": [
                    756,
                    393,
                    447
                ],
                "neuron_alignment_values": [
                    0.144,
                    0.137,
                    0.131
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.006
                ],
                "correlated_neurons_indices": [
                    70,
                    665,
                    570
                ],
                "correlated_neurons_pearson": [
                    0.07,
                    0.061,
                    0.058
                ],
                "correlated_neurons_l1": [
                    0.077,
                    0.07,
                    0.034
                ],
                "correlated_features_indices": [
                    36790,
                    36840,
                    36787
                ],
                "correlated_features_pearson": [
                    0.021,
                    0.005,
                    0.003
                ],
                "correlated_features_l1": [
                    0.021,
                    0.006,
                    0.003
                ],
                "neg_str": [
                    "ortment",
                    "aran",
                    "emonic",
                    "advertising",
                    "oris",
                    "rin",
                    "hon",
                    "odon",
                    "grad",
                    "arty"
                ],
                "neg_values": [
                    -0.622,
                    -0.585,
                    -0.584,
                    -0.573,
                    -0.57,
                    -0.555,
                    -0.553,
                    -0.553,
                    -0.55,
                    -0.545
                ],
                "pos_str": [
                    " differently",
                    " freely",
                    " separately",
                    " excessively",
                    " directly",
                    " continuously",
                    " blindly",
                    " extensively",
                    " elsewhere",
                    " anyway"
                ],
                "pos_values": [
                    0.846,
                    0.829,
                    0.822,
                    0.779,
                    0.767,
                    0.766,
                    0.765,
                    0.764,
                    0.763,
                    0.759
                ],
                "frac_nonzero": 0.00365,
                "freq_hist_data_bar_heights": [
                    1695,
                    1427,
                    1185,
                    1012,
                    832,
                    711,
                    617,
                    515,
                    484,
                    401,
                    352,
                    293,
                    274,
                    220,
                    195,
                    180,
                    157,
                    135,
                    112,
                    104,
                    75,
                    73,
                    67,
                    54,
                    53,
                    48,
                    34,
                    21,
                    26,
                    21,
                    18,
                    18,
                    15,
                    9,
                    10,
                    4,
                    6,
                    8,
                    4,
                    3,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.133,
                    0.399,
                    0.665,
                    0.93,
                    1.196,
                    1.462,
                    1.728,
                    1.994,
                    2.26,
                    2.525,
                    2.791,
                    3.057,
                    3.323,
                    3.589,
                    3.854,
                    4.12,
                    4.386,
                    4.652,
                    4.918,
                    5.184,
                    5.449,
                    5.715,
                    5.981,
                    6.247,
                    6.513,
                    6.779,
                    7.044,
                    7.31,
                    7.576,
                    7.842,
                    8.108,
                    8.373,
                    8.639,
                    8.905,
                    9.171,
                    9.437,
                    9.703,
                    9.968,
                    10.234,
                    10.5,
                    10.766,
                    11.032,
                    11.297,
                    11.563,
                    11.829,
                    12.095,
                    12.361,
                    12.627,
                    12.892,
                    13.158
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    4,
                    14,
                    18,
                    19,
                    42,
                    76,
                    97,
                    180,
                    250,
                    398,
                    595,
                    849,
                    1222,
                    1681,
                    2166,
                    2679,
                    3186,
                    3622,
                    4005,
                    4027,
                    4002,
                    3965,
                    3469,
                    3043,
                    2447,
                    1988,
                    1546,
                    1160,
                    930,
                    685,
                    499,
                    360,
                    264,
                    190,
                    138,
                    101,
                    80,
                    54,
                    64,
                    28,
                    36,
                    24,
                    17,
                    12,
                    6,
                    8,
                    7,
                    0,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.608,
                    -0.578,
                    -0.549,
                    -0.519,
                    -0.49,
                    -0.461,
                    -0.431,
                    -0.402,
                    -0.373,
                    -0.343,
                    -0.314,
                    -0.284,
                    -0.255,
                    -0.226,
                    -0.196,
                    -0.167,
                    -0.138,
                    -0.108,
                    -0.079,
                    -0.049,
                    -0.02,
                    0.009,
                    0.039,
                    0.068,
                    0.097,
                    0.127,
                    0.156,
                    0.186,
                    0.215,
                    0.244,
                    0.274,
                    0.303,
                    0.332,
                    0.362,
                    0.391,
                    0.42,
                    0.45,
                    0.479,
                    0.509,
                    0.538,
                    0.567,
                    0.597,
                    0.626,
                    0.655,
                    0.685,
                    0.714,
                    0.744,
                    0.773,
                    0.802,
                    0.832
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " actions related to learning and practicing skills",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases related to learning and typing skills",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggmwa335lx10exco67ax55",
                        "tokens": [
                            " if",
                            " you",
                            " fix",
                            " your",
                            " bad",
                            " typing",
                            " habits",
                            ".",
                            " The",
                            " earlier",
                            " you",
                            " start",
                            " learning",
                            ",",
                            " the",
                            " more",
                            " rewarding",
                            " it",
                            " can",
                            " be",
                            ".",
                            " Teach",
                            " kids",
                            " to",
                            " touch",
                            " type",
                            " as",
                            " soon",
                            " as",
                            " they",
                            " start",
                            " playing",
                            " with",
                            " the",
                            " computer",
                            ".",
                            " This",
                            " skill",
                            " will",
                            " stay",
                            " relevant",
                            " for",
                            " at",
                            " least",
                            " one",
                            " more",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " take",
                            " away",
                            " only",
                            " one",
                            " thing",
                            " from",
                            " my",
                            " story",
                            ",",
                            " it",
                            "'s",
                            " this",
                            ":",
                            " Learn",
                            " proper",
                            " touch",
                            " typing",
                            " technique",
                            " today",
                            ".",
                            "\n",
                            "\n",
                            "Recipe",
                            "\n",
                            "\n",
                            "Take",
                            " a",
                            " typing",
                            " test",
                            " on",
                            " Key",
                            "hero",
                            ".",
                            " Sl",
                            "ower",
                            " than",
                            " 40",
                            " W",
                            "PM",
                            "?",
                            " Practice",
                            " 15",
                            " minutes",
                            " every",
                            " day",
                            " for",
                            " a",
                            " month",
                            ".",
                            " If",
                            " your",
                            " accuracy",
                            " is",
                            " lower",
                            " than",
                            " 95",
                            "%,",
                            " slow",
                            " down",
                            " and",
                            " try",
                            " to",
                            " type",
                            " as",
                            " accurately",
                            " as",
                            " possible",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " type"
                        ],
                        "dataIndex": null,
                        "index": "36759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.291,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.489,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.528,
                            0,
                            0,
                            1.968,
                            0,
                            10.197,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.291
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:26.333Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.291,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggmwa335m610exgnqozkf4",
                        "tokens": [
                            " if",
                            " you",
                            " fix",
                            " your",
                            " bad",
                            " typing",
                            " habits",
                            ".",
                            " The",
                            " earlier",
                            " you",
                            " start",
                            " learning",
                            ",",
                            " the",
                            " more",
                            " rewarding",
                            " it",
                            " can",
                            " be",
                            ".",
                            " Teach",
                            " kids",
                            " to",
                            " touch",
                            " type",
                            " as",
                            " soon",
                            " as",
                            " they",
                            " start",
                            " playing",
                            " with",
                            " the",
                            " computer",
                            ".",
                            " This",
                            " skill",
                            " will",
                            " stay",
                            " relevant",
                            " for",
                            " at",
                            " least",
                            " one",
                            " more",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " take",
                            " away",
                            " only",
                            " one",
                            " thing",
                            " from",
                            " my",
                            " story",
                            ",",
                            " it",
                            "'s",
                            " this",
                            ":",
                            " Learn",
                            " proper",
                            " touch",
                            " typing",
                            " technique",
                            " today",
                            ".",
                            "\n",
                            "\n",
                            "Recipe",
                            "\n",
                            "\n",
                            "Take",
                            " a",
                            " typing",
                            " test",
                            " on",
                            " Key",
                            "hero",
                            ".",
                            " Sl",
                            "ower",
                            " than",
                            " 40",
                            " W",
                            "PM",
                            "?",
                            " Practice",
                            " 15",
                            " minutes",
                            " every",
                            " day",
                            " for",
                            " a",
                            " month",
                            ".",
                            " If",
                            " your",
                            " accuracy",
                            " is",
                            " lower",
                            " than",
                            " 95",
                            "%,",
                            " slow",
                            " down",
                            " and",
                            " try",
                            " to",
                            " type",
                            " as",
                            " accurately",
                            " as",
                            " possible",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " type"
                        ],
                        "dataIndex": null,
                        "index": "36759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.291,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.489,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.528,
                            0,
                            0,
                            1.968,
                            0,
                            10.197,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.291
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:26.333Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.291,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggmwa535mk10exsw1a50vs",
                        "tokens": [
                            " if",
                            " you",
                            " fix",
                            " your",
                            " bad",
                            " typing",
                            " habits",
                            ".",
                            " The",
                            " earlier",
                            " you",
                            " start",
                            " learning",
                            ",",
                            " the",
                            " more",
                            " rewarding",
                            " it",
                            " can",
                            " be",
                            ".",
                            " Teach",
                            " kids",
                            " to",
                            " touch",
                            " type",
                            " as",
                            " soon",
                            " as",
                            " they",
                            " start",
                            " playing",
                            " with",
                            " the",
                            " computer",
                            ".",
                            " This",
                            " skill",
                            " will",
                            " stay",
                            " relevant",
                            " for",
                            " at",
                            " least",
                            " one",
                            " more",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " take",
                            " away",
                            " only",
                            " one",
                            " thing",
                            " from",
                            " my",
                            " story",
                            ",",
                            " it",
                            "'s",
                            " this",
                            ":",
                            " Learn",
                            " proper",
                            " touch",
                            " typing",
                            " technique",
                            " today",
                            ".",
                            "\n",
                            "\n",
                            "Recipe",
                            "\n",
                            "\n",
                            "Take",
                            " a",
                            " typing",
                            " test",
                            " on",
                            " Key",
                            "hero",
                            ".",
                            " Sl",
                            "ower",
                            " than",
                            " 40",
                            " W",
                            "PM",
                            "?",
                            " Practice",
                            " 15",
                            " minutes",
                            " every",
                            " day",
                            " for",
                            " a",
                            " month",
                            ".",
                            " If",
                            " your",
                            " accuracy",
                            " is",
                            " lower",
                            " than",
                            " 95",
                            "%,",
                            " slow",
                            " down",
                            " and",
                            " try",
                            " to",
                            " type",
                            " as",
                            " accurately",
                            " as",
                            " possible",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " type"
                        ],
                        "dataIndex": null,
                        "index": "36759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.291,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.489,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.528,
                            0,
                            0,
                            1.968,
                            0,
                            10.197,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.291
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:26.333Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 10.633,
                        "binMax": 13.291,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs6144-jb",
            "index": "1278",
            "description": "phrases related to learning or teaching new skills",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5381279748120302,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs6144-jb",
                "index": "1278",
                "sourceSetName": "res_fs6144-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:08:06.054Z",
                "maxActApprox": 27.852,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    1278,
                    1446,
                    1238,
                    5719,
                    4460,
                    1280,
                    5581,
                    2474,
                    1719,
                    6075,
                    3673,
                    2601,
                    5922,
                    1517,
                    5900,
                    4078,
                    5760,
                    2740,
                    5738,
                    2953,
                    3902,
                    4613,
                    1314,
                    2898,
                    5723
                ],
                "topkCosSimValues": [
                    1,
                    0.4381,
                    0.3824,
                    0.3453,
                    0.2857,
                    0.2845,
                    0.2711,
                    0.2711,
                    0.2661,
                    0.2514,
                    0.2437,
                    0.2346,
                    0.23,
                    0.2232,
                    0.2171,
                    0.2152,
                    0.2145,
                    0.2107,
                    0.207,
                    0.206,
                    0.2054,
                    0.1977,
                    0.1958,
                    0.1941,
                    0.1928
                ],
                "neuron_alignment_indices": [
                    80,
                    255,
                    331
                ],
                "neuron_alignment_values": [
                    0.096,
                    0.096,
                    0.093
                ],
                "neuron_alignment_l1": [
                    0.004,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    97,
                    641,
                    285
                ],
                "correlated_neurons_pearson": [
                    0.056,
                    0.054,
                    0.049
                ],
                "correlated_neurons_l1": [
                    0.043,
                    0.064,
                    0.035
                ],
                "correlated_features_indices": [
                    1238,
                    1227,
                    1208
                ],
                "correlated_features_pearson": [
                    0.214,
                    0.022,
                    0.018
                ],
                "correlated_features_l1": [
                    0.216,
                    0.026,
                    0.02
                ],
                "neg_str": [
                    "ocument",
                    "isSpecialOrderable",
                    "holder",
                    "vertisement",
                    "ported",
                    "iture",
                    "atform",
                    "iversary",
                    " claimant",
                    "announced"
                ],
                "neg_values": [
                    -0.822,
                    -0.75,
                    -0.678,
                    -0.678,
                    -0.676,
                    -0.668,
                    -0.668,
                    -0.663,
                    -0.661,
                    -0.653
                ],
                "pos_str": [
                    " basics",
                    " ropes",
                    " lesson",
                    " skills",
                    " fundamentals",
                    " tricks",
                    " techniques",
                    " maths",
                    " nuances",
                    " rudimentary"
                ],
                "pos_values": [
                    1.159,
                    1.137,
                    1.076,
                    1.058,
                    1.025,
                    0.996,
                    0.991,
                    0.97,
                    0.959,
                    0.956
                ],
                "frac_nonzero": 0.009559999999999999,
                "freq_hist_data_bar_heights": [
                    7974,
                    5513,
                    3762,
                    2698,
                    1952,
                    1524,
                    1100,
                    949,
                    755,
                    597,
                    466,
                    384,
                    334,
                    294,
                    231,
                    192,
                    151,
                    152,
                    116,
                    113,
                    94,
                    87,
                    80,
                    75,
                    54,
                    48,
                    50,
                    36,
                    28,
                    34,
                    30,
                    25,
                    28,
                    27,
                    14,
                    21,
                    5,
                    8,
                    10,
                    14,
                    8,
                    3,
                    7,
                    4,
                    4,
                    6,
                    2,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.279,
                    0.836,
                    1.393,
                    1.95,
                    2.507,
                    3.064,
                    3.621,
                    4.178,
                    4.735,
                    5.292,
                    5.849,
                    6.406,
                    6.963,
                    7.52,
                    8.077,
                    8.634,
                    9.191,
                    9.748,
                    10.305,
                    10.862,
                    11.419,
                    11.976,
                    12.533,
                    13.09,
                    13.647,
                    14.204,
                    14.761,
                    15.318,
                    15.875,
                    16.432,
                    16.989,
                    17.546,
                    18.103,
                    18.66,
                    19.218,
                    19.775,
                    20.332,
                    20.889,
                    21.446,
                    22.003,
                    22.56,
                    23.117,
                    23.674,
                    24.231,
                    24.788,
                    25.345,
                    25.902,
                    26.459,
                    27.016,
                    27.573
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    0,
                    5,
                    13,
                    9,
                    32,
                    64,
                    103,
                    177,
                    315,
                    535,
                    834,
                    1320,
                    1772,
                    2439,
                    3009,
                    3741,
                    3969,
                    4254,
                    4386,
                    4339,
                    3865,
                    3451,
                    2903,
                    2231,
                    1854,
                    1359,
                    961,
                    703,
                    467,
                    346,
                    232,
                    160,
                    120,
                    80,
                    56,
                    49,
                    32,
                    18,
                    22,
                    5,
                    6,
                    7,
                    4,
                    3,
                    1,
                    2,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.802,
                    -0.763,
                    -0.723,
                    -0.684,
                    -0.644,
                    -0.604,
                    -0.565,
                    -0.525,
                    -0.485,
                    -0.446,
                    -0.406,
                    -0.367,
                    -0.327,
                    -0.287,
                    -0.248,
                    -0.208,
                    -0.168,
                    -0.129,
                    -0.089,
                    -0.05,
                    -0.01,
                    0.03,
                    0.069,
                    0.109,
                    0.148,
                    0.188,
                    0.228,
                    0.267,
                    0.307,
                    0.347,
                    0.386,
                    0.426,
                    0.465,
                    0.505,
                    0.545,
                    0.584,
                    0.624,
                    0.664,
                    0.703,
                    0.743,
                    0.782,
                    0.822,
                    0.862,
                    0.901,
                    0.941,
                    0.98,
                    1.02,
                    1.06,
                    1.099,
                    1.139
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases related to learning or teaching new skills",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdt9wvvtrqci66674hkr8mc",
                        "tokens": [
                            "When",
                            " we",
                            " enter",
                            " the",
                            " political",
                            " debate",
                            " sphere",
                            " of",
                            " the",
                            " online",
                            " world",
                            ",",
                            " I",
                            " think",
                            " we",
                            " consider",
                            " people",
                            " holding",
                            " these",
                            " beliefs",
                            " to",
                            " be",
                            " unreal",
                            ".",
                            " The",
                            " information",
                            " age",
                            " means",
                            " almost",
                            " anybody",
                            " can",
                            " become",
                            " informed",
                            " about",
                            " any",
                            " topic",
                            ",",
                            " right",
                            "?",
                            " Someone",
                            " who",
                            " believes",
                            " in",
                            " these",
                            " conspir",
                            "acies",
                            " has",
                            " got",
                            " to",
                            " be",
                            " a",
                            " troll",
                            " or",
                            " using",
                            " their",
                            " anonymity",
                            " to",
                            " esp",
                            "ouse",
                            " harmful",
                            " beliefs",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " never",
                            " talk",
                            " about",
                            " in",
                            "-",
                            "person",
                            ".",
                            " They",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " an",
                            " ed",
                            "gy",
                            " teenager",
                            ",",
                            " a",
                            " kid",
                            " who",
                            " hasn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " learned",
                            " to",
                            " navigate",
                            " the",
                            " harmful",
                            " tra",
                            "ppings",
                            " of",
                            " the",
                            " internet",
                            ";",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " an",
                            " old",
                            " cod",
                            "ger",
                            ",",
                            " still",
                            " holding",
                            " onto",
                            " the",
                            " good",
                            " old",
                            " days",
                            " where",
                            " they",
                            " had",
                            " all",
                            " the",
                            " privilege",
                            ";",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " just"
                        ],
                        "dataIndex": null,
                        "index": "1278",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 27.852,
                        "maxValueTokenIndex": 89,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.985,
                            6.58,
                            0.302,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.191,
                            0.036,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.25,
                            27.852,
                            12.248,
                            6.684,
                            0,
                            0,
                            1.034,
                            1.505,
                            1.466,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.361,
                            0,
                            1.375,
                            0,
                            0,
                            0,
                            0,
                            2.266,
                            2.624,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:08:14.741Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 27.851,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdt9wvvtrqdi666wiv2q6fs",
                        "tokens": [
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Apple",
                            " said",
                            " of",
                            " how",
                            " he",
                            " has",
                            " handled",
                            " the",
                            " poor",
                            " performance",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "You",
                            " want",
                            " to",
                            " lean",
                            " on",
                            " your",
                            " teammates",
                            " because",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " going",
                            " to",
                            " give",
                            " you",
                            " the",
                            " real",
                            " talk",
                            " that",
                            " you",
                            " need",
                            ".",
                            " So",
                            " that",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " what",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " been",
                            " doing",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Pick",
                            " my",
                            " head",
                            " up",
                            " a",
                            " little",
                            " bit",
                            " and",
                            " play",
                            " with",
                            " the",
                            " confidence",
                            " I",
                            " played",
                            " with",
                            " in",
                            " college",
                            ".",
                            " Be",
                            " more",
                            " comfortable",
                            ".",
                            " That",
                            " is",
                            " the",
                            " main",
                            " thing",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Apple",
                            " insists",
                            " the",
                            " comfort",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " there",
                            " because",
                            " his",
                            " rookie",
                            " season",
                            " hasn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " gone",
                            " smoothly",
                            " because",
                            " of",
                            " injuries",
                            ".",
                            " He",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " learning",
                            " to",
                            " play",
                            " in",
                            " the",
                            " NFL",
                            " in",
                            " st",
                            "acc",
                            "ato",
                            " style",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "1278",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.985,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.232,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.478,
                            25.985,
                            8.548,
                            5.713,
                            2.621,
                            0,
                            5.678,
                            0,
                            0,
                            0,
                            0.782,
                            0.664
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:08:14.741Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 27.851,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdt9wvvtrqei666lzn9lzle",
                        "tokens": [
                            "Bob",
                            " Hunt",
                            "ley",
                            " wrest",
                            "led",
                            " with",
                            " the",
                            " limitations",
                            " of",
                            " the",
                            " written",
                            " recipe",
                            " before",
                            " founding",
                            " his",
                            " Houston",
                            "-",
                            "based",
                            " software",
                            " company",
                            " called",
                            " C",
                            "ulin",
                            "App",
                            ".",
                            " In",
                            " the",
                            " 1990",
                            "s",
                            ",",
                            " Mr",
                            ".",
                            " Hunt",
                            "ley",
                            " had",
                            " little",
                            " time",
                            " for",
                            " cooking",
                            ";",
                            " he",
                            " was",
                            " busy",
                            " building",
                            " the",
                            " network",
                            " for",
                            " Doom",
                            ",",
                            " the",
                            " first",
                            " international",
                            " online",
                            " gaming",
                            " network",
                            ".",
                            " But",
                            " after",
                            " he",
                            " sold",
                            " that",
                            " business",
                            " and",
                            " retired",
                            " to",
                            " a",
                            " ranch",
                            " outside",
                            " the",
                            " small",
                            " town",
                            " of",
                            " Mason",
                            ",",
                            " Tex",
                            ".,",
                            " with",
                            " his",
                            " pet",
                            " l",
                            "ongh",
                            "orns",
                            " and",
                            " a",
                            " T",
                            "1",
                            " data",
                            " line",
                            " that",
                            " Verizon",
                            " built",
                            " just",
                            " for",
                            " him",
                            ",",
                            " he",
                            " tried",
                            " teaching",
                            " himself",
                            " to",
                            " cook",
                            " from",
                            " cook",
                            "books",
                            " and",
                            " online",
                            " recipes",
                            ".",
                            " It",
                            " didn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " work",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "I",
                            " struggled",
                            " with",
                            " getting",
                            " the",
                            " whole",
                            " recipe",
                            " downloaded"
                        ],
                        "dataIndex": null,
                        "index": "1278",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 25.638,
                        "maxValueTokenIndex": 98,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.125,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.051,
                            2.704,
                            25.638,
                            22.113,
                            5.512,
                            1.116,
                            0,
                            2.79,
                            1.019,
                            0,
                            0.512,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.138,
                            0,
                            0,
                            0,
                            0.949,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:08:14.741Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 27.851,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "67212",
            "description": "the concept of practicing or engaging in activities that can enhance skills or knowledge",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5281821174513041,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "67212",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:55:47.224Z",
                "maxActApprox": 43.903,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    67212,
                    50372,
                    78874,
                    85845,
                    36129,
                    89828,
                    79250,
                    90267,
                    35526,
                    87576,
                    88510,
                    38850,
                    47132,
                    81563,
                    44064,
                    39569,
                    10372,
                    77660,
                    59396,
                    2902,
                    46187,
                    39710,
                    44904,
                    18802,
                    68287
                ],
                "topkCosSimValues": [
                    1,
                    0.5922,
                    0.5611,
                    0.4654,
                    0.4566,
                    0.451,
                    0.436,
                    0.429,
                    0.4282,
                    0.4244,
                    0.4214,
                    0.4201,
                    0.4174,
                    0.416,
                    0.412,
                    0.4077,
                    0.4003,
                    0.3949,
                    0.3943,
                    0.3902,
                    0.3804,
                    0.3801,
                    0.3796,
                    0.3781,
                    0.3679
                ],
                "neuron_alignment_indices": [
                    288,
                    302,
                    70
                ],
                "neuron_alignment_values": [
                    0.126,
                    0.108,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    70,
                    271,
                    212
                ],
                "correlated_neurons_pearson": [
                    0.013,
                    0.013,
                    0.012
                ],
                "correlated_neurons_l1": [
                    0.014,
                    0.013,
                    0.012
                ],
                "correlated_features_indices": [
                    67189,
                    67244,
                    67199
                ],
                "correlated_features_pearson": [
                    0.002,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0,
                    0
                ],
                "neg_str": [
                    "izons",
                    "nette",
                    "leased",
                    "yssey",
                    "plet",
                    "ombies",
                    "bang",
                    "issues",
                    "cknowled",
                    "DragonMagazine"
                ],
                "neg_values": [
                    -0.82,
                    -0.79,
                    -0.784,
                    -0.739,
                    -0.713,
                    -0.692,
                    -0.689,
                    -0.675,
                    -0.672,
                    -0.666
                ],
                "pos_str": [
                    " martial",
                    " patience",
                    " practicing",
                    " diligently",
                    " medicine",
                    " mindfulness",
                    " yoga",
                    " witchcraft",
                    " cannabin",
                    " humility"
                ],
                "pos_values": [
                    0.964,
                    0.895,
                    0.84,
                    0.839,
                    0.835,
                    0.795,
                    0.784,
                    0.769,
                    0.763,
                    0.734
                ],
                "frac_nonzero": 8e-05,
                "freq_hist_data_bar_heights": [
                    48,
                    28,
                    20,
                    14,
                    10,
                    14,
                    6,
                    4,
                    5,
                    6,
                    6,
                    1,
                    2,
                    2,
                    3,
                    3,
                    0,
                    4,
                    1,
                    2,
                    1,
                    0,
                    5,
                    1,
                    1,
                    5,
                    2,
                    3,
                    4,
                    3,
                    5,
                    1,
                    5,
                    6,
                    4,
                    3,
                    7,
                    2,
                    0,
                    3,
                    3,
                    7,
                    3,
                    4,
                    0,
                    1,
                    3,
                    1,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.446,
                    1.324,
                    2.202,
                    3.08,
                    3.958,
                    4.835,
                    5.713,
                    6.591,
                    7.469,
                    8.347,
                    9.225,
                    10.103,
                    10.981,
                    11.859,
                    12.737,
                    13.615,
                    14.493,
                    15.37,
                    16.248,
                    17.126,
                    18.004,
                    18.882,
                    19.76,
                    20.638,
                    21.516,
                    22.394,
                    23.272,
                    24.15,
                    25.028,
                    25.906,
                    26.783,
                    27.661,
                    28.539,
                    29.417,
                    30.295,
                    31.173,
                    32.051,
                    32.929,
                    33.807,
                    34.685,
                    35.563,
                    36.441,
                    37.318,
                    38.196,
                    39.074,
                    39.952,
                    40.83,
                    41.708,
                    42.586,
                    43.464
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    1,
                    2,
                    2,
                    6,
                    18,
                    20,
                    40,
                    77,
                    101,
                    184,
                    294,
                    432,
                    651,
                    883,
                    1188,
                    1645,
                    2060,
                    2615,
                    3228,
                    3662,
                    3909,
                    4293,
                    4078,
                    3919,
                    3745,
                    3063,
                    2540,
                    2071,
                    1644,
                    1241,
                    865,
                    602,
                    400,
                    286,
                    175,
                    111,
                    80,
                    46,
                    31,
                    22,
                    10,
                    4,
                    2,
                    3,
                    1,
                    3,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.802,
                    -0.766,
                    -0.731,
                    -0.695,
                    -0.659,
                    -0.624,
                    -0.588,
                    -0.552,
                    -0.517,
                    -0.481,
                    -0.445,
                    -0.41,
                    -0.374,
                    -0.338,
                    -0.303,
                    -0.267,
                    -0.231,
                    -0.196,
                    -0.16,
                    -0.124,
                    -0.089,
                    -0.053,
                    -0.017,
                    0.018,
                    0.054,
                    0.09,
                    0.125,
                    0.161,
                    0.197,
                    0.232,
                    0.268,
                    0.304,
                    0.339,
                    0.375,
                    0.411,
                    0.446,
                    0.482,
                    0.518,
                    0.553,
                    0.589,
                    0.625,
                    0.66,
                    0.696,
                    0.732,
                    0.767,
                    0.803,
                    0.839,
                    0.874,
                    0.91,
                    0.946
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " variations of the word \"practice.\"",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "the concept of practicing or engaging in activities that can enhance skills or knowledge",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi09xwq9m110exx7becdg2",
                        "tokens": [
                            ",",
                            " which",
                            " was",
                            " distribution",
                            " or",
                            " possession",
                            " with",
                            " intent",
                            " to",
                            " distribute",
                            " a",
                            " schedule",
                            " I",
                            " or",
                            " II",
                            " drug",
                            ",",
                            " not",
                            " including",
                            " Cannabis",
                            ".",
                            " Sur",
                            "prising",
                            ":",
                            " More",
                            " people",
                            " were",
                            " arrested",
                            " for",
                            " an",
                            " alleged",
                            " assault",
                            " on",
                            " a",
                            " family",
                            " or",
                            " household",
                            " member",
                            " than",
                            " for",
                            " assault",
                            " on",
                            " a",
                            " non",
                            "-",
                            "family",
                            " or",
                            " household",
                            " member",
                            ".",
                            " This",
                            " is",
                            " actually",
                            " not",
                            " surprising",
                            ",",
                            " but",
                            " to",
                            " a",
                            " person",
                            " who",
                            " is",
                            " not",
                            " used",
                            " to",
                            " practicing",
                            " criminal",
                            " defense",
                            ",",
                            " it",
                            " might",
                            " be",
                            " a",
                            " shock",
                            ".",
                            " Sur",
                            "prising",
                            ":",
                            " More",
                            " grand",
                            " l",
                            "arc",
                            "eny",
                            " offenses",
                            " were",
                            " the",
                            " basis",
                            " for",
                            " arrest",
                            " than",
                            " pet",
                            "it",
                            " l",
                            "arc",
                            "eny",
                            ".",
                            " We",
                            " would",
                            " have",
                            " expected",
                            " more",
                            " l",
                            "arc",
                            "eny",
                            " charges",
                            " pred",
                            "icated",
                            " upon",
                            " a",
                            " pet",
                            "it",
                            " l",
                            "arc",
                            "eny",
                            " allegation",
                            " (",
                            "less",
                            " than",
                            " $",
                            "200",
                            ",",
                            " and",
                            " not",
                            " from",
                            " a",
                            " person",
                            "),"
                        ],
                        "dataIndex": null,
                        "index": "67212",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.903,
                        "maxValueTokenIndex": 65,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.903,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:55:50.164Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 43.903,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi09xwq9m210exeotenmke",
                        "tokens": [
                            " making",
                            " that",
                            " face",
                            " when",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " excited",
                            " (",
                            "See",
                            " Picture",
                            " Four",
                            ").",
                            " Main",
                            "ly",
                            " because",
                            " of",
                            " who",
                            " I",
                            " am",
                            " as",
                            " a",
                            " person",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " just",
                            " now",
                            " realizing",
                            " how",
                            " long",
                            " it",
                            " took",
                            " me",
                            " to",
                            " actually",
                            " talk",
                            " about",
                            " the",
                            " books",
                            " you",
                            " got",
                            " me",
                            ".",
                            " Sorry",
                            ".",
                            " (",
                            "Not",
                            " really",
                            ",",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " just",
                            " practicing",
                            " on",
                            " what",
                            " to",
                            " say",
                            " to",
                            " laundry",
                            " guy",
                            ".",
                            " I",
                            " actually",
                            " like",
                            " talking",
                            " about",
                            " myself",
                            ".",
                            " See",
                            "?",
                            " Un",
                            "apolog",
                            "etic",
                            ".)",
                            "\n",
                            "\n",
                            "Okay",
                            " so",
                            " book",
                            " num",
                            "ero",
                            " un",
                            "o",
                            ":",
                            " \u00e2\u0122",
                            "\u013e",
                            "P",
                            "awn",
                            "\u00e2\u0122",
                            "\u013f",
                            " by",
                            " Aim",
                            "\u00c3\u00a9e",
                            " Carter",
                            ".",
                            " From",
                            " what",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " gathered",
                            " (",
                            "aka",
                            ",",
                            " the",
                            " inside",
                            " flap",
                            "),",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "m",
                            " gonna",
                            " like",
                            " this",
                            " one",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "67212",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.23,
                        "maxValueTokenIndex": 61,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.23,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:55:50.164Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 43.903,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi09xwq9m310ex9ynixkkc",
                        "tokens": [
                            " be",
                            " done",
                            " with",
                            " a",
                            " romantic",
                            " partner",
                            " by",
                            " any",
                            " means",
                            ".",
                            " Anyone",
                            " who",
                            " is",
                            " willing",
                            " to",
                            " take",
                            " a",
                            " moment",
                            " to",
                            " practice",
                            " raising",
                            " their",
                            " awareness",
                            " in",
                            " their",
                            " interaction",
                            " with",
                            " you",
                            " is",
                            " a",
                            " perfect",
                            " participant",
                            " for",
                            " these",
                            " exercises",
                            ".",
                            "\n",
                            "\n",
                            "Often",
                            " people",
                            " express",
                            " their",
                            " displeasure",
                            " with",
                            " their",
                            " relationships",
                            " to",
                            " me",
                            ".",
                            " And",
                            " I",
                            " notice",
                            " a",
                            " few",
                            " recurring",
                            " themes",
                            ":",
                            " B",
                            "ored",
                            "om",
                            ",",
                            " resentment",
                            ",",
                            " distrust",
                            ",",
                            " immature",
                            " communication",
                            ".",
                            " inc",
                            "ong",
                            "ru",
                            "ities",
                            " in",
                            " the",
                            " verbal",
                            " vs",
                            ".",
                            " behavior",
                            " and",
                            " jealousy",
                            ",",
                            " to",
                            " name",
                            " a",
                            " few",
                            ".",
                            " I",
                            " find",
                            " that",
                            " often",
                            " people",
                            " are",
                            " not",
                            " mindful",
                            " of",
                            " the",
                            " types",
                            " of",
                            " interactions",
                            " they",
                            " want",
                            " to",
                            " have",
                            " with",
                            " others",
                            ",",
                            " and",
                            " have",
                            " a",
                            " la",
                            "isse",
                            "z",
                            " faire",
                            " sort",
                            " of",
                            " approach",
                            " to",
                            " the",
                            " relationships",
                            " that",
                            " are",
                            " formed",
                            ".",
                            " And",
                            " while",
                            " spontaneous",
                            " connections"
                        ],
                        "dataIndex": null,
                        "index": "67212",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 41.913,
                        "maxValueTokenIndex": 19,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            41.913,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:55:50.164Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 43.903,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "36759",
            "description": " phrases related to learning and typing skills",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.51137170127799,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "36759",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:17:20.863Z",
                "maxActApprox": 13.291,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    36759,
                    80530,
                    6057,
                    64733,
                    34954,
                    14052,
                    96770,
                    33115,
                    29063,
                    11105,
                    55382,
                    59850,
                    97527,
                    84712,
                    15165,
                    57852,
                    52248,
                    22083,
                    50986,
                    6850,
                    76062,
                    26071,
                    49673,
                    7364,
                    10485
                ],
                "topkCosSimValues": [
                    1,
                    0.5951,
                    0.5934,
                    0.5701,
                    0.5328,
                    0.4929,
                    0.4908,
                    0.4778,
                    0.4684,
                    0.4549,
                    0.4378,
                    0.4362,
                    0.4357,
                    0.4286,
                    0.428,
                    0.4258,
                    0.4207,
                    0.4182,
                    0.4174,
                    0.417,
                    0.4154,
                    0.4034,
                    0.4003,
                    0.3977,
                    0.396
                ],
                "neuron_alignment_indices": [
                    756,
                    393,
                    447
                ],
                "neuron_alignment_values": [
                    0.144,
                    0.137,
                    0.131
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.006
                ],
                "correlated_neurons_indices": [
                    70,
                    665,
                    570
                ],
                "correlated_neurons_pearson": [
                    0.07,
                    0.061,
                    0.058
                ],
                "correlated_neurons_l1": [
                    0.077,
                    0.07,
                    0.034
                ],
                "correlated_features_indices": [
                    36790,
                    36840,
                    36787
                ],
                "correlated_features_pearson": [
                    0.021,
                    0.005,
                    0.003
                ],
                "correlated_features_l1": [
                    0.021,
                    0.006,
                    0.003
                ],
                "neg_str": [
                    "ortment",
                    "aran",
                    "emonic",
                    "advertising",
                    "oris",
                    "rin",
                    "hon",
                    "odon",
                    "grad",
                    "arty"
                ],
                "neg_values": [
                    -0.622,
                    -0.585,
                    -0.584,
                    -0.573,
                    -0.57,
                    -0.555,
                    -0.553,
                    -0.553,
                    -0.55,
                    -0.545
                ],
                "pos_str": [
                    " differently",
                    " freely",
                    " separately",
                    " excessively",
                    " directly",
                    " continuously",
                    " blindly",
                    " extensively",
                    " elsewhere",
                    " anyway"
                ],
                "pos_values": [
                    0.846,
                    0.829,
                    0.822,
                    0.779,
                    0.767,
                    0.766,
                    0.765,
                    0.764,
                    0.763,
                    0.759
                ],
                "frac_nonzero": 0.00365,
                "freq_hist_data_bar_heights": [
                    1695,
                    1427,
                    1185,
                    1012,
                    832,
                    711,
                    617,
                    515,
                    484,
                    401,
                    352,
                    293,
                    274,
                    220,
                    195,
                    180,
                    157,
                    135,
                    112,
                    104,
                    75,
                    73,
                    67,
                    54,
                    53,
                    48,
                    34,
                    21,
                    26,
                    21,
                    18,
                    18,
                    15,
                    9,
                    10,
                    4,
                    6,
                    8,
                    4,
                    3,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.133,
                    0.399,
                    0.665,
                    0.93,
                    1.196,
                    1.462,
                    1.728,
                    1.994,
                    2.26,
                    2.525,
                    2.791,
                    3.057,
                    3.323,
                    3.589,
                    3.854,
                    4.12,
                    4.386,
                    4.652,
                    4.918,
                    5.184,
                    5.449,
                    5.715,
                    5.981,
                    6.247,
                    6.513,
                    6.779,
                    7.044,
                    7.31,
                    7.576,
                    7.842,
                    8.108,
                    8.373,
                    8.639,
                    8.905,
                    9.171,
                    9.437,
                    9.703,
                    9.968,
                    10.234,
                    10.5,
                    10.766,
                    11.032,
                    11.297,
                    11.563,
                    11.829,
                    12.095,
                    12.361,
                    12.627,
                    12.892,
                    13.158
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    4,
                    14,
                    18,
                    19,
                    42,
                    76,
                    97,
                    180,
                    250,
                    398,
                    595,
                    849,
                    1222,
                    1681,
                    2166,
                    2679,
                    3186,
                    3622,
                    4005,
                    4027,
                    4002,
                    3965,
                    3469,
                    3043,
                    2447,
                    1988,
                    1546,
                    1160,
                    930,
                    685,
                    499,
                    360,
                    264,
                    190,
                    138,
                    101,
                    80,
                    54,
                    64,
                    28,
                    36,
                    24,
                    17,
                    12,
                    6,
                    8,
                    7,
                    0,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.608,
                    -0.578,
                    -0.549,
                    -0.519,
                    -0.49,
                    -0.461,
                    -0.431,
                    -0.402,
                    -0.373,
                    -0.343,
                    -0.314,
                    -0.284,
                    -0.255,
                    -0.226,
                    -0.196,
                    -0.167,
                    -0.138,
                    -0.108,
                    -0.079,
                    -0.049,
                    -0.02,
                    0.009,
                    0.039,
                    0.068,
                    0.097,
                    0.127,
                    0.156,
                    0.186,
                    0.215,
                    0.244,
                    0.274,
                    0.303,
                    0.332,
                    0.362,
                    0.391,
                    0.42,
                    0.45,
                    0.479,
                    0.509,
                    0.538,
                    0.567,
                    0.597,
                    0.626,
                    0.655,
                    0.685,
                    0.714,
                    0.744,
                    0.773,
                    0.802,
                    0.832
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " actions related to learning and practicing skills",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases related to learning and typing skills",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggmwa335lx10exco67ax55",
                        "tokens": [
                            " if",
                            " you",
                            " fix",
                            " your",
                            " bad",
                            " typing",
                            " habits",
                            ".",
                            " The",
                            " earlier",
                            " you",
                            " start",
                            " learning",
                            ",",
                            " the",
                            " more",
                            " rewarding",
                            " it",
                            " can",
                            " be",
                            ".",
                            " Teach",
                            " kids",
                            " to",
                            " touch",
                            " type",
                            " as",
                            " soon",
                            " as",
                            " they",
                            " start",
                            " playing",
                            " with",
                            " the",
                            " computer",
                            ".",
                            " This",
                            " skill",
                            " will",
                            " stay",
                            " relevant",
                            " for",
                            " at",
                            " least",
                            " one",
                            " more",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " take",
                            " away",
                            " only",
                            " one",
                            " thing",
                            " from",
                            " my",
                            " story",
                            ",",
                            " it",
                            "'s",
                            " this",
                            ":",
                            " Learn",
                            " proper",
                            " touch",
                            " typing",
                            " technique",
                            " today",
                            ".",
                            "\n",
                            "\n",
                            "Recipe",
                            "\n",
                            "\n",
                            "Take",
                            " a",
                            " typing",
                            " test",
                            " on",
                            " Key",
                            "hero",
                            ".",
                            " Sl",
                            "ower",
                            " than",
                            " 40",
                            " W",
                            "PM",
                            "?",
                            " Practice",
                            " 15",
                            " minutes",
                            " every",
                            " day",
                            " for",
                            " a",
                            " month",
                            ".",
                            " If",
                            " your",
                            " accuracy",
                            " is",
                            " lower",
                            " than",
                            " 95",
                            "%,",
                            " slow",
                            " down",
                            " and",
                            " try",
                            " to",
                            " type",
                            " as",
                            " accurately",
                            " as",
                            " possible",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " type"
                        ],
                        "dataIndex": null,
                        "index": "36759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.291,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.489,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.528,
                            0,
                            0,
                            1.968,
                            0,
                            10.197,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.291
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:26.333Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.291,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggmwa335m610exgnqozkf4",
                        "tokens": [
                            " if",
                            " you",
                            " fix",
                            " your",
                            " bad",
                            " typing",
                            " habits",
                            ".",
                            " The",
                            " earlier",
                            " you",
                            " start",
                            " learning",
                            ",",
                            " the",
                            " more",
                            " rewarding",
                            " it",
                            " can",
                            " be",
                            ".",
                            " Teach",
                            " kids",
                            " to",
                            " touch",
                            " type",
                            " as",
                            " soon",
                            " as",
                            " they",
                            " start",
                            " playing",
                            " with",
                            " the",
                            " computer",
                            ".",
                            " This",
                            " skill",
                            " will",
                            " stay",
                            " relevant",
                            " for",
                            " at",
                            " least",
                            " one",
                            " more",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " take",
                            " away",
                            " only",
                            " one",
                            " thing",
                            " from",
                            " my",
                            " story",
                            ",",
                            " it",
                            "'s",
                            " this",
                            ":",
                            " Learn",
                            " proper",
                            " touch",
                            " typing",
                            " technique",
                            " today",
                            ".",
                            "\n",
                            "\n",
                            "Recipe",
                            "\n",
                            "\n",
                            "Take",
                            " a",
                            " typing",
                            " test",
                            " on",
                            " Key",
                            "hero",
                            ".",
                            " Sl",
                            "ower",
                            " than",
                            " 40",
                            " W",
                            "PM",
                            "?",
                            " Practice",
                            " 15",
                            " minutes",
                            " every",
                            " day",
                            " for",
                            " a",
                            " month",
                            ".",
                            " If",
                            " your",
                            " accuracy",
                            " is",
                            " lower",
                            " than",
                            " 95",
                            "%,",
                            " slow",
                            " down",
                            " and",
                            " try",
                            " to",
                            " type",
                            " as",
                            " accurately",
                            " as",
                            " possible",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " type"
                        ],
                        "dataIndex": null,
                        "index": "36759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.291,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.489,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.528,
                            0,
                            0,
                            1.968,
                            0,
                            10.197,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.291
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:26.333Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.291,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggmwa535mk10exsw1a50vs",
                        "tokens": [
                            " if",
                            " you",
                            " fix",
                            " your",
                            " bad",
                            " typing",
                            " habits",
                            ".",
                            " The",
                            " earlier",
                            " you",
                            " start",
                            " learning",
                            ",",
                            " the",
                            " more",
                            " rewarding",
                            " it",
                            " can",
                            " be",
                            ".",
                            " Teach",
                            " kids",
                            " to",
                            " touch",
                            " type",
                            " as",
                            " soon",
                            " as",
                            " they",
                            " start",
                            " playing",
                            " with",
                            " the",
                            " computer",
                            ".",
                            " This",
                            " skill",
                            " will",
                            " stay",
                            " relevant",
                            " for",
                            " at",
                            " least",
                            " one",
                            " more",
                            " generation",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " want",
                            " to",
                            " take",
                            " away",
                            " only",
                            " one",
                            " thing",
                            " from",
                            " my",
                            " story",
                            ",",
                            " it",
                            "'s",
                            " this",
                            ":",
                            " Learn",
                            " proper",
                            " touch",
                            " typing",
                            " technique",
                            " today",
                            ".",
                            "\n",
                            "\n",
                            "Recipe",
                            "\n",
                            "\n",
                            "Take",
                            " a",
                            " typing",
                            " test",
                            " on",
                            " Key",
                            "hero",
                            ".",
                            " Sl",
                            "ower",
                            " than",
                            " 40",
                            " W",
                            "PM",
                            "?",
                            " Practice",
                            " 15",
                            " minutes",
                            " every",
                            " day",
                            " for",
                            " a",
                            " month",
                            ".",
                            " If",
                            " your",
                            " accuracy",
                            " is",
                            " lower",
                            " than",
                            " 95",
                            "%,",
                            " slow",
                            " down",
                            " and",
                            " try",
                            " to",
                            " type",
                            " as",
                            " accurately",
                            " as",
                            " possible",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " type"
                        ],
                        "dataIndex": null,
                        "index": "36759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.291,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.971,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.489,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.528,
                            0,
                            0,
                            1.968,
                            0,
                            10.197,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.291
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:26.333Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 10.633,
                        "binMax": 13.291,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "31668",
            "description": " questions related to learning or techniques",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5086902379989624,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "31668",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:55:46.146Z",
                "maxActApprox": 37.731,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    31668,
                    40923,
                    24267,
                    44587,
                    19499,
                    37248,
                    21693,
                    12466,
                    42630,
                    35075,
                    29139,
                    42105,
                    27914,
                    46385,
                    2774,
                    37998,
                    9097,
                    10982,
                    48850,
                    5506,
                    1406,
                    45508,
                    17188,
                    12685,
                    23029
                ],
                "topkCosSimValues": [
                    1,
                    0.7366,
                    0.7068,
                    0.7041,
                    0.689,
                    0.6878,
                    0.6812,
                    0.6211,
                    0.6175,
                    0.5816,
                    0.51,
                    0.5098,
                    0.4955,
                    0.4398,
                    0.4242,
                    0.4238,
                    0.4211,
                    0.4201,
                    0.4162,
                    0.4095,
                    0.4054,
                    0.4048,
                    0.395,
                    0.3871,
                    0.3857
                ],
                "neuron_alignment_indices": [
                    534,
                    393,
                    483
                ],
                "neuron_alignment_values": [
                    0.092,
                    0.092,
                    0.091
                ],
                "neuron_alignment_l1": [
                    0.004,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    236,
                    60,
                    483
                ],
                "correlated_neurons_pearson": [
                    0.034,
                    0.034,
                    0.032
                ],
                "correlated_neurons_l1": [
                    0.036,
                    0.033,
                    0.03
                ],
                "correlated_features_indices": [
                    31613,
                    31632,
                    31668
                ],
                "correlated_features_pearson": [
                    0.001,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0.001,
                    0
                ],
                "neg_str": [
                    "Rum",
                    "oubted",
                    "holder",
                    "estate",
                    "icker",
                    "aredevil",
                    "inion",
                    " Tanz",
                    "luster",
                    "ige"
                ],
                "neg_values": [
                    -0.673,
                    -0.646,
                    -0.617,
                    -0.588,
                    -0.581,
                    -0.565,
                    -0.564,
                    -0.563,
                    -0.55,
                    -0.539
                ],
                "pos_str": [
                    "soever",
                    "itzer",
                    " ropes",
                    " efficiently",
                    "ls",
                    "lers",
                    "beit",
                    " feasible",
                    "ells",
                    "itz"
                ],
                "pos_values": [
                    0.943,
                    0.711,
                    0.701,
                    0.695,
                    0.693,
                    0.686,
                    0.676,
                    0.64,
                    0.638,
                    0.636
                ],
                "frac_nonzero": 0.00047,
                "freq_hist_data_bar_heights": [
                    226,
                    131,
                    127,
                    82,
                    94,
                    79,
                    59,
                    53,
                    56,
                    46,
                    51,
                    52,
                    33,
                    27,
                    13,
                    32,
                    35,
                    17,
                    26,
                    28,
                    19,
                    17,
                    13,
                    13,
                    12,
                    15,
                    9,
                    11,
                    9,
                    8,
                    7,
                    7,
                    4,
                    6,
                    7,
                    5,
                    6,
                    4,
                    5,
                    3,
                    5,
                    5,
                    5,
                    2,
                    1,
                    2,
                    2,
                    1,
                    3,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.378,
                    1.133,
                    1.888,
                    2.642,
                    3.397,
                    4.151,
                    4.906,
                    5.661,
                    6.415,
                    7.17,
                    7.924,
                    8.679,
                    9.434,
                    10.188,
                    10.943,
                    11.697,
                    12.452,
                    13.207,
                    13.961,
                    14.716,
                    15.47,
                    16.225,
                    16.979,
                    17.734,
                    18.489,
                    19.243,
                    19.998,
                    20.752,
                    21.507,
                    22.262,
                    23.016,
                    23.771,
                    24.525,
                    25.28,
                    26.035,
                    26.789,
                    27.544,
                    28.298,
                    29.053,
                    29.808,
                    30.562,
                    31.317,
                    32.071,
                    32.826,
                    33.581,
                    34.335,
                    35.09,
                    35.844,
                    36.599,
                    37.353
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    1,
                    2,
                    4,
                    24,
                    29,
                    61,
                    113,
                    172,
                    288,
                    412,
                    663,
                    972,
                    1280,
                    1830,
                    2291,
                    2870,
                    3327,
                    3732,
                    4051,
                    4187,
                    3974,
                    3670,
                    3458,
                    2989,
                    2421,
                    1996,
                    1592,
                    1178,
                    923,
                    594,
                    430,
                    263,
                    180,
                    111,
                    61,
                    40,
                    26,
                    12,
                    11,
                    10,
                    1,
                    5,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.657,
                    -0.624,
                    -0.592,
                    -0.56,
                    -0.527,
                    -0.495,
                    -0.463,
                    -0.431,
                    -0.398,
                    -0.366,
                    -0.334,
                    -0.301,
                    -0.269,
                    -0.237,
                    -0.204,
                    -0.172,
                    -0.14,
                    -0.107,
                    -0.075,
                    -0.043,
                    -0.01,
                    0.022,
                    0.054,
                    0.086,
                    0.119,
                    0.151,
                    0.183,
                    0.216,
                    0.248,
                    0.28,
                    0.313,
                    0.345,
                    0.377,
                    0.41,
                    0.442,
                    0.474,
                    0.506,
                    0.539,
                    0.571,
                    0.603,
                    0.636,
                    0.668,
                    0.7,
                    0.733,
                    0.765,
                    0.797,
                    0.83,
                    0.862,
                    0.894,
                    0.926
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " questions related to learning or techniques",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk665it4tuki666i1by1v5t",
                        "tokens": [
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "They",
                            " where",
                            " (",
                            "sic",
                            ")",
                            " massively",
                            " outnumbered",
                            " and",
                            " out",
                            "gun",
                            "ned",
                            " but",
                            " fearless",
                            " in",
                            " the",
                            " face",
                            " of",
                            " this",
                            " as",
                            " they",
                            " knew",
                            " another",
                            " ISIS",
                            " death",
                            " meant",
                            " saving",
                            " the",
                            " lives",
                            " of",
                            " countless",
                            " civilians",
                            ".",
                            " He",
                            " was",
                            " a",
                            " fearless",
                            " and",
                            " exceptional",
                            " soldier",
                            " as",
                            " well",
                            " a",
                            " great",
                            " man",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "A",
                            " fellow",
                            " Western",
                            " YPG",
                            " fighter",
                            ",",
                            " New",
                            " York",
                            " man",
                            " Robert",
                            " Rose",
                            ",",
                            " said",
                            " he",
                            " was",
                            " heart",
                            "broken",
                            " over",
                            " his",
                            " Australian",
                            " friend",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " death",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "RIP",
                            " to",
                            " my",
                            " he",
                            "val",
                            " (",
                            "friend",
                            ")",
                            " Ash",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Mr",
                            " Rose",
                            " posted",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "He",
                            " was",
                            " the",
                            " first",
                            " 1",
                            " when",
                            " I",
                            " got",
                            " in",
                            " country",
                            " to",
                            " teach",
                            " the",
                            " basics",
                            " of",
                            " my",
                            " Ak",
                            " 47",
                            " how",
                            " to",
                            " strip",
                            " it",
                            " assemble",
                            " it",
                            " and",
                            " how"
                        ],
                        "dataIndex": null,
                        "index": "31668",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 37.731,
                        "maxValueTokenIndex": 119,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.112,
                            0,
                            0,
                            0,
                            37.731,
                            2.228,
                            0,
                            0,
                            2.705,
                            0,
                            0,
                            28.266
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:55:51.335Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 37.731,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk665it4tuli66651kv6fk0",
                        "tokens": [
                            " death",
                            " will",
                            " need",
                            " to",
                            " be",
                            " registered",
                            " with",
                            " The",
                            " British",
                            " Columbia",
                            " Vital",
                            " Statistics",
                            " Agency",
                            ",",
                            " where",
                            " a",
                            " disposition",
                            " permit",
                            " will",
                            " be",
                            " issued",
                            " to",
                            " confirm",
                            " where",
                            " the",
                            " body",
                            " will",
                            " be",
                            " buried",
                            ",",
                            " or",
                            " crem",
                            "ated",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " a",
                            " funeral",
                            " home",
                            " is",
                            " not",
                            " moving",
                            " the",
                            " body",
                            ",",
                            " then",
                            " a",
                            " private",
                            " transport",
                            " permit",
                            " must",
                            " be",
                            " applied",
                            " for",
                            " through",
                            " Consumer",
                            " Protection",
                            " BC",
                            ".",
                            " Without",
                            " this",
                            " form",
                            ",",
                            " transporting",
                            " a",
                            " body",
                            " violates",
                            " the",
                            " Fun",
                            "eral",
                            " Services",
                            " Act",
                            ".",
                            "\n",
                            "\n",
                            "A",
                            " death",
                            " dou",
                            "la",
                            " can",
                            " also",
                            " teach",
                            " people",
                            " how",
                            " to",
                            " care",
                            " for",
                            " a",
                            " dead",
                            " body",
                            ".",
                            " They",
                            " are",
                            " not",
                            " registered",
                            " funeral",
                            " providers",
                            " and",
                            " cannot",
                            " be",
                            " paid",
                            " to",
                            " wash",
                            " a",
                            " body",
                            ",",
                            " but",
                            " they",
                            " can",
                            " provide",
                            " instruction",
                            " and",
                            " support",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " can",
                            " never",
                            " have",
                            " too",
                            " much",
                            " ice",
                            "\n",
                            "\n",
                            "Dead"
                        ],
                        "dataIndex": null,
                        "index": "31668",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.626,
                        "maxValueTokenIndex": 84,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            36.626,
                            0.423,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:55:51.335Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 37.731,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk665iv4tv7i66648ys75d6",
                        "tokens": [
                            " death",
                            " will",
                            " need",
                            " to",
                            " be",
                            " registered",
                            " with",
                            " The",
                            " British",
                            " Columbia",
                            " Vital",
                            " Statistics",
                            " Agency",
                            ",",
                            " where",
                            " a",
                            " disposition",
                            " permit",
                            " will",
                            " be",
                            " issued",
                            " to",
                            " confirm",
                            " where",
                            " the",
                            " body",
                            " will",
                            " be",
                            " buried",
                            ",",
                            " or",
                            " crem",
                            "ated",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " a",
                            " funeral",
                            " home",
                            " is",
                            " not",
                            " moving",
                            " the",
                            " body",
                            ",",
                            " then",
                            " a",
                            " private",
                            " transport",
                            " permit",
                            " must",
                            " be",
                            " applied",
                            " for",
                            " through",
                            " Consumer",
                            " Protection",
                            " BC",
                            ".",
                            " Without",
                            " this",
                            " form",
                            ",",
                            " transporting",
                            " a",
                            " body",
                            " violates",
                            " the",
                            " Fun",
                            "eral",
                            " Services",
                            " Act",
                            ".",
                            "\n",
                            "\n",
                            "A",
                            " death",
                            " dou",
                            "la",
                            " can",
                            " also",
                            " teach",
                            " people",
                            " how",
                            " to",
                            " care",
                            " for",
                            " a",
                            " dead",
                            " body",
                            ".",
                            " They",
                            " are",
                            " not",
                            " registered",
                            " funeral",
                            " providers",
                            " and",
                            " cannot",
                            " be",
                            " paid",
                            " to",
                            " wash",
                            " a",
                            " body",
                            ",",
                            " but",
                            " they",
                            " can",
                            " provide",
                            " instruction",
                            " and",
                            " support",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " can",
                            " never",
                            " have",
                            " too",
                            " much",
                            " ice",
                            "\n",
                            "\n",
                            "Dead"
                        ],
                        "dataIndex": null,
                        "index": "31668",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.626,
                        "maxValueTokenIndex": 84,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            36.626,
                            0.423,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:55:51.335Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 30.185,
                        "binMax": 37.731,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "39710",
            "description": " verbs related to skill development and improvement",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.49756360054016113,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "39710",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:21:43.193Z",
                "maxActApprox": 34.397,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    39710,
                    22576,
                    90923,
                    96563,
                    33561,
                    18729,
                    13092,
                    16606,
                    47132,
                    38523,
                    61184,
                    91932,
                    13396,
                    9665,
                    28531,
                    67212,
                    92917,
                    73836,
                    88970,
                    36129,
                    49546,
                    32810,
                    3975,
                    75125,
                    30791
                ],
                "topkCosSimValues": [
                    1,
                    0.4705,
                    0.466,
                    0.4572,
                    0.4508,
                    0.4504,
                    0.4377,
                    0.4337,
                    0.4256,
                    0.4179,
                    0.4162,
                    0.4026,
                    0.3865,
                    0.3862,
                    0.3829,
                    0.3801,
                    0.371,
                    0.3666,
                    0.3645,
                    0.362,
                    0.3616,
                    0.3609,
                    0.3561,
                    0.3523,
                    0.3522
                ],
                "neuron_alignment_indices": [
                    302,
                    140,
                    748
                ],
                "neuron_alignment_values": [
                    0.13,
                    0.101,
                    0.1
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    766,
                    641,
                    230
                ],
                "correlated_neurons_pearson": [
                    0.013,
                    0.012,
                    0.012
                ],
                "correlated_neurons_l1": [
                    0.012,
                    0.013,
                    0.011
                ],
                "correlated_features_indices": [
                    39749,
                    39741,
                    39718
                ],
                "correlated_features_pearson": [
                    0.006,
                    0.003,
                    0
                ],
                "correlated_features_l1": [
                    0.006,
                    0.003,
                    0
                ],
                "neg_str": [
                    "ublic",
                    "ylum",
                    "esp",
                    "soDeliveryDate",
                    "iop",
                    "ques",
                    "\u00e3\u0125\u0140",
                    "gmail",
                    " Cele",
                    "\u00c3\u00a1n"
                ],
                "neg_values": [
                    -0.849,
                    -0.74,
                    -0.709,
                    -0.708,
                    -0.678,
                    -0.666,
                    -0.662,
                    -0.656,
                    -0.638,
                    -0.635
                ],
                "pos_str": [
                    " skills",
                    " mastery",
                    " proficiency",
                    " teamwork",
                    " skill",
                    " rapport",
                    " perfected",
                    " technique",
                    " techniques",
                    " expertise"
                ],
                "pos_values": [
                    1.032,
                    0.985,
                    0.911,
                    0.901,
                    0.88,
                    0.877,
                    0.87,
                    0.848,
                    0.84,
                    0.832
                ],
                "frac_nonzero": 0.00025,
                "freq_hist_data_bar_heights": [
                    236,
                    160,
                    108,
                    73,
                    52,
                    31,
                    23,
                    16,
                    9,
                    9,
                    7,
                    7,
                    4,
                    4,
                    3,
                    4,
                    9,
                    5,
                    0,
                    4,
                    0,
                    1,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    3,
                    2,
                    0,
                    0,
                    1,
                    0,
                    0,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.345,
                    1.033,
                    1.721,
                    2.408,
                    3.096,
                    3.784,
                    4.472,
                    5.16,
                    5.848,
                    6.536,
                    7.224,
                    7.912,
                    8.6,
                    9.288,
                    9.976,
                    10.664,
                    11.352,
                    12.039,
                    12.727,
                    13.415,
                    14.103,
                    14.791,
                    15.479,
                    16.167,
                    16.855,
                    17.543,
                    18.231,
                    18.919,
                    19.607,
                    20.295,
                    20.983,
                    21.67,
                    22.358,
                    23.046,
                    23.734,
                    24.422,
                    25.11,
                    25.798,
                    26.486,
                    27.174,
                    27.862,
                    28.55,
                    29.238,
                    29.926,
                    30.614,
                    31.301,
                    31.989,
                    32.677,
                    33.365,
                    34.053
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    2,
                    3,
                    7,
                    14,
                    23,
                    63,
                    104,
                    179,
                    271,
                    476,
                    689,
                    1041,
                    1450,
                    2000,
                    2605,
                    3208,
                    3593,
                    3891,
                    4123,
                    4079,
                    3936,
                    3472,
                    3176,
                    2631,
                    2292,
                    1806,
                    1369,
                    1087,
                    795,
                    553,
                    422,
                    300,
                    208,
                    141,
                    93,
                    45,
                    31,
                    18,
                    20,
                    16,
                    12,
                    3,
                    4,
                    2,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.83,
                    -0.792,
                    -0.755,
                    -0.717,
                    -0.679,
                    -0.642,
                    -0.604,
                    -0.567,
                    -0.529,
                    -0.491,
                    -0.454,
                    -0.416,
                    -0.379,
                    -0.341,
                    -0.303,
                    -0.266,
                    -0.228,
                    -0.19,
                    -0.153,
                    -0.115,
                    -0.078,
                    -0.04,
                    -0.002,
                    0.035,
                    0.073,
                    0.11,
                    0.148,
                    0.186,
                    0.223,
                    0.261,
                    0.298,
                    0.336,
                    0.374,
                    0.411,
                    0.449,
                    0.487,
                    0.524,
                    0.562,
                    0.599,
                    0.637,
                    0.675,
                    0.712,
                    0.75,
                    0.787,
                    0.825,
                    0.863,
                    0.9,
                    0.938,
                    0.975,
                    1.013
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "variations of the word \"hone\" related to skill improvement",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " verbs related to skill development and improvement",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggsfsg5dvb10exlh85sxkc",
                        "tokens": [
                            " little",
                            " mischief",
                            "-",
                            "making",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Mr",
                            ".",
                            " Mac",
                            "key",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "People",
                            " generally",
                            " want",
                            " to",
                            " help",
                            " solve",
                            " the",
                            " puzzle",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Read",
                            "ers",
                            " repeatedly",
                            " drew",
                            " Mr",
                            ".",
                            " Mac",
                            "key",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " attention",
                            " to",
                            " tweets",
                            " and",
                            " photos",
                            " of",
                            " protests",
                            " in",
                            " the",
                            " comments",
                            " thread",
                            " of",
                            " the",
                            " blog",
                            ".",
                            " Some",
                            " even",
                            " shared",
                            " their",
                            " memories",
                            " of",
                            " the",
                            " geography",
                            " of",
                            " Tehran",
                            " in",
                            " an",
                            " attempt",
                            " to",
                            " verify",
                            " scenes",
                            " in",
                            " videos",
                            ".",
                            "\n",
                            "\n",
                            "Over",
                            " time",
                            ",",
                            " the",
                            " imp",
                            "romptu",
                            " Iranian",
                            " reporters",
                            " have",
                            " hon",
                            "ed",
                            " their",
                            " skills",
                            ".",
                            " Some",
                            " put",
                            " the",
                            " date",
                            " of",
                            " a",
                            " skirm",
                            "ish",
                            " in",
                            " the",
                            " file",
                            " descriptions",
                            " they",
                            " send",
                            ".",
                            " Others",
                            " film",
                            " street",
                            " signs",
                            " and",
                            " landmarks",
                            ".",
                            " But",
                            " the",
                            " user",
                            " upload",
                            "s",
                            " can",
                            " sometimes",
                            " be",
                            " misleading",
                            ".",
                            " Last",
                            " Wednesday",
                            ",",
                            " Mr",
                            ".",
                            " Mac"
                        ],
                        "dataIndex": null,
                        "index": "39710",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 34.397,
                        "maxValueTokenIndex": 85,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.389,
                            34.397,
                            13.169,
                            7.819,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:21:44.886Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 34.397,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggsfsi5dvs10ex6fcl4ih5",
                        "tokens": [
                            " little",
                            " mischief",
                            "-",
                            "making",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Mr",
                            ".",
                            " Mac",
                            "key",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "People",
                            " generally",
                            " want",
                            " to",
                            " help",
                            " solve",
                            " the",
                            " puzzle",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Read",
                            "ers",
                            " repeatedly",
                            " drew",
                            " Mr",
                            ".",
                            " Mac",
                            "key",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " attention",
                            " to",
                            " tweets",
                            " and",
                            " photos",
                            " of",
                            " protests",
                            " in",
                            " the",
                            " comments",
                            " thread",
                            " of",
                            " the",
                            " blog",
                            ".",
                            " Some",
                            " even",
                            " shared",
                            " their",
                            " memories",
                            " of",
                            " the",
                            " geography",
                            " of",
                            " Tehran",
                            " in",
                            " an",
                            " attempt",
                            " to",
                            " verify",
                            " scenes",
                            " in",
                            " videos",
                            ".",
                            "\n",
                            "\n",
                            "Over",
                            " time",
                            ",",
                            " the",
                            " imp",
                            "romptu",
                            " Iranian",
                            " reporters",
                            " have",
                            " hon",
                            "ed",
                            " their",
                            " skills",
                            ".",
                            " Some",
                            " put",
                            " the",
                            " date",
                            " of",
                            " a",
                            " skirm",
                            "ish",
                            " in",
                            " the",
                            " file",
                            " descriptions",
                            " they",
                            " send",
                            ".",
                            " Others",
                            " film",
                            " street",
                            " signs",
                            " and",
                            " landmarks",
                            ".",
                            " But",
                            " the",
                            " user",
                            " upload",
                            "s",
                            " can",
                            " sometimes",
                            " be",
                            " misleading",
                            ".",
                            " Last",
                            " Wednesday",
                            ",",
                            " Mr",
                            ".",
                            " Mac"
                        ],
                        "dataIndex": null,
                        "index": "39710",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 34.397,
                        "maxValueTokenIndex": 85,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.389,
                            34.397,
                            13.169,
                            7.819,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:21:44.886Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 34.397,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggsfsg5dvc10ex10ml9bma",
                        "tokens": [
                            " commentary",
                            " and",
                            " people",
                            " who",
                            " want",
                            " to",
                            " make",
                            " money",
                            " off",
                            " of",
                            " commentary",
                            ".",
                            " For",
                            " commentators",
                            " who",
                            " want",
                            " to",
                            " build",
                            " up",
                            " experience",
                            ",",
                            " to",
                            " establish",
                            " a",
                            " portfolio",
                            ",",
                            " and",
                            " further",
                            " hone",
                            " their",
                            " craft",
                            ",",
                            " consider",
                            " letting",
                            " the",
                            " ones",
                            " who",
                            " have",
                            " a",
                            " passion",
                            " for",
                            " it",
                            " comment",
                            "ate",
                            " pools",
                            ".",
                            " They",
                            " get",
                            " the",
                            " experience",
                            " they",
                            " thirst",
                            " for",
                            ",",
                            " while",
                            " entertaining",
                            " people",
                            " who",
                            " sit",
                            " around",
                            " and",
                            " enjoy",
                            " pools",
                            ".",
                            " And",
                            " for",
                            " the",
                            " more",
                            " seasoned",
                            " veterans",
                            " of",
                            " the",
                            " mic",
                            ",",
                            " treat",
                            " them",
                            " with",
                            " the",
                            " respect",
                            " they",
                            " deserve",
                            ".",
                            " The",
                            " intense",
                            " amount",
                            " of",
                            " pressure",
                            " put",
                            " on",
                            " a",
                            " select",
                            " few",
                            " figures",
                            " for",
                            " both",
                            " knowing",
                            " a",
                            " ton",
                            " of",
                            " niche",
                            " information",
                            " about",
                            " a",
                            " game",
                            " while",
                            " presenting",
                            " it",
                            " in",
                            " a",
                            " manner",
                            " that",
                            "'s",
                            " entertaining",
                            " and",
                            " follows",
                            " a",
                            " strict",
                            " flow",
                            " needs",
                            " to",
                            " be",
                            " appreciated",
                            " for",
                            " what",
                            " it",
                            " is",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "39710",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 33.88,
                        "maxValueTokenIndex": 28,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.192,
                            33.88,
                            10.643,
                            1.266,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:21:44.886Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 34.397,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "14572",
            "description": "terms related to learning and valuable lessons",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.48987683593492815,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "14572",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:24:35.724Z",
                "maxActApprox": 36.977,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    14572,
                    46722,
                    33219,
                    19723,
                    37022,
                    35811,
                    33871,
                    7882,
                    41576,
                    39623,
                    2599,
                    9870,
                    785,
                    20747,
                    23357,
                    15624,
                    15480,
                    27850,
                    35043,
                    3993,
                    22563,
                    26719,
                    26441,
                    47084,
                    46953
                ],
                "topkCosSimValues": [
                    1,
                    0.5684,
                    0.5247,
                    0.5194,
                    0.502,
                    0.4875,
                    0.4688,
                    0.4173,
                    0.417,
                    0.409,
                    0.3907,
                    0.3858,
                    0.3748,
                    0.3624,
                    0.3602,
                    0.3526,
                    0.3475,
                    0.3453,
                    0.3358,
                    0.3322,
                    0.3247,
                    0.3243,
                    0.3208,
                    0.3199,
                    0.319
                ],
                "neuron_alignment_indices": [
                    154,
                    415,
                    567
                ],
                "neuron_alignment_values": [
                    0.104,
                    0.101,
                    0.1
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    567,
                    154,
                    568
                ],
                "correlated_neurons_pearson": [
                    0.018,
                    0.017,
                    0.016
                ],
                "correlated_neurons_l1": [
                    0.016,
                    0.019,
                    0.014
                ],
                "correlated_features_indices": [
                    14568,
                    14530,
                    14575
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.002,
                    0.001
                ],
                "correlated_features_l1": [
                    0.003,
                    0.002,
                    0.001
                ],
                "neg_str": [
                    "vertisement",
                    "ItemImage",
                    "ocument",
                    "cohol",
                    "istent",
                    "lished",
                    "IUM",
                    "enance",
                    "athi",
                    "ilitary"
                ],
                "neg_values": [
                    -0.704,
                    -0.666,
                    -0.664,
                    -0.652,
                    -0.646,
                    -0.643,
                    -0.609,
                    -0.601,
                    -0.596,
                    -0.59
                ],
                "pos_str": [
                    " lesson",
                    " lessons",
                    " tricks",
                    " firsthand",
                    " Lessons",
                    " ropes",
                    " basics",
                    " valuable",
                    " skills",
                    " invaluable"
                ],
                "pos_values": [
                    1.36,
                    1.172,
                    1.003,
                    0.966,
                    0.918,
                    0.866,
                    0.853,
                    0.841,
                    0.837,
                    0.789
                ],
                "frac_nonzero": 0.0006,
                "freq_hist_data_bar_heights": [
                    457,
                    308,
                    223,
                    161,
                    100,
                    96,
                    81,
                    63,
                    52,
                    44,
                    37,
                    22,
                    23,
                    19,
                    18,
                    12,
                    18,
                    11,
                    8,
                    9,
                    8,
                    7,
                    8,
                    10,
                    7,
                    8,
                    3,
                    8,
                    8,
                    5,
                    5,
                    4,
                    3,
                    4,
                    4,
                    5,
                    7,
                    3,
                    2,
                    3,
                    2,
                    4,
                    1,
                    2,
                    2,
                    0,
                    3,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.37,
                    1.11,
                    1.849,
                    2.589,
                    3.328,
                    4.068,
                    4.808,
                    5.547,
                    6.287,
                    7.026,
                    7.766,
                    8.505,
                    9.245,
                    9.984,
                    10.724,
                    11.463,
                    12.203,
                    12.942,
                    13.682,
                    14.421,
                    15.161,
                    15.9,
                    16.64,
                    17.379,
                    18.119,
                    18.858,
                    19.598,
                    20.337,
                    21.077,
                    21.816,
                    22.556,
                    23.295,
                    24.035,
                    24.775,
                    25.514,
                    26.254,
                    26.993,
                    27.733,
                    28.472,
                    29.212,
                    29.951,
                    30.691,
                    31.43,
                    32.17,
                    32.909,
                    33.649,
                    34.388,
                    35.128,
                    35.867,
                    36.607
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    3,
                    6,
                    15,
                    34,
                    61,
                    128,
                    254,
                    487,
                    778,
                    1137,
                    1701,
                    2612,
                    3378,
                    4370,
                    5011,
                    5269,
                    5141,
                    4818,
                    4051,
                    3325,
                    2526,
                    1831,
                    1251,
                    789,
                    514,
                    307,
                    190,
                    108,
                    61,
                    36,
                    17,
                    17,
                    10,
                    6,
                    2,
                    1,
                    3,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.684,
                    -0.643,
                    -0.601,
                    -0.56,
                    -0.519,
                    -0.477,
                    -0.436,
                    -0.395,
                    -0.354,
                    -0.312,
                    -0.271,
                    -0.23,
                    -0.188,
                    -0.147,
                    -0.106,
                    -0.065,
                    -0.023,
                    0.018,
                    0.059,
                    0.1,
                    0.142,
                    0.183,
                    0.224,
                    0.266,
                    0.307,
                    0.348,
                    0.389,
                    0.431,
                    0.472,
                    0.513,
                    0.555,
                    0.596,
                    0.637,
                    0.678,
                    0.72,
                    0.761,
                    0.802,
                    0.844,
                    0.885,
                    0.926,
                    0.967,
                    1.009,
                    1.05,
                    1.091,
                    1.132,
                    1.174,
                    1.215,
                    1.256,
                    1.298,
                    1.339
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to learning and valuable lessons",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk5222xp36ei6667oroi4dk",
                        "tokens": [
                            "My",
                            " interview",
                            " series",
                            " continues",
                            ".",
                            " I",
                            " recently",
                            " met",
                            " up",
                            " with",
                            " my",
                            " friend",
                            " Gil",
                            "mar",
                            " Santos",
                            ",",
                            " a",
                            " Brazilian",
                            " guy",
                            " whom",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " known",
                            " for",
                            " some",
                            " time",
                            ".",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " learned",
                            " a",
                            " great",
                            " deal",
                            " about",
                            " social",
                            " dynamics",
                            " in",
                            " Brazil",
                            " from",
                            " listening",
                            " to",
                            " his",
                            " incredibly",
                            " detailed",
                            " breakdown",
                            "s",
                            " of",
                            " the",
                            " dating",
                            " scenes",
                            " in",
                            " different",
                            " parts",
                            " of",
                            " the",
                            " country",
                            ".",
                            " Gil",
                            "mar",
                            " is",
                            " also",
                            " a",
                            " man",
                            " of",
                            " broad",
                            " knowledge",
                            " and",
                            " deep",
                            " intro",
                            "spection",
                            ",",
                            " a",
                            " combination",
                            " that",
                            " is",
                            " becoming",
                            " unfortunately",
                            " all",
                            " too",
                            " rare",
                            " these",
                            " days",
                            ".",
                            " His",
                            " insights",
                            " on",
                            " the",
                            " impact",
                            " of",
                            " social",
                            " media",
                            " on",
                            " the",
                            " dating",
                            " scene",
                            " in",
                            " his",
                            " country",
                            ",",
                            " on",
                            " physical",
                            " fitness",
                            ",",
                            " and",
                            " on",
                            " spiritual",
                            " development",
                            " are",
                            " valuable",
                            ",",
                            " and",
                            " worth",
                            " our",
                            " careful",
                            " attention",
                            ".",
                            " During",
                            " our",
                            " last",
                            " meeting",
                            ",",
                            " I",
                            " asked"
                        ],
                        "dataIndex": null,
                        "index": "14572",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.977,
                        "maxValueTokenIndex": 34,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.201,
                            36.977,
                            26.93,
                            28.618,
                            5.466,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:24:40.680Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.977,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5222vp35vi6664i76pr01",
                        "tokens": [
                            "My",
                            " interview",
                            " series",
                            " continues",
                            ".",
                            " I",
                            " recently",
                            " met",
                            " up",
                            " with",
                            " my",
                            " friend",
                            " Gil",
                            "mar",
                            " Santos",
                            ",",
                            " a",
                            " Brazilian",
                            " guy",
                            " whom",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " known",
                            " for",
                            " some",
                            " time",
                            ".",
                            " I",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " learned",
                            " a",
                            " great",
                            " deal",
                            " about",
                            " social",
                            " dynamics",
                            " in",
                            " Brazil",
                            " from",
                            " listening",
                            " to",
                            " his",
                            " incredibly",
                            " detailed",
                            " breakdown",
                            "s",
                            " of",
                            " the",
                            " dating",
                            " scenes",
                            " in",
                            " different",
                            " parts",
                            " of",
                            " the",
                            " country",
                            ".",
                            " Gil",
                            "mar",
                            " is",
                            " also",
                            " a",
                            " man",
                            " of",
                            " broad",
                            " knowledge",
                            " and",
                            " deep",
                            " intro",
                            "spection",
                            ",",
                            " a",
                            " combination",
                            " that",
                            " is",
                            " becoming",
                            " unfortunately",
                            " all",
                            " too",
                            " rare",
                            " these",
                            " days",
                            ".",
                            " His",
                            " insights",
                            " on",
                            " the",
                            " impact",
                            " of",
                            " social",
                            " media",
                            " on",
                            " the",
                            " dating",
                            " scene",
                            " in",
                            " his",
                            " country",
                            ",",
                            " on",
                            " physical",
                            " fitness",
                            ",",
                            " and",
                            " on",
                            " spiritual",
                            " development",
                            " are",
                            " valuable",
                            ",",
                            " and",
                            " worth",
                            " our",
                            " careful",
                            " attention",
                            ".",
                            " During",
                            " our",
                            " last",
                            " meeting",
                            ",",
                            " I",
                            " asked"
                        ],
                        "dataIndex": null,
                        "index": "14572",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 36.977,
                        "maxValueTokenIndex": 34,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.201,
                            36.977,
                            26.93,
                            28.618,
                            5.466,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:24:40.680Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.977,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5222wp35wi6660ecwqa69",
                        "tokens": [
                            ",",
                            " but",
                            " then",
                            " you",
                            " use",
                            " that",
                            " to",
                            " fight",
                            " Meg",
                            "ac",
                            "orp",
                            " B",
                            " and",
                            " probably",
                            " learn",
                            " a",
                            " little",
                            " more",
                            " about",
                            " A",
                            " to",
                            " begin",
                            " with",
                            " and",
                            "...",
                            "\n",
                            "\n",
                            "Add",
                            " to",
                            " this",
                            " the",
                            " \"",
                            "self",
                            "-",
                            "trained",
                            "\"",
                            " element",
                            " of",
                            " punk",
                            " music",
                            ".",
                            " Don",
                            "'t",
                            " use",
                            " the",
                            " corp",
                            " cyber",
                            "deck",
                            " loaded",
                            " with",
                            " spy",
                            "ware",
                            " and",
                            " apps",
                            " you",
                            " won",
                            "'t",
                            " need",
                            ",",
                            " build",
                            " one",
                            " yourself",
                            " with",
                            " eight",
                            " old",
                            " cell",
                            "phones",
                            " and",
                            " a",
                            " keyboard",
                            " you",
                            " found",
                            " at",
                            " a",
                            " recycling",
                            " plant",
                            ".",
                            " Don",
                            "'t",
                            " get",
                            " the",
                            " flesh",
                            "like",
                            " cyber",
                            " arm",
                            "--",
                            "get",
                            " the",
                            " one",
                            " that",
                            "'s",
                            " been",
                            " jail",
                            "bre",
                            "aked",
                            " and",
                            " uploaded",
                            " with",
                            " new",
                            " moves",
                            " and",
                            " works",
                            " better",
                            " so",
                            " fuck",
                            " the",
                            " warranty",
                            ".",
                            " Don",
                            "'t",
                            " summon",
                            " that",
                            " elemental",
                            "--",
                            "every",
                            " time",
                            " you",
                            " do",
                            " a",
                            " tiny",
                            " bit",
                            " of",
                            " mo",
                            "jo",
                            " is",
                            " going",
                            " back"
                        ],
                        "dataIndex": null,
                        "index": "14572",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 34.822,
                        "maxValueTokenIndex": 15,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.822,
                            26.566,
                            17.44,
                            2.595,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:24:40.680Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 36.977,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "5909",
            "description": "phrases about teaching and learning",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4845396289503805,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "5909",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:36:07.210Z",
                "maxActApprox": 28.887,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    5909,
                    71639,
                    44064,
                    18323,
                    68287,
                    27303,
                    90785,
                    96831,
                    5968,
                    32386,
                    19017,
                    33056,
                    20644,
                    77660,
                    31896,
                    77000,
                    67212,
                    26576,
                    57450,
                    13254,
                    14559,
                    64057,
                    8294,
                    68625,
                    1105
                ],
                "topkCosSimValues": [
                    1,
                    0.5204,
                    0.5038,
                    0.4824,
                    0.4772,
                    0.4715,
                    0.444,
                    0.4255,
                    0.4243,
                    0.3881,
                    0.3849,
                    0.3556,
                    0.352,
                    0.3491,
                    0.3485,
                    0.3482,
                    0.3437,
                    0.3429,
                    0.3425,
                    0.3362,
                    0.334,
                    0.3336,
                    0.3314,
                    0.3306,
                    0.3294
                ],
                "neuron_alignment_indices": [
                    126,
                    602,
                    45
                ],
                "neuron_alignment_values": [
                    0.096,
                    0.096,
                    0.096
                ],
                "neuron_alignment_l1": [
                    0.004,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    279,
                    567,
                    126
                ],
                "correlated_neurons_pearson": [
                    0.017,
                    0.016,
                    0.015
                ],
                "correlated_neurons_l1": [
                    0.018,
                    0.013,
                    0.015
                ],
                "correlated_features_indices": [
                    5812,
                    5888,
                    5762
                ],
                "correlated_features_pearson": [
                    0.003,
                    0.002,
                    0
                ],
                "correlated_features_l1": [
                    0.003,
                    0.003,
                    0.001
                ],
                "neg_str": [
                    "iture",
                    "beck",
                    "obin",
                    "etheus",
                    "ioxide",
                    "pload",
                    "endez",
                    " Corker",
                    " insured",
                    "levard"
                ],
                "neg_values": [
                    -0.804,
                    -0.721,
                    -0.72,
                    -0.72,
                    -0.679,
                    -0.629,
                    -0.628,
                    -0.618,
                    -0.616,
                    -0.615
                ],
                "pos_str": [
                    " lesson",
                    " lessons",
                    " curriculum",
                    " skills",
                    " kindergarten",
                    " Teach",
                    " curric",
                    " basics",
                    " fundamentals",
                    " teach"
                ],
                "pos_values": [
                    1.172,
                    1.081,
                    0.986,
                    0.921,
                    0.903,
                    0.892,
                    0.885,
                    0.88,
                    0.876,
                    0.851
                ],
                "frac_nonzero": 0.00049,
                "freq_hist_data_bar_heights": [
                    337,
                    276,
                    175,
                    125,
                    96,
                    71,
                    64,
                    44,
                    34,
                    41,
                    38,
                    26,
                    20,
                    21,
                    22,
                    9,
                    11,
                    9,
                    11,
                    8,
                    13,
                    8,
                    8,
                    4,
                    4,
                    7,
                    3,
                    7,
                    9,
                    2,
                    8,
                    3,
                    7,
                    0,
                    4,
                    5,
                    3,
                    5,
                    0,
                    2,
                    2,
                    0,
                    2,
                    3,
                    0,
                    2,
                    1,
                    1,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.291,
                    0.869,
                    1.446,
                    2.024,
                    2.602,
                    3.179,
                    3.757,
                    4.335,
                    4.913,
                    5.49,
                    6.068,
                    6.646,
                    7.223,
                    7.801,
                    8.379,
                    8.957,
                    9.534,
                    10.112,
                    10.69,
                    11.267,
                    11.845,
                    12.423,
                    13,
                    13.578,
                    14.156,
                    14.734,
                    15.311,
                    15.889,
                    16.467,
                    17.044,
                    17.622,
                    18.2,
                    18.778,
                    19.355,
                    19.933,
                    20.511,
                    21.088,
                    21.666,
                    22.244,
                    22.821,
                    23.399,
                    23.977,
                    24.555,
                    25.132,
                    25.71,
                    26.288,
                    26.865,
                    27.443,
                    28.021,
                    28.599
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    3,
                    1,
                    8,
                    11,
                    28,
                    46,
                    119,
                    200,
                    312,
                    525,
                    810,
                    1295,
                    1787,
                    2485,
                    3246,
                    3771,
                    4524,
                    4817,
                    4785,
                    4534,
                    4023,
                    3455,
                    2735,
                    2007,
                    1450,
                    1043,
                    802,
                    482,
                    321,
                    194,
                    142,
                    86,
                    65,
                    39,
                    38,
                    19,
                    16,
                    11,
                    6,
                    6,
                    4,
                    2,
                    0,
                    1,
                    0,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.785,
                    -0.745,
                    -0.706,
                    -0.666,
                    -0.627,
                    -0.587,
                    -0.548,
                    -0.508,
                    -0.468,
                    -0.429,
                    -0.389,
                    -0.35,
                    -0.31,
                    -0.271,
                    -0.231,
                    -0.192,
                    -0.152,
                    -0.113,
                    -0.073,
                    -0.034,
                    0.006,
                    0.045,
                    0.085,
                    0.124,
                    0.164,
                    0.204,
                    0.243,
                    0.283,
                    0.322,
                    0.362,
                    0.401,
                    0.441,
                    0.48,
                    0.52,
                    0.559,
                    0.599,
                    0.638,
                    0.678,
                    0.717,
                    0.757,
                    0.796,
                    0.836,
                    0.875,
                    0.915,
                    0.955,
                    0.994,
                    1.034,
                    1.073,
                    1.113,
                    1.152
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases about teaching and learning",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygf5xdgfs3110exo1ctjumz",
                        "tokens": [
                            " movie",
                            " Welcome",
                            " To",
                            " The",
                            " R",
                            "ile",
                            "ys",
                            "\n",
                            "\n",
                            "'",
                            "I",
                            " am",
                            " heart",
                            "broken",
                            ".",
                            " My",
                            " bud",
                            " James",
                            " Gand",
                            "olf",
                            "ini",
                            " just",
                            " died",
                            ".",
                            " Last",
                            " Saturday",
                            " he",
                            " told",
                            " me",
                            " at",
                            " our",
                            " kids",
                            " graduation",
                            " [",
                            "that",
                            "]",
                            " he",
                            " was",
                            " so",
                            " happy",
                            " to",
                            " go",
                            " with",
                            " his",
                            " son",
                            " to",
                            " Italy",
                            ".",
                            " A",
                            " boy",
                            " trip",
                            "!'",
                            " Mar",
                            "ini",
                            " wrote",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " added",
                            ":",
                            " '",
                            "It",
                            " was",
                            " an",
                            " honor",
                            " to",
                            " have",
                            " met",
                            " this",
                            " man",
                            ",",
                            " such",
                            " a",
                            " great",
                            " Dad",
                            "!",
                            " I",
                            " spent",
                            " so",
                            " much",
                            " time",
                            " with",
                            " James",
                            " son",
                            " teaching",
                            " him",
                            " soccer",
                            ".",
                            " I",
                            " feel",
                            " for",
                            " that",
                            " kid",
                            " it",
                            " must",
                            " be",
                            " so",
                            " hard",
                            " right",
                            " now",
                            " for",
                            " little",
                            " [",
                            "Michael",
                            "]",
                            ".'",
                            "\n",
                            "\n",
                            "'",
                            "RIP",
                            " James",
                            " Gand",
                            "olf",
                            "ini",
                            ".",
                            " A",
                            " great",
                            " friend",
                            ",'",
                            " wrote",
                            " Jeff",
                            " Daniels",
                            ",",
                            " his",
                            " co",
                            "-"
                        ],
                        "dataIndex": null,
                        "index": "5909",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 28.887,
                        "maxValueTokenIndex": 86,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            28.887,
                            7.359,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:36:15.003Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 28.887,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf5xdgfs3210exchrp1dz1",
                        "tokens": [
                            " hard",
                            " to",
                            " \u00e2\u0122",
                            "\u013e",
                            "dep",
                            "rogram",
                            "\u00e2\u0122",
                            "\u013f",
                            " his",
                            " kids",
                            " from",
                            " the",
                            " traditional",
                            " way",
                            " of",
                            " learning",
                            " by",
                            " teaching",
                            " them",
                            " about",
                            " how",
                            " their",
                            " brains",
                            " work",
                            " and",
                            " why",
                            " the",
                            " dominant",
                            " teaching",
                            " style",
                            " is",
                            " incompatible",
                            ".",
                            " When",
                            " Hol",
                            "man",
                            " treated",
                            " his",
                            " students",
                            " like",
                            " adults",
                            " who",
                            " could",
                            " understand",
                            " the",
                            " system",
                            " in",
                            " which",
                            " they",
                            " played",
                            ",",
                            " he",
                            " earned",
                            " their",
                            " trust",
                            " and",
                            " their",
                            " hard",
                            " work",
                            ".",
                            "\n",
                            "\n",
                            "Sometimes",
                            " the",
                            " teaching",
                            " and",
                            " studying",
                            " strategies",
                            " thought",
                            " to",
                            " work",
                            " best",
                            " actively",
                            " contradict",
                            " brain",
                            "-",
                            "based",
                            " learning",
                            ".",
                            " New",
                            " York",
                            " Times",
                            " writer",
                            " Benedict",
                            " Carey",
                            " devoted",
                            " an",
                            " entire",
                            " book",
                            " to",
                            " describing",
                            " counter",
                            "-",
                            "intuitive",
                            " study",
                            " strategies",
                            " based",
                            " in",
                            " cognitive",
                            " science",
                            " about",
                            " memory",
                            " and",
                            " learning",
                            ".",
                            " For",
                            " example",
                            ",",
                            " students",
                            " tend",
                            " to",
                            " spend",
                            " hours",
                            " cram",
                            "ming",
                            " for",
                            " a",
                            " test",
                            " the",
                            " next",
                            " day",
                            ",",
                            " only",
                            " to",
                            " promptly",
                            " forget",
                            " everything"
                        ],
                        "dataIndex": null,
                        "index": "5909",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 27.985,
                        "maxValueTokenIndex": 18,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.768,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            27.985,
                            5.008,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:36:15.003Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 28.887,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygf5xdgfs3310ex10c14yz8",
                        "tokens": [
                            " for",
                            " O",
                            "atmeal",
                            " Ra",
                            "isin",
                            " S",
                            "con",
                            "es",
                            ".",
                            " I",
                            " hope",
                            " you",
                            " enjoy",
                            " Ell",
                            "a",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " selection",
                            " and",
                            " please",
                            " spend",
                            " time",
                            " with",
                            " your",
                            " kids",
                            " teaching",
                            " them",
                            " how",
                            " to",
                            " cook",
                            ".",
                            " Be",
                            " sure",
                            " to",
                            " sign",
                            " up",
                            " for",
                            " my",
                            " weekly",
                            " emails",
                            " so",
                            " you",
                            " can",
                            " share",
                            " with",
                            " your",
                            " kids",
                            " what",
                            " Ell",
                            "a",
                            " makes",
                            " next",
                            ".",
                            "\n",
                            "\n",
                            "Follow",
                            " me",
                            " on",
                            " Facebook",
                            " \u2013",
                            " Pinterest",
                            " \u2013",
                            " Twitter",
                            " \u2013",
                            " Google",
                            " +",
                            " \u2013",
                            " Instagram",
                            "\n",
                            "\n",
                            "Pin",
                            " It",
                            " Last",
                            " weekends",
                            " office",
                            " remod",
                            "el",
                            ".",
                            " P",
                            "ainted",
                            " the",
                            " walls",
                            " a",
                            " light",
                            " grey",
                            "-",
                            "blue",
                            ".",
                            " P",
                            "ainted",
                            " the",
                            " desk",
                            " with",
                            " black",
                            " chalk",
                            " paint",
                            ".",
                            " The",
                            " plan",
                            " is",
                            " also",
                            " to",
                            " use",
                            " the",
                            " office",
                            " as",
                            " my",
                            " studio",
                            " for",
                            " food",
                            " photography",
                            ".",
                            " Plenty",
                            " of",
                            " natural",
                            " light",
                            " and",
                            " I",
                            " added",
                            " 5000",
                            " K",
                            " natural",
                            " daylight",
                            " bulbs",
                            " to",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "5909",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 27.592,
                        "maxValueTokenIndex": 27,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            27.592,
                            6.04,
                            1.556,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:36:15.003Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 28.887,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs6144-jb",
            "index": "5738",
            "description": "phrases related to practicing or honing skills",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4707868239518056,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs6144-jb",
                "index": "5738",
                "sourceSetName": "res_fs6144-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:13:59.134Z",
                "maxActApprox": 40.861,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    5738,
                    5723,
                    6043,
                    4891,
                    1109,
                    3069,
                    5376,
                    1076,
                    5651,
                    4782,
                    4222,
                    3025,
                    4023,
                    5581,
                    202,
                    5521,
                    5420,
                    2601,
                    4453,
                    3439,
                    3062,
                    5465,
                    1608,
                    2244,
                    5466
                ],
                "topkCosSimValues": [
                    1,
                    0.3565,
                    0.3104,
                    0.2987,
                    0.2891,
                    0.2793,
                    0.2719,
                    0.2658,
                    0.2627,
                    0.254,
                    0.2512,
                    0.2442,
                    0.2417,
                    0.2406,
                    0.2396,
                    0.2337,
                    0.2279,
                    0.2255,
                    0.222,
                    0.2212,
                    0.22,
                    0.2152,
                    0.2141,
                    0.2132,
                    0.2109
                ],
                "neuron_alignment_indices": [
                    288,
                    297,
                    401
                ],
                "neuron_alignment_values": [
                    0.114,
                    0.108,
                    0.093
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    288,
                    401,
                    540
                ],
                "correlated_neurons_pearson": [
                    0.039,
                    0.031,
                    0.029
                ],
                "correlated_neurons_l1": [
                    0.046,
                    0.035,
                    0.036
                ],
                "correlated_features_indices": [
                    5723,
                    5651,
                    5672
                ],
                "correlated_features_pearson": [
                    0.075,
                    0.029,
                    0.012
                ],
                "correlated_features_l1": [
                    0.075,
                    0.03,
                    0.013
                ],
                "neg_str": [
                    "worms",
                    "gin",
                    "gow",
                    "sea",
                    "este",
                    "izons",
                    "mented",
                    "hyde",
                    "ovies",
                    "\u00ef\u00b8\u0131"
                ],
                "neg_values": [
                    -0.899,
                    -0.843,
                    -0.753,
                    -0.74,
                    -0.704,
                    -0.702,
                    -0.695,
                    -0.69,
                    -0.674,
                    -0.669
                ],
                "pos_str": [
                    " practiced",
                    " regimen",
                    " practice",
                    "itual",
                    " Practices",
                    " pract",
                    " practise",
                    " practicing",
                    " practices",
                    " Practice"
                ],
                "pos_values": [
                    0.894,
                    0.89,
                    0.889,
                    0.823,
                    0.798,
                    0.794,
                    0.789,
                    0.787,
                    0.781,
                    0.769
                ],
                "frac_nonzero": 0.00304,
                "freq_hist_data_bar_heights": [
                    3259,
                    2027,
                    1207,
                    796,
                    527,
                    375,
                    252,
                    211,
                    121,
                    85,
                    68,
                    54,
                    52,
                    23,
                    17,
                    14,
                    7,
                    4,
                    12,
                    4,
                    10,
                    5,
                    6,
                    8,
                    11,
                    18,
                    8,
                    10,
                    11,
                    14,
                    24,
                    21,
                    25,
                    27,
                    21,
                    22,
                    18,
                    23,
                    29,
                    18,
                    21,
                    21,
                    16,
                    8,
                    11,
                    4,
                    13,
                    6,
                    2,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.409,
                    1.226,
                    2.043,
                    2.86,
                    3.678,
                    4.495,
                    5.312,
                    6.129,
                    6.946,
                    7.764,
                    8.581,
                    9.398,
                    10.215,
                    11.032,
                    11.85,
                    12.667,
                    13.484,
                    14.301,
                    15.119,
                    15.936,
                    16.753,
                    17.57,
                    18.387,
                    19.205,
                    20.022,
                    20.839,
                    21.656,
                    22.473,
                    23.291,
                    24.108,
                    24.925,
                    25.742,
                    26.559,
                    27.377,
                    28.194,
                    29.011,
                    29.828,
                    30.646,
                    31.463,
                    32.28,
                    33.097,
                    33.914,
                    34.732,
                    35.549,
                    36.366,
                    37.183,
                    38,
                    38.818,
                    39.635,
                    40.452
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    0,
                    0,
                    2,
                    4,
                    6,
                    13,
                    19,
                    39,
                    49,
                    97,
                    164,
                    239,
                    338,
                    514,
                    815,
                    1110,
                    1496,
                    1936,
                    2479,
                    3091,
                    3527,
                    3993,
                    4364,
                    4513,
                    4442,
                    3894,
                    3427,
                    2770,
                    2142,
                    1592,
                    1102,
                    723,
                    510,
                    340,
                    205,
                    116,
                    68,
                    38,
                    19,
                    17,
                    18,
                    3,
                    6,
                    5,
                    2,
                    4,
                    1,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.881,
                    -0.845,
                    -0.809,
                    -0.773,
                    -0.738,
                    -0.702,
                    -0.666,
                    -0.63,
                    -0.594,
                    -0.558,
                    -0.522,
                    -0.487,
                    -0.451,
                    -0.415,
                    -0.379,
                    -0.343,
                    -0.307,
                    -0.271,
                    -0.236,
                    -0.2,
                    -0.164,
                    -0.128,
                    -0.092,
                    -0.056,
                    -0.02,
                    0.015,
                    0.051,
                    0.087,
                    0.123,
                    0.159,
                    0.195,
                    0.231,
                    0.266,
                    0.302,
                    0.338,
                    0.374,
                    0.41,
                    0.446,
                    0.482,
                    0.517,
                    0.553,
                    0.589,
                    0.625,
                    0.661,
                    0.697,
                    0.733,
                    0.768,
                    0.804,
                    0.84,
                    0.876
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases related to practicing or honing skills",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdthfugy2dsi666wo9bqve6",
                        "tokens": [
                            " to",
                            " date",
                            ",",
                            " and",
                            " builds",
                            " on",
                            " a",
                            " practice",
                            " of",
                            " site",
                            "-",
                            "specific",
                            " concert",
                            "sc",
                            "apes",
                            " presented",
                            " at",
                            " the",
                            " Museum",
                            " of",
                            " Modern",
                            " Art",
                            " (",
                            "2011",
                            "),",
                            " Tate",
                            " Britain",
                            " and",
                            " Mo",
                            "MA",
                            " PS",
                            "1",
                            " (",
                            "2013",
                            "),",
                            " and",
                            " Edinburgh",
                            " International",
                            " Festival",
                            " (",
                            "2015",
                            "),",
                            " amongst",
                            " many",
                            " others",
                            ".",
                            "\n",
                            "\n",
                            "Pull",
                            "ing",
                            " from",
                            " long",
                            "-",
                            "standing",
                            " fasc",
                            "inations",
                            " with",
                            " film",
                            " and",
                            " television",
                            " tropes",
                            ",",
                            " abstract",
                            " sculpture",
                            ",",
                            " game",
                            " ep",
                            "hemer",
                            "a",
                            ",",
                            " poetry",
                            ",",
                            " ap",
                            "ocry",
                            "ph",
                            "ic",
                            " histories",
                            ",",
                            " internet",
                            " es",
                            "oter",
                            "ica",
                            ",",
                            " and",
                            " philosophies",
                            " of",
                            " being",
                            ",",
                            " MY",
                            "RI",
                            "AD",
                            " generates",
                            " a",
                            " conceptual",
                            " spectrum",
                            " that",
                            " is",
                            " as",
                            " much",
                            " a",
                            " speculation",
                            " on",
                            " the",
                            " unthinkable",
                            " future",
                            " as",
                            " it",
                            " is",
                            " an",
                            " alleg",
                            "ory",
                            " for",
                            " the",
                            " current",
                            " dis",
                            "quiet",
                            " of",
                            " a",
                            " civilization",
                            " out",
                            " of",
                            " balance",
                            " with",
                            " its",
                            " environment",
                            ".",
                            " Ori"
                        ],
                        "dataIndex": null,
                        "index": "5738",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.861,
                        "maxValueTokenIndex": 7,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.861,
                            2.669,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.446,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.631,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:14:05.883Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.861,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdthfugy2dti666h35zpxit",
                        "tokens": [
                            "boost",
                            " morale",
                            "\"",
                            " -",
                            " also",
                            " had",
                            " its",
                            " educational",
                            " aspects",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "We",
                            " visited",
                            " the",
                            " detainees",
                            "'",
                            " camps",
                            " and",
                            " we",
                            " saw",
                            " the",
                            " jails",
                            ",",
                            " where",
                            " they",
                            " shower",
                            ",",
                            " how",
                            " the",
                            "[",
                            "y",
                            "]",
                            " recreate",
                            " themselves",
                            " with",
                            " movies",
                            ",",
                            " classes",
                            " of",
                            " art",
                            ",",
                            " books",
                            ".",
                            " It",
                            " was",
                            " very",
                            " interesting",
                            ",\"",
                            " wrote",
                            " Mend",
                            "o",
                            "za",
                            ".",
                            " \"",
                            "I",
                            " didn",
                            "'t",
                            " want",
                            " to",
                            " leave",
                            ",",
                            " it",
                            " was",
                            " such",
                            " a",
                            " relaxing",
                            " place",
                            ",",
                            " so",
                            " calm",
                            " and",
                            " beautiful",
                            ".\"",
                            "\n",
                            "\n",
                            "Her",
                            " experiences",
                            " are",
                            " a",
                            " far",
                            " cry",
                            " from",
                            " those",
                            " of",
                            " former",
                            " detainees",
                            ",",
                            " who",
                            " have",
                            " alleged",
                            " that",
                            " torture",
                            ",",
                            " including",
                            " \"",
                            "water",
                            "boarding",
                            "\",",
                            " was",
                            " pract",
                            "ised",
                            " at",
                            " Guant",
                            "\u00c3\u00a1",
                            "nam",
                            "o",
                            " Bay",
                            ".",
                            "\n",
                            "\n",
                            "Britain",
                            " announced",
                            " last",
                            " week",
                            " it",
                            " would",
                            " investigate",
                            " whether",
                            " its",
                            " secret",
                            " services",
                            " were",
                            " complicit",
                            " in",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "5738",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.369,
                        "maxValueTokenIndex": 101,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.369,
                            19.12,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:14:05.883Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.861,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdthfugy2dui66642bwhw5a",
                        "tokens": [
                            "2",
                            ".",
                            "jpg",
                            "\",\"",
                            "big",
                            "Url",
                            "\":\"",
                            "https",
                            ":\\",
                            "/",
                            "\\/",
                            "www",
                            ".",
                            "wik",
                            "ih",
                            "ow",
                            ".",
                            "com",
                            "\\/",
                            "images",
                            "\\/",
                            "th",
                            "umb",
                            "\\/",
                            "d",
                            "\\/",
                            "d",
                            "0",
                            "\\/",
                            "H",
                            "ang",
                            "-",
                            "Someone",
                            "-",
                            "in",
                            "-",
                            "Red",
                            "-",
                            "Dead",
                            "-",
                            "Red",
                            "emption",
                            "-",
                            "Step",
                            "-",
                            "2",
                            "-",
                            "Version",
                            "-",
                            "2",
                            ".",
                            "jpg",
                            "\\/",
                            "v",
                            "4",
                            "-",
                            "760",
                            "px",
                            "-",
                            "H",
                            "ang",
                            "-",
                            "Someone",
                            "-",
                            "in",
                            "-",
                            "Red",
                            "-",
                            "Dead",
                            "-",
                            "Red",
                            "emption",
                            "-",
                            "Step",
                            "-",
                            "2",
                            "-",
                            "Version",
                            "-",
                            "2",
                            ".",
                            "jpg",
                            "\",\"",
                            "small",
                            "Width",
                            "\":",
                            "460",
                            ",\"",
                            "small",
                            "Height",
                            "\":",
                            "345",
                            ",\"",
                            "big",
                            "Width",
                            "\":",
                            "760",
                            ",\"",
                            "big",
                            "Height",
                            "\":",
                            "570",
                            "}",
                            " 2",
                            " Practice",
                            " l",
                            "asso",
                            "ing",
                            " people",
                            " in",
                            " the",
                            " world",
                            ".",
                            " Simply",
                            " draw",
                            ",",
                            " aim",
                            " and",
                            " fire",
                            " the",
                            " l",
                            "asso",
                            " as",
                            " you",
                            " would",
                            " a",
                            " normal"
                        ],
                        "dataIndex": null,
                        "index": "5738",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.094,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.094,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:14:05.883Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.861,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "8181",
            "description": "references to lessons and learning experiences",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4696304500102997,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "8181",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:12:28.743Z",
                "maxActApprox": 53.204,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    8181,
                    46953,
                    11474,
                    33871,
                    37022,
                    46722,
                    46531,
                    44019,
                    32839,
                    5768,
                    44382,
                    14838,
                    27830,
                    35811,
                    10248,
                    34244,
                    47808,
                    12664,
                    22854,
                    24835,
                    46048,
                    46696,
                    47724,
                    48202,
                    11447
                ],
                "topkCosSimValues": [
                    1,
                    0.5135,
                    0.4978,
                    0.4883,
                    0.4749,
                    0.458,
                    0.4562,
                    0.4173,
                    0.4081,
                    0.4074,
                    0.407,
                    0.4065,
                    0.4019,
                    0.3995,
                    0.388,
                    0.3831,
                    0.381,
                    0.3798,
                    0.3789,
                    0.3775,
                    0.37,
                    0.3698,
                    0.3689,
                    0.3677,
                    0.3659
                ],
                "neuron_alignment_indices": [
                    35,
                    615,
                    438
                ],
                "neuron_alignment_values": [
                    0.11,
                    0.107,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    438,
                    324,
                    98
                ],
                "correlated_neurons_pearson": [
                    0.014,
                    0.013,
                    0.012
                ],
                "correlated_neurons_l1": [
                    0.014,
                    0.013,
                    0.014
                ],
                "correlated_features_indices": [
                    8126,
                    8201,
                    8185
                ],
                "correlated_features_pearson": [
                    0.007,
                    0.004,
                    0.001
                ],
                "correlated_features_l1": [
                    0.007,
                    0.004,
                    0.001
                ],
                "neg_str": [
                    "BLIC",
                    "rencies",
                    "idays",
                    "ords",
                    " contiguous",
                    " occupancy",
                    "endars",
                    "roid",
                    "oreal",
                    "ovo"
                ],
                "neg_values": [
                    -0.66,
                    -0.657,
                    -0.645,
                    -0.636,
                    -0.623,
                    -0.622,
                    -0.621,
                    -0.615,
                    -0.603,
                    -0.598
                ],
                "pos_str": [
                    " Learned",
                    " learned",
                    " learnt",
                    " lessons",
                    " taught",
                    "Lear",
                    " lesson",
                    " Teach",
                    "learn",
                    "ister"
                ],
                "pos_values": [
                    1.353,
                    1.16,
                    1.091,
                    1.054,
                    1.038,
                    1.023,
                    1.006,
                    0.909,
                    0.907,
                    0.807
                ],
                "frac_nonzero": 0.0001,
                "freq_hist_data_bar_heights": [
                    87,
                    40,
                    40,
                    14,
                    13,
                    12,
                    7,
                    4,
                    3,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    2,
                    2,
                    2,
                    2,
                    0,
                    3,
                    0,
                    1,
                    2,
                    4,
                    4,
                    1,
                    4,
                    6,
                    10,
                    4,
                    7,
                    1,
                    7,
                    8,
                    5,
                    5,
                    5,
                    4
                ],
                "freq_hist_data_bar_values": [
                    0.533,
                    1.597,
                    2.661,
                    3.725,
                    4.789,
                    5.853,
                    6.917,
                    7.981,
                    9.045,
                    10.109,
                    11.174,
                    12.238,
                    13.302,
                    14.366,
                    15.43,
                    16.494,
                    17.558,
                    18.622,
                    19.686,
                    20.75,
                    21.814,
                    22.878,
                    23.942,
                    25.006,
                    26.07,
                    27.134,
                    28.198,
                    29.263,
                    30.327,
                    31.391,
                    32.455,
                    33.519,
                    34.583,
                    35.647,
                    36.711,
                    37.775,
                    38.839,
                    39.903,
                    40.967,
                    42.031,
                    43.095,
                    44.159,
                    45.223,
                    46.287,
                    47.352,
                    48.416,
                    49.48,
                    50.544,
                    51.608,
                    52.672
                ],
                "logits_hist_data_bar_heights": [
                    7,
                    7,
                    18,
                    34,
                    77,
                    131,
                    243,
                    426,
                    676,
                    1089,
                    1621,
                    2306,
                    3088,
                    3793,
                    4551,
                    5011,
                    5265,
                    4817,
                    4478,
                    3770,
                    2848,
                    2102,
                    1418,
                    900,
                    647,
                    390,
                    227,
                    119,
                    81,
                    49,
                    20,
                    15,
                    12,
                    2,
                    7,
                    2,
                    1,
                    0,
                    2,
                    0,
                    0,
                    2,
                    2,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.64,
                    -0.6,
                    -0.56,
                    -0.52,
                    -0.479,
                    -0.439,
                    -0.399,
                    -0.358,
                    -0.318,
                    -0.278,
                    -0.238,
                    -0.197,
                    -0.157,
                    -0.117,
                    -0.077,
                    -0.036,
                    0.004,
                    0.044,
                    0.084,
                    0.125,
                    0.165,
                    0.205,
                    0.245,
                    0.286,
                    0.326,
                    0.366,
                    0.406,
                    0.447,
                    0.487,
                    0.527,
                    0.568,
                    0.608,
                    0.648,
                    0.688,
                    0.729,
                    0.769,
                    0.809,
                    0.849,
                    0.89,
                    0.93,
                    0.97,
                    1.01,
                    1.051,
                    1.091,
                    1.131,
                    1.171,
                    1.212,
                    1.252,
                    1.292,
                    1.333
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to lessons and learning experiences",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4mjp1j6xhi666yxp4bygr",
                        "tokens": [
                            "\"",
                            " know",
                            " and",
                            " newcomers",
                            " do",
                            " not",
                            ".",
                            " Instead",
                            ",",
                            " it",
                            " is",
                            " about",
                            " lessons",
                            " that",
                            " we",
                            " all",
                            " need",
                            " to",
                            " learn",
                            " more",
                            " than",
                            " once",
                            ",",
                            " and",
                            " remind",
                            " ourselves",
                            " of",
                            ".",
                            " It",
                            " is",
                            " about",
                            " tendencies",
                            " that",
                            " are",
                            " common",
                            ",",
                            " and",
                            " understandable",
                            ",",
                            " and",
                            " come",
                            " with",
                            " the",
                            " flush",
                            " of",
                            " excitement",
                            " of",
                            " learning",
                            " any",
                            " new",
                            " thing",
                            " that",
                            " we",
                            " understand",
                            " is",
                            " important",
                            ",",
                            " and",
                            " about",
                            " the",
                            " difficulty",
                            ",",
                            " always",
                            ",",
                            " in",
                            " trying",
                            " to",
                            " decide",
                            " how",
                            " best",
                            " to",
                            " convey",
                            " that",
                            " excitement",
                            " and",
                            " sense",
                            " of",
                            " importance",
                            " to",
                            " others",
                            ",",
                            " in",
                            " a",
                            " way",
                            " that",
                            " they",
                            " will",
                            " listen",
                            ".",
                            " It",
                            " is",
                            " written",
                            " more",
                            " specifically",
                            ",",
                            " but",
                            " only",
                            " because",
                            " I",
                            " have",
                            " found",
                            " that",
                            " if",
                            " we",
                            " don",
                            "'t",
                            " talk",
                            " specifics",
                            " as",
                            " well",
                            " as",
                            " general",
                            "ities",
                            ",",
                            " the",
                            " general",
                            "ities",
                            " make",
                            " no",
                            " sense",
                            ".",
                            " This",
                            " holds",
                            " for",
                            " algebra",
                            "ic",
                            " structures"
                        ],
                        "dataIndex": null,
                        "index": "8181",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 53.204,
                        "maxValueTokenIndex": 12,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            53.204,
                            2.58,
                            0,
                            0,
                            0,
                            0.684,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:12:37.029Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 53.204,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4mjp1j6xii666zfxspbvm",
                        "tokens": [
                            " race",
                            " report",
                            " immediately",
                            " after",
                            ",",
                            " trying",
                            " to",
                            " remember",
                            " as",
                            " much",
                            " detail",
                            " as",
                            " I",
                            " possibly",
                            " can",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " the",
                            " post",
                            "-",
                            "mortem",
                            ",",
                            " to",
                            " assess",
                            " what",
                            ",",
                            " if",
                            " any",
                            ",",
                            " went",
                            " wrong",
                            ",",
                            " lessons",
                            " learned",
                            " and",
                            " things",
                            " to",
                            " improve",
                            " for",
                            " a",
                            " subsequent",
                            " race",
                            ".",
                            "\n",
                            "\n",
                            "Maybe",
                            " elite",
                            " runners",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " have",
                            " PR",
                            "S",
                            ",",
                            " but",
                            " for",
                            " a",
                            " late",
                            "-",
                            "bl",
                            "oom",
                            "er",
                            ",",
                            " mere",
                            "-",
                            "m",
                            "ortal",
                            ",",
                            " mid",
                            "-",
                            "pack",
                            " runner",
                            " like",
                            " me",
                            "?",
                            " I",
                            " find",
                            " this",
                            " preparation",
                            " insanely",
                            " helpful",
                            " to",
                            " get",
                            " to",
                            " the",
                            " finish",
                            " line",
                            " in",
                            " one",
                            " piece",
                            " while",
                            " still",
                            " smiling",
                            ".",
                            " Not",
                            " to",
                            " mention",
                            " how",
                            " grat",
                            "ifying",
                            " it",
                            " is",
                            " to",
                            " see",
                            " the",
                            " week",
                            " long",
                            " strategy",
                            " play",
                            " out",
                            " during",
                            " the",
                            " race",
                            ".",
                            " Most",
                            " of",
                            " the",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "Related"
                        ],
                        "dataIndex": null,
                        "index": "8181",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 53.077,
                        "maxValueTokenIndex": 35,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            53.077,
                            8.3,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:12:37.029Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 53.204,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4mjp1j6xji666f21i7qgq",
                        "tokens": [
                            " EU",
                            " when",
                            " other",
                            " players",
                            " \u2013",
                            " the",
                            " US",
                            ",",
                            " China",
                            ",",
                            " India",
                            " \u2013",
                            " are",
                            " the",
                            " size",
                            " of",
                            " continents",
                            ".",
                            "\n",
                            "\n",
                            "C",
                            "ameron",
                            " touches",
                            " on",
                            " this",
                            " when",
                            " he",
                            " talks",
                            " about",
                            " a",
                            " \u00e2\u0122",
                            "\u013e",
                            "global",
                            " race",
                            "\u00e2\u0122",
                            "\u013f",
                            " but",
                            " he",
                            " has",
                            " in",
                            " mind",
                            " a",
                            " commercial",
                            " rivalry",
                            " played",
                            " out",
                            " within",
                            " globally",
                            " recognised",
                            " boundaries",
                            " of",
                            " free",
                            "-",
                            "market",
                            " capitalism",
                            ".",
                            " A",
                            " lesson",
                            " from",
                            " Crimea",
                            " is",
                            " that",
                            " some",
                            " states",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " play",
                            " by",
                            " those",
                            " rules",
                            ".",
                            "\n",
                            "\n",
                            "There",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " much",
                            " point",
                            " expecting",
                            " a",
                            " more",
                            " sophisticated",
                            " account",
                            " of",
                            " Britain",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " role",
                            " in",
                            " the",
                            " world",
                            " from",
                            " the",
                            " Prime",
                            " Minister",
                            ".",
                            " It",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " in",
                            " his",
                            " nature",
                            " to",
                            " dwell",
                            " on",
                            " perplex",
                            "ing",
                            " things",
                            ".",
                            " His",
                            " friends",
                            " present",
                            " his",
                            " short",
                            " attention",
                            " span",
                            " as",
                            " a",
                            " healthy",
                            " aversion"
                        ],
                        "dataIndex": null,
                        "index": "8181",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 52.317,
                        "maxValueTokenIndex": 57,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            52.317,
                            0.365,
                            0,
                            0.291,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:12:37.029Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 53.204,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "2550",
            "description": "terms related to repetitions and practice in various contexts",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4664601981639862,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "2550",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:31:24.791Z",
                "maxActApprox": 38.785,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    2550,
                    35193,
                    89520,
                    35820,
                    30381,
                    29098,
                    98235,
                    10074,
                    39016,
                    78399,
                    62926,
                    77302,
                    29571,
                    24366,
                    3645,
                    7281,
                    96170,
                    86367,
                    96267,
                    75236,
                    59258,
                    5404,
                    29617,
                    58284,
                    69113
                ],
                "topkCosSimValues": [
                    1,
                    0.4737,
                    0.4326,
                    0.4298,
                    0.4216,
                    0.3908,
                    0.3893,
                    0.3728,
                    0.3561,
                    0.3467,
                    0.3389,
                    0.3356,
                    0.3355,
                    0.3249,
                    0.3223,
                    0.312,
                    0.3099,
                    0.307,
                    0.302,
                    0.3007,
                    0.2989,
                    0.2982,
                    0.2933,
                    0.2832,
                    0.2781
                ],
                "neuron_alignment_indices": [
                    255,
                    90,
                    695
                ],
                "neuron_alignment_values": [
                    0.118,
                    0.094,
                    0.094
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    90,
                    540,
                    162
                ],
                "correlated_neurons_pearson": [
                    0.006,
                    0.006,
                    0.006
                ],
                "correlated_neurons_l1": [
                    0.006,
                    0.007,
                    0.005
                ],
                "correlated_features_indices": [
                    2518,
                    2550,
                    2532
                ],
                "correlated_features_pearson": [
                    0.001,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0,
                    0
                ],
                "neg_str": [
                    "istically",
                    " Pound",
                    " Fare",
                    " Galile",
                    "\u00e2\u0122\u00a2\u00e2\u0122\u00a2",
                    "cock",
                    "resources",
                    "SPONSORED",
                    " Nost",
                    "OUS"
                ],
                "neg_values": [
                    -0.669,
                    -0.659,
                    -0.655,
                    -0.628,
                    -0.621,
                    -0.619,
                    -0.606,
                    -0.605,
                    -0.599,
                    -0.591
                ],
                "pos_str": [
                    "onse",
                    " tremend",
                    "undown",
                    "utations",
                    "roach",
                    "uted",
                    "rieve",
                    "imated",
                    "nyder",
                    "\u00e8\u00a6\u013c\u00e9\u0128\u0134"
                ],
                "pos_values": [
                    1.152,
                    1.142,
                    1.081,
                    1.068,
                    0.973,
                    0.947,
                    0.914,
                    0.889,
                    0.862,
                    0.857
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    28,
                    10,
                    8,
                    2,
                    8,
                    3,
                    2,
                    2,
                    1,
                    4,
                    0,
                    1,
                    2,
                    2,
                    0,
                    0,
                    3,
                    0,
                    1,
                    2,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    2,
                    2,
                    1,
                    0,
                    2,
                    0,
                    2,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.392,
                    1.168,
                    1.944,
                    2.719,
                    3.495,
                    4.27,
                    5.046,
                    5.822,
                    6.597,
                    7.373,
                    8.148,
                    8.924,
                    9.7,
                    10.475,
                    11.251,
                    12.027,
                    12.802,
                    13.578,
                    14.353,
                    15.129,
                    15.905,
                    16.68,
                    17.456,
                    18.231,
                    19.007,
                    19.783,
                    20.558,
                    21.334,
                    22.11,
                    22.885,
                    23.661,
                    24.436,
                    25.212,
                    25.988,
                    26.763,
                    27.539,
                    28.314,
                    29.09,
                    29.866,
                    30.641,
                    31.417,
                    32.193,
                    32.968,
                    33.744,
                    34.519,
                    35.295,
                    36.071,
                    36.846,
                    37.622,
                    38.398
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    6,
                    6,
                    18,
                    35,
                    72,
                    147,
                    254,
                    481,
                    739,
                    1110,
                    1592,
                    2112,
                    2756,
                    3263,
                    3884,
                    4235,
                    4383,
                    4237,
                    3889,
                    3483,
                    3038,
                    2369,
                    1844,
                    1440,
                    1179,
                    876,
                    709,
                    522,
                    439,
                    297,
                    251,
                    155,
                    134,
                    86,
                    58,
                    50,
                    33,
                    24,
                    19,
                    12,
                    8,
                    2,
                    1,
                    1,
                    1,
                    0,
                    1,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.651,
                    -0.614,
                    -0.578,
                    -0.542,
                    -0.505,
                    -0.469,
                    -0.432,
                    -0.396,
                    -0.36,
                    -0.323,
                    -0.287,
                    -0.25,
                    -0.214,
                    -0.177,
                    -0.141,
                    -0.105,
                    -0.068,
                    -0.032,
                    0.005,
                    0.041,
                    0.078,
                    0.114,
                    0.15,
                    0.187,
                    0.223,
                    0.26,
                    0.296,
                    0.333,
                    0.369,
                    0.405,
                    0.442,
                    0.478,
                    0.515,
                    0.551,
                    0.587,
                    0.624,
                    0.66,
                    0.697,
                    0.733,
                    0.77,
                    0.806,
                    0.842,
                    0.879,
                    0.915,
                    0.952,
                    0.988,
                    1.025,
                    1.061,
                    1.097,
                    1.134
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to repetitions and practice in various contexts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to the concept of \"reps\" or repetitions in the context of physical training or exercise",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygezum9d97v10exib15uxw2",
                        "tokens": [
                            " tendency",
                            " to",
                            " hesitate",
                            " on",
                            " my",
                            " shot",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " N",
                            "til",
                            "ik",
                            "ina",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Now",
                            " I",
                            " feel",
                            " more",
                            " comfortable",
                            " while",
                            " getting",
                            " a",
                            " lot",
                            " of",
                            " reps",
                            ".",
                            " H",
                            "itting",
                            " shots",
                            " in",
                            " the",
                            " real",
                            " game",
                            " gives",
                            " me",
                            " confidence",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Yeah",
                            ",",
                            " those",
                            " phony",
                            " games",
                            " rarely",
                            " help",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "I",
                            " just",
                            " need",
                            " to",
                            " keep",
                            " working",
                            ",",
                            " keep",
                            " getting",
                            " reps",
                            ",",
                            " keep",
                            " taking",
                            " those",
                            " shots",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "And",
                            " keep",
                            " avoiding",
                            " all",
                            " that",
                            " thinking",
                            ".",
                            "<|endoftext|>",
                            "Last",
                            " weekend",
                            " I",
                            " was",
                            " playing",
                            " around",
                            " with",
                            " a",
                            " way",
                            " to",
                            " represent",
                            " null",
                            "-",
                            "termin",
                            "ated",
                            " UTF",
                            "8",
                            " strings",
                            " in",
                            " Rust",
                            ".",
                            " Rather",
                            " than",
                            " just",
                            " to",
                            "ying",
                            " with",
                            " it",
                            " forever",
                            ",",
                            " I",
                            " decided",
                            " to",
                            " clean",
                            " up",
                            " a",
                            " minimal",
                            " version",
                            " and",
                            " publish"
                        ],
                        "dataIndex": null,
                        "index": "2550",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.785,
                        "maxValueTokenIndex": 27,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            38.785,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.002,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:31:31.479Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 38.785,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygezumad97x10exlyu2mo1s",
                        "tokens": [
                            " tendency",
                            " to",
                            " hesitate",
                            " on",
                            " my",
                            " shot",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " N",
                            "til",
                            "ik",
                            "ina",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Now",
                            " I",
                            " feel",
                            " more",
                            " comfortable",
                            " while",
                            " getting",
                            " a",
                            " lot",
                            " of",
                            " reps",
                            ".",
                            " H",
                            "itting",
                            " shots",
                            " in",
                            " the",
                            " real",
                            " game",
                            " gives",
                            " me",
                            " confidence",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Yeah",
                            ",",
                            " those",
                            " phony",
                            " games",
                            " rarely",
                            " help",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "I",
                            " just",
                            " need",
                            " to",
                            " keep",
                            " working",
                            ",",
                            " keep",
                            " getting",
                            " reps",
                            ",",
                            " keep",
                            " taking",
                            " those",
                            " shots",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "And",
                            " keep",
                            " avoiding",
                            " all",
                            " that",
                            " thinking",
                            ".",
                            "<|endoftext|>",
                            "Last",
                            " weekend",
                            " I",
                            " was",
                            " playing",
                            " around",
                            " with",
                            " a",
                            " way",
                            " to",
                            " represent",
                            " null",
                            "-",
                            "termin",
                            "ated",
                            " UTF",
                            "8",
                            " strings",
                            " in",
                            " Rust",
                            ".",
                            " Rather",
                            " than",
                            " just",
                            " to",
                            "ying",
                            " with",
                            " it",
                            " forever",
                            ",",
                            " I",
                            " decided",
                            " to",
                            " clean",
                            " up",
                            " a",
                            " minimal",
                            " version",
                            " and",
                            " publish"
                        ],
                        "dataIndex": null,
                        "index": "2550",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.785,
                        "maxValueTokenIndex": 27,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            38.785,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.002,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:31:31.479Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 38.785,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygezumbd98f10ex7jr4x6kg",
                        "tokens": [
                            " tendency",
                            " to",
                            " hesitate",
                            " on",
                            " my",
                            " shot",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " N",
                            "til",
                            "ik",
                            "ina",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Now",
                            " I",
                            " feel",
                            " more",
                            " comfortable",
                            " while",
                            " getting",
                            " a",
                            " lot",
                            " of",
                            " reps",
                            ".",
                            " H",
                            "itting",
                            " shots",
                            " in",
                            " the",
                            " real",
                            " game",
                            " gives",
                            " me",
                            " confidence",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Yeah",
                            ",",
                            " those",
                            " phony",
                            " games",
                            " rarely",
                            " help",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "I",
                            " just",
                            " need",
                            " to",
                            " keep",
                            " working",
                            ",",
                            " keep",
                            " getting",
                            " reps",
                            ",",
                            " keep",
                            " taking",
                            " those",
                            " shots",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "And",
                            " keep",
                            " avoiding",
                            " all",
                            " that",
                            " thinking",
                            ".",
                            "<|endoftext|>",
                            "Last",
                            " weekend",
                            " I",
                            " was",
                            " playing",
                            " around",
                            " with",
                            " a",
                            " way",
                            " to",
                            " represent",
                            " null",
                            "-",
                            "termin",
                            "ated",
                            " UTF",
                            "8",
                            " strings",
                            " in",
                            " Rust",
                            ".",
                            " Rather",
                            " than",
                            " just",
                            " to",
                            "ying",
                            " with",
                            " it",
                            " forever",
                            ",",
                            " I",
                            " decided",
                            " to",
                            " clean",
                            " up",
                            " a",
                            " minimal",
                            " version",
                            " and",
                            " publish"
                        ],
                        "dataIndex": null,
                        "index": "2550",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 38.785,
                        "maxValueTokenIndex": 27,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            38.785,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.002,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:31:31.479Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 31.028,
                        "binMax": 38.785,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "37022",
            "description": "phrases related to learning and educational pursuits",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4638743081017924,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "37022",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:05:26.694Z",
                "maxActApprox": 54.752,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    37022,
                    35811,
                    46722,
                    46953,
                    11474,
                    30335,
                    11731,
                    14572,
                    19723,
                    4782,
                    8181,
                    3216,
                    33871,
                    9870,
                    13352,
                    26719,
                    10589,
                    47553,
                    26949,
                    46109,
                    3729,
                    19994,
                    15624,
                    39880,
                    20747
                ],
                "topkCosSimValues": [
                    1,
                    0.7809,
                    0.7607,
                    0.7516,
                    0.5495,
                    0.5354,
                    0.5069,
                    0.502,
                    0.4814,
                    0.4786,
                    0.4749,
                    0.4663,
                    0.4466,
                    0.4412,
                    0.4241,
                    0.4225,
                    0.4215,
                    0.4166,
                    0.4125,
                    0.4109,
                    0.4036,
                    0.4026,
                    0.4024,
                    0.4005,
                    0.3989
                ],
                "neuron_alignment_indices": [
                    271,
                    665,
                    285
                ],
                "neuron_alignment_values": [
                    0.12,
                    0.102,
                    0.101
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    271,
                    62,
                    285
                ],
                "correlated_neurons_pearson": [
                    0.034,
                    0.029,
                    0.024
                ],
                "correlated_neurons_l1": [
                    0.033,
                    0.027,
                    0.021
                ],
                "correlated_features_indices": [
                    37070,
                    37064,
                    37085
                ],
                "correlated_features_pearson": [
                    0.006,
                    0.002,
                    0.002
                ],
                "correlated_features_l1": [
                    0.006,
                    0.002,
                    0.002
                ],
                "neg_str": [
                    "ordered",
                    "conn",
                    "govtrack",
                    "inth",
                    "zzi",
                    "een",
                    "raviolet",
                    "lished",
                    "berus",
                    "hao"
                ],
                "neg_values": [
                    -0.685,
                    -0.677,
                    -0.669,
                    -0.634,
                    -0.629,
                    -0.625,
                    -0.621,
                    -0.611,
                    -0.606,
                    -0.604
                ],
                "pos_str": [
                    "learn",
                    " lessons",
                    " lesson",
                    " Teach",
                    " Curve",
                    " firsthand",
                    " anew",
                    "Lear",
                    " humility",
                    " maths"
                ],
                "pos_values": [
                    0.896,
                    0.892,
                    0.812,
                    0.81,
                    0.797,
                    0.77,
                    0.757,
                    0.752,
                    0.739,
                    0.733
                ],
                "frac_nonzero": 0.00024,
                "freq_hist_data_bar_heights": [
                    79,
                    55,
                    46,
                    36,
                    32,
                    15,
                    23,
                    14,
                    11,
                    14,
                    16,
                    12,
                    14,
                    15,
                    15,
                    16,
                    13,
                    11,
                    8,
                    12,
                    12,
                    12,
                    20,
                    18,
                    17,
                    13,
                    15,
                    11,
                    15,
                    11,
                    9,
                    16,
                    14,
                    17,
                    9,
                    10,
                    16,
                    8,
                    13,
                    6,
                    5,
                    3,
                    4,
                    3,
                    5,
                    2,
                    1,
                    1,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.557,
                    1.652,
                    2.746,
                    3.841,
                    4.936,
                    6.031,
                    7.126,
                    8.221,
                    9.316,
                    10.41,
                    11.505,
                    12.6,
                    13.695,
                    14.79,
                    15.885,
                    16.98,
                    18.074,
                    19.169,
                    20.264,
                    21.359,
                    22.454,
                    23.549,
                    24.643,
                    25.738,
                    26.833,
                    27.928,
                    29.023,
                    30.118,
                    31.213,
                    32.307,
                    33.402,
                    34.497,
                    35.592,
                    36.687,
                    37.782,
                    38.876,
                    39.971,
                    41.066,
                    42.161,
                    43.256,
                    44.351,
                    45.446,
                    46.54,
                    47.635,
                    48.73,
                    49.825,
                    50.92,
                    52.015,
                    53.11,
                    54.204
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    3,
                    7,
                    12,
                    23,
                    35,
                    48,
                    103,
                    131,
                    205,
                    318,
                    488,
                    698,
                    982,
                    1411,
                    1964,
                    2386,
                    2915,
                    3428,
                    3844,
                    4124,
                    3936,
                    3842,
                    3611,
                    3319,
                    2881,
                    2405,
                    1891,
                    1379,
                    1090,
                    826,
                    607,
                    403,
                    278,
                    204,
                    141,
                    81,
                    63,
                    47,
                    38,
                    26,
                    23,
                    12,
                    7,
                    10,
                    3,
                    2,
                    2,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.669,
                    -0.637,
                    -0.606,
                    -0.574,
                    -0.543,
                    -0.511,
                    -0.479,
                    -0.448,
                    -0.416,
                    -0.384,
                    -0.353,
                    -0.321,
                    -0.29,
                    -0.258,
                    -0.226,
                    -0.195,
                    -0.163,
                    -0.132,
                    -0.1,
                    -0.068,
                    -0.037,
                    -0.005,
                    0.027,
                    0.058,
                    0.09,
                    0.121,
                    0.153,
                    0.185,
                    0.216,
                    0.248,
                    0.28,
                    0.311,
                    0.343,
                    0.374,
                    0.406,
                    0.438,
                    0.469,
                    0.501,
                    0.532,
                    0.564,
                    0.596,
                    0.627,
                    0.659,
                    0.691,
                    0.722,
                    0.754,
                    0.785,
                    0.817,
                    0.849,
                    0.88
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases related to learning and educational pursuits",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk6ijsz9rh8i666h5fly3lj",
                        "tokens": [
                            ",",
                            " too",
                            ".",
                            " Lee",
                            " has",
                            " previously",
                            " told",
                            " me",
                            " that",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " like",
                            " the",
                            " site",
                            " where",
                            " the",
                            " Falcon",
                            " is",
                            " built",
                            " to",
                            " become",
                            " a",
                            " sort",
                            " of",
                            " \u00e2\u0122",
                            "\u013e",
                            "NASA",
                            " Space",
                            " Camp",
                            "\u00e2\u0122",
                            "\u013f",
                            " for",
                            " kids",
                            " that",
                            " want",
                            " to",
                            " learn",
                            " how",
                            " to",
                            " build",
                            " hardware",
                            " from",
                            " scratch",
                            ".",
                            " But",
                            " those",
                            " plans",
                            " are",
                            " all",
                            " in",
                            " the",
                            " far",
                            " future",
                            " while",
                            " he",
                            " and",
                            " other",
                            " g",
                            "eeks",
                            " focus",
                            " on",
                            " finishing",
                            " the",
                            " replica",
                            " of",
                            " Star",
                            " Wars",
                            "\u00e2\u0122",
                            "\u013b",
                            " most",
                            " famous",
                            " ship",
                            ".",
                            "\n",
                            "\n",
                            "As",
                            " for",
                            " the",
                            " photo",
                            ",",
                            " Lee",
                            " brought",
                            " portions",
                            " of",
                            " the",
                            " Falcon",
                            " cockpit",
                            " to",
                            " the",
                            " GM",
                            "X",
                            " event",
                            " last",
                            " weekend",
                            " to",
                            " show",
                            " off",
                            " some",
                            " of",
                            " the",
                            " progress",
                            ".",
                            " Hod",
                            "or",
                            " actor",
                            " (",
                            "and",
                            " DJ",
                            ")",
                            " Krist",
                            "ian",
                            " N",
                            "air",
                            "n",
                            " was",
                            " in",
                            " attendance",
                            " and",
                            " didn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " pass",
                            " up",
                            " a"
                        ],
                        "dataIndex": null,
                        "index": "37022",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 54.752,
                        "maxValueTokenIndex": 38,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            54.752,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:05:29.472Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 54.752,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6ijsz9rh9i666dm38ulfe",
                        "tokens": [
                            " to",
                            " get",
                            " better",
                            " at",
                            " it",
                            ".",
                            " By",
                            " participating",
                            " in",
                            " the",
                            " KC",
                            "IT",
                            "P",
                            " community",
                            ",",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " illustrated",
                            " an",
                            " enhanced",
                            " dedication",
                            " to",
                            " your",
                            " technology",
                            " career",
                            ".",
                            "\n",
                            "\n",
                            "Whether",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " sharing",
                            " content",
                            " or",
                            " answering",
                            " questions",
                            " on",
                            " our",
                            " Link",
                            "edin",
                            " forum",
                            ",",
                            " interacting",
                            " on",
                            " Twitter",
                            ",",
                            " or",
                            " attending",
                            " events",
                            "\u00e2\u0122\u00a6",
                            "you",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " made",
                            " it",
                            " clear",
                            " that",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " motivated",
                            ".",
                            "\n",
                            "\n",
                            "Through",
                            " these",
                            " community",
                            " interactions",
                            ",",
                            " a",
                            " potential",
                            " employer",
                            " might",
                            " be",
                            " able",
                            " to",
                            " see",
                            " that",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " simply",
                            " not",
                            " interested",
                            " in",
                            " doing",
                            " the",
                            " bare",
                            " minimum",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " want",
                            " to",
                            " excel",
                            ".",
                            " That",
                            " matters",
                            ".",
                            "\n",
                            "\n",
                            "Reason",
                            " #",
                            "2",
                            ":",
                            " You",
                            " want",
                            " to",
                            " learn",
                            " more",
                            "\n",
                            "\n",
                            "Some",
                            " of",
                            " the",
                            " best",
                            " people",
                            " I",
                            "\u00e2\u0122"
                        ],
                        "dataIndex": null,
                        "index": "37022",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 54.141,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            54.141,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:05:29.472Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 54.752,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6ijsz9rhai666s2i2hn3u",
                        "tokens": [
                            " an",
                            " email",
                            " a",
                            " few",
                            " days",
                            " after",
                            " later",
                            " asking",
                            " if",
                            " I",
                            " wanted",
                            " to",
                            " write",
                            " an",
                            " N",
                            "ginx",
                            " module",
                            " for",
                            " an",
                            " Internet",
                            " start",
                            "-",
                            "up",
                            ".\"",
                            "\n",
                            "\n",
                            "E",
                            "van",
                            " Miller",
                            ",",
                            " open",
                            " source",
                            " contractor",
                            "\n",
                            "\n",
                            "2",
                            ".",
                            " The",
                            " more",
                            " esoteric",
                            ",",
                            " the",
                            " better",
                            "\n",
                            "\n",
                            "\"",
                            "I",
                            " started",
                            " working",
                            " on",
                            " x",
                            "264",
                            ",",
                            " the",
                            " only",
                            " open",
                            " source",
                            " H",
                            ".",
                            "264",
                            " video",
                            " enc",
                            "oder",
                            ".",
                            " I",
                            " knew",
                            " basically",
                            " nothing",
                            " and",
                            " was",
                            " experimenting",
                            " with",
                            " the",
                            " simplest",
                            " things",
                            ".",
                            " Slowly",
                            " but",
                            " surely",
                            ",",
                            " I",
                            " learnt",
                            " the",
                            " code",
                            "base",
                            " and",
                            " eventually",
                            " got",
                            " my",
                            " first",
                            " major",
                            " patch",
                            " in",
                            ".",
                            " I",
                            " taught",
                            " myself",
                            " x",
                            "86",
                            " assembly",
                            ",",
                            " and",
                            " then",
                            " SIM",
                            "D",
                            " assembly",
                            ".",
                            " and",
                            " finally",
                            ",",
                            " the",
                            " subt",
                            "let",
                            "ies",
                            " of",
                            " C",
                            " pointers",
                            ".",
                            " I",
                            " finally",
                            " realised",
                            " that",
                            " the",
                            " best",
                            " way",
                            " to",
                            " learn"
                        ],
                        "dataIndex": null,
                        "index": "37022",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 51.529,
                        "maxValueTokenIndex": 126,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            21.502,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.075,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            51.529
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:05:29.472Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 54.752,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "11",
            "description": " questions and statements related to learning processes and methodologies",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4626651406288147,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "11",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:28:31.021Z",
                "maxActApprox": 39.394,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    11,
                    21306,
                    29674,
                    5418,
                    24863,
                    59028,
                    63520,
                    60147,
                    38758,
                    90284,
                    42965,
                    23492,
                    62741,
                    97707,
                    5228,
                    2086,
                    78040,
                    58522,
                    29326,
                    23145,
                    2430,
                    28390,
                    25084,
                    28472,
                    69877
                ],
                "topkCosSimValues": [
                    1,
                    0.7454,
                    0.7111,
                    0.7028,
                    0.6897,
                    0.6778,
                    0.6541,
                    0.6504,
                    0.6484,
                    0.6384,
                    0.6347,
                    0.6211,
                    0.6082,
                    0.5782,
                    0.5764,
                    0.5566,
                    0.5289,
                    0.5175,
                    0.4836,
                    0.4809,
                    0.4673,
                    0.4652,
                    0.4393,
                    0.4262,
                    0.4102
                ],
                "neuron_alignment_indices": [
                    534,
                    483,
                    60
                ],
                "neuron_alignment_values": [
                    0.104,
                    0.103,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    60,
                    483,
                    236
                ],
                "correlated_neurons_pearson": [
                    0.032,
                    0.03,
                    0.029
                ],
                "correlated_neurons_l1": [
                    0.031,
                    0.029,
                    0.031
                ],
                "correlated_features_indices": [
                    26,
                    113,
                    59
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.006,
                    0.003,
                    0.002
                ],
                "neg_str": [
                    "vertisement",
                    "holder",
                    "enture",
                    "Rum",
                    "UX",
                    "EStream",
                    "oubted",
                    "idon",
                    "Reader",
                    "Guest"
                ],
                "neg_values": [
                    -0.745,
                    -0.663,
                    -0.62,
                    -0.599,
                    -0.59,
                    -0.585,
                    -0.584,
                    -0.576,
                    -0.57,
                    -0.569
                ],
                "pos_str": [
                    "soever",
                    "ls",
                    "itzer",
                    "olds",
                    "ells",
                    " efficiently",
                    " messed",
                    "ards",
                    "lers",
                    "ling"
                ],
                "pos_values": [
                    0.802,
                    0.747,
                    0.735,
                    0.721,
                    0.719,
                    0.708,
                    0.695,
                    0.69,
                    0.676,
                    0.662
                ],
                "frac_nonzero": 0.0004,
                "freq_hist_data_bar_heights": [
                    157,
                    114,
                    108,
                    92,
                    83,
                    60,
                    61,
                    39,
                    55,
                    50,
                    30,
                    37,
                    23,
                    20,
                    18,
                    21,
                    15,
                    20,
                    18,
                    13,
                    20,
                    10,
                    16,
                    8,
                    9,
                    6,
                    8,
                    12,
                    8,
                    8,
                    3,
                    13,
                    9,
                    4,
                    6,
                    8,
                    3,
                    6,
                    7,
                    5,
                    10,
                    4,
                    3,
                    5,
                    7,
                    8,
                    0,
                    0,
                    1,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.401,
                    1.189,
                    1.976,
                    2.764,
                    3.552,
                    4.34,
                    5.127,
                    5.915,
                    6.703,
                    7.491,
                    8.278,
                    9.066,
                    9.854,
                    10.642,
                    11.429,
                    12.217,
                    13.005,
                    13.792,
                    14.58,
                    15.368,
                    16.156,
                    16.943,
                    17.731,
                    18.519,
                    19.307,
                    20.094,
                    20.882,
                    21.67,
                    22.458,
                    23.245,
                    24.033,
                    24.821,
                    25.609,
                    26.396,
                    27.184,
                    27.972,
                    28.76,
                    29.547,
                    30.335,
                    31.123,
                    31.911,
                    32.698,
                    33.486,
                    34.274,
                    35.062,
                    35.849,
                    36.637,
                    37.425,
                    38.213,
                    39
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    1,
                    0,
                    2,
                    11,
                    8,
                    26,
                    50,
                    72,
                    116,
                    180,
                    259,
                    445,
                    709,
                    939,
                    1172,
                    1661,
                    2194,
                    2718,
                    3093,
                    3631,
                    3844,
                    3854,
                    4054,
                    3855,
                    3516,
                    3096,
                    2505,
                    2137,
                    1630,
                    1318,
                    961,
                    720,
                    518,
                    348,
                    222,
                    132,
                    101,
                    61,
                    37,
                    23,
                    15,
                    8,
                    3,
                    3,
                    3,
                    3,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.73,
                    -0.699,
                    -0.668,
                    -0.637,
                    -0.606,
                    -0.575,
                    -0.544,
                    -0.513,
                    -0.482,
                    -0.451,
                    -0.42,
                    -0.389,
                    -0.358,
                    -0.327,
                    -0.296,
                    -0.265,
                    -0.234,
                    -0.204,
                    -0.173,
                    -0.142,
                    -0.111,
                    -0.08,
                    -0.049,
                    -0.018,
                    0.013,
                    0.044,
                    0.075,
                    0.106,
                    0.137,
                    0.168,
                    0.199,
                    0.23,
                    0.261,
                    0.292,
                    0.323,
                    0.354,
                    0.385,
                    0.415,
                    0.446,
                    0.477,
                    0.508,
                    0.539,
                    0.57,
                    0.601,
                    0.632,
                    0.663,
                    0.694,
                    0.725,
                    0.756,
                    0.787
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "questions and phrases that express \"how to\" achieve something or perform an action",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " questions and statements related to learning processes and methodologies",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygew0ixbceo10exrqgsclg9",
                        "tokens": [
                            " commentary",
                            " on",
                            " the",
                            " failure",
                            " by",
                            " one",
                            " or",
                            " more",
                            " members",
                            " of",
                            " that",
                            " family",
                            " to",
                            " live",
                            " up",
                            " to",
                            " their",
                            " duties",
                            ",",
                            " not",
                            " of",
                            " the",
                            " family",
                            " itself",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " family",
                            " is",
                            " the",
                            " basis",
                            " of",
                            " any",
                            " decent",
                            " society",
                            " because",
                            " only",
                            " in",
                            " it",
                            " do",
                            " children",
                            " learn",
                            " how",
                            " to",
                            " be",
                            " decent",
                            " adults",
                            ".",
                            " They",
                            " are",
                            " taught",
                            " virtue",
                            " in",
                            " families",
                            ",",
                            " or",
                            " nowhere",
                            ",",
                            " because",
                            " it",
                            " is",
                            " only",
                            " in",
                            " the",
                            " home",
                            " that",
                            " the",
                            " kind",
                            " of",
                            " intensive",
                            ",",
                            " round",
                            "-",
                            "the",
                            "-",
                            "clock",
                            " nurturing",
                            " and",
                            " acc",
                            "ult",
                            "uration",
                            " necessary",
                            " for",
                            " character",
                            " formation",
                            " can",
                            " occur",
                            ".",
                            " And",
                            ",",
                            " while",
                            " it",
                            " may",
                            " be",
                            " nice",
                            " to",
                            " talk",
                            " about",
                            " how",
                            " common",
                            " emotions",
                            " and",
                            " dedication",
                            " to",
                            " abstract",
                            " ideals",
                            " like",
                            " justice",
                            " or",
                            " tolerance",
                            " or",
                            " love",
                            " are",
                            " what",
                            " really",
                            " matter",
                            ",",
                            " those",
                            " emotions",
                            " and",
                            " ideals",
                            " only",
                            " become",
                            " real",
                            " when",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.394,
                        "maxValueTokenIndex": 43,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.394,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew0ixbcep10ex8drtvb0k",
                        "tokens": [
                            " sexuality",
                            ".",
                            " No",
                            " long",
                            ",",
                            " complex",
                            " process",
                            " of",
                            " re",
                            "acqu",
                            "ain",
                            "ting",
                            " yourself",
                            " with",
                            " new",
                            " genital",
                            "ia",
                            " and",
                            " learning",
                            " to",
                            " understand",
                            " them",
                            ".",
                            " No",
                            " learning",
                            " what",
                            " you",
                            " are",
                            " and",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " comfortable",
                            " wearing",
                            ".",
                            " No",
                            " getting",
                            " nail",
                            " polish",
                            " all",
                            " over",
                            " your",
                            " fingers",
                            " and",
                            " eyel",
                            "iner",
                            " in",
                            " your",
                            " eyeb",
                            "all",
                            " because",
                            " you",
                            " never",
                            " got",
                            " a",
                            " chance",
                            " to",
                            " learn",
                            " how",
                            " to",
                            " do",
                            " that",
                            " stuff",
                            " as",
                            " a",
                            " little",
                            " girl",
                            ".",
                            " No",
                            " coming",
                            " out",
                            ".",
                            " No",
                            " losing",
                            " friends",
                            ".",
                            " No",
                            " being",
                            " dis",
                            "owned",
                            " by",
                            " family",
                            ".",
                            " No",
                            " growing",
                            " closer",
                            " to",
                            " the",
                            " people",
                            " who",
                            " supported",
                            " you",
                            ".",
                            " No",
                            " adapting",
                            " to",
                            " the",
                            " loss",
                            " of",
                            " male",
                            " privilege",
                            " and",
                            " learning",
                            " how",
                            " to",
                            " deal",
                            " with",
                            " cat",
                            " calls",
                            ".",
                            " No",
                            " nothing",
                            ".",
                            "\n",
                            "\n",
                            "Basically",
                            "?",
                            " No",
                            " transition",
                            ".",
                            " None",
                            " of",
                            " any",
                            " of",
                            " the",
                            " stuff"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.371,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.818,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.371,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygew0iybcf410exd6leeuku",
                        "tokens": [
                            " sexuality",
                            ".",
                            " No",
                            " long",
                            ",",
                            " complex",
                            " process",
                            " of",
                            " re",
                            "acqu",
                            "ain",
                            "ting",
                            " yourself",
                            " with",
                            " new",
                            " genital",
                            "ia",
                            " and",
                            " learning",
                            " to",
                            " understand",
                            " them",
                            ".",
                            " No",
                            " learning",
                            " what",
                            " you",
                            " are",
                            " and",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " comfortable",
                            " wearing",
                            ".",
                            " No",
                            " getting",
                            " nail",
                            " polish",
                            " all",
                            " over",
                            " your",
                            " fingers",
                            " and",
                            " eyel",
                            "iner",
                            " in",
                            " your",
                            " eyeb",
                            "all",
                            " because",
                            " you",
                            " never",
                            " got",
                            " a",
                            " chance",
                            " to",
                            " learn",
                            " how",
                            " to",
                            " do",
                            " that",
                            " stuff",
                            " as",
                            " a",
                            " little",
                            " girl",
                            ".",
                            " No",
                            " coming",
                            " out",
                            ".",
                            " No",
                            " losing",
                            " friends",
                            ".",
                            " No",
                            " being",
                            " dis",
                            "owned",
                            " by",
                            " family",
                            ".",
                            " No",
                            " growing",
                            " closer",
                            " to",
                            " the",
                            " people",
                            " who",
                            " supported",
                            " you",
                            ".",
                            " No",
                            " adapting",
                            " to",
                            " the",
                            " loss",
                            " of",
                            " male",
                            " privilege",
                            " and",
                            " learning",
                            " how",
                            " to",
                            " deal",
                            " with",
                            " cat",
                            " calls",
                            ".",
                            " No",
                            " nothing",
                            ".",
                            "\n",
                            "\n",
                            "Basically",
                            "?",
                            " No",
                            " transition",
                            ".",
                            " None",
                            " of",
                            " any",
                            " of",
                            " the",
                            " stuff"
                        ],
                        "dataIndex": null,
                        "index": "11",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.371,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.818,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.371,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:28:32.277Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 39.394,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "43122",
            "description": "phrases related to learning and educational processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4614237684435778,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "43122",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:26:34.871Z",
                "maxActApprox": 9.554,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    43122,
                    52484,
                    71577,
                    70356,
                    63113,
                    79545,
                    98024,
                    57938,
                    41142,
                    7937,
                    55004,
                    29194,
                    26647,
                    83399,
                    27815,
                    43712,
                    15818,
                    34679,
                    17495,
                    9873,
                    42810,
                    60433,
                    68178,
                    84593,
                    13797
                ],
                "topkCosSimValues": [
                    1,
                    0.3592,
                    0.3534,
                    0.351,
                    0.3384,
                    0.3351,
                    0.3311,
                    0.3275,
                    0.3272,
                    0.325,
                    0.3192,
                    0.3169,
                    0.3116,
                    0.3107,
                    0.3105,
                    0.303,
                    0.3017,
                    0.3001,
                    0.2975,
                    0.2945,
                    0.2932,
                    0.292,
                    0.2914,
                    0.2894,
                    0.2892
                ],
                "neuron_alignment_indices": [
                    283,
                    154,
                    192
                ],
                "neuron_alignment_values": [
                    0.113,
                    0.095,
                    0.092
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    283,
                    362,
                    526
                ],
                "correlated_neurons_pearson": [
                    0.038,
                    0.037,
                    0.035
                ],
                "correlated_neurons_l1": [
                    0.021,
                    0.043,
                    0.002
                ],
                "correlated_features_indices": [
                    42998,
                    43042,
                    43138
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.008,
                    0.004,
                    0.003
                ],
                "neg_str": [
                    "ampire",
                    "Virgin",
                    " denotes",
                    "moon",
                    " Warning",
                    "itar",
                    "icter",
                    " commemor",
                    " denote",
                    " Bri"
                ],
                "neg_values": [
                    -0.725,
                    -0.682,
                    -0.663,
                    -0.656,
                    -0.654,
                    -0.637,
                    -0.629,
                    -0.618,
                    -0.606,
                    -0.606
                ],
                "pos_str": [
                    " painstaking",
                    " exped",
                    " homework",
                    " subconscious",
                    " timetable",
                    " timelines",
                    "\u00bb\u0134",
                    " digest",
                    " timely",
                    " runtime"
                ],
                "pos_values": [
                    0.795,
                    0.768,
                    0.761,
                    0.758,
                    0.748,
                    0.734,
                    0.729,
                    0.726,
                    0.711,
                    0.703
                ],
                "frac_nonzero": 0.00234,
                "freq_hist_data_bar_heights": [
                    1059,
                    858,
                    730,
                    710,
                    576,
                    491,
                    433,
                    352,
                    298,
                    266,
                    221,
                    190,
                    181,
                    166,
                    131,
                    114,
                    78,
                    67,
                    53,
                    66,
                    50,
                    35,
                    40,
                    33,
                    27,
                    16,
                    21,
                    16,
                    15,
                    12,
                    13,
                    6,
                    9,
                    6,
                    1,
                    5,
                    6,
                    6,
                    0,
                    1,
                    1,
                    2,
                    1,
                    2,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.096,
                    0.287,
                    0.478,
                    0.669,
                    0.86,
                    1.051,
                    1.242,
                    1.433,
                    1.624,
                    1.815,
                    2.006,
                    2.197,
                    2.389,
                    2.58,
                    2.771,
                    2.962,
                    3.153,
                    3.344,
                    3.535,
                    3.726,
                    3.917,
                    4.108,
                    4.299,
                    4.49,
                    4.681,
                    4.873,
                    5.064,
                    5.255,
                    5.446,
                    5.637,
                    5.828,
                    6.019,
                    6.21,
                    6.401,
                    6.592,
                    6.783,
                    6.974,
                    7.165,
                    7.357,
                    7.548,
                    7.739,
                    7.93,
                    8.121,
                    8.312,
                    8.503,
                    8.694,
                    8.885,
                    9.076,
                    9.267,
                    9.458
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    4,
                    5,
                    10,
                    20,
                    33,
                    57,
                    84,
                    129,
                    195,
                    296,
                    441,
                    626,
                    862,
                    1185,
                    1647,
                    1933,
                    2404,
                    2816,
                    3186,
                    3364,
                    3444,
                    3513,
                    3546,
                    3338,
                    2988,
                    2698,
                    2351,
                    2016,
                    1609,
                    1329,
                    1087,
                    789,
                    615,
                    474,
                    352,
                    260,
                    170,
                    124,
                    85,
                    66,
                    34,
                    27,
                    16,
                    7,
                    11,
                    4,
                    3,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.71,
                    -0.68,
                    -0.649,
                    -0.619,
                    -0.588,
                    -0.558,
                    -0.527,
                    -0.497,
                    -0.467,
                    -0.436,
                    -0.406,
                    -0.375,
                    -0.345,
                    -0.315,
                    -0.284,
                    -0.254,
                    -0.223,
                    -0.193,
                    -0.163,
                    -0.132,
                    -0.102,
                    -0.071,
                    -0.041,
                    -0.01,
                    0.02,
                    0.05,
                    0.081,
                    0.111,
                    0.142,
                    0.172,
                    0.202,
                    0.233,
                    0.263,
                    0.294,
                    0.324,
                    0.354,
                    0.385,
                    0.415,
                    0.446,
                    0.476,
                    0.506,
                    0.537,
                    0.567,
                    0.598,
                    0.628,
                    0.659,
                    0.689,
                    0.719,
                    0.75,
                    0.78
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases related to learning and educational processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases related to learning and development in game design",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " phrases indicating the learning and application of skills or concepts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggytrc7z4j10exsu95j5kf",
                        "tokens": [
                            " for",
                            " you",
                            " to",
                            " learn",
                            " will",
                            " propel",
                            " you",
                            " ahead",
                            " of",
                            " most",
                            " amateur",
                            " game",
                            " designers",
                            ".",
                            " Following",
                            " up",
                            " and",
                            " actually",
                            " trying",
                            " to",
                            " learn",
                            " it",
                            " will",
                            " take",
                            " you",
                            " even",
                            " further",
                            ".",
                            " There",
                            " is",
                            " so",
                            " much",
                            " good",
                            " rhetoric",
                            ",",
                            " much",
                            " of",
                            " it",
                            " freely",
                            " available",
                            " online",
                            ",",
                            " by",
                            " master",
                            " level",
                            " game",
                            " designers",
                            " from",
                            " popular",
                            " games",
                            " or",
                            " game",
                            " companies",
                            ".",
                            "\n",
                            "\n",
                            "Of",
                            " course",
                            ",",
                            " even",
                            " just",
                            " \u00e2\u0122",
                            "\u013e",
                            "learning",
                            "\u00e2\u0122",
                            "\u013f",
                            " or",
                            " \u00e2\u0122",
                            "\u013e",
                            "reading",
                            " about",
                            "\u00e2\u0122",
                            "\u013f",
                            " these",
                            " game",
                            " design",
                            " principles",
                            ",",
                            " and",
                            " understanding",
                            " them",
                            " on",
                            " an",
                            " intellectual",
                            " level",
                            ",",
                            " doesn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " necessarily",
                            " cement",
                            " them",
                            " as",
                            " an",
                            " able",
                            " tool",
                            " in",
                            " your",
                            " tool",
                            " kit",
                            ".",
                            " You",
                            " have",
                            " to",
                            " apply",
                            " the",
                            " principle",
                            ",",
                            " work",
                            " with",
                            " it",
                            ",",
                            " and",
                            " understand",
                            " it",
                            " at",
                            " its",
                            " essence",
                            " so",
                            " you",
                            " can",
                            " see",
                            " the",
                            " ways",
                            " in",
                            " which"
                        ],
                        "dataIndex": null,
                        "index": "43122",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.554,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.224,
                            6.926,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.48,
                            9.554,
                            1.9,
                            0,
                            1.835,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:26:42.936Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.554,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggytrd7z4t10ex7nmgztaz",
                        "tokens": [
                            " for",
                            " you",
                            " to",
                            " learn",
                            " will",
                            " propel",
                            " you",
                            " ahead",
                            " of",
                            " most",
                            " amateur",
                            " game",
                            " designers",
                            ".",
                            " Following",
                            " up",
                            " and",
                            " actually",
                            " trying",
                            " to",
                            " learn",
                            " it",
                            " will",
                            " take",
                            " you",
                            " even",
                            " further",
                            ".",
                            " There",
                            " is",
                            " so",
                            " much",
                            " good",
                            " rhetoric",
                            ",",
                            " much",
                            " of",
                            " it",
                            " freely",
                            " available",
                            " online",
                            ",",
                            " by",
                            " master",
                            " level",
                            " game",
                            " designers",
                            " from",
                            " popular",
                            " games",
                            " or",
                            " game",
                            " companies",
                            ".",
                            "\n",
                            "\n",
                            "Of",
                            " course",
                            ",",
                            " even",
                            " just",
                            " \u00e2\u0122",
                            "\u013e",
                            "learning",
                            "\u00e2\u0122",
                            "\u013f",
                            " or",
                            " \u00e2\u0122",
                            "\u013e",
                            "reading",
                            " about",
                            "\u00e2\u0122",
                            "\u013f",
                            " these",
                            " game",
                            " design",
                            " principles",
                            ",",
                            " and",
                            " understanding",
                            " them",
                            " on",
                            " an",
                            " intellectual",
                            " level",
                            ",",
                            " doesn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " necessarily",
                            " cement",
                            " them",
                            " as",
                            " an",
                            " able",
                            " tool",
                            " in",
                            " your",
                            " tool",
                            " kit",
                            ".",
                            " You",
                            " have",
                            " to",
                            " apply",
                            " the",
                            " principle",
                            ",",
                            " work",
                            " with",
                            " it",
                            ",",
                            " and",
                            " understand",
                            " it",
                            " at",
                            " its",
                            " essence",
                            " so",
                            " you",
                            " can",
                            " see",
                            " the",
                            " ways",
                            " in",
                            " which"
                        ],
                        "dataIndex": null,
                        "index": "43122",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.554,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.224,
                            6.926,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.48,
                            9.554,
                            1.9,
                            0,
                            1.835,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:26:42.936Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.554,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggytre7z5310ex78lhno9q",
                        "tokens": [
                            " for",
                            " you",
                            " to",
                            " learn",
                            " will",
                            " propel",
                            " you",
                            " ahead",
                            " of",
                            " most",
                            " amateur",
                            " game",
                            " designers",
                            ".",
                            " Following",
                            " up",
                            " and",
                            " actually",
                            " trying",
                            " to",
                            " learn",
                            " it",
                            " will",
                            " take",
                            " you",
                            " even",
                            " further",
                            ".",
                            " There",
                            " is",
                            " so",
                            " much",
                            " good",
                            " rhetoric",
                            ",",
                            " much",
                            " of",
                            " it",
                            " freely",
                            " available",
                            " online",
                            ",",
                            " by",
                            " master",
                            " level",
                            " game",
                            " designers",
                            " from",
                            " popular",
                            " games",
                            " or",
                            " game",
                            " companies",
                            ".",
                            "\n",
                            "\n",
                            "Of",
                            " course",
                            ",",
                            " even",
                            " just",
                            " \u00e2\u0122",
                            "\u013e",
                            "learning",
                            "\u00e2\u0122",
                            "\u013f",
                            " or",
                            " \u00e2\u0122",
                            "\u013e",
                            "reading",
                            " about",
                            "\u00e2\u0122",
                            "\u013f",
                            " these",
                            " game",
                            " design",
                            " principles",
                            ",",
                            " and",
                            " understanding",
                            " them",
                            " on",
                            " an",
                            " intellectual",
                            " level",
                            ",",
                            " doesn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " necessarily",
                            " cement",
                            " them",
                            " as",
                            " an",
                            " able",
                            " tool",
                            " in",
                            " your",
                            " tool",
                            " kit",
                            ".",
                            " You",
                            " have",
                            " to",
                            " apply",
                            " the",
                            " principle",
                            ",",
                            " work",
                            " with",
                            " it",
                            ",",
                            " and",
                            " understand",
                            " it",
                            " at",
                            " its",
                            " essence",
                            " so",
                            " you",
                            " can",
                            " see",
                            " the",
                            " ways",
                            " in",
                            " which"
                        ],
                        "dataIndex": null,
                        "index": "43122",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.554,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.224,
                            6.926,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.48,
                            9.554,
                            1.9,
                            0,
                            1.835,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:26:42.936Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 7.643,
                        "binMax": 9.554,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs768-jb",
            "index": "431",
            "description": "phrases related to training or education",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4600627148114025,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs768-jb",
                "index": "431",
                "sourceSetName": "res_fs768-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:36:08.148Z",
                "maxActApprox": 44.52,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    431,
                    541,
                    442,
                    441,
                    250,
                    339,
                    747,
                    408,
                    82,
                    426,
                    155,
                    337,
                    725,
                    554,
                    663,
                    334,
                    256,
                    94,
                    322,
                    714,
                    230,
                    99,
                    103,
                    523,
                    677
                ],
                "topkCosSimValues": [
                    1,
                    0.2066,
                    0.2012,
                    0.1925,
                    0.156,
                    0.1481,
                    0.1464,
                    0.1386,
                    0.1348,
                    0.1307,
                    0.1298,
                    0.1241,
                    0.124,
                    0.1235,
                    0.121,
                    0.1209,
                    0.1104,
                    0.1092,
                    0.1061,
                    0.1042,
                    0.1041,
                    0.1013,
                    0.1005,
                    0.1005,
                    0.1003
                ],
                "neuron_alignment_indices": [
                    575,
                    302,
                    679
                ],
                "neuron_alignment_values": [
                    0.143,
                    0.113,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    575,
                    288,
                    302
                ],
                "correlated_neurons_pearson": [
                    0.163,
                    0.159,
                    0.088
                ],
                "correlated_neurons_l1": [
                    0.197,
                    0.211,
                    0.11
                ],
                "correlated_features_indices": [
                    441,
                    442,
                    408
                ],
                "correlated_features_pearson": [
                    0.114,
                    0.084,
                    0.055
                ],
                "correlated_features_l1": [
                    0.132,
                    0.099,
                    0.069
                ],
                "neg_str": [
                    "bum",
                    "pard",
                    " Uruguay",
                    "adra",
                    " headlines",
                    " extrad",
                    "govtrack",
                    "caps",
                    " headline",
                    "rants"
                ],
                "neg_values": [
                    -0.679,
                    -0.633,
                    -0.629,
                    -0.609,
                    -0.6,
                    -0.598,
                    -0.589,
                    -0.581,
                    -0.58,
                    -0.578
                ],
                "pos_str": [
                    " instructors",
                    " regimen",
                    " manuals",
                    "learn",
                    "Learning",
                    " instructor",
                    " Instruct",
                    " instructional",
                    " manual",
                    " taught"
                ],
                "pos_values": [
                    1.026,
                    1.008,
                    0.989,
                    0.985,
                    0.964,
                    0.948,
                    0.93,
                    0.922,
                    0.91,
                    0.906
                ],
                "frac_nonzero": 0.05551,
                "freq_hist_data_bar_heights": [
                    59713,
                    37744,
                    24314,
                    15720,
                    10284,
                    6917,
                    4672,
                    3248,
                    2365,
                    1738,
                    1302,
                    1008,
                    907,
                    671,
                    538,
                    431,
                    355,
                    399,
                    310,
                    285,
                    251,
                    181,
                    193,
                    164,
                    132,
                    119,
                    95,
                    74,
                    63,
                    61,
                    44,
                    40,
                    41,
                    34,
                    39,
                    34,
                    34,
                    23,
                    19,
                    21,
                    13,
                    13,
                    7,
                    5,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.445,
                    1.336,
                    2.226,
                    3.116,
                    4.007,
                    4.897,
                    5.788,
                    6.678,
                    7.568,
                    8.459,
                    9.349,
                    10.24,
                    11.13,
                    12.02,
                    12.911,
                    13.801,
                    14.692,
                    15.582,
                    16.472,
                    17.363,
                    18.253,
                    19.144,
                    20.034,
                    20.924,
                    21.815,
                    22.705,
                    23.596,
                    24.486,
                    25.376,
                    26.267,
                    27.157,
                    28.048,
                    28.938,
                    29.828,
                    30.719,
                    31.609,
                    32.5,
                    33.39,
                    34.28,
                    35.171,
                    36.061,
                    36.952,
                    37.842,
                    38.732,
                    39.623,
                    40.513,
                    41.404,
                    42.294,
                    43.184,
                    44.075
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    8,
                    5,
                    20,
                    45,
                    81,
                    148,
                    260,
                    360,
                    561,
                    878,
                    1251,
                    1750,
                    2333,
                    3005,
                    3455,
                    4059,
                    4220,
                    4232,
                    3953,
                    3812,
                    3336,
                    2855,
                    2288,
                    1795,
                    1485,
                    1092,
                    826,
                    615,
                    429,
                    292,
                    234,
                    144,
                    112,
                    79,
                    57,
                    42,
                    32,
                    25,
                    15,
                    20,
                    16,
                    6,
                    8,
                    3,
                    5,
                    2,
                    3,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.662,
                    -0.628,
                    -0.594,
                    -0.56,
                    -0.526,
                    -0.492,
                    -0.458,
                    -0.423,
                    -0.389,
                    -0.355,
                    -0.321,
                    -0.287,
                    -0.253,
                    -0.219,
                    -0.185,
                    -0.15,
                    -0.116,
                    -0.082,
                    -0.048,
                    -0.014,
                    0.02,
                    0.054,
                    0.088,
                    0.122,
                    0.157,
                    0.191,
                    0.225,
                    0.259,
                    0.293,
                    0.327,
                    0.361,
                    0.395,
                    0.429,
                    0.464,
                    0.498,
                    0.532,
                    0.566,
                    0.6,
                    0.634,
                    0.668,
                    0.702,
                    0.737,
                    0.771,
                    0.805,
                    0.839,
                    0.873,
                    0.907,
                    0.941,
                    0.975,
                    1.009
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases related to training or education",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdnud8dnrxvi666j9sxouzk",
                        "tokens": [
                            "Michigan",
                            "'s",
                            " governor",
                            " has",
                            " made",
                            " it",
                            " legal",
                            " for",
                            " holders",
                            " of",
                            " concealed",
                            "-",
                            "carry",
                            " permits",
                            " to",
                            " also",
                            " pack",
                            " electric",
                            " heat",
                            " for",
                            " self",
                            "-",
                            "defense",
                            ",",
                            " the",
                            " Detroit",
                            " Free",
                            " Press",
                            " reports",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " state",
                            " joins",
                            " 44",
                            " others",
                            " that",
                            " allow",
                            " the",
                            " carrying",
                            " of",
                            " T",
                            "asers",
                            " and",
                            " other",
                            " brands",
                            " of",
                            " stun",
                            " guns",
                            ".",
                            "\n",
                            "\n",
                            "Gov",
                            ".",
                            " Rick",
                            " Snyder",
                            ",",
                            " a",
                            " Republican",
                            ",",
                            " signed",
                            " the",
                            " bipartisan",
                            " legislation",
                            " that",
                            " allows",
                            " licensed",
                            " Mich",
                            "ig",
                            "anders",
                            " to",
                            " carry",
                            " single",
                            "-",
                            "shot",
                            ",",
                            " consumer",
                            "-",
                            "grade",
                            ",",
                            " non",
                            "-",
                            "lethal",
                            " stun",
                            " guns",
                            " after",
                            " completing",
                            " additional",
                            " training",
                            ".",
                            " The",
                            " laws",
                            " are",
                            " the",
                            " same",
                            " as",
                            " those",
                            " for",
                            " carrying",
                            " a",
                            " handgun",
                            ".",
                            "\n",
                            "\n",
                            "As",
                            " of",
                            " last",
                            " October",
                            ",",
                            " the",
                            " Michigan",
                            " State",
                            " Police",
                            " said",
                            " there",
                            " were",
                            " more",
                            " than",
                            " 286",
                            ",",
                            "000",
                            " Michigan",
                            " residents",
                            " with",
                            " valid",
                            " concealed"
                        ],
                        "dataIndex": null,
                        "index": "431",
                        "layer": "8-res_fs768-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.52,
                        "maxValueTokenIndex": 89,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.355,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.162,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.191,
                            0,
                            0,
                            0,
                            0,
                            4.659,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.526,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.331,
                            0,
                            0,
                            0,
                            0,
                            4.599,
                            0,
                            0,
                            0,
                            0,
                            44.52,
                            1.125,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.226,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:36:11.322Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 44.52,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdnud8fnryhi666jig45gpc",
                        "tokens": [
                            "Michigan",
                            "'s",
                            " governor",
                            " has",
                            " made",
                            " it",
                            " legal",
                            " for",
                            " holders",
                            " of",
                            " concealed",
                            "-",
                            "carry",
                            " permits",
                            " to",
                            " also",
                            " pack",
                            " electric",
                            " heat",
                            " for",
                            " self",
                            "-",
                            "defense",
                            ",",
                            " the",
                            " Detroit",
                            " Free",
                            " Press",
                            " reports",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " state",
                            " joins",
                            " 44",
                            " others",
                            " that",
                            " allow",
                            " the",
                            " carrying",
                            " of",
                            " T",
                            "asers",
                            " and",
                            " other",
                            " brands",
                            " of",
                            " stun",
                            " guns",
                            ".",
                            "\n",
                            "\n",
                            "Gov",
                            ".",
                            " Rick",
                            " Snyder",
                            ",",
                            " a",
                            " Republican",
                            ",",
                            " signed",
                            " the",
                            " bipartisan",
                            " legislation",
                            " that",
                            " allows",
                            " licensed",
                            " Mich",
                            "ig",
                            "anders",
                            " to",
                            " carry",
                            " single",
                            "-",
                            "shot",
                            ",",
                            " consumer",
                            "-",
                            "grade",
                            ",",
                            " non",
                            "-",
                            "lethal",
                            " stun",
                            " guns",
                            " after",
                            " completing",
                            " additional",
                            " training",
                            ".",
                            " The",
                            " laws",
                            " are",
                            " the",
                            " same",
                            " as",
                            " those",
                            " for",
                            " carrying",
                            " a",
                            " handgun",
                            ".",
                            "\n",
                            "\n",
                            "As",
                            " of",
                            " last",
                            " October",
                            ",",
                            " the",
                            " Michigan",
                            " State",
                            " Police",
                            " said",
                            " there",
                            " were",
                            " more",
                            " than",
                            " 286",
                            ",",
                            "000",
                            " Michigan",
                            " residents",
                            " with",
                            " valid",
                            " concealed"
                        ],
                        "dataIndex": null,
                        "index": "431",
                        "layer": "8-res_fs768-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.52,
                        "maxValueTokenIndex": 89,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.355,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.162,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.191,
                            0,
                            0,
                            0,
                            0,
                            4.659,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.526,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.331,
                            0,
                            0,
                            0,
                            0,
                            4.599,
                            0,
                            0,
                            0,
                            0,
                            44.52,
                            1.125,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.226,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:36:11.322Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 35.616,
                        "binMax": 44.52,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdnud8dnrxwi6663g34dfqa",
                        "tokens": [
                            " them",
                            " to",
                            " carry",
                            " weapons",
                            " around",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Whit",
                            "lock",
                            " says",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "And",
                            " NC",
                            "IS",
                            " \u00e2\u0122\u00a6",
                            " did",
                            " a",
                            " search",
                            " warrant",
                            " on",
                            " their",
                            " office",
                            " at",
                            " the",
                            " Pentagon",
                            ".",
                            " But",
                            " as",
                            " part",
                            " of",
                            " that",
                            " investigation",
                            ",",
                            " they",
                            " found",
                            " that",
                            " this",
                            " small",
                            " group",
                            " of",
                            " civilians",
                            " at",
                            " the",
                            " Pentagon",
                            " were",
                            " involved",
                            " in",
                            " some",
                            " kind",
                            " of",
                            " secret",
                            " weapons",
                            " program",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Al",
                            "leg",
                            "edly",
                            ",",
                            " the",
                            " intelligence",
                            " officers",
                            " were",
                            " setting",
                            " up",
                            " a",
                            " type",
                            " of",
                            " training",
                            " camp",
                            " at",
                            " Circle",
                            " Ranch",
                            " in",
                            " west",
                            " Texas",
                            ",",
                            " but",
                            " not",
                            " much",
                            " more",
                            " than",
                            " that",
                            " is",
                            " known",
                            ".",
                            " There",
                            " is",
                            " speculation",
                            ",",
                            " however",
                            ",",
                            " that",
                            " the",
                            " case",
                            " might",
                            " have",
                            " something",
                            " to",
                            " do",
                            " with",
                            " counter",
                            "-",
                            "n",
                            "arc",
                            "otics",
                            " \u2013",
                            " drug",
                            " investigations",
                            " or",
                            " training",
                            " people",
                            " along",
                            " the",
                            " border",
                            " how",
                            " to",
                            " look",
                            " out",
                            " for",
                            " Mexican"
                        ],
                        "dataIndex": null,
                        "index": "431",
                        "layer": "8-res_fs768-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.368,
                        "maxValueTokenIndex": 74,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.92,
                            1.628,
                            0,
                            0,
                            0.946,
                            0,
                            0,
                            0,
                            40.368,
                            9.347,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            36.3,
                            0.767,
                            0.674,
                            0.406,
                            0,
                            8.786,
                            11.344,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:36:11.322Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 44.52,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "1872",
            "description": "phrases related to training or education",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.460001677274704,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "1872",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:46:55.038Z",
                "maxActApprox": 14.36,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    1872,
                    15744,
                    2165,
                    8676,
                    1959,
                    17345,
                    15504,
                    24326,
                    3815,
                    2943,
                    18279,
                    5288,
                    16659,
                    19023,
                    4961,
                    7082,
                    17021,
                    13386,
                    21762,
                    7495,
                    3397,
                    11355,
                    3647,
                    10535,
                    16007
                ],
                "topkCosSimValues": [
                    1,
                    0.3787,
                    0.3769,
                    0.3653,
                    0.3649,
                    0.3171,
                    0.3088,
                    0.3084,
                    0.308,
                    0.3079,
                    0.3044,
                    0.2979,
                    0.2973,
                    0.2938,
                    0.2932,
                    0.2864,
                    0.2819,
                    0.2807,
                    0.2804,
                    0.28,
                    0.2799,
                    0.2774,
                    0.2747,
                    0.2738,
                    0.2737
                ],
                "neuron_alignment_indices": [
                    362,
                    640,
                    124
                ],
                "neuron_alignment_values": [
                    0.149,
                    0.126,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.004
                ],
                "correlated_neurons_indices": [
                    362,
                    608,
                    257
                ],
                "correlated_neurons_pearson": [
                    0.07,
                    0.041,
                    0.039
                ],
                "correlated_neurons_l1": [
                    0.077,
                    0.054,
                    0.034
                ],
                "correlated_features_indices": [
                    1886,
                    1830,
                    1799
                ],
                "correlated_features_pearson": [
                    0.033,
                    0.008,
                    0.005
                ],
                "correlated_features_l1": [
                    0.034,
                    0.008,
                    0.008
                ],
                "neg_str": [
                    "phabet",
                    "bernatorial",
                    "INAL",
                    " represents",
                    "\u00e3\u0125\u012b\u00e3\u0125\u00a9",
                    "DonaldTrump",
                    "ItemImage",
                    "!--",
                    "Population",
                    "OT"
                ],
                "neg_values": [
                    -0.848,
                    -0.812,
                    -0.767,
                    -0.735,
                    -0.713,
                    -0.696,
                    -0.689,
                    -0.688,
                    -0.685,
                    -0.662
                ],
                "pos_str": [
                    " laboratories",
                    " nearby",
                    " Buenos",
                    " acad",
                    " makeshift",
                    " labs",
                    " semin",
                    " university",
                    "graduate",
                    " Marin"
                ],
                "pos_values": [
                    0.816,
                    0.786,
                    0.781,
                    0.76,
                    0.741,
                    0.736,
                    0.734,
                    0.729,
                    0.71,
                    0.698
                ],
                "frac_nonzero": 0.00343,
                "freq_hist_data_bar_heights": [
                    2013,
                    1609,
                    1210,
                    1064,
                    871,
                    726,
                    553,
                    469,
                    387,
                    322,
                    250,
                    207,
                    166,
                    146,
                    121,
                    96,
                    92,
                    67,
                    71,
                    55,
                    27,
                    42,
                    29,
                    22,
                    17,
                    14,
                    23,
                    10,
                    9,
                    19,
                    12,
                    7,
                    8,
                    5,
                    5,
                    5,
                    1,
                    3,
                    3,
                    4,
                    6,
                    1,
                    0,
                    2,
                    3,
                    1,
                    0,
                    1,
                    2,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.144,
                    0.431,
                    0.718,
                    1.005,
                    1.292,
                    1.58,
                    1.867,
                    2.154,
                    2.441,
                    2.729,
                    3.016,
                    3.303,
                    3.59,
                    3.877,
                    4.165,
                    4.452,
                    4.739,
                    5.026,
                    5.313,
                    5.601,
                    5.888,
                    6.175,
                    6.462,
                    6.749,
                    7.037,
                    7.324,
                    7.611,
                    7.898,
                    8.185,
                    8.473,
                    8.76,
                    9.047,
                    9.334,
                    9.622,
                    9.909,
                    10.196,
                    10.483,
                    10.77,
                    11.058,
                    11.345,
                    11.632,
                    11.919,
                    12.206,
                    12.494,
                    12.781,
                    13.068,
                    13.355,
                    13.642,
                    13.93,
                    14.217
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    1,
                    1,
                    5,
                    4,
                    7,
                    16,
                    34,
                    69,
                    106,
                    149,
                    258,
                    392,
                    560,
                    831,
                    1121,
                    1446,
                    1860,
                    2202,
                    2555,
                    2765,
                    2879,
                    3272,
                    3293,
                    3279,
                    3229,
                    3158,
                    2882,
                    2633,
                    2328,
                    2069,
                    1708,
                    1360,
                    1043,
                    869,
                    632,
                    419,
                    292,
                    184,
                    146,
                    70,
                    53,
                    30,
                    21,
                    12,
                    4,
                    4,
                    2,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.831,
                    -0.798,
                    -0.765,
                    -0.732,
                    -0.698,
                    -0.665,
                    -0.632,
                    -0.598,
                    -0.565,
                    -0.532,
                    -0.499,
                    -0.465,
                    -0.432,
                    -0.399,
                    -0.365,
                    -0.332,
                    -0.299,
                    -0.266,
                    -0.232,
                    -0.199,
                    -0.166,
                    -0.132,
                    -0.099,
                    -0.066,
                    -0.033,
                    0.001,
                    0.034,
                    0.067,
                    0.101,
                    0.134,
                    0.167,
                    0.2,
                    0.234,
                    0.267,
                    0.3,
                    0.334,
                    0.367,
                    0.4,
                    0.433,
                    0.467,
                    0.5,
                    0.533,
                    0.567,
                    0.6,
                    0.633,
                    0.666,
                    0.7,
                    0.733,
                    0.766,
                    0.8
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases related to training or education",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdm347v1rzui666c38uzbvv",
                        "tokens": [
                            " in",
                            " August",
                            " at",
                            " Na",
                            "as",
                            " in",
                            " Ireland",
                            ",",
                            " and",
                            " presumably",
                            " Hor",
                            "ace",
                            " proceeded",
                            " there",
                            " to",
                            " commence",
                            " his",
                            " training",
                            " at",
                            " the",
                            " Cur",
                            "r",
                            "agh",
                            " in",
                            " County",
                            " K",
                            "ild",
                            "are",
                            ".",
                            " The",
                            " 30",
                            "th",
                            " Brigade",
                            " moved",
                            " to",
                            " Dublin",
                            " in",
                            " February",
                            " 1915",
                            " and",
                            " then",
                            " embarked",
                            " for",
                            " England",
                            " in",
                            " May",
                            " 1915",
                            " and",
                            " onto",
                            " the",
                            " B",
                            "asing",
                            "st",
                            "oke",
                            " area",
                            ",",
                            " where",
                            " intensive",
                            " training",
                            " of",
                            " the",
                            " 10",
                            "th",
                            " Division",
                            " took",
                            " place",
                            " for",
                            " the",
                            " next",
                            " 3",
                            " months",
                            ".",
                            " During",
                            " that",
                            " time",
                            ",",
                            " the",
                            " division",
                            " was",
                            " inspected",
                            " by",
                            " King",
                            " George",
                            " V",
                            " on",
                            " 28",
                            " May",
                            " at",
                            " Hack",
                            "wood",
                            " Park",
                            " and",
                            " by",
                            " Field",
                            " Marshal",
                            ",",
                            " Lord",
                            " Kitchen",
                            "er",
                            " on",
                            " 1",
                            " June",
                            ".",
                            "\n",
                            "\n",
                            "As",
                            " a",
                            " result",
                            " of",
                            " these",
                            " inspections",
                            " the",
                            " following",
                            " division",
                            "al",
                            " orders",
                            " were",
                            " issued",
                            ":",
                            "\n",
                            "\n",
                            "\"",
                            "Lie",
                            "utenant",
                            "-",
                            "General",
                            " Sir"
                        ],
                        "dataIndex": null,
                        "index": "1872",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.36,
                        "maxValueTokenIndex": 18,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.36,
                            9.406,
                            0,
                            0,
                            0,
                            2.902,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.805,
                            5.145,
                            6.836,
                            0,
                            0,
                            0,
                            3.107,
                            4.734,
                            5.228,
                            3.688,
                            0.019,
                            0,
                            0.407,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.761,
                            0,
                            0,
                            0,
                            3.418,
                            0,
                            0,
                            1.737,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.542,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:47:00.325Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 14.36,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdm347y1s0li666u2hk9z0b",
                        "tokens": [
                            " in",
                            " August",
                            " at",
                            " Na",
                            "as",
                            " in",
                            " Ireland",
                            ",",
                            " and",
                            " presumably",
                            " Hor",
                            "ace",
                            " proceeded",
                            " there",
                            " to",
                            " commence",
                            " his",
                            " training",
                            " at",
                            " the",
                            " Cur",
                            "r",
                            "agh",
                            " in",
                            " County",
                            " K",
                            "ild",
                            "are",
                            ".",
                            " The",
                            " 30",
                            "th",
                            " Brigade",
                            " moved",
                            " to",
                            " Dublin",
                            " in",
                            " February",
                            " 1915",
                            " and",
                            " then",
                            " embarked",
                            " for",
                            " England",
                            " in",
                            " May",
                            " 1915",
                            " and",
                            " onto",
                            " the",
                            " B",
                            "asing",
                            "st",
                            "oke",
                            " area",
                            ",",
                            " where",
                            " intensive",
                            " training",
                            " of",
                            " the",
                            " 10",
                            "th",
                            " Division",
                            " took",
                            " place",
                            " for",
                            " the",
                            " next",
                            " 3",
                            " months",
                            ".",
                            " During",
                            " that",
                            " time",
                            ",",
                            " the",
                            " division",
                            " was",
                            " inspected",
                            " by",
                            " King",
                            " George",
                            " V",
                            " on",
                            " 28",
                            " May",
                            " at",
                            " Hack",
                            "wood",
                            " Park",
                            " and",
                            " by",
                            " Field",
                            " Marshal",
                            ",",
                            " Lord",
                            " Kitchen",
                            "er",
                            " on",
                            " 1",
                            " June",
                            ".",
                            "\n",
                            "\n",
                            "As",
                            " a",
                            " result",
                            " of",
                            " these",
                            " inspections",
                            " the",
                            " following",
                            " division",
                            "al",
                            " orders",
                            " were",
                            " issued",
                            ":",
                            "\n",
                            "\n",
                            "\"",
                            "Lie",
                            "utenant",
                            "-",
                            "General",
                            " Sir"
                        ],
                        "dataIndex": null,
                        "index": "1872",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.36,
                        "maxValueTokenIndex": 18,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.36,
                            9.406,
                            0,
                            0,
                            0,
                            2.902,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.805,
                            5.145,
                            6.836,
                            0,
                            0,
                            0,
                            3.107,
                            4.734,
                            5.228,
                            3.688,
                            0.019,
                            0,
                            0.407,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.761,
                            0,
                            0,
                            0,
                            3.418,
                            0,
                            0,
                            1.737,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.542,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:47:00.325Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 8.616,
                        "binMax": 11.488,
                        "binContains": 2e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdm347v1rzvi666mkjth1ge",
                        "tokens": [
                            "Story",
                            " highlights",
                            " B",
                            "oun",
                            "a",
                            " C",
                            "ound",
                            "oul",
                            " is",
                            " New",
                            " York",
                            " Red",
                            " Bulls",
                            "'",
                            " Sen",
                            "eg",
                            "ales",
                            "e",
                            " goalkeeper",
                            "\n",
                            "\n",
                            "He",
                            " moved",
                            " to",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " aged",
                            " 14",
                            ",",
                            " where",
                            " his",
                            " talents",
                            " were",
                            " spotted",
                            " in",
                            " high",
                            " school",
                            "\n",
                            "\n",
                            "He",
                            "'s",
                            " created",
                            " the",
                            " '",
                            "B",
                            "oun",
                            "a",
                            " Time",
                            " Academy",
                            "'",
                            " in",
                            " Senegal",
                            "\n",
                            "\n",
                            "Now",
                            " goalkeeper",
                            " for",
                            " the",
                            " New",
                            " York",
                            " Red",
                            " Bulls",
                            ",",
                            " as",
                            " a",
                            " child",
                            " growing",
                            " up",
                            " in",
                            " Senegal",
                            ",",
                            " B",
                            "oun",
                            "a",
                            " C",
                            "ound",
                            "oul",
                            " could",
                            " only",
                            " dream",
                            " of",
                            " being",
                            " a",
                            " professional",
                            " footballer",
                            ".",
                            "\n",
                            "\n",
                            "At",
                            " the",
                            " age",
                            " of",
                            " 14",
                            " C",
                            "ound",
                            "oul",
                            " was",
                            " sent",
                            " to",
                            " study",
                            " in",
                            " the",
                            " unfamiliar",
                            " surroundings",
                            " of",
                            " New",
                            " York",
                            ".",
                            " But",
                            " his",
                            " passion",
                            " for",
                            " football",
                            " followed",
                            " him",
                            " across",
                            " the",
                            " Atlantic",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "When",
                            " I"
                        ],
                        "dataIndex": null,
                        "index": "1872",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.336,
                        "maxValueTokenIndex": 103,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.495,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.656,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.705,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.336,
                            8.347,
                            0,
                            0,
                            1.868,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:47:00.325Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 14.36,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "41576",
            "description": "phrases indicating actions or objectives involving learning or improvement",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4597169893895685,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "41576",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:13:06.026Z",
                "maxActApprox": 62.788,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    41576,
                    18775,
                    36731,
                    5654,
                    31347,
                    6087,
                    36176,
                    25636,
                    3007,
                    28780,
                    18793,
                    7145,
                    3071,
                    30498,
                    44523,
                    32350,
                    22913,
                    41070,
                    14572,
                    19723,
                    30047,
                    4177,
                    7696,
                    27883,
                    41395
                ],
                "topkCosSimValues": [
                    1,
                    0.5689,
                    0.5684,
                    0.5371,
                    0.486,
                    0.4859,
                    0.4844,
                    0.4798,
                    0.4751,
                    0.4638,
                    0.459,
                    0.4583,
                    0.4425,
                    0.4411,
                    0.4403,
                    0.4303,
                    0.4225,
                    0.4205,
                    0.417,
                    0.416,
                    0.4155,
                    0.414,
                    0.411,
                    0.4098,
                    0.4095
                ],
                "neuron_alignment_indices": [
                    608,
                    665,
                    718
                ],
                "neuron_alignment_values": [
                    0.13,
                    0.125,
                    0.109
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    665,
                    718,
                    49
                ],
                "correlated_neurons_pearson": [
                    0.024,
                    0.02,
                    0.02
                ],
                "correlated_neurons_l1": [
                    0.025,
                    0.022,
                    0.021
                ],
                "correlated_features_indices": [
                    41541,
                    41581,
                    41576
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "lights",
                    "listed",
                    "holder",
                    "teen",
                    " Hartford",
                    "isite",
                    " Coff",
                    " Appears",
                    "quished",
                    "prem"
                ],
                "neg_values": [
                    -0.885,
                    -0.743,
                    -0.725,
                    -0.724,
                    -0.698,
                    -0.694,
                    -0.684,
                    -0.678,
                    -0.658,
                    -0.64
                ],
                "pos_str": [
                    " differentiate",
                    " cope",
                    " recognize",
                    " behave",
                    " manipulate",
                    " tolerate",
                    " wrestle",
                    " imitate",
                    " distinguish",
                    " identify"
                ],
                "pos_values": [
                    1.281,
                    1.26,
                    1.237,
                    1.231,
                    1.163,
                    1.153,
                    1.143,
                    1.127,
                    1.126,
                    1.1
                ],
                "frac_nonzero": 0.0004,
                "freq_hist_data_bar_heights": [
                    472,
                    233,
                    123,
                    85,
                    49,
                    40,
                    26,
                    18,
                    20,
                    12,
                    11,
                    14,
                    10,
                    11,
                    10,
                    10,
                    12,
                    7,
                    7,
                    5,
                    9,
                    3,
                    4,
                    3,
                    3,
                    3,
                    3,
                    0,
                    3,
                    1,
                    2,
                    4,
                    1,
                    3,
                    0,
                    0,
                    2,
                    3,
                    1,
                    5,
                    6,
                    1,
                    2,
                    4,
                    3,
                    5,
                    2,
                    2,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.628,
                    1.884,
                    3.14,
                    4.395,
                    5.651,
                    6.907,
                    8.163,
                    9.418,
                    10.674,
                    11.93,
                    13.186,
                    14.441,
                    15.697,
                    16.953,
                    18.209,
                    19.464,
                    20.72,
                    21.976,
                    23.232,
                    24.487,
                    25.743,
                    26.999,
                    28.255,
                    29.51,
                    30.766,
                    32.022,
                    33.278,
                    34.534,
                    35.789,
                    37.045,
                    38.301,
                    39.557,
                    40.812,
                    42.068,
                    43.324,
                    44.58,
                    45.835,
                    47.091,
                    48.347,
                    49.603,
                    50.858,
                    52.114,
                    53.37,
                    54.626,
                    55.881,
                    57.137,
                    58.393,
                    59.649,
                    60.905,
                    62.16
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    3,
                    4,
                    3,
                    16,
                    34,
                    67,
                    143,
                    306,
                    507,
                    898,
                    1434,
                    2111,
                    2845,
                    3581,
                    4250,
                    4472,
                    4508,
                    4469,
                    4062,
                    3482,
                    3017,
                    2374,
                    1867,
                    1482,
                    1080,
                    741,
                    588,
                    445,
                    321,
                    237,
                    175,
                    165,
                    125,
                    105,
                    95,
                    71,
                    51,
                    39,
                    26,
                    23,
                    9,
                    11,
                    5,
                    3,
                    2,
                    2,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.863,
                    -0.82,
                    -0.777,
                    -0.733,
                    -0.69,
                    -0.647,
                    -0.603,
                    -0.56,
                    -0.517,
                    -0.473,
                    -0.43,
                    -0.387,
                    -0.344,
                    -0.3,
                    -0.257,
                    -0.214,
                    -0.17,
                    -0.127,
                    -0.084,
                    -0.04,
                    0.003,
                    0.046,
                    0.09,
                    0.133,
                    0.176,
                    0.22,
                    0.263,
                    0.306,
                    0.35,
                    0.393,
                    0.436,
                    0.48,
                    0.523,
                    0.566,
                    0.609,
                    0.653,
                    0.696,
                    0.739,
                    0.783,
                    0.826,
                    0.869,
                    0.913,
                    0.956,
                    0.999,
                    1.043,
                    1.086,
                    1.129,
                    1.173,
                    1.216,
                    1.259
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases indicating actions or objectives involving learning or improvement",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk6sgccdz0ri666fmmqiany",
                        "tokens": [
                            "When",
                            " we",
                            " enter",
                            " the",
                            " political",
                            " debate",
                            " sphere",
                            " of",
                            " the",
                            " online",
                            " world",
                            ",",
                            " I",
                            " think",
                            " we",
                            " consider",
                            " people",
                            " holding",
                            " these",
                            " beliefs",
                            " to",
                            " be",
                            " unreal",
                            ".",
                            " The",
                            " information",
                            " age",
                            " means",
                            " almost",
                            " anybody",
                            " can",
                            " become",
                            " informed",
                            " about",
                            " any",
                            " topic",
                            ",",
                            " right",
                            "?",
                            " Someone",
                            " who",
                            " believes",
                            " in",
                            " these",
                            " conspir",
                            "acies",
                            " has",
                            " got",
                            " to",
                            " be",
                            " a",
                            " troll",
                            " or",
                            " using",
                            " their",
                            " anonymity",
                            " to",
                            " esp",
                            "ouse",
                            " harmful",
                            " beliefs",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " never",
                            " talk",
                            " about",
                            " in",
                            "-",
                            "person",
                            ".",
                            " They",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " an",
                            " ed",
                            "gy",
                            " teenager",
                            ",",
                            " a",
                            " kid",
                            " who",
                            " hasn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " learned",
                            " to",
                            " navigate",
                            " the",
                            " harmful",
                            " tra",
                            "ppings",
                            " of",
                            " the",
                            " internet",
                            ";",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " an",
                            " old",
                            " cod",
                            "ger",
                            ",",
                            " still",
                            " holding",
                            " onto",
                            " the",
                            " good",
                            " old",
                            " days",
                            " where",
                            " they",
                            " had",
                            " all",
                            " the",
                            " privilege",
                            ";",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " just"
                        ],
                        "dataIndex": null,
                        "index": "41576",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 62.788,
                        "maxValueTokenIndex": 89,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            62.788,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:13:11.369Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 62.788,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6sgccdz0si666fs9w3arf",
                        "tokens": [
                            " flight",
                            ",",
                            " Kim",
                            " can",
                            " make",
                            " the",
                            " US",
                            " considerably",
                            " less",
                            " likely",
                            " to",
                            " launch",
                            " a",
                            " nuclear",
                            " attack",
                            " against",
                            " him",
                            " no",
                            " matter",
                            " what",
                            " else",
                            " he",
                            " does",
                            ",",
                            " as",
                            " well",
                            " as",
                            " give",
                            " him",
                            " more",
                            " bargaining",
                            " power",
                            " at",
                            " the",
                            " table",
                            ".",
                            "\n",
                            "\n",
                            "0",
                            ":",
                            "00",
                            " The",
                            " three",
                            " latest",
                            " Inter",
                            "continental",
                            " Ballistic",
                            " Missile",
                            " tests",
                            " by",
                            " North",
                            " Korea",
                            ".",
                            " 00",
                            ":",
                            "00",
                            " /",
                            " 00",
                            ":",
                            "00",
                            " Share",
                            " Share",
                            " on",
                            " Twitter",
                            "\n",
                            "\n",
                            "Share",
                            " on",
                            " Facebook",
                            "\n",
                            "\n",
                            "The",
                            " security",
                            " dilemma",
                            "\n",
                            "\n",
                            "In",
                            " some",
                            " ways",
                            " the",
                            " world",
                            " has",
                            " begun",
                            " to",
                            " accept",
                            " Kim",
                            "'s",
                            " logic",
                            ":",
                            " more",
                            " western",
                            " experts",
                            " have",
                            " been",
                            " arguing",
                            " the",
                            " once",
                            "-",
                            "un",
                            "thinkable",
                            ":",
                            " that",
                            " the",
                            " west",
                            " will",
                            " have",
                            " to",
                            " learn",
                            " to",
                            " live",
                            " with",
                            " nuclear",
                            "-",
                            "armed",
                            " North",
                            " Korea",
                            ".",
                            " This",
                            " argument",
                            " is",
                            " well",
                            " laid",
                            " out",
                            " here",
                            " in",
                            " Foreign",
                            " Policy"
                        ],
                        "dataIndex": null,
                        "index": "41576",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.869,
                        "maxValueTokenIndex": 108,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.869,
                            10.644,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:13:11.369Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 62.788,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6sgccdz0ti666xfpukv3r",
                        "tokens": [
                            "\u013b",
                            "t",
                            " reapp",
                            "ear",
                            " for",
                            " about",
                            " 20",
                            " years",
                            ".",
                            " Compos",
                            "ers",
                            " or",
                            " performers",
                            " of",
                            " concert",
                            "os",
                            " could",
                            " hire",
                            " theater",
                            " orchestr",
                            "as",
                            " in",
                            " Vienna",
                            ",",
                            " but",
                            " they",
                            " played",
                            " badly",
                            ".",
                            "\n",
                            "\n",
                            "No",
                            " other",
                            " cities",
                            " in",
                            " Europe",
                            " had",
                            " enough",
                            " influence",
                            " to",
                            " put",
                            " their",
                            " resident",
                            " compos",
                            "ers",
                            " on",
                            " the",
                            " international",
                            " stage",
                            ".",
                            "\n",
                            "\n",
                            "By",
                            " the",
                            " time",
                            " concert",
                            " life",
                            " revived",
                            " in",
                            " these",
                            " capitals",
                            ",",
                            " Hay",
                            "dn",
                            " and",
                            " Moz",
                            "art",
                            " were",
                            " dead",
                            ".",
                            " There",
                            " was",
                            " no",
                            " logical",
                            " successor",
                            " to",
                            " Be",
                            "eth",
                            "oven",
                            ".",
                            " After",
                            " all",
                            ",",
                            " why",
                            " would",
                            " anyone",
                            " learn",
                            " to",
                            " compose",
                            " that",
                            " kind",
                            " of",
                            " music",
                            "?",
                            " They",
                            " couldn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " get",
                            " it",
                            " heard",
                            " with",
                            " no",
                            " concert",
                            " life",
                            ".",
                            "\n",
                            "\n",
                            "Twenty",
                            " years",
                            " later",
                            ",",
                            " mass",
                            " audiences",
                            " no",
                            " longer",
                            " remembered",
                            " how",
                            " to",
                            " listen",
                            " to",
                            " that",
                            " music",
                            ".",
                            "\n",
                            "\n"
                        ],
                        "dataIndex": null,
                        "index": "41576",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.204,
                        "maxValueTokenIndex": 87,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.204,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.712,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:13:11.369Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 62.788,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "24144",
            "description": " activities related to practical skills or tasks",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.45790162682533264,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "24144",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:42:05.035Z",
                "maxActApprox": 16.154,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    24144,
                    28025,
                    37774,
                    39148,
                    16232,
                    14135,
                    9445,
                    31299,
                    33929,
                    9355,
                    34418,
                    15343,
                    7136,
                    38404,
                    18111,
                    22557,
                    18693,
                    8529,
                    13683,
                    43282,
                    43612,
                    7460,
                    36658,
                    41555,
                    7271
                ],
                "topkCosSimValues": [
                    1,
                    0.7273,
                    0.691,
                    0.6308,
                    0.6214,
                    0.619,
                    0.609,
                    0.6027,
                    0.5776,
                    0.5692,
                    0.569,
                    0.5689,
                    0.5674,
                    0.5642,
                    0.5528,
                    0.5433,
                    0.5398,
                    0.5334,
                    0.5333,
                    0.5242,
                    0.5124,
                    0.5082,
                    0.4997,
                    0.4988,
                    0.4823
                ],
                "neuron_alignment_indices": [
                    216,
                    481,
                    17
                ],
                "neuron_alignment_values": [
                    0.114,
                    0.107,
                    0.104
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    216,
                    288,
                    524
                ],
                "correlated_neurons_pearson": [
                    0.047,
                    0.046,
                    0.039
                ],
                "correlated_neurons_l1": [
                    0.048,
                    0.052,
                    0.041
                ],
                "correlated_features_indices": [
                    24032,
                    24119,
                    24027
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.003,
                    0.002,
                    0.001
                ],
                "neg_str": [
                    "ivic",
                    "uate",
                    "ifies",
                    "zynski",
                    "udos",
                    "ridges",
                    "ighed",
                    "rition",
                    "mented",
                    "iosis"
                ],
                "neg_values": [
                    -0.793,
                    -0.776,
                    -0.765,
                    -0.747,
                    -0.747,
                    -0.747,
                    -0.737,
                    -0.719,
                    -0.714,
                    -0.704
                ],
                "pos_str": [
                    " prowess",
                    " spree",
                    " apparatus",
                    " process",
                    " mechanism",
                    " habits",
                    " technique",
                    " ability",
                    " regimen",
                    " experience"
                ],
                "pos_values": [
                    1.148,
                    1.091,
                    1.075,
                    1.056,
                    1.028,
                    1.014,
                    1.011,
                    0.971,
                    0.95,
                    0.94
                ],
                "frac_nonzero": 0.00148,
                "freq_hist_data_bar_heights": [
                    463,
                    377,
                    355,
                    308,
                    271,
                    244,
                    219,
                    204,
                    170,
                    171,
                    144,
                    116,
                    115,
                    106,
                    114,
                    131,
                    94,
                    84,
                    88,
                    83,
                    79,
                    71,
                    61,
                    55,
                    50,
                    50,
                    57,
                    48,
                    43,
                    40,
                    34,
                    20,
                    23,
                    24,
                    28,
                    18,
                    11,
                    16,
                    15,
                    11,
                    6,
                    5,
                    3,
                    7,
                    6,
                    3,
                    2,
                    1,
                    3,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.163,
                    0.486,
                    0.809,
                    1.132,
                    1.455,
                    1.778,
                    2.101,
                    2.424,
                    2.747,
                    3.07,
                    3.393,
                    3.716,
                    4.039,
                    4.362,
                    4.685,
                    5.008,
                    5.331,
                    5.654,
                    5.978,
                    6.301,
                    6.624,
                    6.947,
                    7.27,
                    7.593,
                    7.916,
                    8.239,
                    8.562,
                    8.885,
                    9.208,
                    9.531,
                    9.854,
                    10.177,
                    10.5,
                    10.823,
                    11.146,
                    11.469,
                    11.792,
                    12.115,
                    12.438,
                    12.761,
                    13.085,
                    13.408,
                    13.731,
                    14.054,
                    14.377,
                    14.7,
                    15.023,
                    15.346,
                    15.669,
                    15.992
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    5,
                    16,
                    22,
                    39,
                    67,
                    128,
                    164,
                    277,
                    414,
                    527,
                    770,
                    1068,
                    1470,
                    1945,
                    2709,
                    3145,
                    3717,
                    4045,
                    4238,
                    4107,
                    3775,
                    3388,
                    2812,
                    2378,
                    1889,
                    1528,
                    1272,
                    1085,
                    813,
                    635,
                    483,
                    362,
                    264,
                    180,
                    166,
                    112,
                    78,
                    55,
                    32,
                    25,
                    19,
                    10,
                    10,
                    2,
                    1,
                    3,
                    1,
                    2,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.774,
                    -0.735,
                    -0.696,
                    -0.657,
                    -0.618,
                    -0.58,
                    -0.541,
                    -0.502,
                    -0.463,
                    -0.424,
                    -0.385,
                    -0.347,
                    -0.308,
                    -0.269,
                    -0.23,
                    -0.191,
                    -0.152,
                    -0.114,
                    -0.075,
                    -0.036,
                    0.003,
                    0.042,
                    0.081,
                    0.119,
                    0.158,
                    0.197,
                    0.236,
                    0.275,
                    0.314,
                    0.352,
                    0.391,
                    0.43,
                    0.469,
                    0.508,
                    0.547,
                    0.585,
                    0.624,
                    0.663,
                    0.702,
                    0.741,
                    0.779,
                    0.818,
                    0.857,
                    0.896,
                    0.935,
                    0.974,
                    1.012,
                    1.051,
                    1.09,
                    1.129
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " activities related to practical skills or tasks",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk5omozxw96i6663x2wv8mt",
                        "tokens": [
                            " misses",
                            " the",
                            " point",
                            " utterly",
                            " and",
                            " completely",
                            ".",
                            " Psychological",
                            " research",
                            " like",
                            " this",
                            " first",
                            " becomes",
                            " really",
                            " value",
                            "able",
                            " when",
                            " you",
                            " stop",
                            " thinking",
                            " about",
                            " yourself",
                            " and",
                            " start",
                            " asking",
                            " how",
                            " this",
                            " can",
                            " help",
                            " you",
                            " understand",
                            " other",
                            " people",
                            ".",
                            " If",
                            " you",
                            " design",
                            " API",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " and",
                            " base",
                            " your",
                            " design",
                            " on",
                            " what",
                            " makes",
                            " most",
                            " sense",
                            " to",
                            " your",
                            " own",
                            " coding",
                            " style",
                            ",",
                            " you",
                            " will",
                            " create",
                            " something",
                            " that",
                            " two",
                            " thirds",
                            " of",
                            " your",
                            " audience",
                            " will",
                            " find",
                            " difficult",
                            " to",
                            " use",
                            ".",
                            " Even",
                            " if",
                            " you",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " like",
                            " or",
                            " agree",
                            " with",
                            " their",
                            " style",
                            ".",
                            "\n",
                            "\n",
                            "Gr",
                            "anted",
                            ",",
                            " that",
                            " makes",
                            " the",
                            " assumption",
                            " that",
                            " programmers",
                            " are",
                            " always",
                            " equally",
                            " distributed",
                            " among",
                            " styles",
                            ",",
                            " which",
                            " is",
                            " a",
                            " pretty",
                            " wild",
                            " assumption",
                            ".",
                            " The",
                            " point",
                            " is",
                            " that",
                            " other",
                            " people",
                            " are",
                            " more",
                            " likely",
                            " to",
                            " think",
                            " differently",
                            " than",
                            " similarly",
                            " to",
                            " you"
                        ],
                        "dataIndex": null,
                        "index": "24144",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.154,
                        "maxValueTokenIndex": 53,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.242,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            16.154,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:42:13.806Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 16.153,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5omozxw97i666i7pgkm7w",
                        "tokens": [
                            " A",
                            " fantastic",
                            " collection",
                            " of",
                            " punk",
                            " music",
                            ",",
                            " ranging",
                            " from",
                            " scream",
                            "o",
                            " to",
                            " post",
                            "-",
                            "hard",
                            "core",
                            " to",
                            " pop",
                            "-",
                            "punk",
                            " along",
                            " with",
                            " any",
                            " other",
                            " notable",
                            " releases",
                            " that",
                            " can",
                            " somehow",
                            " shoe",
                            "horn",
                            " themselves",
                            " into",
                            " the",
                            " canon",
                            ".",
                            " If",
                            " this",
                            " blog",
                            " appeals",
                            " to",
                            " your",
                            " listening",
                            " tastes",
                            " then",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " make",
                            " no",
                            " qual",
                            "ms",
                            " as",
                            " to",
                            " how",
                            " Death",
                            " Gri",
                            "ps",
                            " are",
                            " on",
                            " there",
                            " or",
                            " how",
                            " Sunny",
                            " Day",
                            " Real",
                            " Estate",
                            " or",
                            " Texas",
                            " Is",
                            " the",
                            " Reason",
                            " belong",
                            " next",
                            " to",
                            " entries",
                            " about",
                            " Jaw",
                            "breaker",
                            " and",
                            " Touch",
                            "\u00c3\u00a9",
                            " Am",
                            "or",
                            "\u00c3\u00a9",
                            ".",
                            " It",
                            " just",
                            " makes",
                            " sense",
                            ".",
                            "\n",
                            "\n",
                            "Why",
                            ":",
                            " What",
                            " Sophie",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Floor",
                            "boards",
                            " excel",
                            " at",
                            " is",
                            " providing",
                            " a",
                            " fantastic",
                            " point",
                            " of",
                            " reference",
                            " for",
                            " people",
                            " looking",
                            " to",
                            " get",
                            " themselves",
                            " started",
                            " along",
                            " with",
                            " shining",
                            " a",
                            " light",
                            " on",
                            " lesser",
                            "-"
                        ],
                        "dataIndex": null,
                        "index": "24144",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.803,
                        "maxValueTokenIndex": 42,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.803,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:42:13.806Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 16.153,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk5omozxw98i6668l1l8vwl",
                        "tokens": [
                            " at",
                            " Bore",
                            "fts",
                            " had",
                            " met",
                            " the",
                            " challenge",
                            " by",
                            " taking",
                            " a",
                            " non",
                            "-",
                            "rad",
                            "ler",
                            " and",
                            " call",
                            " it",
                            " their",
                            " rad",
                            "ler",
                            ".",
                            " There",
                            " were",
                            " a",
                            " few",
                            " interesting",
                            " and",
                            " tasty",
                            " fruit",
                            " beers",
                            " among",
                            " them",
                            ",",
                            " but",
                            " they",
                            " had",
                            " very",
                            " little",
                            " in",
                            " common",
                            ".",
                            " I",
                            " really",
                            " hope",
                            " that",
                            " the",
                            " challenge",
                            " next",
                            " year",
                            " is",
                            " something",
                            " that",
                            " challenges",
                            " the",
                            " brewers",
                            " on",
                            " their",
                            " brewing",
                            " skills",
                            " and",
                            " not",
                            " their",
                            " imagination",
                            ".",
                            " Like",
                            " a",
                            " single",
                            " hop",
                            " pale",
                            " ale",
                            ",",
                            " a",
                            " crisp",
                            ",",
                            " clean",
                            " p",
                            "ils",
                            "ner",
                            ",",
                            " or",
                            " a",
                            " 5",
                            "%",
                            " p",
                            "orter",
                            ".",
                            " That",
                            " would",
                            " be",
                            " much",
                            " more",
                            " interesting",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " food",
                            " served",
                            " at",
                            " the",
                            " Bore",
                            "fts",
                            " Beer",
                            " Festival",
                            " has",
                            " definitely",
                            " also",
                            " evolved",
                            ",",
                            " from",
                            " a",
                            " choice",
                            " of",
                            " two",
                            " different",
                            " sandwiches",
                            " (",
                            "if",
                            " memory",
                            " serves",
                            " me",
                            " right",
                            "),",
                            " to",
                            " several",
                            " food",
                            " stalls"
                        ],
                        "dataIndex": null,
                        "index": "24144",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.677,
                        "maxValueTokenIndex": 57,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.221,
                            0,
                            0,
                            15.677,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:42:13.806Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 16.153,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "45208",
            "description": " phrases related to guidance and advice for learning processes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4574197828769684,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "45208",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:30:40.284Z",
                "maxActApprox": 12.487,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    45208,
                    21009,
                    23083,
                    5163,
                    24954,
                    12247,
                    60744,
                    94653,
                    11219,
                    45713,
                    67935,
                    73860,
                    56547,
                    66362,
                    28076,
                    4735,
                    37015,
                    43166,
                    31504,
                    51045,
                    68503,
                    11285,
                    65233,
                    12471,
                    23540
                ],
                "topkCosSimValues": [
                    1,
                    0.5972,
                    0.5367,
                    0.5257,
                    0.5084,
                    0.4863,
                    0.4831,
                    0.4831,
                    0.4763,
                    0.4687,
                    0.4662,
                    0.4554,
                    0.4496,
                    0.4485,
                    0.4479,
                    0.4312,
                    0.4255,
                    0.4254,
                    0.4172,
                    0.4168,
                    0.4146,
                    0.4062,
                    0.4034,
                    0.3914,
                    0.3892
                ],
                "neuron_alignment_indices": [
                    581,
                    299,
                    718
                ],
                "neuron_alignment_values": [
                    0.128,
                    0.126,
                    0.124
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.006,
                    0.006
                ],
                "correlated_neurons_indices": [
                    299,
                    581,
                    718
                ],
                "correlated_neurons_pearson": [
                    0.03,
                    0.027,
                    0.022
                ],
                "correlated_neurons_l1": [
                    0.032,
                    0.025,
                    0.026
                ],
                "correlated_features_indices": [
                    45247,
                    45153,
                    45255
                ],
                "correlated_features_pearson": [
                    0.013,
                    0.006,
                    0.005
                ],
                "correlated_features_l1": [
                    0.014,
                    0.007,
                    0.006
                ],
                "neg_str": [
                    "ahime",
                    "Bs",
                    "ounding",
                    "ORK",
                    "uers",
                    "clusion",
                    " Sixth",
                    "egu",
                    "izons",
                    " councils"
                ],
                "neg_values": [
                    -0.711,
                    -0.682,
                    -0.639,
                    -0.622,
                    -0.621,
                    -0.611,
                    -0.604,
                    -0.596,
                    -0.594,
                    -0.591
                ],
                "pos_str": [
                    " whatsoever",
                    " imaginable",
                    " except",
                    " anywhere",
                    " conceivable",
                    " regardless",
                    "soever",
                    " irrespective",
                    "except",
                    " anytime"
                ],
                "pos_values": [
                    1.463,
                    1.45,
                    1.07,
                    1.004,
                    0.978,
                    0.925,
                    0.873,
                    0.864,
                    0.849,
                    0.82
                ],
                "frac_nonzero": 0.0013,
                "freq_hist_data_bar_heights": [
                    698,
                    536,
                    401,
                    356,
                    288,
                    248,
                    220,
                    170,
                    149,
                    132,
                    116,
                    83,
                    66,
                    80,
                    75,
                    67,
                    61,
                    39,
                    38,
                    36,
                    30,
                    24,
                    31,
                    13,
                    21,
                    16,
                    19,
                    8,
                    11,
                    6,
                    6,
                    7,
                    2,
                    3,
                    3,
                    2,
                    4,
                    5,
                    3,
                    3,
                    1,
                    3,
                    2,
                    2,
                    1,
                    0,
                    1,
                    0,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.125,
                    0.375,
                    0.625,
                    0.874,
                    1.124,
                    1.374,
                    1.624,
                    1.873,
                    2.123,
                    2.373,
                    2.623,
                    2.872,
                    3.122,
                    3.372,
                    3.621,
                    3.871,
                    4.121,
                    4.371,
                    4.62,
                    4.87,
                    5.12,
                    5.37,
                    5.619,
                    5.869,
                    6.119,
                    6.369,
                    6.618,
                    6.868,
                    7.118,
                    7.367,
                    7.617,
                    7.867,
                    8.117,
                    8.366,
                    8.616,
                    8.866,
                    9.116,
                    9.365,
                    9.615,
                    9.865,
                    10.115,
                    10.364,
                    10.614,
                    10.864,
                    11.114,
                    11.363,
                    11.613,
                    11.863,
                    12.112,
                    12.362
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    1,
                    12,
                    16,
                    36,
                    58,
                    128,
                    254,
                    494,
                    806,
                    1380,
                    2263,
                    3042,
                    4096,
                    5021,
                    5680,
                    5729,
                    5537,
                    4725,
                    3667,
                    2679,
                    1799,
                    1194,
                    737,
                    377,
                    233,
                    119,
                    68,
                    42,
                    28,
                    7,
                    9,
                    3,
                    4,
                    1,
                    2,
                    2,
                    1,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.689,
                    -0.645,
                    -0.602,
                    -0.558,
                    -0.515,
                    -0.471,
                    -0.428,
                    -0.384,
                    -0.341,
                    -0.297,
                    -0.254,
                    -0.211,
                    -0.167,
                    -0.124,
                    -0.08,
                    -0.037,
                    0.007,
                    0.05,
                    0.094,
                    0.137,
                    0.181,
                    0.224,
                    0.268,
                    0.311,
                    0.355,
                    0.398,
                    0.442,
                    0.485,
                    0.529,
                    0.572,
                    0.616,
                    0.659,
                    0.702,
                    0.746,
                    0.789,
                    0.833,
                    0.876,
                    0.92,
                    0.963,
                    1.007,
                    1.05,
                    1.094,
                    1.137,
                    1.181,
                    1.224,
                    1.268,
                    1.311,
                    1.355,
                    1.398,
                    1.442
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " phrases related to guidance and advice for learning processes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygh40tv9jg110exg3vaa945",
                        "tokens": [
                            ";",
                            " Accept",
                            "ed",
                            ":",
                            " December",
                            " 21",
                            ",",
                            " 2010",
                            ";",
                            " Published",
                            ":",
                            " January",
                            " 26",
                            ",",
                            " 2011",
                            " Copyright",
                            ":",
                            " \u00c2\u00a9",
                            " 2011",
                            " K",
                            "\u00c3\u00bc",
                            "hn",
                            " et",
                            " al",
                            ".",
                            " This",
                            " is",
                            " an",
                            " open",
                            "-",
                            "access",
                            " article",
                            " distributed",
                            " under",
                            " the",
                            " terms",
                            " of",
                            " the",
                            " Creative",
                            " Commons",
                            " Attribution",
                            " License",
                            ",",
                            " which",
                            " permits",
                            " unrestricted",
                            " use",
                            ",",
                            " distribution",
                            ",",
                            " and",
                            " reproduction",
                            " in",
                            " any",
                            " medium",
                            ",",
                            " provided",
                            " the",
                            " original",
                            " author",
                            " and",
                            " source",
                            " are",
                            " credited",
                            ".",
                            " Funding",
                            ":",
                            " SK",
                            " is",
                            " a",
                            " Post",
                            "doctoral",
                            " Fellow",
                            " of",
                            " the",
                            " Research",
                            " Foundation",
                            " F",
                            "landers",
                            " (",
                            "FW",
                            "O",
                            ").",
                            " The",
                            " fund",
                            "ers",
                            " had",
                            " no",
                            " role",
                            " in",
                            " study",
                            " design",
                            ",",
                            " data",
                            " collection",
                            " and",
                            " analysis",
                            ",",
                            " decision",
                            " to",
                            " publish",
                            ",",
                            " or",
                            " preparation",
                            " of",
                            " the",
                            " manuscript",
                            ".",
                            " Comp",
                            "eting",
                            " interests",
                            ":",
                            " J",
                            "G",
                            " has",
                            " received",
                            " research",
                            " funding",
                            " from",
                            " Ast",
                            "ra",
                            "Zen",
                            "eca",
                            ",",
                            " Eli",
                            " Lilly",
                            " &"
                        ],
                        "dataIndex": null,
                        "index": "45208",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 12.487,
                        "maxValueTokenIndex": 54,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.487,
                            5.669,
                            2.284,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:30:45.411Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 12.487,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh40tv9jg210ex27s4w2ux",
                        "tokens": [
                            " 74",
                            ",",
                            " 20",
                            "259",
                            " Hamburg",
                            ",",
                            " Germany",
                            "\n",
                            "\n",
                            "Re",
                            "ceived",
                            " 14",
                            " February",
                            " 2014",
                            ";",
                            " Revised",
                            " 28",
                            " May",
                            " 2014",
                            ";",
                            " Accept",
                            "ed",
                            " 29",
                            " May",
                            " 2014",
                            ";",
                            " Published",
                            " 15",
                            " July",
                            " 2014",
                            "\n",
                            "\n",
                            "Ac",
                            "ademic",
                            " Editor",
                            ":",
                            " N",
                            "ong",
                            "ya",
                            "o",
                            " Saw",
                            "ang",
                            "jar",
                            "oen",
                            "\n",
                            "\n",
                            "Copyright",
                            " \u00c2\u00a9",
                            " 2014",
                            " Dana",
                            " D",
                            "it",
                            "gen",
                            " et",
                            " al",
                            ".",
                            " This",
                            " is",
                            " an",
                            " open",
                            " access",
                            " article",
                            " distributed",
                            " under",
                            " the",
                            " Creative",
                            " Commons",
                            " Attribution",
                            " License",
                            " ,",
                            " which",
                            " permits",
                            " unrestricted",
                            " use",
                            ",",
                            " distribution",
                            ",",
                            " and",
                            " reproduction",
                            " in",
                            " any",
                            " medium",
                            ",",
                            " provided",
                            " the",
                            " original",
                            " work",
                            " is",
                            " properly",
                            " cited",
                            ".",
                            "\n",
                            "\n",
                            "Abstract",
                            "\n",
                            "\n",
                            "Hel",
                            "min",
                            "ths",
                            " are",
                            " the",
                            " largest",
                            " and",
                            " most",
                            " complex",
                            " pathogens",
                            " to",
                            " invade",
                            " and",
                            " live",
                            " within",
                            " the",
                            " human",
                            " body",
                            ".",
                            " Since",
                            " they",
                            " are",
                            " not",
                            " able",
                            " to",
                            " out",
                            "pace",
                            " the",
                            " immune",
                            " system",
                            " by"
                        ],
                        "dataIndex": null,
                        "index": "45208",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 12.342,
                        "maxValueTokenIndex": 81,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.342,
                            5.708,
                            2.215,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:30:45.411Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 12.487,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh40tv9jg310ex0ok2mky0",
                        "tokens": [
                            " to",
                            " anywhere",
                            " in",
                            " the",
                            " world",
                            " in",
                            " any",
                            " vague",
                            " time",
                            " period",
                            " (",
                            "\u00e2\u0122",
                            "\u013e",
                            "an",
                            "cient",
                            "\u00e2\u0122",
                            "\u013f",
                            " is",
                            " not",
                            " clearly",
                            " defined",
                            ")",
                            " while",
                            " leaving",
                            " their",
                            " Latter",
                            "-",
                            "day",
                            " Saint",
                            " readers",
                            " to",
                            " interpret",
                            " \u00e2\u0122",
                            "\u013e",
                            "an",
                            "cient",
                            " world",
                            "\u00e2\u0122",
                            "\u013f",
                            " to",
                            " also",
                            " mean",
                            " pre",
                            "-",
                            "Columb",
                            "ian",
                            " Americas",
                            ".",
                            "\n",
                            "\n",
                            "Further",
                            ",",
                            " Fair",
                            "M",
                            "ormon",
                            " makes",
                            " these",
                            " astounding",
                            " claims",
                            " without",
                            " providing",
                            " any",
                            " sources",
                            " in",
                            " their",
                            " response",
                            ".",
                            " Fair",
                            "M",
                            "ormon",
                            "'s",
                            " claims",
                            " and",
                            " findings",
                            " would",
                            " shock",
                            " and",
                            " surprise",
                            " non",
                            "-",
                            "M",
                            "ormon",
                            " archaeologists",
                            ",",
                            " anthrop",
                            "ologists",
                            ",",
                            " lingu",
                            "ists",
                            ",",
                            " and",
                            " scientists",
                            ".",
                            "\n",
                            "\n",
                            "Z",
                            "o",
                            "ology",
                            ",",
                            " Metall",
                            "urgy",
                            ",",
                            " Archae",
                            "ology",
                            ",",
                            " Anthropology",
                            ",",
                            " L",
                            "ingu",
                            "istics",
                            ",",
                            " and",
                            " Biology",
                            " are",
                            " all",
                            " branches",
                            " of",
                            " science",
                            " domains",
                            " which",
                            " expand",
                            " well",
                            " beyond",
                            " BYU",
                            ".",
                            " Where",
                            " are"
                        ],
                        "dataIndex": null,
                        "index": "45208",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 11.55,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            9.5,
                            6.595,
                            11.55,
                            6.539,
                            4.205,
                            2.983,
                            0.438,
                            8.758,
                            3.525,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.119,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:30:45.411Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 12.487,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}