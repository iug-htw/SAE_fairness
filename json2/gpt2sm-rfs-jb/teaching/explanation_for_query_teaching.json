{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "teaching"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "30175",
            "description": " verbs associated with teaching, helping, and guidance",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6486114472978456,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "30175",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:08:43.878Z",
                "maxActApprox": 15.392,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    30175,
                    83716,
                    59599,
                    54019,
                    37993,
                    57172,
                    28937,
                    50172,
                    19844,
                    53547,
                    86404,
                    10487,
                    79022,
                    76434,
                    45330,
                    54596,
                    89209,
                    64857,
                    16526,
                    71624,
                    68280,
                    63495,
                    26988,
                    81634,
                    36158
                ],
                "topkCosSimValues": [
                    1,
                    0.5887,
                    0.5858,
                    0.5819,
                    0.5746,
                    0.5573,
                    0.5424,
                    0.5404,
                    0.518,
                    0.5174,
                    0.5101,
                    0.5054,
                    0.4956,
                    0.491,
                    0.4725,
                    0.4673,
                    0.4645,
                    0.4563,
                    0.4403,
                    0.4396,
                    0.4291,
                    0.4265,
                    0.4241,
                    0.42,
                    0.4188
                ],
                "neuron_alignment_indices": [
                    447,
                    644,
                    32
                ],
                "neuron_alignment_values": [
                    0.121,
                    0.118,
                    0.108
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    665,
                    750,
                    70
                ],
                "correlated_neurons_pearson": [
                    0.03,
                    0.03,
                    0.029
                ],
                "correlated_neurons_l1": [
                    0.035,
                    0.027,
                    0.033
                ],
                "correlated_features_indices": [
                    30128,
                    30170,
                    30194
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.003,
                    0.003
                ],
                "correlated_features_l1": [
                    0.008,
                    0.004,
                    0.003
                ],
                "neg_str": [
                    "ikuman",
                    " starring",
                    "FU",
                    "esides",
                    "stroke",
                    "aith",
                    "ringe",
                    "Storm",
                    " Stern",
                    "ranged"
                ],
                "neg_values": [
                    -0.588,
                    -0.569,
                    -0.554,
                    -0.542,
                    -0.536,
                    -0.535,
                    -0.525,
                    -0.525,
                    -0.518,
                    -0.517
                ],
                "pos_str": [
                    " ourselves",
                    " our",
                    " ours",
                    " OUR",
                    "Our",
                    "esville",
                    "etimes",
                    "eport",
                    "ida",
                    "ourses"
                ],
                "pos_values": [
                    1.481,
                    0.997,
                    0.801,
                    0.682,
                    0.623,
                    0.615,
                    0.605,
                    0.596,
                    0.592,
                    0.592
                ],
                "frac_nonzero": 0.00115,
                "freq_hist_data_bar_heights": [
                    406,
                    388,
                    317,
                    285,
                    227,
                    195,
                    166,
                    145,
                    144,
                    105,
                    123,
                    95,
                    80,
                    77,
                    71,
                    58,
                    57,
                    52,
                    70,
                    51,
                    41,
                    53,
                    35,
                    52,
                    37,
                    38,
                    28,
                    23,
                    25,
                    20,
                    12,
                    18,
                    10,
                    12,
                    17,
                    18,
                    10,
                    7,
                    7,
                    6,
                    6,
                    5,
                    2,
                    2,
                    5,
                    2,
                    1,
                    2,
                    3,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.154,
                    0.462,
                    0.77,
                    1.077,
                    1.385,
                    1.693,
                    2.001,
                    2.309,
                    2.617,
                    2.924,
                    3.232,
                    3.54,
                    3.848,
                    4.156,
                    4.464,
                    4.771,
                    5.079,
                    5.387,
                    5.695,
                    6.003,
                    6.311,
                    6.618,
                    6.926,
                    7.234,
                    7.542,
                    7.85,
                    8.158,
                    8.465,
                    8.773,
                    9.081,
                    9.389,
                    9.697,
                    10.005,
                    10.312,
                    10.62,
                    10.928,
                    11.236,
                    11.544,
                    11.851,
                    12.159,
                    12.467,
                    12.775,
                    13.083,
                    13.391,
                    13.698,
                    14.006,
                    14.314,
                    14.622,
                    14.93,
                    15.238
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    10,
                    26,
                    70,
                    118,
                    228,
                    473,
                    879,
                    1522,
                    2210,
                    3312,
                    4224,
                    5200,
                    5699,
                    5838,
                    5450,
                    4569,
                    3560,
                    2644,
                    1713,
                    1137,
                    622,
                    358,
                    181,
                    113,
                    58,
                    20,
                    10,
                    4,
                    2,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.568,
                    -0.526,
                    -0.485,
                    -0.444,
                    -0.402,
                    -0.361,
                    -0.319,
                    -0.278,
                    -0.237,
                    -0.195,
                    -0.154,
                    -0.113,
                    -0.071,
                    -0.03,
                    0.012,
                    0.053,
                    0.094,
                    0.136,
                    0.177,
                    0.219,
                    0.26,
                    0.301,
                    0.343,
                    0.384,
                    0.426,
                    0.467,
                    0.508,
                    0.55,
                    0.591,
                    0.633,
                    0.674,
                    0.715,
                    0.757,
                    0.798,
                    0.839,
                    0.881,
                    0.922,
                    0.964,
                    1.005,
                    1.046,
                    1.088,
                    1.129,
                    1.171,
                    1.212,
                    1.253,
                    1.295,
                    1.336,
                    1.378,
                    1.419,
                    1.46
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "action verbs related to education and support",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " verbs associated with teaching, helping, and guidance",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggbsw0y5qy10exsxe9zt16",
                        "tokens": [
                            " is",
                            " what",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " all",
                            " about",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Jordan",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "This",
                            " is",
                            " what",
                            " kids",
                            " need",
                            " to",
                            " know",
                            ".",
                            " We",
                            " teach",
                            " them",
                            " how",
                            " to",
                            " read",
                            ".",
                            " We",
                            " teach",
                            " them",
                            " all",
                            " about",
                            " math",
                            " and",
                            " I",
                            " strongly",
                            " believe",
                            " they",
                            " also",
                            " need",
                            " to",
                            " learn",
                            " about",
                            " computers",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Wall",
                            " said",
                            " coding",
                            " helps",
                            " with",
                            " problem",
                            "-",
                            "s",
                            "olving",
                            " and",
                            " process",
                            "-",
                            "oriented",
                            " thinking",
                            ",",
                            " and",
                            " beyond",
                            " that",
                            ",",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " language",
                            " we",
                            " live",
                            " in",
                            " every",
                            " day",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "If",
                            " you",
                            " look",
                            " around",
                            " from",
                            " your",
                            " home",
                            " to",
                            " your",
                            " vehicle",
                            " to",
                            " what",
                            " we",
                            " have",
                            " in",
                            " our",
                            " hands",
                            " to",
                            " the",
                            " camera",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " using",
                            ",",
                            " there",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " code",
                            " embedded",
                            " inside",
                            " them",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s"
                        ],
                        "dataIndex": null,
                        "index": "30175",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.392,
                        "maxValueTokenIndex": 25,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.392,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            8.122,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.247,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:08:48.723Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.392,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggbsw0y5qz10ex20in2xjf",
                        "tokens": [
                            " W",
                            "ore",
                            " it",
                            " Better",
                            "\u00e2\u0122",
                            "\u013b",
                            " between",
                            " two",
                            " women",
                            ",",
                            " instead",
                            " of",
                            " a",
                            " \u00e2\u0122",
                            "\u013a",
                            "They",
                            " Both",
                            " Sl",
                            "ayed",
                            ".",
                            "\u00e2\u0122",
                            "\u013b",
                            " As",
                            " prominent",
                            " novelist",
                            " Chim",
                            "am",
                            "anda",
                            " N",
                            "go",
                            "zi",
                            " Ad",
                            "ich",
                            "ie",
                            " pointed",
                            " out",
                            " in",
                            " her",
                            " personal",
                            " essay",
                            " We",
                            " Should",
                            " All",
                            " Be",
                            " Femin",
                            "ists",
                            " and",
                            " in",
                            " Beyon",
                            "c\u00c3\u00a9",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " song",
                            " \u00e2\u0122",
                            "\u013a",
                            "F",
                            "law",
                            "less",
                            "\u00e2\u0122",
                            "\u013b",
                            ":",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "We",
                            " raise",
                            " girls",
                            " to",
                            " see",
                            " each",
                            " other",
                            " as",
                            " competitors",
                            " \u2014",
                            "\n",
                            "\n",
                            "not",
                            " for",
                            " jobs",
                            " or",
                            " for",
                            " accomplishments",
                            ",",
                            "\n",
                            "\n",
                            "which",
                            " I",
                            " think",
                            " can",
                            " be",
                            " a",
                            " good",
                            " thing",
                            ",",
                            "\n",
                            "\n",
                            "but",
                            " for",
                            " the",
                            " attention",
                            " of",
                            " men",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            " teach",
                            " girls",
                            " that",
                            " they",
                            " cannot",
                            " be",
                            " sexual",
                            " beings",
                            "\n",
                            "\n",
                            "in",
                            " the",
                            " way",
                            " that",
                            " boys",
                            " are",
                            ".",
                            "\u00e2\u0122",
                            "\u013f"
                        ],
                        "dataIndex": null,
                        "index": "30175",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.338,
                        "maxValueTokenIndex": 108,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.78,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.338,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:08:48.723Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.392,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggbsw0y5r210ex4xf1ph6w",
                        "tokens": [
                            " W",
                            "ore",
                            " it",
                            " Better",
                            "\u00e2\u0122",
                            "\u013b",
                            " between",
                            " two",
                            " women",
                            ",",
                            " instead",
                            " of",
                            " a",
                            " \u00e2\u0122",
                            "\u013a",
                            "They",
                            " Both",
                            " Sl",
                            "ayed",
                            ".",
                            "\u00e2\u0122",
                            "\u013b",
                            " As",
                            " prominent",
                            " novelist",
                            " Chim",
                            "am",
                            "anda",
                            " N",
                            "go",
                            "zi",
                            " Ad",
                            "ich",
                            "ie",
                            " pointed",
                            " out",
                            " in",
                            " her",
                            " personal",
                            " essay",
                            " We",
                            " Should",
                            " All",
                            " Be",
                            " Femin",
                            "ists",
                            " and",
                            " in",
                            " Beyon",
                            "c\u00c3\u00a9",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " song",
                            " \u00e2\u0122",
                            "\u013a",
                            "F",
                            "law",
                            "less",
                            "\u00e2\u0122",
                            "\u013b",
                            ":",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "We",
                            " raise",
                            " girls",
                            " to",
                            " see",
                            " each",
                            " other",
                            " as",
                            " competitors",
                            " \u2014",
                            "\n",
                            "\n",
                            "not",
                            " for",
                            " jobs",
                            " or",
                            " for",
                            " accomplishments",
                            ",",
                            "\n",
                            "\n",
                            "which",
                            " I",
                            " think",
                            " can",
                            " be",
                            " a",
                            " good",
                            " thing",
                            ",",
                            "\n",
                            "\n",
                            "but",
                            " for",
                            " the",
                            " attention",
                            " of",
                            " men",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            " teach",
                            " girls",
                            " that",
                            " they",
                            " cannot",
                            " be",
                            " sexual",
                            " beings",
                            "\n",
                            "\n",
                            "in",
                            " the",
                            " way",
                            " that",
                            " boys",
                            " are",
                            ".",
                            "\u00e2\u0122",
                            "\u013f"
                        ],
                        "dataIndex": null,
                        "index": "30175",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.338,
                        "maxValueTokenIndex": 108,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.78,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.338,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:08:48.723Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.392,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "3552",
            "description": "verbs related to teaching, informing, and educating",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6321415085876898,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "3552",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:20:01.903Z",
                "maxActApprox": 21.7,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    3552,
                    8090,
                    8924,
                    2525,
                    1831,
                    863,
                    6230,
                    2007,
                    1111,
                    214,
                    6538,
                    3346,
                    2715,
                    4515,
                    7513,
                    4568,
                    1351,
                    10942,
                    3344,
                    5314,
                    2996,
                    1368,
                    11812,
                    9659,
                    1533
                ],
                "topkCosSimValues": [
                    1,
                    0.5013,
                    0.4866,
                    0.4672,
                    0.4664,
                    0.4579,
                    0.448,
                    0.4265,
                    0.426,
                    0.4056,
                    0.392,
                    0.3829,
                    0.3797,
                    0.3794,
                    0.3789,
                    0.3756,
                    0.3607,
                    0.3565,
                    0.3528,
                    0.3512,
                    0.347,
                    0.3442,
                    0.3441,
                    0.3419,
                    0.341
                ],
                "neuron_alignment_indices": [
                    664,
                    59,
                    63
                ],
                "neuron_alignment_values": [
                    0.1,
                    0.1,
                    0.098
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    184,
                    59,
                    665
                ],
                "correlated_neurons_pearson": [
                    0.066,
                    0.063,
                    0.053
                ],
                "correlated_neurons_l1": [
                    0.051,
                    0.06,
                    0.063
                ],
                "correlated_features_indices": [
                    3560,
                    3564,
                    3539
                ],
                "correlated_features_pearson": [
                    0.011,
                    0.008,
                    0.007
                ],
                "correlated_features_l1": [
                    0.016,
                    0.009,
                    0.008
                ],
                "neg_str": [
                    "mone",
                    "imposed",
                    " Accessed",
                    "inian",
                    "ynski",
                    "pmwiki",
                    "rought",
                    "lived",
                    "nothing",
                    "\u00cb\u013e"
                ],
                "neg_values": [
                    -0.709,
                    -0.647,
                    -0.629,
                    -0.627,
                    -0.627,
                    -0.595,
                    -0.579,
                    -0.555,
                    -0.55,
                    -0.544
                ],
                "pos_str": [
                    " us",
                    " him",
                    " oneself",
                    " them",
                    " ourselves",
                    " viewers",
                    " listeners",
                    " readers",
                    "ingly",
                    " unsuspecting"
                ],
                "pos_values": [
                    1.197,
                    1.119,
                    1.065,
                    1.058,
                    1.037,
                    1.032,
                    1.011,
                    1.001,
                    0.979,
                    0.969
                ],
                "frac_nonzero": 0.00515,
                "freq_hist_data_bar_heights": [
                    2769,
                    2268,
                    1762,
                    1452,
                    1171,
                    1002,
                    853,
                    653,
                    591,
                    513,
                    454,
                    411,
                    303,
                    250,
                    223,
                    211,
                    190,
                    138,
                    127,
                    117,
                    97,
                    92,
                    68,
                    65,
                    69,
                    52,
                    51,
                    46,
                    33,
                    28,
                    26,
                    19,
                    17,
                    18,
                    8,
                    13,
                    9,
                    0,
                    3,
                    3,
                    7,
                    2,
                    5,
                    3,
                    4,
                    2,
                    1,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.217,
                    0.651,
                    1.085,
                    1.519,
                    1.953,
                    2.387,
                    2.821,
                    3.255,
                    3.689,
                    4.123,
                    4.557,
                    4.991,
                    5.425,
                    5.859,
                    6.293,
                    6.727,
                    7.161,
                    7.595,
                    8.029,
                    8.463,
                    8.897,
                    9.331,
                    9.765,
                    10.199,
                    10.633,
                    11.067,
                    11.501,
                    11.935,
                    12.369,
                    12.803,
                    13.237,
                    13.671,
                    14.105,
                    14.539,
                    14.973,
                    15.407,
                    15.841,
                    16.275,
                    16.709,
                    17.143,
                    17.577,
                    18.011,
                    18.445,
                    18.879,
                    19.313,
                    19.747,
                    20.181,
                    20.615,
                    21.049,
                    21.483
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    4,
                    1,
                    12,
                    22,
                    45,
                    103,
                    199,
                    342,
                    655,
                    1100,
                    1708,
                    2440,
                    3289,
                    4017,
                    4514,
                    4918,
                    4835,
                    4585,
                    4147,
                    3468,
                    2819,
                    2062,
                    1520,
                    1076,
                    725,
                    487,
                    325,
                    212,
                    157,
                    96,
                    89,
                    55,
                    58,
                    42,
                    38,
                    26,
                    22,
                    9,
                    6,
                    9,
                    5,
                    3,
                    3,
                    3,
                    2,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.69,
                    -0.652,
                    -0.613,
                    -0.575,
                    -0.537,
                    -0.499,
                    -0.461,
                    -0.423,
                    -0.385,
                    -0.347,
                    -0.309,
                    -0.27,
                    -0.232,
                    -0.194,
                    -0.156,
                    -0.118,
                    -0.08,
                    -0.042,
                    -0.004,
                    0.034,
                    0.073,
                    0.111,
                    0.149,
                    0.187,
                    0.225,
                    0.263,
                    0.301,
                    0.339,
                    0.377,
                    0.416,
                    0.454,
                    0.492,
                    0.53,
                    0.568,
                    0.606,
                    0.644,
                    0.682,
                    0.72,
                    0.759,
                    0.797,
                    0.835,
                    0.873,
                    0.911,
                    0.949,
                    0.987,
                    1.025,
                    1.063,
                    1.102,
                    1.14,
                    1.178
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "verbs related to teaching, informing, and educating",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtpaxd1v86i6660kz8veki",
                        "tokens": [
                            " experiences",
                            ",",
                            " famously",
                            " writing",
                            " The",
                            " Doors",
                            " of",
                            " Perception",
                            " about",
                            " his",
                            " experiences",
                            " with",
                            " m",
                            "esc",
                            "aline",
                            ".",
                            "\n",
                            "\n",
                            "Beyond",
                            " becoming",
                            " one",
                            " of",
                            " the",
                            " pre",
                            "em",
                            "inent",
                            " intellectuals",
                            " of",
                            " his",
                            " time",
                            ",",
                            " H",
                            "ux",
                            "ley",
                            " also",
                            " had",
                            " a",
                            " prod",
                            "igious",
                            " talent",
                            " for",
                            " writing",
                            ".",
                            "\n",
                            "\n",
                            "His",
                            " words",
                            " contain",
                            " a",
                            " seemingly",
                            " effort",
                            "less",
                            " eloqu",
                            "ence",
                            ".",
                            " He",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " one",
                            " of",
                            " those",
                            " writers",
                            " whose",
                            " presence",
                            " you",
                            " can",
                            " really",
                            " feel",
                            " in",
                            " the",
                            " sentences",
                            ".",
                            " You",
                            " can",
                            " almost",
                            " picture",
                            " H",
                            "ux",
                            "ley",
                            ",",
                            " cross",
                            "-",
                            "legged",
                            " and",
                            " s",
                            "ipping",
                            " a",
                            " cup",
                            " of",
                            " tea",
                            ",",
                            " reg",
                            "aling",
                            " you",
                            " with",
                            " his",
                            " profound",
                            " ideas",
                            " over",
                            " a",
                            " lovely",
                            " lun",
                            "cheon",
                            ".",
                            "\n",
                            "\n",
                            "Keep",
                            " that",
                            " image",
                            " in",
                            " mind",
                            " while",
                            " you",
                            " sav",
                            "or",
                            " these",
                            " quotes",
                            "\u2014",
                            "these",
                            " dusty",
                            " treasures",
                            " pl",
                            "ucked",
                            " from",
                            " the",
                            " consciousness"
                        ],
                        "dataIndex": null,
                        "index": "3552",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 21.7,
                        "maxValueTokenIndex": 93,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            21.7,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:20:12.724Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 21.7,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtpaxd1v87i6661heyxl35",
                        "tokens": [
                            " we",
                            "'ll",
                            " cover",
                            " on",
                            " a",
                            " very",
                            " top",
                            "-",
                            "level",
                            " in",
                            " a",
                            " section",
                            " below",
                            " (",
                            "see",
                            ":",
                            " Materials",
                            " &",
                            " Thermal",
                            " Conduct",
                            "ivity",
                            ").",
                            "\n",
                            "\n",
                            "We",
                            "'ve",
                            " put",
                            " together",
                            " the",
                            " below",
                            " image",
                            " to",
                            " help",
                            " familiar",
                            "ize",
                            " you",
                            " with",
                            " the",
                            " inner",
                            "-",
                            "work",
                            "ings",
                            " of",
                            " a",
                            " CPU",
                            " heats",
                            "ink",
                            " and",
                            " its",
                            " related",
                            " terminology",
                            ":",
                            "\n",
                            "\n",
                            "The",
                            " anatomy",
                            " of",
                            " a",
                            " heats",
                            "ink",
                            ".",
                            " This",
                            " is",
                            " NZ",
                            "XT",
                            "'s",
                            " Res",
                            "pire",
                            " T",
                            "40",
                            " -",
                            " click",
                            " to",
                            " enlarge",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " primary",
                            " elements",
                            " of",
                            " a",
                            " CPU",
                            " cooler",
                            " are",
                            " all",
                            " covered",
                            " in",
                            " this",
                            " graphic",
                            ".",
                            " For",
                            " the",
                            " most",
                            " part",
                            ",",
                            " the",
                            " action",
                            " happens",
                            " in",
                            " the",
                            " heat",
                            "p",
                            "ipes",
                            ",",
                            " but",
                            " we",
                            "'re",
                            " also",
                            " faced",
                            " with",
                            " the",
                            " actual",
                            " heats",
                            "ink",
                            ",",
                            " the",
                            " overall",
                            " surface",
                            " area",
                            ",",
                            " the",
                            " contact",
                            " technology",
                            " used",
                            " to",
                            " transfer"
                        ],
                        "dataIndex": null,
                        "index": "3552",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 20.549,
                        "maxValueTokenIndex": 34,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.851,
                            20.549,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:20:12.724Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 21.7,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtpaxd1v88i6662bn9u897",
                        "tokens": [
                            "\n",
                            "Campaign",
                            "s",
                            "\n",
                            "\n",
                            "It",
                            " also",
                            " sets",
                            " out",
                            " each",
                            " department",
                            "'s",
                            " \"",
                            "priority",
                            " communication",
                            " activities",
                            "\"",
                            " for",
                            " 2012",
                            "-",
                            "13",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " health",
                            " department",
                            "'s",
                            " priorities",
                            " -",
                            " in",
                            " addition",
                            " to",
                            " long",
                            "-",
                            "running",
                            " campaigns",
                            " against",
                            " smoking",
                            ",",
                            " obesity",
                            " and",
                            " other",
                            " public",
                            " health",
                            " problems",
                            " -",
                            " include",
                            " \"",
                            "support",
                            "ing",
                            " the",
                            " implementation",
                            " of",
                            " the",
                            " NHS",
                            "'s",
                            " efficiency",
                            " and",
                            " productivity",
                            " challenge",
                            "\"",
                            " and",
                            " \"",
                            "in",
                            "forming",
                            " and",
                            " engaging",
                            " staff",
                            " groups",
                            " and",
                            " stakeholders",
                            " in",
                            " the",
                            " health",
                            " and",
                            " care",
                            " reforms",
                            "\".",
                            "\n",
                            "\n",
                            "The",
                            " department",
                            " for",
                            " work",
                            " and",
                            " pensions",
                            "'",
                            " priorities",
                            " include",
                            " \"",
                            "building",
                            " understanding",
                            " and",
                            " positive",
                            " perceptions",
                            " of",
                            " Personal",
                            " Independence",
                            " Payments",
                            " as",
                            " a",
                            " fair",
                            " benefit",
                            ",",
                            " personal",
                            "ised",
                            " to",
                            " reflect",
                            " claimants",
                            "'",
                            " needs",
                            "\".",
                            "\n",
                            "\n",
                            "And",
                            " the",
                            " business",
                            " department",
                            " plans",
                            " to",
                            " spend",
                            " money",
                            " on",
                            " \"",
                            "commun",
                            "icating"
                        ],
                        "dataIndex": null,
                        "index": "3552",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 20.139,
                        "maxValueTokenIndex": 65,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.108,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            20.139,
                            0,
                            8.117,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:20:12.724Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 21.7,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs6144-jb",
            "index": "5581",
            "description": "instances related to teaching or education",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6294600963592529,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs6144-jb",
                "index": "5581",
                "sourceSetName": "res_fs6144-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:13:48.353Z",
                "maxActApprox": 49.851,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    5581,
                    1050,
                    5732,
                    1446,
                    5723,
                    3229,
                    4202,
                    3252,
                    104,
                    4222,
                    197,
                    846,
                    4495,
                    1536,
                    1646,
                    827,
                    728,
                    1278,
                    2591,
                    1510,
                    5430,
                    5439,
                    788,
                    2067,
                    2084
                ],
                "topkCosSimValues": [
                    1,
                    0.5579,
                    0.472,
                    0.467,
                    0.4114,
                    0.3985,
                    0.3969,
                    0.3666,
                    0.3635,
                    0.3485,
                    0.3373,
                    0.3304,
                    0.3049,
                    0.3024,
                    0.2867,
                    0.2838,
                    0.2743,
                    0.2711,
                    0.2711,
                    0.2685,
                    0.2628,
                    0.2533,
                    0.2509,
                    0.2439,
                    0.2427
                ],
                "neuron_alignment_indices": [
                    679,
                    71,
                    575
                ],
                "neuron_alignment_values": [
                    0.124,
                    0.102,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    575,
                    224,
                    414
                ],
                "correlated_neurons_pearson": [
                    0.03,
                    0.027,
                    0.026
                ],
                "correlated_neurons_l1": [
                    0.035,
                    0.029,
                    0.021
                ],
                "correlated_features_indices": [
                    5529,
                    5624,
                    5577
                ],
                "correlated_features_pearson": [
                    0.019,
                    0.016,
                    0.004
                ],
                "correlated_features_l1": [
                    0.021,
                    0.017,
                    0.006
                ],
                "neg_str": [
                    " Ports",
                    " Launcher",
                    "axy",
                    "atos",
                    "reens",
                    " ports",
                    "tar",
                    "ogene",
                    " contiguous",
                    "ablished"
                ],
                "neg_values": [
                    -0.735,
                    -0.68,
                    -0.672,
                    -0.616,
                    -0.608,
                    -0.607,
                    -0.603,
                    -0.599,
                    -0.595,
                    -0.59
                ],
                "pos_str": [
                    "girls",
                    "yout",
                    "children",
                    "piece",
                    "girl",
                    " taught",
                    " curriculum",
                    "kids",
                    "student",
                    "ingly"
                ],
                "pos_values": [
                    0.91,
                    0.89,
                    0.876,
                    0.837,
                    0.82,
                    0.815,
                    0.814,
                    0.807,
                    0.801,
                    0.796
                ],
                "frac_nonzero": 0.00151,
                "freq_hist_data_bar_heights": [
                    1454,
                    896,
                    564,
                    362,
                    271,
                    187,
                    160,
                    102,
                    81,
                    57,
                    43,
                    39,
                    38,
                    22,
                    20,
                    22,
                    25,
                    28,
                    23,
                    24,
                    26,
                    17,
                    17,
                    13,
                    11,
                    10,
                    2,
                    7,
                    9,
                    8,
                    5,
                    4,
                    11,
                    13,
                    15,
                    6,
                    9,
                    10,
                    11,
                    13,
                    22,
                    17,
                    19,
                    10,
                    14,
                    10,
                    5,
                    10,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.499,
                    1.496,
                    2.493,
                    3.49,
                    4.487,
                    5.484,
                    6.481,
                    7.478,
                    8.475,
                    9.472,
                    10.469,
                    11.466,
                    12.463,
                    13.46,
                    14.457,
                    15.454,
                    16.451,
                    17.448,
                    18.445,
                    19.442,
                    20.439,
                    21.436,
                    22.433,
                    23.43,
                    24.427,
                    25.424,
                    26.421,
                    27.418,
                    28.415,
                    29.412,
                    30.409,
                    31.406,
                    32.403,
                    33.4,
                    34.397,
                    35.394,
                    36.391,
                    37.388,
                    38.385,
                    39.382,
                    40.379,
                    41.376,
                    42.373,
                    43.37,
                    44.367,
                    45.364,
                    46.361,
                    47.358,
                    48.355,
                    49.352
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    0,
                    3,
                    8,
                    12,
                    23,
                    29,
                    60,
                    96,
                    175,
                    277,
                    445,
                    708,
                    972,
                    1450,
                    1995,
                    2561,
                    3298,
                    3759,
                    4263,
                    4304,
                    4362,
                    4097,
                    3711,
                    3140,
                    2702,
                    2027,
                    1565,
                    1167,
                    855,
                    667,
                    452,
                    348,
                    229,
                    144,
                    112,
                    60,
                    44,
                    41,
                    20,
                    20,
                    14,
                    11,
                    7,
                    7,
                    7,
                    4,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.718,
                    -0.686,
                    -0.653,
                    -0.62,
                    -0.587,
                    -0.554,
                    -0.521,
                    -0.488,
                    -0.455,
                    -0.422,
                    -0.389,
                    -0.357,
                    -0.324,
                    -0.291,
                    -0.258,
                    -0.225,
                    -0.192,
                    -0.159,
                    -0.126,
                    -0.093,
                    -0.06,
                    -0.028,
                    0.005,
                    0.038,
                    0.071,
                    0.104,
                    0.137,
                    0.17,
                    0.203,
                    0.236,
                    0.269,
                    0.301,
                    0.334,
                    0.367,
                    0.4,
                    0.433,
                    0.466,
                    0.499,
                    0.532,
                    0.565,
                    0.598,
                    0.63,
                    0.663,
                    0.696,
                    0.729,
                    0.762,
                    0.795,
                    0.828,
                    0.861,
                    0.894
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "instances related to teaching or education",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdth771xwxki666gj12pruk",
                        "tokens": [
                            " destinations",
                            ",",
                            " and",
                            " explore",
                            " the",
                            " world",
                            " with",
                            " kindred",
                            " spirits",
                            ".",
                            " Be",
                            " the",
                            " first",
                            " to",
                            " hear",
                            " about",
                            " Nation",
                            " Travels",
                            " destinations",
                            ",",
                            " and",
                            " explore",
                            " the",
                            " world",
                            " with",
                            " kindred",
                            " spirits",
                            ".",
                            "\n",
                            "\n",
                            "Sign",
                            " up",
                            " for",
                            " our",
                            " Wine",
                            " Club",
                            " today",
                            ".",
                            " Did",
                            " you",
                            " know",
                            " you",
                            " can",
                            " support",
                            " The",
                            " Nation",
                            " by",
                            " drinking",
                            " wine",
                            "?",
                            "\n",
                            "\n",
                            "A",
                            " few",
                            " years",
                            " ago",
                            ",",
                            " when",
                            " I",
                            " was",
                            " still",
                            " teaching",
                            " at",
                            " Yale",
                            ",",
                            " I",
                            " was",
                            " approached",
                            " by",
                            " a",
                            " student",
                            " who",
                            " was",
                            " interested",
                            " in",
                            " going",
                            " to",
                            " graduate",
                            " school",
                            ".",
                            " She",
                            " had",
                            " her",
                            " eye",
                            " on",
                            " Columbia",
                            ";",
                            " did",
                            " I",
                            " know",
                            " someone",
                            " there",
                            " she",
                            " could",
                            " talk",
                            " with",
                            "?",
                            " I",
                            " did",
                            ",",
                            " an",
                            " old",
                            " professor",
                            " of",
                            " mine",
                            ".",
                            " But",
                            " when",
                            " I",
                            " wrote",
                            " to",
                            " arrange",
                            " the",
                            " introduction",
                            ",",
                            " he",
                            " refused",
                            " to",
                            " even",
                            " meet",
                            " with",
                            " her",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "I",
                            " won"
                        ],
                        "dataIndex": null,
                        "index": "5581",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.851,
                        "maxValueTokenIndex": 61,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.851,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.921,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:13:54.691Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.851,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdth771xwxli666qkzo915v",
                        "tokens": [
                            "\u00e2\u0138\u00ba",
                            " Author",
                            ":",
                            " Joseph",
                            " F",
                            "its",
                            "an",
                            "akis",
                            " |",
                            " Date",
                            ":",
                            " 26",
                            " June",
                            " 2017",
                            " |",
                            " Per",
                            "malink",
                            "\n",
                            "\n",
                            "Advertisements",
                            "<|endoftext|>",
                            "And",
                            " now",
                            " here",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " my",
                            " recap",
                            " and",
                            " review",
                            " of",
                            " the",
                            " 5",
                            "th",
                            " disc",
                            " from",
                            " this",
                            " classic",
                            " Soft",
                            "core",
                            " TV",
                            " series",
                            ".",
                            " Once",
                            " again",
                            " produced",
                            " by",
                            " Al",
                            "ain",
                            " S",
                            "irit",
                            "z",
                            "ky",
                            " and",
                            " this",
                            " is",
                            " directed",
                            " by",
                            " David",
                            " Cove",
                            " with",
                            " Mark",
                            " Evan",
                            " Schwartz",
                            " listed",
                            " as",
                            " screen",
                            "writer",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " theme",
                            " of",
                            " this",
                            " disc",
                            ",",
                            " as",
                            " evidenced",
                            " by",
                            " the",
                            " title",
                            ",",
                            " is",
                            " dreams",
                            ".",
                            " The",
                            " alien",
                            " crew",
                            " doesn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " dream",
                            ",",
                            " and",
                            " so",
                            " Emmanuel",
                            "le",
                            " decides",
                            " to",
                            " teach",
                            " them",
                            " about",
                            " dreams",
                            ",",
                            " and",
                            " how",
                            " you",
                            " can",
                            " explore",
                            " sexual",
                            " fantasies",
                            " in",
                            " them",
                            ".",
                            " So",
                            " while",
                            " she",
                            " sleeps",
                            " on",
                            " a",
                            " special",
                            " table",
                            " in",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "5581",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.093,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.093,
                            5.343,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:13:54.691Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.851,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdth771xwxmi666yhs37bap",
                        "tokens": [
                            " in",
                            " a",
                            " leaf",
                            " while",
                            " the",
                            " produce",
                            " was",
                            " washed",
                            " and",
                            " stocked",
                            ",",
                            " although",
                            " this",
                            " is",
                            " the",
                            " first",
                            " time",
                            " in",
                            " his",
                            " 17",
                            " years",
                            " in",
                            " produce",
                            " that",
                            " he",
                            "'s",
                            " heard",
                            " of",
                            " a",
                            " lizard",
                            " making",
                            " it",
                            " to",
                            " the",
                            " customer",
                            ".",
                            "\n",
                            "\n",
                            "Science",
                            " teacher",
                            " Mark",
                            " East",
                            "burn",
                            " said",
                            " he",
                            " has",
                            " been",
                            " teaching",
                            " his",
                            " class",
                            " about",
                            " DNA",
                            ",",
                            " so",
                            " this",
                            " is",
                            " a",
                            " perfect",
                            " mascot",
                            " for",
                            " the",
                            " class",
                            ",",
                            " according",
                            " to",
                            " the",
                            " report",
                            ".",
                            "\n",
                            "\n",
                            "Read",
                            " more",
                            " at",
                            " n",
                            "j",
                            ".",
                            "com",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " attached",
                            " image",
                            " was",
                            " posted",
                            " on",
                            " an",
                            "ole",
                            "ann",
                            "als",
                            ".",
                            "org",
                            ".",
                            "<|endoftext|>",
                            "Gov",
                            ".",
                            " Bill",
                            " Has",
                            "lam",
                            " took",
                            " part",
                            " in",
                            " a",
                            " panel",
                            " discussion",
                            " with",
                            " Vermont",
                            " Gov",
                            ".",
                            " Peter",
                            " Sh",
                            "um",
                            "lin",
                            ",",
                            " H",
                            "CA",
                            " chief",
                            " financial",
                            " officer",
                            " Bill",
                            " Rutherford",
                            " and",
                            " two",
                            " other",
                            " health",
                            " care",
                            " executives"
                        ],
                        "dataIndex": null,
                        "index": "5581",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.054,
                        "maxValueTokenIndex": 47,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.521,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.054,
                            8.642,
                            15.124,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.917,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:13:54.691Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.851,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "48216",
            "description": "references to teaching and educational practices",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.6110641956329346,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "48216",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:35:05.088Z",
                "maxActApprox": 46.89,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    48216,
                    68287,
                    84880,
                    27303,
                    92518,
                    1477,
                    78484,
                    27016,
                    39280,
                    23900,
                    50465,
                    45929,
                    25065,
                    52515,
                    48115,
                    87007,
                    90381,
                    45552,
                    54088,
                    77027,
                    94019,
                    15349,
                    89657,
                    50443,
                    73850
                ],
                "topkCosSimValues": [
                    1,
                    0.6812,
                    0.6548,
                    0.6288,
                    0.5675,
                    0.54,
                    0.5117,
                    0.488,
                    0.4872,
                    0.4807,
                    0.47,
                    0.4614,
                    0.4327,
                    0.4317,
                    0.4292,
                    0.4272,
                    0.4269,
                    0.4226,
                    0.42,
                    0.414,
                    0.4021,
                    0.3964,
                    0.3924,
                    0.3913,
                    0.3898
                ],
                "neuron_alignment_indices": [
                    679,
                    288,
                    71
                ],
                "neuron_alignment_values": [
                    0.118,
                    0.116,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    108,
                    350,
                    224
                ],
                "correlated_neurons_pearson": [
                    0.012,
                    0.012,
                    0.011
                ],
                "correlated_neurons_l1": [
                    0.012,
                    0.012,
                    0.012
                ],
                "correlated_features_indices": [
                    48115,
                    48130,
                    48165
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.008,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "tar",
                    "CLUD",
                    "axy",
                    "rals",
                    " Launcher",
                    " launchers",
                    " snapping",
                    "00200000",
                    " launcher",
                    "ionage"
                ],
                "neg_values": [
                    -0.81,
                    -0.745,
                    -0.688,
                    -0.684,
                    -0.68,
                    -0.666,
                    -0.661,
                    -0.656,
                    -0.648,
                    -0.644
                ],
                "pos_str": [
                    " assistants",
                    "method",
                    "piece",
                    " Practices",
                    "material",
                    " materials",
                    "room",
                    " profession",
                    " Teachers",
                    "pieces"
                ],
                "pos_values": [
                    0.896,
                    0.886,
                    0.84,
                    0.817,
                    0.796,
                    0.794,
                    0.785,
                    0.781,
                    0.729,
                    0.724
                ],
                "frac_nonzero": 0.00011,
                "freq_hist_data_bar_heights": [
                    61,
                    54,
                    31,
                    24,
                    16,
                    17,
                    13,
                    6,
                    8,
                    8,
                    11,
                    5,
                    2,
                    6,
                    4,
                    5,
                    2,
                    5,
                    2,
                    2,
                    3,
                    2,
                    2,
                    1,
                    0,
                    3,
                    3,
                    0,
                    1,
                    3,
                    3,
                    3,
                    0,
                    1,
                    2,
                    1,
                    0,
                    0,
                    4,
                    1,
                    2,
                    1,
                    7,
                    7,
                    1,
                    0,
                    1,
                    1,
                    4,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.474,
                    1.412,
                    2.349,
                    3.287,
                    4.225,
                    5.162,
                    6.1,
                    7.038,
                    7.976,
                    8.913,
                    9.851,
                    10.789,
                    11.726,
                    12.664,
                    13.602,
                    14.539,
                    15.477,
                    16.415,
                    17.352,
                    18.29,
                    19.228,
                    20.166,
                    21.103,
                    22.041,
                    22.979,
                    23.916,
                    24.854,
                    25.792,
                    26.729,
                    27.667,
                    28.605,
                    29.542,
                    30.48,
                    31.418,
                    32.356,
                    33.293,
                    34.231,
                    35.169,
                    36.106,
                    37.044,
                    37.982,
                    38.919,
                    39.857,
                    40.795,
                    41.733,
                    42.67,
                    43.608,
                    44.546,
                    45.483,
                    46.421
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    0,
                    3,
                    5,
                    7,
                    12,
                    17,
                    29,
                    64,
                    103,
                    174,
                    243,
                    385,
                    581,
                    894,
                    1219,
                    1684,
                    2183,
                    2841,
                    3484,
                    3922,
                    4292,
                    4427,
                    4363,
                    3957,
                    3496,
                    2985,
                    2410,
                    1913,
                    1387,
                    992,
                    707,
                    456,
                    314,
                    229,
                    162,
                    108,
                    71,
                    33,
                    38,
                    26,
                    13,
                    10,
                    7,
                    1,
                    2,
                    3,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.793,
                    -0.759,
                    -0.725,
                    -0.691,
                    -0.657,
                    -0.623,
                    -0.588,
                    -0.554,
                    -0.52,
                    -0.486,
                    -0.452,
                    -0.418,
                    -0.384,
                    -0.35,
                    -0.315,
                    -0.281,
                    -0.247,
                    -0.213,
                    -0.179,
                    -0.145,
                    -0.111,
                    -0.077,
                    -0.042,
                    -0.008,
                    0.026,
                    0.06,
                    0.094,
                    0.128,
                    0.162,
                    0.196,
                    0.231,
                    0.265,
                    0.299,
                    0.333,
                    0.367,
                    0.401,
                    0.435,
                    0.469,
                    0.504,
                    0.538,
                    0.572,
                    0.606,
                    0.64,
                    0.674,
                    0.708,
                    0.742,
                    0.777,
                    0.811,
                    0.845,
                    0.879
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to teaching and educational practices",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygh9qembu7o10exveoqrkjz",
                        "tokens": [
                            " replacing",
                            " retirees",
                            " with",
                            " new",
                            " tenure",
                            "-",
                            "eligible",
                            " hires",
                            ",",
                            " departments",
                            " gradually",
                            " shifted",
                            " the",
                            " teaching",
                            " load",
                            " to",
                            " part",
                            "-",
                            "tim",
                            "ers",
                            ":",
                            " adjunct",
                            "s",
                            ",",
                            " post",
                            "docs",
                            ",",
                            " graduate",
                            " students",
                            ".",
                            " From",
                            " 1991",
                            " to",
                            " 2003",
                            ",",
                            " the",
                            " number",
                            " of",
                            " full",
                            "-",
                            "time",
                            " faculty",
                            " members",
                            " increased",
                            " by",
                            " 18",
                            " percent",
                            ".",
                            " The",
                            " number",
                            " of",
                            " part",
                            "-",
                            "tim",
                            "ers",
                            " increased",
                            " by",
                            " 87",
                            " percent",
                            "\u2014",
                            "to",
                            " almost",
                            " half",
                            " the",
                            " entire",
                            " faculty",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " as",
                            " Jack",
                            " Sch",
                            "uster",
                            " and",
                            " Martin",
                            " Fin",
                            "kel",
                            "stein",
                            " point",
                            " out",
                            " in",
                            " their",
                            " comprehensive",
                            " study",
                            " The",
                            " American",
                            " Faculty",
                            " (",
                            "2006",
                            "),",
                            " the",
                            " move",
                            " to",
                            " part",
                            "-",
                            "time",
                            " labor",
                            " is",
                            " already",
                            " an",
                            " old",
                            " story",
                            ".",
                            " Less",
                            " visible",
                            " but",
                            " equally",
                            " important",
                            " has",
                            " been",
                            " the",
                            " advent",
                            " and",
                            " rapid",
                            " expansion",
                            " of",
                            " full",
                            "-",
                            "time",
                            " positions",
                            " that",
                            " are",
                            " not",
                            " tenure",
                            "-",
                            "eligible"
                        ],
                        "dataIndex": null,
                        "index": "48216",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.89,
                        "maxValueTokenIndex": 13,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.89,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:35:11.814Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 46.89,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh9qembu7p10exhmvn7f9a",
                        "tokens": [
                            " to",
                            " other",
                            " school",
                            " staff",
                            ",",
                            " Ann",
                            " M",
                            "ester",
                            ",",
                            " an",
                            " associate",
                            " dean",
                            " at",
                            " the",
                            " College",
                            " of",
                            " Liberal",
                            " Arts",
                            " and",
                            " Sciences",
                            ",",
                            " said",
                            " Howell",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " e",
                            "-",
                            "mail",
                            " justified",
                            " his",
                            " firing",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "The",
                            " e",
                            "-",
                            "mails",
                            " sent",
                            " by",
                            " Dr",
                            ".",
                            " Howell",
                            " violate",
                            " university",
                            " standards",
                            " of",
                            " in",
                            "clus",
                            "ivity",
                            ",",
                            " which",
                            " would",
                            " then",
                            " entitle",
                            " us",
                            " to",
                            " have",
                            " him",
                            " discontin",
                            "ue",
                            " his",
                            " teaching",
                            " arrangement",
                            " with",
                            " us",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " M",
                            "ester",
                            " wrote",
                            ".",
                            " Cary",
                            " Nelson",
                            ",",
                            " president",
                            " of",
                            " the",
                            " American",
                            " Association",
                            " of",
                            " University",
                            " Prof",
                            "essors",
                            ",",
                            " said",
                            " professors",
                            " should",
                            " be",
                            " able",
                            " to",
                            " tell",
                            " students",
                            " their",
                            " own",
                            " views",
                            " and",
                            " even",
                            " argue",
                            " in",
                            " favor",
                            " of",
                            " them",
                            ",",
                            " provided",
                            " students",
                            " can",
                            " disagree",
                            " without",
                            " being",
                            " penal",
                            "ized",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " part",
                            " of",
                            " intellectual",
                            " life",
                            " to",
                            " advocate"
                        ],
                        "dataIndex": null,
                        "index": "48216",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 45.912,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.912,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:35:11.814Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 46.89,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygh9qembu7q10exib8i1qct",
                        "tokens": [
                            " which",
                            " he",
                            " apologised",
                            " for",
                            " breaking",
                            " pledges",
                            " on",
                            " university",
                            " tuition",
                            " fees",
                            ".",
                            "\n",
                            "\n",
                            "Mrs",
                            " Ob",
                            "ors",
                            "ki",
                            ",",
                            " a",
                            " former",
                            " teacher",
                            " and",
                            " education",
                            " adviser",
                            ",",
                            " said",
                            ":",
                            " \"",
                            "School",
                            " pupils",
                            ",",
                            " especially",
                            " those",
                            " in",
                            " the",
                            " primary",
                            " phase",
                            ",",
                            " are",
                            " extremely",
                            " trusting",
                            " of",
                            " members",
                            " of",
                            " the",
                            " teaching",
                            " profession",
                            " and",
                            " really",
                            " do",
                            " believe",
                            " everything",
                            " their",
                            " teacher",
                            " tells",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "\"",
                            "This",
                            " puts",
                            " a",
                            " very",
                            " great",
                            " responsibility",
                            " upon",
                            " teachers",
                            ",",
                            " especially",
                            " at",
                            " election",
                            " time",
                            ",",
                            " to",
                            " maintain",
                            " professional",
                            " standards",
                            " and",
                            " not",
                            " seek",
                            " to",
                            " impose",
                            " their",
                            " personal",
                            " political",
                            " beliefs",
                            " upon",
                            " vulnerable",
                            ",",
                            " trusting",
                            " young",
                            " children",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "\u00e2\u0122\u00a2",
                            " Left",
                            "-",
                            "wing",
                            " thinking",
                            " still",
                            " prev",
                            "ails",
                            " in",
                            " schools",
                            "\n",
                            "\n",
                            "John",
                            " Camp",
                            "ion",
                            ",",
                            " the",
                            " county",
                            " council",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " cabinet",
                            " member",
                            " for",
                            " children",
                            " and",
                            " families",
                            ","
                        ],
                        "dataIndex": null,
                        "index": "48216",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 45.635,
                        "maxValueTokenIndex": 45,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.635,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:35:11.814Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 46.89,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs6144-jb",
            "index": "5368",
            "description": "statements related to education and teaching methods",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5888017591476967,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs6144-jb",
                "index": "5368",
                "sourceSetName": "res_fs6144-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:13:26.905Z",
                "maxActApprox": 40.572,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    5368,
                    5681,
                    4191,
                    3878,
                    4574,
                    723,
                    407,
                    3647,
                    2419,
                    1460,
                    2278,
                    2769,
                    3848,
                    3311,
                    1370,
                    1154,
                    2255,
                    4728,
                    4634,
                    2208,
                    3651,
                    24,
                    4188,
                    5488,
                    1073
                ],
                "topkCosSimValues": [
                    1,
                    0.4779,
                    0.4544,
                    0.4237,
                    0.4202,
                    0.3907,
                    0.3893,
                    0.375,
                    0.3556,
                    0.3397,
                    0.3274,
                    0.3194,
                    0.3128,
                    0.3117,
                    0.3048,
                    0.293,
                    0.2913,
                    0.2848,
                    0.2829,
                    0.2712,
                    0.2708,
                    0.2705,
                    0.2698,
                    0.2661,
                    0.2601
                ],
                "neuron_alignment_indices": [
                    546,
                    698,
                    765
                ],
                "neuron_alignment_values": [
                    0.131,
                    0.112,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    546,
                    765,
                    43
                ],
                "correlated_neurons_pearson": [
                    0.147,
                    0.117,
                    0.116
                ],
                "correlated_neurons_l1": [
                    0.146,
                    0.121,
                    0.105
                ],
                "correlated_features_indices": [
                    5286,
                    5324,
                    5358
                ],
                "correlated_features_pearson": [
                    0.115,
                    0.035,
                    0.016
                ],
                "correlated_features_l1": [
                    0.119,
                    0.04,
                    0.02
                ],
                "neg_str": [
                    "uta",
                    "itol",
                    " Zeal",
                    "\u00e3\u0123\u0142",
                    "cast",
                    "thora",
                    "venth",
                    "chnology",
                    "uther",
                    " GG"
                ],
                "neg_values": [
                    -0.677,
                    -0.584,
                    -0.577,
                    -0.576,
                    -0.566,
                    -0.559,
                    -0.556,
                    -0.551,
                    -0.544,
                    -0.541
                ],
                "pos_str": [
                    " according",
                    " says",
                    "according",
                    " said",
                    " writes",
                    " experts",
                    "said",
                    " analysts",
                    " observes",
                    " explained"
                ],
                "pos_values": [
                    1.418,
                    1.113,
                    1.1,
                    1.079,
                    0.911,
                    0.904,
                    0.886,
                    0.884,
                    0.829,
                    0.828
                ],
                "frac_nonzero": 0.01185,
                "freq_hist_data_bar_heights": [
                    7376,
                    5300,
                    3830,
                    3039,
                    2342,
                    1933,
                    1697,
                    1450,
                    1190,
                    1033,
                    868,
                    833,
                    636,
                    653,
                    534,
                    506,
                    423,
                    416,
                    302,
                    330,
                    286,
                    271,
                    251,
                    202,
                    189,
                    182,
                    141,
                    156,
                    119,
                    118,
                    102,
                    85,
                    91,
                    63,
                    57,
                    45,
                    36,
                    35,
                    36,
                    17,
                    27,
                    22,
                    19,
                    13,
                    11,
                    8,
                    3,
                    4,
                    4,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.406,
                    1.217,
                    2.029,
                    2.84,
                    3.651,
                    4.463,
                    5.274,
                    6.086,
                    6.897,
                    7.709,
                    8.52,
                    9.331,
                    10.143,
                    10.954,
                    11.766,
                    12.577,
                    13.389,
                    14.2,
                    15.011,
                    15.823,
                    16.634,
                    17.446,
                    18.257,
                    19.069,
                    19.88,
                    20.691,
                    21.503,
                    22.314,
                    23.126,
                    23.937,
                    24.749,
                    25.56,
                    26.371,
                    27.183,
                    27.994,
                    28.806,
                    29.617,
                    30.429,
                    31.24,
                    32.051,
                    32.863,
                    33.674,
                    34.486,
                    35.297,
                    36.109,
                    36.92,
                    37.731,
                    38.543,
                    39.354,
                    40.166
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    7,
                    24,
                    31,
                    65,
                    154,
                    313,
                    558,
                    990,
                    1568,
                    2592,
                    3493,
                    4521,
                    5249,
                    5643,
                    5445,
                    4876,
                    4117,
                    3263,
                    2374,
                    1716,
                    1189,
                    772,
                    516,
                    296,
                    178,
                    105,
                    69,
                    45,
                    25,
                    23,
                    9,
                    10,
                    4,
                    8,
                    0,
                    4,
                    0,
                    0,
                    0,
                    1,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.656,
                    -0.614,
                    -0.572,
                    -0.53,
                    -0.488,
                    -0.446,
                    -0.404,
                    -0.363,
                    -0.321,
                    -0.279,
                    -0.237,
                    -0.195,
                    -0.153,
                    -0.111,
                    -0.069,
                    -0.027,
                    0.014,
                    0.056,
                    0.098,
                    0.14,
                    0.182,
                    0.224,
                    0.266,
                    0.308,
                    0.35,
                    0.391,
                    0.433,
                    0.475,
                    0.517,
                    0.559,
                    0.601,
                    0.643,
                    0.685,
                    0.727,
                    0.768,
                    0.81,
                    0.852,
                    0.894,
                    0.936,
                    0.978,
                    1.02,
                    1.062,
                    1.104,
                    1.145,
                    1.187,
                    1.229,
                    1.271,
                    1.313,
                    1.355,
                    1.397
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "statements related to education and teaching methods",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtgs65xpjwi6667wv6k8da",
                        "tokens": [
                            " It",
                            " also",
                            " could",
                            " mean",
                            " that",
                            " schools",
                            " are",
                            " missing",
                            " the",
                            " right",
                            " time",
                            " to",
                            " teach",
                            " those",
                            " subjects",
                            ".",
                            "\n",
                            "\n",
                            "School",
                            "s",
                            " ought",
                            " to",
                            " consider",
                            " some",
                            " gender",
                            "-",
                            "based",
                            " curric",
                            "ula",
                            ",",
                            " Jensen",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " beyond",
                            " gender",
                            " differences",
                            ",",
                            " if",
                            " every",
                            " student",
                            " were",
                            " given",
                            " a",
                            " neurological",
                            " evaluation",
                            ",",
                            " educators",
                            " would",
                            " have",
                            " powerful",
                            " clues",
                            " as",
                            " to",
                            " the",
                            " best",
                            " way",
                            " to",
                            " personal",
                            "ize",
                            " learning",
                            ",",
                            " she",
                            " said",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Br",
                            "ains",
                            " are",
                            " in",
                            " such",
                            " a",
                            " different",
                            " state",
                            " from",
                            " person",
                            " to",
                            " person",
                            ",",
                            " they",
                            " should",
                            " be",
                            " taught",
                            " differently",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " she",
                            " said",
                            ".",
                            "<|endoftext|>",
                            "Why",
                            " has",
                            " the",
                            " BBC",
                            " become",
                            " the",
                            " official",
                            " propaganda",
                            " arm",
                            " of",
                            " the",
                            " Vatican",
                            "?",
                            "\n",
                            "\n",
                            "The",
                            " Vatican",
                            " is",
                            " desperate",
                            " to",
                            " rehabilit",
                            "ate",
                            " its",
                            " reputation",
                            ".",
                            " And",
                            " well",
                            " it",
                            " might",
                            " be",
                            ".",
                            " The",
                            " past"
                        ],
                        "dataIndex": null,
                        "index": "5368",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 40.572,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.621,
                            0,
                            5.03,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            24.4,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.215,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.66,
                            0.712,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            40.572,
                            2.983,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            25.879,
                            11.477,
                            5.085,
                            0,
                            0,
                            6.51,
                            33.86,
                            3.338,
                            10.238,
                            1.222,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:13:35.250Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.571,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtgs65xpjxi666fvxm0wp4",
                        "tokens": [
                            " and",
                            " run",
                            " east",
                            "bound",
                            " on",
                            " Roosevelt",
                            " Street",
                            ",",
                            " said",
                            " Deputy",
                            " Jo",
                            "aquin",
                            " En",
                            "ri",
                            "quez",
                            ",",
                            " a",
                            " sheriff",
                            "'s",
                            " spokesman",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " of",
                            " the",
                            " detention",
                            " officers",
                            " secured",
                            " the",
                            " other",
                            " two",
                            " inmates",
                            ",",
                            " and",
                            " the",
                            " second",
                            " detention",
                            " officer",
                            " hopped",
                            " back",
                            " in",
                            " the",
                            " van",
                            " and",
                            " took",
                            " off",
                            " after",
                            " Fres",
                            "cas",
                            ",",
                            " En",
                            "ri",
                            "quez",
                            " said",
                            ".",
                            " Another",
                            " deputy",
                            " was",
                            " called",
                            " for",
                            " backup",
                            ",",
                            " and",
                            " the",
                            " hospital",
                            " was",
                            " placed",
                            " on",
                            " a",
                            " brief",
                            " lockdown",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " officer",
                            " caught",
                            " up",
                            " with",
                            " Fres",
                            "cas",
                            " about",
                            " 500",
                            " yards",
                            " away",
                            " from",
                            " the",
                            " hospital",
                            ",",
                            " exited",
                            " the",
                            " van",
                            " and",
                            " a",
                            " struggle",
                            " ensued",
                            " over",
                            " the",
                            " officer",
                            "'s",
                            " weapon",
                            ",",
                            " En",
                            "ri",
                            "quez",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "Investigators",
                            " say",
                            " Fres",
                            "cas",
                            " held",
                            " the",
                            " gun",
                            " at",
                            " one",
                            " point",
                            ",",
                            " but",
                            " it",
                            " was",
                            " unclear",
                            " whether",
                            " Fres"
                        ],
                        "dataIndex": null,
                        "index": "5368",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.617,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.701,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.935,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.219,
                            0,
                            0,
                            3.136,
                            0,
                            0,
                            15.275,
                            0,
                            0,
                            5.967,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            16.623,
                            0,
                            0,
                            0,
                            0.513,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            24.758,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.191,
                            0,
                            0.513,
                            39.617,
                            1.141,
                            0,
                            5.073,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.155,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:13:35.250Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.571,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtgs65xpjyi666ft8m5a48",
                        "tokens": [
                            "than",
                            "-",
                            "usual",
                            " target",
                            " number",
                            " may",
                            " be",
                            " partially",
                            " driven",
                            " by",
                            " an",
                            " effort",
                            " to",
                            " reach",
                            " a",
                            " deportation",
                            " goal",
                            " at",
                            " the",
                            " end",
                            " of",
                            " the",
                            " fiscal",
                            " year",
                            ",",
                            " which",
                            " ends",
                            " Sept",
                            ".",
                            " 30",
                            ",",
                            " one",
                            " of",
                            " the",
                            " officials",
                            " said",
                            ".",
                            " Operation",
                            " Mega",
                            " is",
                            " still",
                            " in",
                            " the",
                            " planning",
                            " stage",
                            " and",
                            " its",
                            " details",
                            " may",
                            " change",
                            " or",
                            " it",
                            " may",
                            " even",
                            " be",
                            " cancelled",
                            ",",
                            " the",
                            " officials",
                            " said",
                            ",",
                            " especially",
                            " as",
                            " the",
                            " agency",
                            " re",
                            "alloc",
                            "ates",
                            " resources",
                            " toward",
                            " rescue",
                            " operations",
                            " in",
                            " Florida",
                            " ahead",
                            " of",
                            " the",
                            " looming",
                            " Hurricane",
                            " Irma",
                            ".",
                            " If",
                            " carried",
                            " out",
                            ",",
                            " it",
                            " would",
                            " come",
                            " on",
                            " the",
                            " heels",
                            " of",
                            " Trump",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " controversial",
                            " decision",
                            " to",
                            " end",
                            " the",
                            " Def",
                            "erred",
                            " Action",
                            " for",
                            " Childhood",
                            " Arri",
                            "vals",
                            " program",
                            ",",
                            " known",
                            " as",
                            " DACA",
                            ",",
                            " that",
                            " allows",
                            " some",
                            " immigrants",
                            " who",
                            " were",
                            " brought",
                            " into",
                            " the",
                            " United",
                            " States",
                            " as",
                            " children"
                        ],
                        "dataIndex": null,
                        "index": "5368",
                        "layer": "8-res_fs6144-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 39.38,
                        "maxValueTokenIndex": 56,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            24.587,
                            0.206,
                            0,
                            0,
                            0,
                            0,
                            29.692,
                            9.692,
                            0.4,
                            3.468,
                            0.9,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.005,
                            1.471,
                            0,
                            2.862,
                            0,
                            0,
                            0,
                            0.226,
                            39.38,
                            4.746,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.903,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:13:35.250Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 40.571,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "70159",
            "description": "words related to teaching, learning, and instilling beliefs or values",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5871750116348267,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "70159",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:59:02.898Z",
                "maxActApprox": 46.329,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    70159,
                    84145,
                    15540,
                    79957,
                    86720,
                    38123,
                    9665,
                    23771,
                    82563,
                    74978,
                    80415,
                    66224,
                    79161,
                    83035,
                    17240,
                    19056,
                    27303,
                    47515,
                    33707,
                    66029,
                    18254,
                    67986,
                    7629,
                    86951,
                    40868
                ],
                "topkCosSimValues": [
                    1,
                    0.5027,
                    0.4782,
                    0.4704,
                    0.4535,
                    0.4522,
                    0.4314,
                    0.4241,
                    0.4201,
                    0.4083,
                    0.4043,
                    0.4034,
                    0.3995,
                    0.3986,
                    0.3806,
                    0.3776,
                    0.3689,
                    0.3666,
                    0.3637,
                    0.3589,
                    0.3586,
                    0.3579,
                    0.3569,
                    0.3526,
                    0.3522
                ],
                "neuron_alignment_indices": [
                    414,
                    549,
                    459
                ],
                "neuron_alignment_values": [
                    0.125,
                    0.106,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    414,
                    301,
                    549
                ],
                "correlated_neurons_pearson": [
                    0.006,
                    0.006,
                    0.006
                ],
                "correlated_neurons_l1": [
                    0.005,
                    0.006,
                    0.006
                ],
                "correlated_features_indices": [
                    70243,
                    70190,
                    70204
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0,
                    0
                ],
                "neg_str": [
                    " Estimates",
                    "\u0124\u0130",
                    "\u013c\u00e9\u0128\u0134",
                    " SECTION",
                    "apter",
                    "FT",
                    "fml",
                    " Sack",
                    "ft",
                    "assian"
                ],
                "neg_values": [
                    -0.618,
                    -0.611,
                    -0.604,
                    -0.602,
                    -0.598,
                    -0.593,
                    -0.589,
                    -0.584,
                    -0.581,
                    -0.574
                ],
                "pos_str": [
                    " confidence",
                    "aneously",
                    "ment",
                    "rained",
                    " memories",
                    " patriotism",
                    " hatred",
                    " fear",
                    "inct",
                    " faith"
                ],
                "pos_values": [
                    0.84,
                    0.806,
                    0.806,
                    0.785,
                    0.784,
                    0.784,
                    0.779,
                    0.777,
                    0.729,
                    0.727
                ],
                "frac_nonzero": 6e-05,
                "freq_hist_data_bar_heights": [
                    56,
                    30,
                    17,
                    20,
                    10,
                    12,
                    5,
                    4,
                    4,
                    1,
                    1,
                    4,
                    1,
                    1,
                    1,
                    1,
                    2,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.469,
                    1.395,
                    2.321,
                    3.248,
                    4.174,
                    5.101,
                    6.027,
                    6.954,
                    7.88,
                    8.807,
                    9.733,
                    10.66,
                    11.586,
                    12.513,
                    13.439,
                    14.366,
                    15.292,
                    16.218,
                    17.145,
                    18.071,
                    18.998,
                    19.924,
                    20.851,
                    21.777,
                    22.704,
                    23.63,
                    24.557,
                    25.483,
                    26.41,
                    27.336,
                    28.263,
                    29.189,
                    30.115,
                    31.042,
                    31.968,
                    32.895,
                    33.821,
                    34.748,
                    35.674,
                    36.601,
                    37.527,
                    38.454,
                    39.38,
                    40.307,
                    41.233,
                    42.16,
                    43.086,
                    44.012,
                    44.939,
                    45.865
                ],
                "logits_hist_data_bar_heights": [
                    7,
                    4,
                    22,
                    22,
                    30,
                    52,
                    101,
                    143,
                    205,
                    356,
                    504,
                    728,
                    975,
                    1441,
                    1754,
                    2271,
                    2736,
                    3105,
                    3403,
                    3592,
                    3735,
                    3685,
                    3582,
                    3230,
                    2828,
                    2478,
                    2025,
                    1772,
                    1342,
                    1009,
                    808,
                    634,
                    460,
                    335,
                    235,
                    183,
                    133,
                    105,
                    59,
                    36,
                    30,
                    30,
                    31,
                    15,
                    7,
                    9,
                    2,
                    2,
                    5,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.603,
                    -0.574,
                    -0.545,
                    -0.516,
                    -0.487,
                    -0.457,
                    -0.428,
                    -0.399,
                    -0.37,
                    -0.341,
                    -0.312,
                    -0.282,
                    -0.253,
                    -0.224,
                    -0.195,
                    -0.166,
                    -0.137,
                    -0.107,
                    -0.078,
                    -0.049,
                    -0.02,
                    0.009,
                    0.038,
                    0.068,
                    0.097,
                    0.126,
                    0.155,
                    0.184,
                    0.213,
                    0.243,
                    0.272,
                    0.301,
                    0.33,
                    0.359,
                    0.388,
                    0.417,
                    0.447,
                    0.476,
                    0.505,
                    0.534,
                    0.563,
                    0.592,
                    0.622,
                    0.651,
                    0.68,
                    0.709,
                    0.738,
                    0.767,
                    0.797,
                    0.826
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "words related to teaching, learning, and instilling beliefs or values",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "words related to instilling beliefs or skills",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi4f5msifr10exqvx6t0ll",
                        "tokens": [
                            "M",
                            "ans",
                            "our",
                            " added",
                            " that",
                            " he",
                            " has",
                            " seen",
                            " and",
                            " heard",
                            " the",
                            " inc",
                            "itement",
                            " against",
                            " N",
                            "asser",
                            ",",
                            " not",
                            " just",
                            " from",
                            " older",
                            " people",
                            " but",
                            " also",
                            " from",
                            " young",
                            " Arab",
                            "-",
                            "Israel",
                            "is",
                            " who",
                            " do",
                            " not",
                            " lead",
                            " a",
                            " religious",
                            " or",
                            " conservative",
                            " way",
                            " of",
                            " life",
                            " and",
                            " yet",
                            " cannot",
                            " accept",
                            " young",
                            " Arab",
                            " women",
                            " who",
                            " refuse",
                            " to",
                            " behave",
                            " according",
                            " to",
                            " the",
                            " moral",
                            " code",
                            " inst",
                            "illed",
                            " in",
                            " them",
                            " at",
                            " home",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " new",
                            " film",
                            " by",
                            " Arab",
                            " director",
                            " M",
                            "ays",
                            "al",
                            "oun",
                            " Ham",
                            "oud",
                            ",",
                            " a",
                            " resident",
                            " of",
                            " the",
                            " mixed",
                            " Jewish",
                            "-",
                            "Arab",
                            " city",
                            " of",
                            " Tel",
                            " Aviv",
                            "-",
                            "J",
                            "aff",
                            "a",
                            ",",
                            " offers",
                            " a",
                            " fascinating",
                            " glimpse",
                            " of",
                            " the",
                            " currents",
                            " shaking",
                            " up",
                            " Arab",
                            " society",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Not",
                            " Here",
                            ",",
                            " Not",
                            " There",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " which",
                            " hit",
                            " Israeli",
                            " movie",
                            " screens",
                            " Dec",
                            ".",
                            " 30",
                            ","
                        ],
                        "dataIndex": null,
                        "index": "70159",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.329,
                        "maxValueTokenIndex": 58,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.704,
                            46.329,
                            6.83,
                            0.777,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:59:03.560Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 46.329,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi4f5osigc10ex350sfk2i",
                        "tokens": [
                            "M",
                            "ans",
                            "our",
                            " added",
                            " that",
                            " he",
                            " has",
                            " seen",
                            " and",
                            " heard",
                            " the",
                            " inc",
                            "itement",
                            " against",
                            " N",
                            "asser",
                            ",",
                            " not",
                            " just",
                            " from",
                            " older",
                            " people",
                            " but",
                            " also",
                            " from",
                            " young",
                            " Arab",
                            "-",
                            "Israel",
                            "is",
                            " who",
                            " do",
                            " not",
                            " lead",
                            " a",
                            " religious",
                            " or",
                            " conservative",
                            " way",
                            " of",
                            " life",
                            " and",
                            " yet",
                            " cannot",
                            " accept",
                            " young",
                            " Arab",
                            " women",
                            " who",
                            " refuse",
                            " to",
                            " behave",
                            " according",
                            " to",
                            " the",
                            " moral",
                            " code",
                            " inst",
                            "illed",
                            " in",
                            " them",
                            " at",
                            " home",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " new",
                            " film",
                            " by",
                            " Arab",
                            " director",
                            " M",
                            "ays",
                            "al",
                            "oun",
                            " Ham",
                            "oud",
                            ",",
                            " a",
                            " resident",
                            " of",
                            " the",
                            " mixed",
                            " Jewish",
                            "-",
                            "Arab",
                            " city",
                            " of",
                            " Tel",
                            " Aviv",
                            "-",
                            "J",
                            "aff",
                            "a",
                            ",",
                            " offers",
                            " a",
                            " fascinating",
                            " glimpse",
                            " of",
                            " the",
                            " currents",
                            " shaking",
                            " up",
                            " Arab",
                            " society",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "Not",
                            " Here",
                            ",",
                            " Not",
                            " There",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " which",
                            " hit",
                            " Israeli",
                            " movie",
                            " screens",
                            " Dec",
                            ".",
                            " 30",
                            ","
                        ],
                        "dataIndex": null,
                        "index": "70159",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.329,
                        "maxValueTokenIndex": 58,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.704,
                            46.329,
                            6.83,
                            0.777,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:59:03.560Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 37.063,
                        "binMax": 46.329,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi4f5msifs10exnncb2dy5",
                        "tokens": [
                            ",",
                            " Z",
                            "im",
                            " has",
                            " probably",
                            " been",
                            " the",
                            " most",
                            " important",
                            " Blue",
                            " Ch",
                            "ipper",
                            " of",
                            " them",
                            " all",
                            ".",
                            " In",
                            " just",
                            " two",
                            " seasons",
                            " he",
                            " has",
                            " completely",
                            " changed",
                            " the",
                            " culture",
                            " in",
                            " Minnesota",
                            ".",
                            " The",
                            " Vikings",
                            " head",
                            " coach",
                            " has",
                            " inst",
                            "illed",
                            " a",
                            " mindset",
                            " and",
                            " will",
                            " that",
                            " the",
                            " Vikings",
                            " haven",
                            "'t",
                            " possessed",
                            " in",
                            " decades",
                            ".",
                            " His",
                            " tough",
                            "-",
                            "love",
                            ",",
                            " no",
                            "-",
                            "n",
                            "onsense",
                            " approach",
                            " to",
                            " mixing",
                            " in",
                            " savvy",
                            ",",
                            " depend",
                            "able",
                            " veterans",
                            " with",
                            " a",
                            " be",
                            "vy",
                            " of",
                            " young",
                            ",",
                            " impression",
                            "able",
                            " talent",
                            " has",
                            " been",
                            " a",
                            " master",
                            " class",
                            " of",
                            " how",
                            " to",
                            " build",
                            " a",
                            " team",
                            " for",
                            " both",
                            " the",
                            " present",
                            " and",
                            " the",
                            " future",
                            ".",
                            " This",
                            " team",
                            " has",
                            " been",
                            " checking",
                            " off",
                            " tasks",
                            " that",
                            " haven",
                            "'t",
                            " been",
                            " completed",
                            " in",
                            " years",
                            ".",
                            " Winning",
                            " on",
                            " the",
                            " road",
                            ".",
                            " Winning",
                            " at",
                            " Chicago",
                            ".",
                            " Winning",
                            " when",
                            " everything",
                            " wasn",
                            "'t",
                            " clicking",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "70159",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.48,
                        "maxValueTokenIndex": 35,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.48,
                            14.34,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:59:03.560Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 46.329,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "6942",
            "description": "actions involving instruction, support, and guidance",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5819858312606812,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "6942",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:10:29.382Z",
                "maxActApprox": 16.189,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    6942,
                    9712,
                    3555,
                    33822,
                    41728,
                    10474,
                    27246,
                    36496,
                    22388,
                    24424,
                    41567,
                    14585,
                    2438,
                    8064,
                    47617,
                    3536,
                    3862,
                    25244,
                    32675,
                    10493,
                    26277,
                    11447,
                    18245,
                    32948,
                    6308
                ],
                "topkCosSimValues": [
                    1,
                    0.5472,
                    0.5419,
                    0.5224,
                    0.5021,
                    0.5009,
                    0.4805,
                    0.4674,
                    0.46,
                    0.4515,
                    0.4485,
                    0.4481,
                    0.4469,
                    0.4317,
                    0.4303,
                    0.4244,
                    0.4226,
                    0.4221,
                    0.4154,
                    0.4152,
                    0.4093,
                    0.4061,
                    0.4058,
                    0.4052,
                    0.404
                ],
                "neuron_alignment_indices": [
                    458,
                    63,
                    310
                ],
                "neuron_alignment_values": [
                    0.103,
                    0.098,
                    0.096
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    59,
                    282,
                    184
                ],
                "correlated_neurons_pearson": [
                    0.033,
                    0.031,
                    0.031
                ],
                "correlated_neurons_l1": [
                    0.031,
                    0.033,
                    0.023
                ],
                "correlated_features_indices": [
                    7015,
                    7043,
                    6968
                ],
                "correlated_features_pearson": [
                    0.004,
                    0.003,
                    0.003
                ],
                "correlated_features_l1": [
                    0.004,
                    0.004,
                    0.005
                ],
                "neg_str": [
                    "estate",
                    "alde",
                    "\u00dc",
                    "yond",
                    "fman",
                    "Ranked",
                    "abouts",
                    "levard",
                    " outs",
                    "\"},"
                ],
                "neg_values": [
                    -0.681,
                    -0.678,
                    -0.656,
                    -0.649,
                    -0.649,
                    -0.64,
                    -0.637,
                    -0.636,
                    -0.621,
                    -0.619
                ],
                "pos_str": [
                    " him",
                    " us",
                    " me",
                    " himself",
                    " attendees",
                    " viewers",
                    " listeners",
                    " everyone",
                    " passers",
                    " reporters"
                ],
                "pos_values": [
                    1.183,
                    1.125,
                    1.021,
                    1.011,
                    1.006,
                    0.997,
                    0.99,
                    0.927,
                    0.922,
                    0.914
                ],
                "frac_nonzero": 0.00147,
                "freq_hist_data_bar_heights": [
                    761,
                    638,
                    518,
                    425,
                    372,
                    276,
                    238,
                    215,
                    185,
                    133,
                    132,
                    102,
                    106,
                    77,
                    75,
                    57,
                    44,
                    29,
                    37,
                    32,
                    29,
                    24,
                    17,
                    15,
                    16,
                    11,
                    11,
                    9,
                    5,
                    8,
                    9,
                    4,
                    1,
                    3,
                    2,
                    3,
                    2,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.162,
                    0.486,
                    0.809,
                    1.133,
                    1.457,
                    1.781,
                    2.105,
                    2.428,
                    2.752,
                    3.076,
                    3.4,
                    3.723,
                    4.047,
                    4.371,
                    4.695,
                    5.019,
                    5.342,
                    5.666,
                    5.99,
                    6.314,
                    6.637,
                    6.961,
                    7.285,
                    7.609,
                    7.933,
                    8.256,
                    8.58,
                    8.904,
                    9.228,
                    9.551,
                    9.875,
                    10.199,
                    10.523,
                    10.847,
                    11.17,
                    11.494,
                    11.818,
                    12.142,
                    12.465,
                    12.789,
                    13.113,
                    13.437,
                    13.761,
                    14.084,
                    14.408,
                    14.732,
                    15.056,
                    15.379,
                    15.703,
                    16.027
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    9,
                    14,
                    26,
                    50,
                    65,
                    126,
                    268,
                    450,
                    756,
                    1193,
                    1666,
                    2250,
                    2840,
                    3487,
                    3929,
                    4113,
                    4314,
                    4106,
                    3703,
                    3309,
                    2857,
                    2351,
                    1891,
                    1521,
                    1234,
                    976,
                    842,
                    561,
                    425,
                    337,
                    218,
                    161,
                    77,
                    51,
                    24,
                    17,
                    10,
                    5,
                    4,
                    3,
                    0,
                    4,
                    2,
                    1,
                    4,
                    0,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.662,
                    -0.625,
                    -0.588,
                    -0.551,
                    -0.513,
                    -0.476,
                    -0.439,
                    -0.401,
                    -0.364,
                    -0.327,
                    -0.29,
                    -0.252,
                    -0.215,
                    -0.178,
                    -0.141,
                    -0.103,
                    -0.066,
                    -0.029,
                    0.009,
                    0.046,
                    0.083,
                    0.12,
                    0.158,
                    0.195,
                    0.232,
                    0.269,
                    0.307,
                    0.344,
                    0.381,
                    0.419,
                    0.456,
                    0.493,
                    0.53,
                    0.568,
                    0.605,
                    0.642,
                    0.68,
                    0.717,
                    0.754,
                    0.791,
                    0.829,
                    0.866,
                    0.903,
                    0.94,
                    0.978,
                    1.015,
                    1.052,
                    1.09,
                    1.127,
                    1.164
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "actions involving instruction, support, and guidance",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4jus5i1pzi666bn9olf6c",
                        "tokens": [
                            ".",
                            " It",
                            " was",
                            " a",
                            " short",
                            " flight",
                            ".",
                            " In",
                            " one",
                            " and",
                            " a",
                            " half",
                            " hours",
                            ",",
                            " we",
                            " were",
                            " in",
                            " St",
                            ".",
                            " Petersburg",
                            ",",
                            " the",
                            " city",
                            " known",
                            " for",
                            " its",
                            " art",
                            ",",
                            " splendid",
                            " architecture",
                            ",",
                            " beautiful",
                            " gardens",
                            ",",
                            " magnificent",
                            " cat",
                            "hed",
                            "rals",
                            " and",
                            " the",
                            " largest",
                            " museum",
                            " in",
                            " Europe",
                            ",",
                            "\n",
                            "\n",
                            "Ar",
                            "rival",
                            " at",
                            " St",
                            " Petersburg",
                            "\n",
                            "\n",
                            "A",
                            " young",
                            " lady",
                            " named",
                            " Jane",
                            " received",
                            " us",
                            " at",
                            " the",
                            " airport",
                            " at",
                            " St",
                            " Petersburg",
                            " and",
                            " accompanied",
                            " us",
                            " to",
                            " our",
                            " hotel",
                            " in",
                            " the",
                            " van",
                            ".",
                            " On",
                            " the",
                            " way",
                            ",",
                            " she",
                            " briefed",
                            " us",
                            " a",
                            " little",
                            " on",
                            " the",
                            " city",
                            ".",
                            " The",
                            " driver",
                            " spoke",
                            " only",
                            " Russian",
                            " though",
                            ".",
                            " The",
                            " weather",
                            " was",
                            " pleasantly",
                            " warm",
                            ".",
                            " We",
                            " reached",
                            " hotel",
                            " Marco",
                            " Polo",
                            " by",
                            " 1",
                            ".",
                            "30",
                            " pm",
                            " and",
                            " checked",
                            " into",
                            " the",
                            " two",
                            " rooms",
                            " that",
                            " were",
                            " booked",
                            " for",
                            " the",
                            " five",
                            " of",
                            " us"
                        ],
                        "dataIndex": null,
                        "index": "6942",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.189,
                        "maxValueTokenIndex": 82,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.168,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            16.189,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:10:30.874Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 16.189,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4jus7i1qki666uaarn1z0",
                        "tokens": [
                            ".",
                            " It",
                            " was",
                            " a",
                            " short",
                            " flight",
                            ".",
                            " In",
                            " one",
                            " and",
                            " a",
                            " half",
                            " hours",
                            ",",
                            " we",
                            " were",
                            " in",
                            " St",
                            ".",
                            " Petersburg",
                            ",",
                            " the",
                            " city",
                            " known",
                            " for",
                            " its",
                            " art",
                            ",",
                            " splendid",
                            " architecture",
                            ",",
                            " beautiful",
                            " gardens",
                            ",",
                            " magnificent",
                            " cat",
                            "hed",
                            "rals",
                            " and",
                            " the",
                            " largest",
                            " museum",
                            " in",
                            " Europe",
                            ",",
                            "\n",
                            "\n",
                            "Ar",
                            "rival",
                            " at",
                            " St",
                            " Petersburg",
                            "\n",
                            "\n",
                            "A",
                            " young",
                            " lady",
                            " named",
                            " Jane",
                            " received",
                            " us",
                            " at",
                            " the",
                            " airport",
                            " at",
                            " St",
                            " Petersburg",
                            " and",
                            " accompanied",
                            " us",
                            " to",
                            " our",
                            " hotel",
                            " in",
                            " the",
                            " van",
                            ".",
                            " On",
                            " the",
                            " way",
                            ",",
                            " she",
                            " briefed",
                            " us",
                            " a",
                            " little",
                            " on",
                            " the",
                            " city",
                            ".",
                            " The",
                            " driver",
                            " spoke",
                            " only",
                            " Russian",
                            " though",
                            ".",
                            " The",
                            " weather",
                            " was",
                            " pleasantly",
                            " warm",
                            ".",
                            " We",
                            " reached",
                            " hotel",
                            " Marco",
                            " Polo",
                            " by",
                            " 1",
                            ".",
                            "30",
                            " pm",
                            " and",
                            " checked",
                            " into",
                            " the",
                            " two",
                            " rooms",
                            " that",
                            " were",
                            " booked",
                            " for",
                            " the",
                            " five",
                            " of",
                            " us"
                        ],
                        "dataIndex": null,
                        "index": "6942",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.189,
                        "maxValueTokenIndex": 82,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.168,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            16.189,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:10:30.874Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 12.951,
                        "binMax": 16.189,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4jus5i1q0i666egekhvf3",
                        "tokens": [
                            " the",
                            " nice",
                            " list",
                            ",",
                            " when",
                            " every",
                            " human",
                            " being",
                            " is",
                            " totally",
                            " dep",
                            "raved",
                            " from",
                            " birth",
                            "?",
                            "\u00e2\u0122",
                            "\u013f",
                            " St",
                            ".",
                            " Nick",
                            " was",
                            " overheard",
                            " saying",
                            " to",
                            " Mrs",
                            ".",
                            " Claus",
                            " in",
                            " his",
                            " office",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "No",
                            " matter",
                            " what",
                            " filthy",
                            " r",
                            "ags",
                            " of",
                            " righteousness",
                            " they",
                            " bring",
                            " before",
                            " the",
                            " Lord",
                            ",",
                            " they",
                            " are",
                            " condemned",
                            " already",
                            " based",
                            " on",
                            " their",
                            " sin",
                            " nature",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "The",
                            " j",
                            "olly",
                            " gift",
                            "-",
                            "giving",
                            " man",
                            " tasked",
                            " his",
                            " elves",
                            " with",
                            " pur",
                            "ging",
                            " the",
                            " entire",
                            " \u00e2\u0122",
                            "\u013e",
                            "nice",
                            "\u00e2\u0122",
                            "\u013f",
                            " list",
                            " and",
                            " moving",
                            " all",
                            " the",
                            " names",
                            " over",
                            " to",
                            " the",
                            " naughty",
                            " list",
                            " all",
                            " afternoon",
                            ",",
                            " as",
                            " he",
                            " lect",
                            "ured",
                            " them",
                            " about",
                            " their",
                            " need",
                            " for",
                            " a",
                            " Savior",
                            " who",
                            " could",
                            " save",
                            " them",
                            " completely",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "He",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " actually",
                            " getting",
                            " kind",
                            " of",
                            " annoying",
                            " at",
                            " this"
                        ],
                        "dataIndex": null,
                        "index": "6942",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.158,
                        "maxValueTokenIndex": 98,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.633,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.284,
                            0,
                            0,
                            0,
                            0.413,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.118,
                            15.158,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:10:30.874Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 16.189,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "27303",
            "description": "instances of the word \"teach\" and its variations, indicating a focus on educational themes or instructional content",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5813759565353394,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "27303",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:04:35.738Z",
                "maxActApprox": 35.141,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    27303,
                    68287,
                    48216,
                    44064,
                    84880,
                    39551,
                    68269,
                    78484,
                    90381,
                    1477,
                    32386,
                    27016,
                    5909,
                    61552,
                    45929,
                    62592,
                    77660,
                    13254,
                    45552,
                    50465,
                    77000,
                    25065,
                    87134,
                    36129,
                    64882
                ],
                "topkCosSimValues": [
                    1,
                    0.8089,
                    0.6288,
                    0.5568,
                    0.5379,
                    0.5377,
                    0.5313,
                    0.5177,
                    0.5094,
                    0.4993,
                    0.4828,
                    0.4798,
                    0.4715,
                    0.4608,
                    0.4488,
                    0.4444,
                    0.4384,
                    0.4343,
                    0.4311,
                    0.4283,
                    0.4261,
                    0.4242,
                    0.424,
                    0.4218,
                    0.4175
                ],
                "neuron_alignment_indices": [
                    679,
                    414,
                    575
                ],
                "neuron_alignment_values": [
                    0.115,
                    0.086,
                    0.086
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    108,
                    25,
                    119
                ],
                "correlated_neurons_pearson": [
                    0.018,
                    0.015,
                    0.015
                ],
                "correlated_neurons_l1": [
                    0.018,
                    0.014,
                    0.015
                ],
                "correlated_features_indices": [
                    27307,
                    27394,
                    27294
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    " Ports",
                    "ascus",
                    " busiest",
                    "atos",
                    "ablished",
                    " allotted",
                    " Seeking",
                    "FTWARE",
                    "etting",
                    " Launcher"
                ],
                "neg_values": [
                    -0.704,
                    -0.693,
                    -0.681,
                    -0.676,
                    -0.62,
                    -0.613,
                    -0.61,
                    -0.607,
                    -0.601,
                    -0.6
                ],
                "pos_str": [
                    "children",
                    " kids",
                    "yout",
                    "kids",
                    "fulness",
                    " lessons",
                    " students",
                    "ingly",
                    "tale",
                    "parents"
                ],
                "pos_values": [
                    0.924,
                    0.882,
                    0.846,
                    0.803,
                    0.789,
                    0.785,
                    0.782,
                    0.781,
                    0.779,
                    0.777
                ],
                "frac_nonzero": 0.00017,
                "freq_hist_data_bar_heights": [
                    119,
                    69,
                    47,
                    27,
                    16,
                    20,
                    10,
                    10,
                    10,
                    8,
                    5,
                    10,
                    5,
                    6,
                    5,
                    8,
                    9,
                    7,
                    9,
                    8,
                    8,
                    4,
                    8,
                    8,
                    5,
                    10,
                    4,
                    7,
                    4,
                    4,
                    10,
                    9,
                    7,
                    5,
                    5,
                    2,
                    5,
                    5,
                    4,
                    3,
                    6,
                    2,
                    1,
                    2,
                    1,
                    1,
                    1,
                    2,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.354,
                    1.057,
                    1.76,
                    2.462,
                    3.165,
                    3.868,
                    4.571,
                    5.273,
                    5.976,
                    6.679,
                    7.382,
                    8.084,
                    8.787,
                    9.49,
                    10.193,
                    10.895,
                    11.598,
                    12.301,
                    13.004,
                    13.706,
                    14.409,
                    15.112,
                    15.815,
                    16.518,
                    17.22,
                    17.923,
                    18.626,
                    19.329,
                    20.031,
                    20.734,
                    21.437,
                    22.14,
                    22.842,
                    23.545,
                    24.248,
                    24.951,
                    25.653,
                    26.356,
                    27.059,
                    27.762,
                    28.464,
                    29.167,
                    29.87,
                    30.573,
                    31.275,
                    31.978,
                    32.681,
                    33.384,
                    34.087,
                    34.789
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    0,
                    4,
                    8,
                    11,
                    11,
                    43,
                    48,
                    91,
                    156,
                    254,
                    397,
                    612,
                    967,
                    1343,
                    1904,
                    2390,
                    3001,
                    3566,
                    3911,
                    4238,
                    4424,
                    4207,
                    3746,
                    3358,
                    2819,
                    2309,
                    1763,
                    1341,
                    981,
                    743,
                    500,
                    355,
                    243,
                    168,
                    91,
                    74,
                    57,
                    33,
                    32,
                    12,
                    16,
                    5,
                    5,
                    4,
                    8,
                    1,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.687,
                    -0.655,
                    -0.622,
                    -0.59,
                    -0.557,
                    -0.525,
                    -0.492,
                    -0.46,
                    -0.427,
                    -0.394,
                    -0.362,
                    -0.329,
                    -0.297,
                    -0.264,
                    -0.232,
                    -0.199,
                    -0.167,
                    -0.134,
                    -0.102,
                    -0.069,
                    -0.036,
                    -0.004,
                    0.029,
                    0.061,
                    0.094,
                    0.126,
                    0.159,
                    0.191,
                    0.224,
                    0.256,
                    0.289,
                    0.322,
                    0.354,
                    0.387,
                    0.419,
                    0.452,
                    0.484,
                    0.517,
                    0.549,
                    0.582,
                    0.615,
                    0.647,
                    0.68,
                    0.712,
                    0.745,
                    0.777,
                    0.81,
                    0.842,
                    0.875,
                    0.907
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " references to education or teaching concepts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "instances of the word \"teach\" and its variations, indicating a focus on educational themes or instructional content",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygg6hoyvz8d10ex3kjt3d3y",
                        "tokens": [
                            ".\"",
                            " You",
                            " will",
                            " likely",
                            " feel",
                            " very",
                            " alone",
                            ".",
                            " Unfortunately",
                            ",",
                            " coming",
                            " out",
                            " of",
                            " the",
                            " fog",
                            " with",
                            " your",
                            " eyes",
                            " open",
                            " is",
                            " more",
                            " painful",
                            " than",
                            " slipping",
                            " into",
                            " one",
                            " without",
                            " noticing",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " remember",
                            ":",
                            " feelings",
                            " aren",
                            "'t",
                            " the",
                            " truth",
                            ".",
                            " You",
                            " aren",
                            "'t",
                            " the",
                            " worst",
                            " off",
                            " you",
                            "'ve",
                            " ever",
                            " been",
                            ".",
                            " Expect",
                            " the",
                            " sadness",
                            ".",
                            " It",
                            " sounds",
                            " crazy",
                            " but",
                            " welcome",
                            " it",
                            ".",
                            " That",
                            " sadness",
                            " is",
                            " going",
                            " to",
                            " live",
                            " in",
                            " you",
                            " for",
                            " a",
                            " long",
                            " time",
                            " and",
                            " it",
                            " will",
                            " teach",
                            " you",
                            " a",
                            " lot",
                            ".",
                            " I",
                            " know",
                            " you",
                            " don",
                            "'t",
                            " believe",
                            " me",
                            ",",
                            " but",
                            " that",
                            " sadness",
                            " is",
                            " your",
                            " friend",
                            ".",
                            " That",
                            " sadness",
                            " is",
                            " your",
                            " becoming",
                            ".",
                            "\n",
                            "\n",
                            "Not",
                            " everyone",
                            " you",
                            " lose",
                            " is",
                            " a",
                            " loss",
                            ".",
                            "\n",
                            "\n",
                            "Tell",
                            " your",
                            " story",
                            " no",
                            " matter",
                            " how",
                            " murky",
                            " the",
                            " details",
                            " seem",
                            " at",
                            " first"
                        ],
                        "dataIndex": null,
                        "index": "27303",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 35.141,
                        "maxValueTokenIndex": 77,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.141,
                            0,
                            3.522,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:04:40.934Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 35.141,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygg6hoyvz8e10excnfifv6x",
                        "tokens": [
                            " to",
                            " the",
                            " audience",
                            ".",
                            "\n",
                            "\n",
                            "#",
                            "2",
                            ":",
                            " Recre",
                            "ate",
                            " Photograph",
                            "s",
                            ":",
                            "\n",
                            "\n",
                            "One",
                            " of",
                            " the",
                            " things",
                            " that",
                            " will",
                            " help",
                            " you",
                            " be",
                            " a",
                            " great",
                            " V",
                            "FX",
                            " artist",
                            " is",
                            " to",
                            " recreate",
                            " photographs",
                            ".",
                            " Just",
                            " pick",
                            " some",
                            " that",
                            " have",
                            " different",
                            " shadows",
                            " and",
                            " lights",
                            " and",
                            " try",
                            " to",
                            " reproduce",
                            " them",
                            ".",
                            " This",
                            " will",
                            " help",
                            " you",
                            " to",
                            " see",
                            " the",
                            " difference",
                            " between",
                            " real",
                            " things",
                            " and",
                            " fake",
                            " ones",
                            ".",
                            " Despite",
                            " the",
                            " fact",
                            " that",
                            " the",
                            " first",
                            " ones",
                            " won",
                            "'t",
                            " be",
                            " that",
                            " good",
                            ",",
                            " it",
                            "'s",
                            " a",
                            " matter",
                            " of",
                            " practicing",
                            " and",
                            " experimenting",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " working",
                            " on",
                            " making",
                            " CG",
                            " look",
                            " realistic",
                            " and",
                            " looking",
                            " at",
                            " real",
                            " world",
                            " references",
                            " will",
                            " teach",
                            " you",
                            " that",
                            " what",
                            " are",
                            " those",
                            " differences",
                            " in",
                            " the",
                            " render",
                            " you",
                            " have",
                            " in",
                            " front",
                            " of",
                            " you",
                            " compared",
                            " to",
                            " a",
                            " photograph",
                            " that"
                        ],
                        "dataIndex": null,
                        "index": "27303",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 34.402,
                        "maxValueTokenIndex": 106,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.402,
                            0.916,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:04:40.934Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 35.141,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygg6hoyvz8f10expdsbx3sa",
                        "tokens": [
                            " escape",
                            " pods",
                            ".",
                            " The",
                            " high",
                            "-",
                            "tech",
                            " lifestyle",
                            " the",
                            " Jets",
                            "ons",
                            " and",
                            " their",
                            " friends",
                            " enjoy",
                            " has",
                            " undoubtedly",
                            " come",
                            " at",
                            " a",
                            " great",
                            " cost",
                            ",",
                            " particularly",
                            " to",
                            " the",
                            " poor",
                            " and",
                            " marginalized",
                            " \u2014",
                            " already",
                            " at",
                            " the",
                            " doorstep",
                            " of",
                            " the",
                            " real",
                            "-",
                            "life",
                            " tech",
                            " industry",
                            ".",
                            " With",
                            " so",
                            " much",
                            " familiar",
                            " darkness",
                            " lurking",
                            " under",
                            " the",
                            " surface",
                            ",",
                            " here",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " hoping",
                            " the",
                            " ominous",
                            " origins",
                            " of",
                            " this",
                            " reim",
                            "ag",
                            "ined",
                            " Jets",
                            "ons",
                            " are",
                            " only",
                            " the",
                            " beginning",
                            ",",
                            " and",
                            " that",
                            " they",
                            " teach",
                            " us",
                            " to",
                            " think",
                            " twice",
                            " before",
                            " wishing",
                            " for",
                            " flying",
                            " cars",
                            " again",
                            ".",
                            "<|endoftext|>",
                            "Leon",
                            " Trotsky",
                            "\n",
                            "\n",
                            "For",
                            " Gry",
                            "ns",
                            "z",
                            "pan",
                            "\n",
                            "\n",
                            "Against",
                            " F",
                            "ascist",
                            " Pog",
                            "rom",
                            " Gang",
                            "s",
                            " and",
                            " Stalin",
                            "ist",
                            " Sc",
                            "ound",
                            "rel",
                            "s",
                            "\n",
                            "\n",
                            "(",
                            "19",
                            "39",
                            ")",
                            "\n",
                            "\n",
                            "Source",
                            ":",
                            " Socialist",
                            " Appeal",
                            " [",
                            "New"
                        ],
                        "dataIndex": null,
                        "index": "27303",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 33.195,
                        "maxValueTokenIndex": 75,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            33.195,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:04:40.934Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 35.141,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "68269",
            "description": "texts related to education and the sharing of knowledge",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5707252961829491,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "68269",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:56:56.587Z",
                "maxActApprox": 45.403,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    68269,
                    90381,
                    38082,
                    13891,
                    68287,
                    27303,
                    4045,
                    67551,
                    63993,
                    53622,
                    71497,
                    48368,
                    40088,
                    55801,
                    97672,
                    78484,
                    95659,
                    61552,
                    84172,
                    79161,
                    200,
                    21601,
                    36129,
                    67636,
                    92910
                ],
                "topkCosSimValues": [
                    1,
                    0.5593,
                    0.5463,
                    0.5461,
                    0.5321,
                    0.5313,
                    0.5305,
                    0.5125,
                    0.5092,
                    0.5076,
                    0.4921,
                    0.4901,
                    0.4862,
                    0.4681,
                    0.4655,
                    0.4647,
                    0.4599,
                    0.4571,
                    0.4561,
                    0.4553,
                    0.4462,
                    0.4426,
                    0.4413,
                    0.4365,
                    0.428
                ],
                "neuron_alignment_indices": [
                    679,
                    108,
                    255
                ],
                "neuron_alignment_values": [
                    0.131,
                    0.106,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    641,
                    108,
                    679
                ],
                "correlated_neurons_pearson": [
                    0.015,
                    0.014,
                    0.013
                ],
                "correlated_neurons_l1": [
                    0.016,
                    0.014,
                    0.016
                ],
                "correlated_features_indices": [
                    68287,
                    68278,
                    68255
                ],
                "correlated_features_pearson": [
                    0.077,
                    0.002,
                    0.002
                ],
                "correlated_features_l1": [
                    0.077,
                    0.002,
                    0.002
                ],
                "neg_str": [
                    "imposed",
                    " Mehran",
                    " Roses",
                    "same",
                    " odds",
                    " Amen",
                    "\u00e3\u0124\u00bb",
                    " fav",
                    " LIMITED",
                    " transporter"
                ],
                "neg_values": [
                    -0.668,
                    -0.612,
                    -0.609,
                    -0.583,
                    -0.571,
                    -0.545,
                    -0.544,
                    -0.541,
                    -0.538,
                    -0.528
                ],
                "pos_str": [
                    "ingly",
                    "yout",
                    " audiences",
                    "hetically",
                    " policymakers",
                    " consumers",
                    " youngsters",
                    "ADRA",
                    " viewers",
                    " everyone"
                ],
                "pos_values": [
                    0.97,
                    0.809,
                    0.803,
                    0.777,
                    0.772,
                    0.768,
                    0.762,
                    0.761,
                    0.76,
                    0.756
                ],
                "frac_nonzero": 0.00028,
                "freq_hist_data_bar_heights": [
                    236,
                    190,
                    104,
                    87,
                    54,
                    40,
                    26,
                    25,
                    16,
                    16,
                    9,
                    11,
                    14,
                    7,
                    1,
                    4,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    2,
                    0,
                    0,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    2,
                    0,
                    2,
                    3,
                    3,
                    3,
                    2,
                    1,
                    3,
                    4,
                    3,
                    1,
                    1,
                    1,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.456,
                    1.364,
                    2.272,
                    3.18,
                    4.088,
                    4.996,
                    5.904,
                    6.812,
                    7.72,
                    8.628,
                    9.536,
                    10.444,
                    11.352,
                    12.26,
                    13.168,
                    14.076,
                    14.984,
                    15.892,
                    16.8,
                    17.708,
                    18.616,
                    19.524,
                    20.432,
                    21.34,
                    22.248,
                    23.156,
                    24.064,
                    24.972,
                    25.88,
                    26.788,
                    27.696,
                    28.604,
                    29.512,
                    30.42,
                    31.328,
                    32.236,
                    33.144,
                    34.052,
                    34.96,
                    35.868,
                    36.776,
                    37.684,
                    38.592,
                    39.5,
                    40.409,
                    41.317,
                    42.225,
                    43.133,
                    44.041,
                    44.949
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    2,
                    4,
                    12,
                    35,
                    59,
                    101,
                    192,
                    301,
                    487,
                    763,
                    1075,
                    1610,
                    2109,
                    2657,
                    3179,
                    3608,
                    4068,
                    4053,
                    4092,
                    3954,
                    3625,
                    3164,
                    2600,
                    2100,
                    1634,
                    1241,
                    988,
                    751,
                    506,
                    378,
                    288,
                    194,
                    131,
                    85,
                    71,
                    51,
                    34,
                    16,
                    10,
                    6,
                    9,
                    7,
                    2,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.652,
                    -0.619,
                    -0.586,
                    -0.554,
                    -0.521,
                    -0.488,
                    -0.455,
                    -0.423,
                    -0.39,
                    -0.357,
                    -0.324,
                    -0.291,
                    -0.259,
                    -0.226,
                    -0.193,
                    -0.16,
                    -0.128,
                    -0.095,
                    -0.062,
                    -0.029,
                    0.003,
                    0.036,
                    0.069,
                    0.102,
                    0.134,
                    0.167,
                    0.2,
                    0.233,
                    0.266,
                    0.298,
                    0.331,
                    0.364,
                    0.397,
                    0.429,
                    0.462,
                    0.495,
                    0.528,
                    0.56,
                    0.593,
                    0.626,
                    0.659,
                    0.691,
                    0.724,
                    0.757,
                    0.79,
                    0.823,
                    0.855,
                    0.888,
                    0.921,
                    0.954
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to education and the act of educating",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "texts related to education and the sharing of knowledge",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi1rzcr2iw10exutkd0ahs",
                        "tokens": [
                            "ides",
                            "h",
                            "aring",
                            " Works",
                            " for",
                            " Austin",
                            ",",
                            " which",
                            " is",
                            " behind",
                            " the",
                            " effort",
                            ",",
                            " plans",
                            " to",
                            " set",
                            " up",
                            " a",
                            " way",
                            " for",
                            " individual",
                            " supporters",
                            " to",
                            " donate",
                            ".",
                            "\n",
                            "\n",
                            "On",
                            " Monday",
                            ",",
                            " Le",
                            "ff",
                            "ing",
                            "well",
                            " announced",
                            " he",
                            " was",
                            " partnering",
                            " with",
                            " the",
                            " campaign",
                            " to",
                            " support",
                            " the",
                            " May",
                            " 7",
                            " ballot",
                            " initiative",
                            ".",
                            " Le",
                            "ff",
                            "ing",
                            "well",
                            " said",
                            " he",
                            " wants",
                            " to",
                            " educate",
                            " the",
                            " public",
                            " due",
                            " to",
                            " what",
                            " he",
                            " calls",
                            " confusing",
                            " ballot",
                            " language",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " campaign",
                            " said",
                            " in",
                            " January",
                            " it",
                            " collected",
                            " more",
                            " than",
                            " 65",
                            ",",
                            "000",
                            " signatures",
                            " from",
                            " Austin",
                            " voters",
                            " to",
                            " support",
                            " its",
                            " petition",
                            ".",
                            " District",
                            " 5",
                            " Council",
                            " Member",
                            " Ann",
                            " Kitchen",
                            ",",
                            " who",
                            " authored",
                            " much",
                            " of",
                            " the",
                            " city",
                            "'s",
                            " pending",
                            " ordinance",
                            " regulating",
                            " T",
                            "NC",
                            "s",
                            ",",
                            " replaced",
                            " ballot",
                            " language",
                            " submitted",
                            " with",
                            " the",
                            " petition",
                            " because",
                            " it",
                            " did",
                            " not",
                            " refer",
                            " to",
                            " fingerprint"
                        ],
                        "dataIndex": null,
                        "index": "68269",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 45.403,
                        "maxValueTokenIndex": 57,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.403,
                            8.809,
                            7.063,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:57:00.234Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 45.403,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi1rzcr2ix10ex92083jtf",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "Mot",
                            "iv",
                            "ations",
                            " to",
                            " Build",
                            " the",
                            " Blockchain",
                            " Embassy",
                            " in",
                            " Panama",
                            "\n",
                            "\n",
                            "Bitcoin",
                            ".",
                            "com",
                            " reached",
                            " out",
                            " to",
                            " one",
                            " of",
                            " the",
                            " founders",
                            " of",
                            " the",
                            " Blockchain",
                            " Embassy",
                            " (",
                            "and",
                            " Crypt",
                            "ob",
                            "uy",
                            "er",
                            "),",
                            " Jorge",
                            " F",
                            "ari",
                            "as",
                            ",",
                            " to",
                            " get",
                            " some",
                            " insight",
                            " on",
                            " the",
                            " motivations",
                            " behind",
                            " setting",
                            " up",
                            " the",
                            " embassy",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "We",
                            " created",
                            " the",
                            " embassy",
                            " because",
                            " we",
                            " were",
                            " motivated",
                            " by",
                            " the",
                            " need",
                            " to",
                            " educate",
                            " the",
                            " people",
                            " not",
                            " only",
                            " of",
                            " Panama",
                            ",",
                            " but",
                            " also",
                            " of",
                            " the",
                            " world",
                            ".",
                            " Panama",
                            " is",
                            " a",
                            " tourist",
                            " site",
                            ",",
                            " and",
                            " at",
                            " the",
                            " same",
                            " time",
                            ",",
                            " a",
                            " major",
                            " financial",
                            " and",
                            " log",
                            "istic",
                            " center",
                            ".",
                            " We",
                            " believe",
                            " that",
                            " it",
                            " is",
                            " an",
                            " ideal",
                            " place",
                            " to",
                            " show",
                            " the",
                            " power",
                            " of",
                            " technology",
                            " in",
                            " a",
                            " real",
                            ",",
                            " palpable",
                            " way"
                        ],
                        "dataIndex": null,
                        "index": "68269",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.796,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.796,
                            11.788,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:57:00.234Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 45.403,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi1rzer2jh10exh3vd9dpe",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "Mot",
                            "iv",
                            "ations",
                            " to",
                            " Build",
                            " the",
                            " Blockchain",
                            " Embassy",
                            " in",
                            " Panama",
                            "\n",
                            "\n",
                            "Bitcoin",
                            ".",
                            "com",
                            " reached",
                            " out",
                            " to",
                            " one",
                            " of",
                            " the",
                            " founders",
                            " of",
                            " the",
                            " Blockchain",
                            " Embassy",
                            " (",
                            "and",
                            " Crypt",
                            "ob",
                            "uy",
                            "er",
                            "),",
                            " Jorge",
                            " F",
                            "ari",
                            "as",
                            ",",
                            " to",
                            " get",
                            " some",
                            " insight",
                            " on",
                            " the",
                            " motivations",
                            " behind",
                            " setting",
                            " up",
                            " the",
                            " embassy",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "We",
                            " created",
                            " the",
                            " embassy",
                            " because",
                            " we",
                            " were",
                            " motivated",
                            " by",
                            " the",
                            " need",
                            " to",
                            " educate",
                            " the",
                            " people",
                            " not",
                            " only",
                            " of",
                            " Panama",
                            ",",
                            " but",
                            " also",
                            " of",
                            " the",
                            " world",
                            ".",
                            " Panama",
                            " is",
                            " a",
                            " tourist",
                            " site",
                            ",",
                            " and",
                            " at",
                            " the",
                            " same",
                            " time",
                            ",",
                            " a",
                            " major",
                            " financial",
                            " and",
                            " log",
                            "istic",
                            " center",
                            ".",
                            " We",
                            " believe",
                            " that",
                            " it",
                            " is",
                            " an",
                            " ideal",
                            " place",
                            " to",
                            " show",
                            " the",
                            " power",
                            " of",
                            " technology",
                            " in",
                            " a",
                            " real",
                            ",",
                            " palpable",
                            " way"
                        ],
                        "dataIndex": null,
                        "index": "68269",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.796,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.796,
                            11.788,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:57:00.234Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 36.322,
                        "binMax": 45.403,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "30175",
            "description": "action verbs related to education and support",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5655533075332642,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "30175",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:08:43.878Z",
                "maxActApprox": 15.392,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    30175,
                    83716,
                    59599,
                    54019,
                    37993,
                    57172,
                    28937,
                    50172,
                    19844,
                    53547,
                    86404,
                    10487,
                    79022,
                    76434,
                    45330,
                    54596,
                    89209,
                    64857,
                    16526,
                    71624,
                    68280,
                    63495,
                    26988,
                    81634,
                    36158
                ],
                "topkCosSimValues": [
                    1,
                    0.5887,
                    0.5858,
                    0.5819,
                    0.5746,
                    0.5573,
                    0.5424,
                    0.5404,
                    0.518,
                    0.5174,
                    0.5101,
                    0.5054,
                    0.4956,
                    0.491,
                    0.4725,
                    0.4673,
                    0.4645,
                    0.4563,
                    0.4403,
                    0.4396,
                    0.4291,
                    0.4265,
                    0.4241,
                    0.42,
                    0.4188
                ],
                "neuron_alignment_indices": [
                    447,
                    644,
                    32
                ],
                "neuron_alignment_values": [
                    0.121,
                    0.118,
                    0.108
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    665,
                    750,
                    70
                ],
                "correlated_neurons_pearson": [
                    0.03,
                    0.03,
                    0.029
                ],
                "correlated_neurons_l1": [
                    0.035,
                    0.027,
                    0.033
                ],
                "correlated_features_indices": [
                    30128,
                    30170,
                    30194
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.003,
                    0.003
                ],
                "correlated_features_l1": [
                    0.008,
                    0.004,
                    0.003
                ],
                "neg_str": [
                    "ikuman",
                    " starring",
                    "FU",
                    "esides",
                    "stroke",
                    "aith",
                    "ringe",
                    "Storm",
                    " Stern",
                    "ranged"
                ],
                "neg_values": [
                    -0.588,
                    -0.569,
                    -0.554,
                    -0.542,
                    -0.536,
                    -0.535,
                    -0.525,
                    -0.525,
                    -0.518,
                    -0.517
                ],
                "pos_str": [
                    " ourselves",
                    " our",
                    " ours",
                    " OUR",
                    "Our",
                    "esville",
                    "etimes",
                    "eport",
                    "ida",
                    "ourses"
                ],
                "pos_values": [
                    1.481,
                    0.997,
                    0.801,
                    0.682,
                    0.623,
                    0.615,
                    0.605,
                    0.596,
                    0.592,
                    0.592
                ],
                "frac_nonzero": 0.00115,
                "freq_hist_data_bar_heights": [
                    406,
                    388,
                    317,
                    285,
                    227,
                    195,
                    166,
                    145,
                    144,
                    105,
                    123,
                    95,
                    80,
                    77,
                    71,
                    58,
                    57,
                    52,
                    70,
                    51,
                    41,
                    53,
                    35,
                    52,
                    37,
                    38,
                    28,
                    23,
                    25,
                    20,
                    12,
                    18,
                    10,
                    12,
                    17,
                    18,
                    10,
                    7,
                    7,
                    6,
                    6,
                    5,
                    2,
                    2,
                    5,
                    2,
                    1,
                    2,
                    3,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.154,
                    0.462,
                    0.77,
                    1.077,
                    1.385,
                    1.693,
                    2.001,
                    2.309,
                    2.617,
                    2.924,
                    3.232,
                    3.54,
                    3.848,
                    4.156,
                    4.464,
                    4.771,
                    5.079,
                    5.387,
                    5.695,
                    6.003,
                    6.311,
                    6.618,
                    6.926,
                    7.234,
                    7.542,
                    7.85,
                    8.158,
                    8.465,
                    8.773,
                    9.081,
                    9.389,
                    9.697,
                    10.005,
                    10.312,
                    10.62,
                    10.928,
                    11.236,
                    11.544,
                    11.851,
                    12.159,
                    12.467,
                    12.775,
                    13.083,
                    13.391,
                    13.698,
                    14.006,
                    14.314,
                    14.622,
                    14.93,
                    15.238
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    10,
                    26,
                    70,
                    118,
                    228,
                    473,
                    879,
                    1522,
                    2210,
                    3312,
                    4224,
                    5200,
                    5699,
                    5838,
                    5450,
                    4569,
                    3560,
                    2644,
                    1713,
                    1137,
                    622,
                    358,
                    181,
                    113,
                    58,
                    20,
                    10,
                    4,
                    2,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.568,
                    -0.526,
                    -0.485,
                    -0.444,
                    -0.402,
                    -0.361,
                    -0.319,
                    -0.278,
                    -0.237,
                    -0.195,
                    -0.154,
                    -0.113,
                    -0.071,
                    -0.03,
                    0.012,
                    0.053,
                    0.094,
                    0.136,
                    0.177,
                    0.219,
                    0.26,
                    0.301,
                    0.343,
                    0.384,
                    0.426,
                    0.467,
                    0.508,
                    0.55,
                    0.591,
                    0.633,
                    0.674,
                    0.715,
                    0.757,
                    0.798,
                    0.839,
                    0.881,
                    0.922,
                    0.964,
                    1.005,
                    1.046,
                    1.088,
                    1.129,
                    1.171,
                    1.212,
                    1.253,
                    1.295,
                    1.336,
                    1.378,
                    1.419,
                    1.46
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "action verbs related to education and support",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " verbs associated with teaching, helping, and guidance",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggbsw0y5qy10exsxe9zt16",
                        "tokens": [
                            " is",
                            " what",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " all",
                            " about",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Jordan",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "This",
                            " is",
                            " what",
                            " kids",
                            " need",
                            " to",
                            " know",
                            ".",
                            " We",
                            " teach",
                            " them",
                            " how",
                            " to",
                            " read",
                            ".",
                            " We",
                            " teach",
                            " them",
                            " all",
                            " about",
                            " math",
                            " and",
                            " I",
                            " strongly",
                            " believe",
                            " they",
                            " also",
                            " need",
                            " to",
                            " learn",
                            " about",
                            " computers",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Wall",
                            " said",
                            " coding",
                            " helps",
                            " with",
                            " problem",
                            "-",
                            "s",
                            "olving",
                            " and",
                            " process",
                            "-",
                            "oriented",
                            " thinking",
                            ",",
                            " and",
                            " beyond",
                            " that",
                            ",",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " language",
                            " we",
                            " live",
                            " in",
                            " every",
                            " day",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "If",
                            " you",
                            " look",
                            " around",
                            " from",
                            " your",
                            " home",
                            " to",
                            " your",
                            " vehicle",
                            " to",
                            " what",
                            " we",
                            " have",
                            " in",
                            " our",
                            " hands",
                            " to",
                            " the",
                            " camera",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " using",
                            ",",
                            " there",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " code",
                            " embedded",
                            " inside",
                            " them",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s"
                        ],
                        "dataIndex": null,
                        "index": "30175",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.392,
                        "maxValueTokenIndex": 25,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.392,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            8.122,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.247,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:08:48.723Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.392,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggbsw0y5qz10ex20in2xjf",
                        "tokens": [
                            " W",
                            "ore",
                            " it",
                            " Better",
                            "\u00e2\u0122",
                            "\u013b",
                            " between",
                            " two",
                            " women",
                            ",",
                            " instead",
                            " of",
                            " a",
                            " \u00e2\u0122",
                            "\u013a",
                            "They",
                            " Both",
                            " Sl",
                            "ayed",
                            ".",
                            "\u00e2\u0122",
                            "\u013b",
                            " As",
                            " prominent",
                            " novelist",
                            " Chim",
                            "am",
                            "anda",
                            " N",
                            "go",
                            "zi",
                            " Ad",
                            "ich",
                            "ie",
                            " pointed",
                            " out",
                            " in",
                            " her",
                            " personal",
                            " essay",
                            " We",
                            " Should",
                            " All",
                            " Be",
                            " Femin",
                            "ists",
                            " and",
                            " in",
                            " Beyon",
                            "c\u00c3\u00a9",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " song",
                            " \u00e2\u0122",
                            "\u013a",
                            "F",
                            "law",
                            "less",
                            "\u00e2\u0122",
                            "\u013b",
                            ":",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "We",
                            " raise",
                            " girls",
                            " to",
                            " see",
                            " each",
                            " other",
                            " as",
                            " competitors",
                            " \u2014",
                            "\n",
                            "\n",
                            "not",
                            " for",
                            " jobs",
                            " or",
                            " for",
                            " accomplishments",
                            ",",
                            "\n",
                            "\n",
                            "which",
                            " I",
                            " think",
                            " can",
                            " be",
                            " a",
                            " good",
                            " thing",
                            ",",
                            "\n",
                            "\n",
                            "but",
                            " for",
                            " the",
                            " attention",
                            " of",
                            " men",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            " teach",
                            " girls",
                            " that",
                            " they",
                            " cannot",
                            " be",
                            " sexual",
                            " beings",
                            "\n",
                            "\n",
                            "in",
                            " the",
                            " way",
                            " that",
                            " boys",
                            " are",
                            ".",
                            "\u00e2\u0122",
                            "\u013f"
                        ],
                        "dataIndex": null,
                        "index": "30175",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.338,
                        "maxValueTokenIndex": 108,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.78,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.338,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:08:48.723Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.392,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggbsw0y5r210ex4xf1ph6w",
                        "tokens": [
                            " W",
                            "ore",
                            " it",
                            " Better",
                            "\u00e2\u0122",
                            "\u013b",
                            " between",
                            " two",
                            " women",
                            ",",
                            " instead",
                            " of",
                            " a",
                            " \u00e2\u0122",
                            "\u013a",
                            "They",
                            " Both",
                            " Sl",
                            "ayed",
                            ".",
                            "\u00e2\u0122",
                            "\u013b",
                            " As",
                            " prominent",
                            " novelist",
                            " Chim",
                            "am",
                            "anda",
                            " N",
                            "go",
                            "zi",
                            " Ad",
                            "ich",
                            "ie",
                            " pointed",
                            " out",
                            " in",
                            " her",
                            " personal",
                            " essay",
                            " We",
                            " Should",
                            " All",
                            " Be",
                            " Femin",
                            "ists",
                            " and",
                            " in",
                            " Beyon",
                            "c\u00c3\u00a9",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " song",
                            " \u00e2\u0122",
                            "\u013a",
                            "F",
                            "law",
                            "less",
                            "\u00e2\u0122",
                            "\u013b",
                            ":",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "We",
                            " raise",
                            " girls",
                            " to",
                            " see",
                            " each",
                            " other",
                            " as",
                            " competitors",
                            " \u2014",
                            "\n",
                            "\n",
                            "not",
                            " for",
                            " jobs",
                            " or",
                            " for",
                            " accomplishments",
                            ",",
                            "\n",
                            "\n",
                            "which",
                            " I",
                            " think",
                            " can",
                            " be",
                            " a",
                            " good",
                            " thing",
                            ",",
                            "\n",
                            "\n",
                            "but",
                            " for",
                            " the",
                            " attention",
                            " of",
                            " men",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            " teach",
                            " girls",
                            " that",
                            " they",
                            " cannot",
                            " be",
                            " sexual",
                            " beings",
                            "\n",
                            "\n",
                            "in",
                            " the",
                            " way",
                            " that",
                            " boys",
                            " are",
                            ".",
                            "\u00e2\u0122",
                            "\u013f"
                        ],
                        "dataIndex": null,
                        "index": "30175",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.338,
                        "maxValueTokenIndex": 108,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.78,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            15.338,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:08:48.723Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.392,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "7804",
            "description": "phrases related to teaching or instruction",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5654679536819458,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "7804",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T18:54:38.356Z",
                "maxActApprox": 57.203,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    7804,
                    9709,
                    13240,
                    20008,
                    22409,
                    12849,
                    8895,
                    1353,
                    8581,
                    4375,
                    9365,
                    11989,
                    22103,
                    6249,
                    2943,
                    7511,
                    19632,
                    11745,
                    10438,
                    17912,
                    10445,
                    17375,
                    2951,
                    16368,
                    7976
                ],
                "topkCosSimValues": [
                    1,
                    0.5934,
                    0.5188,
                    0.5171,
                    0.4982,
                    0.4831,
                    0.4768,
                    0.4737,
                    0.4595,
                    0.4503,
                    0.4383,
                    0.4299,
                    0.4124,
                    0.3927,
                    0.3925,
                    0.3878,
                    0.3817,
                    0.3768,
                    0.3738,
                    0.3722,
                    0.3654,
                    0.3627,
                    0.3538,
                    0.3537,
                    0.3482
                ],
                "neuron_alignment_indices": [
                    679,
                    108,
                    575
                ],
                "neuron_alignment_values": [
                    0.118,
                    0.1,
                    0.093
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    108,
                    414,
                    119
                ],
                "correlated_neurons_pearson": [
                    0.022,
                    0.018,
                    0.018
                ],
                "correlated_neurons_l1": [
                    0.022,
                    0.016,
                    0.017
                ],
                "correlated_features_indices": [
                    7784,
                    7740,
                    7780
                ],
                "correlated_features_pearson": [
                    0.003,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.003,
                    0.003,
                    0.002
                ],
                "neg_str": [
                    " sidx",
                    " Ports",
                    "tar",
                    "76561",
                    "ilings",
                    "ablished",
                    "atos",
                    " Launcher",
                    "axy",
                    "FTWARE"
                ],
                "neg_values": [
                    -0.755,
                    -0.742,
                    -0.676,
                    -0.667,
                    -0.644,
                    -0.636,
                    -0.634,
                    -0.624,
                    -0.612,
                    -0.595
                ],
                "pos_str": [
                    "yout",
                    "ingly",
                    "children",
                    "girls",
                    " students",
                    " kindergarten",
                    " kids",
                    " curriculum",
                    " undergrad",
                    "classes"
                ],
                "pos_values": [
                    0.944,
                    0.913,
                    0.889,
                    0.863,
                    0.853,
                    0.846,
                    0.843,
                    0.83,
                    0.815,
                    0.793
                ],
                "frac_nonzero": 0.00033,
                "freq_hist_data_bar_heights": [
                    232,
                    169,
                    88,
                    77,
                    47,
                    43,
                    40,
                    29,
                    29,
                    16,
                    11,
                    4,
                    3,
                    2,
                    3,
                    1,
                    1,
                    3,
                    0,
                    1,
                    1,
                    6,
                    6,
                    3,
                    9,
                    8,
                    3,
                    9,
                    5,
                    7,
                    4,
                    11,
                    7,
                    10,
                    9,
                    8,
                    8,
                    12,
                    13,
                    19,
                    14,
                    9,
                    10,
                    3,
                    10,
                    10,
                    4,
                    4,
                    4,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.573,
                    1.718,
                    2.862,
                    4.006,
                    5.15,
                    6.294,
                    7.438,
                    8.582,
                    9.726,
                    10.87,
                    12.014,
                    13.158,
                    14.302,
                    15.446,
                    16.59,
                    17.734,
                    18.878,
                    20.022,
                    21.166,
                    22.31,
                    23.454,
                    24.598,
                    25.742,
                    26.886,
                    28.03,
                    29.174,
                    30.318,
                    31.462,
                    32.606,
                    33.75,
                    34.894,
                    36.038,
                    37.182,
                    38.326,
                    39.47,
                    40.615,
                    41.759,
                    42.903,
                    44.047,
                    45.191,
                    46.335,
                    47.479,
                    48.623,
                    49.767,
                    50.911,
                    52.055,
                    53.199,
                    54.343,
                    55.487,
                    56.631
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    0,
                    2,
                    4,
                    5,
                    8,
                    18,
                    30,
                    47,
                    93,
                    145,
                    270,
                    410,
                    658,
                    975,
                    1444,
                    1995,
                    2545,
                    3330,
                    4056,
                    4298,
                    4509,
                    4596,
                    4135,
                    3622,
                    3278,
                    2548,
                    2001,
                    1523,
                    1049,
                    794,
                    558,
                    451,
                    275,
                    172,
                    119,
                    81,
                    62,
                    37,
                    34,
                    17,
                    22,
                    11,
                    10,
                    6,
                    3,
                    2,
                    4,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.738,
                    -0.704,
                    -0.67,
                    -0.636,
                    -0.602,
                    -0.568,
                    -0.535,
                    -0.501,
                    -0.467,
                    -0.433,
                    -0.399,
                    -0.365,
                    -0.331,
                    -0.297,
                    -0.263,
                    -0.229,
                    -0.195,
                    -0.161,
                    -0.127,
                    -0.093,
                    -0.059,
                    -0.025,
                    0.009,
                    0.043,
                    0.077,
                    0.111,
                    0.145,
                    0.179,
                    0.213,
                    0.247,
                    0.281,
                    0.315,
                    0.349,
                    0.383,
                    0.417,
                    0.451,
                    0.485,
                    0.519,
                    0.553,
                    0.587,
                    0.621,
                    0.655,
                    0.689,
                    0.723,
                    0.757,
                    0.791,
                    0.825,
                    0.859,
                    0.893,
                    0.927
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases related to teaching or instruction",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmd4ia7ewsi6664908qnsc",
                        "tokens": [
                            "\u00e2\u0138\u00ba",
                            " Author",
                            ":",
                            " Joseph",
                            " F",
                            "its",
                            "an",
                            "akis",
                            " |",
                            " Date",
                            ":",
                            " 26",
                            " June",
                            " 2017",
                            " |",
                            " Per",
                            "malink",
                            "\n",
                            "\n",
                            "Advertisements",
                            "<|endoftext|>",
                            "And",
                            " now",
                            " here",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " my",
                            " recap",
                            " and",
                            " review",
                            " of",
                            " the",
                            " 5",
                            "th",
                            " disc",
                            " from",
                            " this",
                            " classic",
                            " Soft",
                            "core",
                            " TV",
                            " series",
                            ".",
                            " Once",
                            " again",
                            " produced",
                            " by",
                            " Al",
                            "ain",
                            " S",
                            "irit",
                            "z",
                            "ky",
                            " and",
                            " this",
                            " is",
                            " directed",
                            " by",
                            " David",
                            " Cove",
                            " with",
                            " Mark",
                            " Evan",
                            " Schwartz",
                            " listed",
                            " as",
                            " screen",
                            "writer",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " theme",
                            " of",
                            " this",
                            " disc",
                            ",",
                            " as",
                            " evidenced",
                            " by",
                            " the",
                            " title",
                            ",",
                            " is",
                            " dreams",
                            ".",
                            " The",
                            " alien",
                            " crew",
                            " doesn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " dream",
                            ",",
                            " and",
                            " so",
                            " Emmanuel",
                            "le",
                            " decides",
                            " to",
                            " teach",
                            " them",
                            " about",
                            " dreams",
                            ",",
                            " and",
                            " how",
                            " you",
                            " can",
                            " explore",
                            " sexual",
                            " fantasies",
                            " in",
                            " them",
                            ".",
                            " So",
                            " while",
                            " she",
                            " sleeps",
                            " on",
                            " a",
                            " special",
                            " table",
                            " in",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "7804",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 57.203,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            57.203,
                            2.21,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:54:47.284Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 57.203,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmd4ia7ewti666m1gfm6wm",
                        "tokens": [
                            ".",
                            " Every",
                            " time",
                            " the",
                            " ball",
                            " hits",
                            " a",
                            " brick",
                            " your",
                            " score",
                            " increases",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " idea",
                            "\n",
                            "\n",
                            "If",
                            " we",
                            " want",
                            " to",
                            " teach",
                            " a",
                            " computer",
                            " how",
                            " to",
                            " play",
                            " that",
                            " game",
                            ",",
                            " one",
                            " solution",
                            " might",
                            " be",
                            " to",
                            " use",
                            " a",
                            " class",
                            "ifier",
                            " such",
                            " as",
                            " a",
                            " neural",
                            " network",
                            " where",
                            " the",
                            " input",
                            " would",
                            " be",
                            " the",
                            " screen",
                            " images",
                            " and",
                            " the",
                            " output",
                            " the",
                            " action",
                            " to",
                            " perform",
                            ".",
                            " It",
                            " makes",
                            " sense",
                            " as",
                            " for",
                            " each",
                            " screen",
                            " we",
                            " want",
                            " to",
                            " know",
                            " if",
                            " the",
                            " paddle",
                            " should",
                            " move",
                            " left",
                            " or",
                            " right",
                            " (",
                            "or",
                            " stay",
                            " still",
                            ").",
                            " The",
                            " problem",
                            " is",
                            " that",
                            " we",
                            " need",
                            " lots",
                            " of",
                            " training",
                            " examples",
                            ".",
                            " But",
                            " this",
                            " is",
                            " not",
                            " how",
                            " we",
                            " learn",
                            "!",
                            " We",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " want",
                            " someone",
                            " to",
                            " tell",
                            " us",
                            " a",
                            " million",
                            " time",
                            " what",
                            " we",
                            " should",
                            " do",
                            "!",
                            "\n",
                            "\n",
                            "Instead",
                            " we",
                            " learn"
                        ],
                        "dataIndex": null,
                        "index": "7804",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 55.449,
                        "maxValueTokenIndex": 22,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            55.449,
                            7.361,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.483,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:54:47.284Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 57.203,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmd4ia7ewui6668ucoi048",
                        "tokens": [
                            "What",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " up",
                            " with",
                            " Estonia",
                            "?",
                            " The",
                            " tiny",
                            " Baltic",
                            " nation",
                            " aff",
                            "ords",
                            " its",
                            " citizens",
                            " the",
                            " greatest",
                            " measure",
                            " of",
                            " digital",
                            " freedom",
                            " as",
                            " measured",
                            " by",
                            " Freedom",
                            " House",
                            " ,",
                            " a",
                            " Washington",
                            " advocacy",
                            " group",
                            ".",
                            "\n",
                            "\n",
                            "Freedom",
                            " House",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " rankings",
                            " are",
                            " based",
                            " on",
                            " things",
                            " like",
                            " access",
                            " to",
                            " the",
                            " Internet",
                            " and",
                            " online",
                            " free",
                            " expression",
                            " laws",
                            ".",
                            " Estonia",
                            " has",
                            " a",
                            " national",
                            " digital",
                            " identification",
                            " system",
                            ",",
                            " allows",
                            " its",
                            " citizens",
                            " to",
                            " vote",
                            " online",
                            " and",
                            " has",
                            " announced",
                            " plans",
                            " to",
                            " teach",
                            " computer",
                            " coding",
                            " to",
                            " public",
                            " school",
                            " students",
                            " as",
                            " early",
                            " as",
                            " first",
                            " grade",
                            ",",
                            " according",
                            " to",
                            " the",
                            " technology",
                            " blog",
                            " Ubuntu",
                            "Life",
                            ".",
                            "\n",
                            "\n",
                            "E",
                            "ston",
                            "ia",
                            " is",
                            " a",
                            " standout",
                            " at",
                            " a",
                            " time",
                            " when",
                            ",",
                            " according",
                            " to",
                            " Freedom",
                            " House",
                            ",",
                            " online",
                            " censorship",
                            " has",
                            " grown",
                            ",",
                            " from",
                            " widespread",
                            " blocking",
                            " and",
                            " filtering",
                            " in",
                            " some",
                            " countries"
                        ],
                        "dataIndex": null,
                        "index": "7804",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 55.25,
                        "maxValueTokenIndex": 75,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            55.25,
                            0,
                            0,
                            4.149,
                            0,
                            0.649,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T18:54:47.284Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 57.203,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs12288-jb",
            "index": "7513",
            "description": "phrases related to teaching or instruction",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5652186870574951,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs12288-jb",
                "index": "7513",
                "sourceSetName": "res_fs12288-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T22:26:08.107Z",
                "maxActApprox": 54.533,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    7513,
                    5113,
                    8048,
                    1017,
                    11816,
                    5975,
                    6806,
                    1831,
                    10918,
                    3552,
                    6926,
                    9470,
                    11921,
                    7686,
                    5661,
                    11406,
                    2525,
                    1452,
                    3640,
                    10415,
                    863,
                    1716,
                    5042,
                    6231,
                    2558
                ],
                "topkCosSimValues": [
                    1,
                    0.5789,
                    0.5245,
                    0.5237,
                    0.4725,
                    0.4638,
                    0.4539,
                    0.4145,
                    0.3877,
                    0.3789,
                    0.3752,
                    0.3624,
                    0.3605,
                    0.3571,
                    0.3531,
                    0.3525,
                    0.3467,
                    0.3363,
                    0.32,
                    0.3129,
                    0.3077,
                    0.303,
                    0.2991,
                    0.2936,
                    0.2827
                ],
                "neuron_alignment_indices": [
                    679,
                    167,
                    575
                ],
                "neuron_alignment_values": [
                    0.121,
                    0.092,
                    0.089
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    108,
                    414,
                    279
                ],
                "correlated_neurons_pearson": [
                    0.023,
                    0.02,
                    0.019
                ],
                "correlated_neurons_l1": [
                    0.023,
                    0.017,
                    0.02
                ],
                "correlated_features_indices": [
                    7488,
                    7547,
                    7520
                ],
                "correlated_features_pearson": [
                    0.008,
                    0.007,
                    0.006
                ],
                "correlated_features_l1": [
                    0.009,
                    0.008,
                    0.006
                ],
                "neg_str": [
                    " Ports",
                    " sidx",
                    "atos",
                    " Launcher",
                    "ilings",
                    "ablished",
                    "axy",
                    "tar",
                    "76561",
                    " allotted"
                ],
                "neg_values": [
                    -0.709,
                    -0.652,
                    -0.641,
                    -0.641,
                    -0.634,
                    -0.633,
                    -0.633,
                    -0.616,
                    -0.611,
                    -0.599
                ],
                "pos_str": [
                    "yout",
                    "ingly",
                    "children",
                    "girls",
                    " kids",
                    " students",
                    " kindergarten",
                    " curriculum",
                    "kids",
                    "piece"
                ],
                "pos_values": [
                    0.909,
                    0.899,
                    0.897,
                    0.864,
                    0.848,
                    0.827,
                    0.8,
                    0.788,
                    0.781,
                    0.762
                ],
                "frac_nonzero": 0.00054,
                "freq_hist_data_bar_heights": [
                    464,
                    303,
                    179,
                    134,
                    74,
                    67,
                    39,
                    37,
                    38,
                    33,
                    22,
                    20,
                    13,
                    11,
                    4,
                    3,
                    4,
                    2,
                    3,
                    0,
                    3,
                    0,
                    1,
                    3,
                    4,
                    3,
                    7,
                    8,
                    5,
                    7,
                    9,
                    3,
                    8,
                    11,
                    9,
                    9,
                    15,
                    17,
                    9,
                    8,
                    15,
                    17,
                    10,
                    10,
                    10,
                    9,
                    13,
                    4,
                    3,
                    4
                ],
                "freq_hist_data_bar_values": [
                    0.548,
                    1.639,
                    2.729,
                    3.82,
                    4.91,
                    6.001,
                    7.092,
                    8.182,
                    9.273,
                    10.363,
                    11.454,
                    12.545,
                    13.635,
                    14.726,
                    15.816,
                    16.907,
                    17.998,
                    19.088,
                    20.179,
                    21.269,
                    22.36,
                    23.451,
                    24.541,
                    25.632,
                    26.722,
                    27.813,
                    28.904,
                    29.994,
                    31.085,
                    32.175,
                    33.266,
                    34.357,
                    35.447,
                    36.538,
                    37.628,
                    38.719,
                    39.81,
                    40.9,
                    41.991,
                    43.081,
                    44.172,
                    45.263,
                    46.353,
                    47.444,
                    48.534,
                    49.625,
                    50.716,
                    51.806,
                    52.897,
                    53.987
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    6,
                    4,
                    13,
                    10,
                    35,
                    35,
                    72,
                    119,
                    208,
                    392,
                    555,
                    816,
                    1178,
                    1690,
                    2203,
                    2957,
                    3504,
                    3989,
                    4267,
                    4310,
                    4242,
                    3871,
                    3409,
                    2953,
                    2327,
                    1906,
                    1395,
                    1072,
                    789,
                    574,
                    422,
                    282,
                    198,
                    124,
                    105,
                    49,
                    52,
                    36,
                    21,
                    18,
                    16,
                    7,
                    8,
                    7,
                    3,
                    1,
                    2,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.693,
                    -0.661,
                    -0.628,
                    -0.596,
                    -0.564,
                    -0.531,
                    -0.499,
                    -0.467,
                    -0.434,
                    -0.402,
                    -0.369,
                    -0.337,
                    -0.305,
                    -0.272,
                    -0.24,
                    -0.208,
                    -0.175,
                    -0.143,
                    -0.11,
                    -0.078,
                    -0.046,
                    -0.013,
                    0.019,
                    0.051,
                    0.084,
                    0.116,
                    0.149,
                    0.181,
                    0.213,
                    0.246,
                    0.278,
                    0.31,
                    0.343,
                    0.375,
                    0.408,
                    0.44,
                    0.472,
                    0.505,
                    0.537,
                    0.569,
                    0.602,
                    0.634,
                    0.667,
                    0.699,
                    0.731,
                    0.764,
                    0.796,
                    0.829,
                    0.861,
                    0.893
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases related to teaching or instruction",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdtx1e75o3bi666oj3igp6a",
                        "tokens": [
                            "\u00e2\u0138\u00ba",
                            " Author",
                            ":",
                            " Joseph",
                            " F",
                            "its",
                            "an",
                            "akis",
                            " |",
                            " Date",
                            ":",
                            " 26",
                            " June",
                            " 2017",
                            " |",
                            " Per",
                            "malink",
                            "\n",
                            "\n",
                            "Advertisements",
                            "<|endoftext|>",
                            "And",
                            " now",
                            " here",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " my",
                            " recap",
                            " and",
                            " review",
                            " of",
                            " the",
                            " 5",
                            "th",
                            " disc",
                            " from",
                            " this",
                            " classic",
                            " Soft",
                            "core",
                            " TV",
                            " series",
                            ".",
                            " Once",
                            " again",
                            " produced",
                            " by",
                            " Al",
                            "ain",
                            " S",
                            "irit",
                            "z",
                            "ky",
                            " and",
                            " this",
                            " is",
                            " directed",
                            " by",
                            " David",
                            " Cove",
                            " with",
                            " Mark",
                            " Evan",
                            " Schwartz",
                            " listed",
                            " as",
                            " screen",
                            "writer",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " theme",
                            " of",
                            " this",
                            " disc",
                            ",",
                            " as",
                            " evidenced",
                            " by",
                            " the",
                            " title",
                            ",",
                            " is",
                            " dreams",
                            ".",
                            " The",
                            " alien",
                            " crew",
                            " doesn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " dream",
                            ",",
                            " and",
                            " so",
                            " Emmanuel",
                            "le",
                            " decides",
                            " to",
                            " teach",
                            " them",
                            " about",
                            " dreams",
                            ",",
                            " and",
                            " how",
                            " you",
                            " can",
                            " explore",
                            " sexual",
                            " fantasies",
                            " in",
                            " them",
                            ".",
                            " So",
                            " while",
                            " she",
                            " sleeps",
                            " on",
                            " a",
                            " special",
                            " table",
                            " in",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "7513",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 54.533,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            54.533,
                            5.735,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:26:13.672Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 54.533,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtx1e95o3xi66616xmsz95",
                        "tokens": [
                            "\u00e2\u0138\u00ba",
                            " Author",
                            ":",
                            " Joseph",
                            " F",
                            "its",
                            "an",
                            "akis",
                            " |",
                            " Date",
                            ":",
                            " 26",
                            " June",
                            " 2017",
                            " |",
                            " Per",
                            "malink",
                            "\n",
                            "\n",
                            "Advertisements",
                            "<|endoftext|>",
                            "And",
                            " now",
                            " here",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " my",
                            " recap",
                            " and",
                            " review",
                            " of",
                            " the",
                            " 5",
                            "th",
                            " disc",
                            " from",
                            " this",
                            " classic",
                            " Soft",
                            "core",
                            " TV",
                            " series",
                            ".",
                            " Once",
                            " again",
                            " produced",
                            " by",
                            " Al",
                            "ain",
                            " S",
                            "irit",
                            "z",
                            "ky",
                            " and",
                            " this",
                            " is",
                            " directed",
                            " by",
                            " David",
                            " Cove",
                            " with",
                            " Mark",
                            " Evan",
                            " Schwartz",
                            " listed",
                            " as",
                            " screen",
                            "writer",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " theme",
                            " of",
                            " this",
                            " disc",
                            ",",
                            " as",
                            " evidenced",
                            " by",
                            " the",
                            " title",
                            ",",
                            " is",
                            " dreams",
                            ".",
                            " The",
                            " alien",
                            " crew",
                            " doesn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " dream",
                            ",",
                            " and",
                            " so",
                            " Emmanuel",
                            "le",
                            " decides",
                            " to",
                            " teach",
                            " them",
                            " about",
                            " dreams",
                            ",",
                            " and",
                            " how",
                            " you",
                            " can",
                            " explore",
                            " sexual",
                            " fantasies",
                            " in",
                            " them",
                            ".",
                            " So",
                            " while",
                            " she",
                            " sleeps",
                            " on",
                            " a",
                            " special",
                            " table",
                            " in",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "7513",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 54.533,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            54.533,
                            5.735,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:26:13.672Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 43.626,
                        "binMax": 54.533,
                        "binContains": 3e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdtx1e75o3ci666mq5uexqw",
                        "tokens": [
                            " to",
                            " teach",
                            " you",
                            " something",
                            " new",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " a",
                            " master",
                            " collection",
                            " with",
                            " everything",
                            " you",
                            " can",
                            " find",
                            " off",
                            " the",
                            " beaten",
                            " and",
                            " bizarre",
                            " path",
                            ":",
                            " garage",
                            ",",
                            " no",
                            " wave",
                            ",",
                            " post",
                            "-",
                            "punk",
                            ",",
                            " psych",
                            " and",
                            " noise",
                            " music",
                            ".",
                            " After",
                            " years",
                            " of",
                            " in",
                            "activity",
                            ",",
                            " this",
                            " blog",
                            " made",
                            " a",
                            " return",
                            " with",
                            " sporadic",
                            " updates",
                            ".",
                            "\n",
                            "\n",
                            "Why",
                            ":",
                            " It",
                            " is",
                            " home",
                            " to",
                            " over",
                            " 200",
                            " releases",
                            ",",
                            " often",
                            " accompanied",
                            " by",
                            " good",
                            " write",
                            "-",
                            "ups",
                            " on",
                            " each",
                            " one",
                            ".",
                            " Blog",
                            "s",
                            " hosted",
                            " on",
                            " Blog",
                            "spot",
                            " tend",
                            " to",
                            " incorporate",
                            " throw",
                            "back",
                            " features",
                            " such",
                            " as",
                            " live",
                            " comment",
                            " boxes",
                            " and",
                            " side",
                            "bars",
                            " featuring",
                            " other",
                            " sites",
                            " you",
                            " need",
                            " to",
                            " check",
                            " out",
                            ".",
                            " Buffalo",
                            " T",
                            "ones",
                            " out",
                            "does",
                            " a",
                            " few",
                            " of",
                            " these",
                            " by",
                            " having",
                            " a",
                            " list",
                            " of",
                            " blogs",
                            " complete",
                            " with",
                            " a",
                            " thumbnail",
                            " of",
                            " its"
                        ],
                        "dataIndex": null,
                        "index": "7513",
                        "layer": "8-res_fs12288-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 54.295,
                        "maxValueTokenIndex": 1,
                        "minValue": 0,
                        "values": [
                            0,
                            54.295,
                            3.554,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T22:26:13.672Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 54.533,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "11474",
            "description": "phrases and words related to teaching and lessons",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5623965263366699,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "11474",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:18:35.672Z",
                "maxActApprox": 60.762,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    11474,
                    44019,
                    11447,
                    47724,
                    37022,
                    46531,
                    17582,
                    3862,
                    8181,
                    24835,
                    5198,
                    14407,
                    46953,
                    24424,
                    19723,
                    22854,
                    12787,
                    7269,
                    44382,
                    46722,
                    3429,
                    6722,
                    12106,
                    36496,
                    35811
                ],
                "topkCosSimValues": [
                    1,
                    0.7285,
                    0.6009,
                    0.5772,
                    0.5495,
                    0.5457,
                    0.5276,
                    0.5219,
                    0.4978,
                    0.4824,
                    0.4674,
                    0.4572,
                    0.4529,
                    0.4509,
                    0.4477,
                    0.4353,
                    0.4191,
                    0.416,
                    0.4138,
                    0.4058,
                    0.4051,
                    0.4037,
                    0.4033,
                    0.4021,
                    0.3972
                ],
                "neuron_alignment_indices": [
                    679,
                    575,
                    108
                ],
                "neuron_alignment_values": [
                    0.116,
                    0.094,
                    0.092
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    108,
                    414,
                    279
                ],
                "correlated_neurons_pearson": [
                    0.02,
                    0.016,
                    0.016
                ],
                "correlated_neurons_l1": [
                    0.019,
                    0.014,
                    0.017
                ],
                "correlated_features_indices": [
                    11447,
                    11468,
                    11514
                ],
                "correlated_features_pearson": [
                    0.041,
                    0.01,
                    0.006
                ],
                "correlated_features_l1": [
                    0.041,
                    0.01,
                    0.006
                ],
                "neg_str": [
                    " sidx",
                    "76561",
                    " Ports",
                    "ablished",
                    "atos",
                    " Launcher",
                    "FTWARE",
                    "ilings",
                    "tar",
                    " busiest"
                ],
                "neg_values": [
                    -0.728,
                    -0.718,
                    -0.705,
                    -0.643,
                    -0.613,
                    -0.607,
                    -0.602,
                    -0.6,
                    -0.599,
                    -0.598
                ],
                "pos_str": [
                    "yout",
                    "ingly",
                    " students",
                    " kids",
                    "girls",
                    "children",
                    " kindergarten",
                    " undergrad",
                    " curriculum",
                    "classes"
                ],
                "pos_values": [
                    0.933,
                    0.933,
                    0.903,
                    0.881,
                    0.88,
                    0.871,
                    0.819,
                    0.811,
                    0.807,
                    0.789
                ],
                "frac_nonzero": 0.00016,
                "freq_hist_data_bar_heights": [
                    109,
                    59,
                    34,
                    17,
                    23,
                    12,
                    11,
                    3,
                    6,
                    5,
                    1,
                    2,
                    0,
                    2,
                    0,
                    2,
                    3,
                    7,
                    7,
                    7,
                    3,
                    5,
                    8,
                    7,
                    9,
                    11,
                    5,
                    7,
                    6,
                    8,
                    8,
                    9,
                    8,
                    9,
                    9,
                    8,
                    5,
                    13,
                    6,
                    6,
                    5,
                    7,
                    3,
                    3,
                    5,
                    4,
                    8,
                    1,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.612,
                    1.827,
                    3.042,
                    4.258,
                    5.473,
                    6.688,
                    7.903,
                    9.118,
                    10.333,
                    11.548,
                    12.764,
                    13.979,
                    15.194,
                    16.409,
                    17.624,
                    18.839,
                    20.054,
                    21.27,
                    22.485,
                    23.7,
                    24.915,
                    26.13,
                    27.345,
                    28.56,
                    29.776,
                    30.991,
                    32.206,
                    33.421,
                    34.636,
                    35.851,
                    37.066,
                    38.281,
                    39.497,
                    40.712,
                    41.927,
                    43.142,
                    44.357,
                    45.572,
                    46.787,
                    48.003,
                    49.218,
                    50.433,
                    51.648,
                    52.863,
                    54.078,
                    55.293,
                    56.509,
                    57.724,
                    58.939,
                    60.154
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    0,
                    1,
                    6,
                    5,
                    11,
                    25,
                    39,
                    76,
                    99,
                    200,
                    323,
                    519,
                    748,
                    1207,
                    1653,
                    2229,
                    2922,
                    3577,
                    3972,
                    4403,
                    4365,
                    4237,
                    3964,
                    3467,
                    3027,
                    2378,
                    1855,
                    1412,
                    1041,
                    707,
                    550,
                    392,
                    269,
                    154,
                    137,
                    84,
                    46,
                    49,
                    24,
                    20,
                    19,
                    14,
                    7,
                    9,
                    3,
                    3,
                    0,
                    3,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.711,
                    -0.678,
                    -0.644,
                    -0.611,
                    -0.578,
                    -0.545,
                    -0.512,
                    -0.478,
                    -0.445,
                    -0.412,
                    -0.379,
                    -0.346,
                    -0.312,
                    -0.279,
                    -0.246,
                    -0.213,
                    -0.179,
                    -0.146,
                    -0.113,
                    -0.08,
                    -0.047,
                    -0.013,
                    0.02,
                    0.053,
                    0.086,
                    0.12,
                    0.153,
                    0.186,
                    0.219,
                    0.252,
                    0.286,
                    0.319,
                    0.352,
                    0.385,
                    0.418,
                    0.452,
                    0.485,
                    0.518,
                    0.551,
                    0.585,
                    0.618,
                    0.651,
                    0.684,
                    0.717,
                    0.751,
                    0.784,
                    0.817,
                    0.85,
                    0.883,
                    0.917
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases and words related to teaching and lessons",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4ucwgm8gyi66658nilmyh",
                        "tokens": [
                            "\u00e2\u0138\u00ba",
                            " Author",
                            ":",
                            " Joseph",
                            " F",
                            "its",
                            "an",
                            "akis",
                            " |",
                            " Date",
                            ":",
                            " 26",
                            " June",
                            " 2017",
                            " |",
                            " Per",
                            "malink",
                            "\n",
                            "\n",
                            "Advertisements",
                            "<|endoftext|>",
                            "And",
                            " now",
                            " here",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " my",
                            " recap",
                            " and",
                            " review",
                            " of",
                            " the",
                            " 5",
                            "th",
                            " disc",
                            " from",
                            " this",
                            " classic",
                            " Soft",
                            "core",
                            " TV",
                            " series",
                            ".",
                            " Once",
                            " again",
                            " produced",
                            " by",
                            " Al",
                            "ain",
                            " S",
                            "irit",
                            "z",
                            "ky",
                            " and",
                            " this",
                            " is",
                            " directed",
                            " by",
                            " David",
                            " Cove",
                            " with",
                            " Mark",
                            " Evan",
                            " Schwartz",
                            " listed",
                            " as",
                            " screen",
                            "writer",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " theme",
                            " of",
                            " this",
                            " disc",
                            ",",
                            " as",
                            " evidenced",
                            " by",
                            " the",
                            " title",
                            ",",
                            " is",
                            " dreams",
                            ".",
                            " The",
                            " alien",
                            " crew",
                            " doesn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " dream",
                            ",",
                            " and",
                            " so",
                            " Emmanuel",
                            "le",
                            " decides",
                            " to",
                            " teach",
                            " them",
                            " about",
                            " dreams",
                            ",",
                            " and",
                            " how",
                            " you",
                            " can",
                            " explore",
                            " sexual",
                            " fantasies",
                            " in",
                            " them",
                            ".",
                            " So",
                            " while",
                            " she",
                            " sleeps",
                            " on",
                            " a",
                            " special",
                            " table",
                            " in",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "11474",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 60.762,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            60.762,
                            0.187,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:18:41.456Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 60.762,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4ucwim8hmi666q1bdgr6a",
                        "tokens": [
                            "et",
                            " K",
                            "aur",
                            ",",
                            " faced",
                            " anti",
                            "-",
                            "inc",
                            "umb",
                            "ency",
                            ",",
                            " Amar",
                            "inder",
                            " had",
                            " ro",
                            "ped",
                            " in",
                            " T",
                            "oh",
                            "ra",
                            " loyal",
                            "ist",
                            " Raj",
                            "la",
                            " with",
                            " a",
                            " promise",
                            " of",
                            " election",
                            " ticket",
                            " in",
                            " 2012",
                            ".",
                            " Raj",
                            "la",
                            " ensured",
                            " lead",
                            " for",
                            " Pre",
                            "ne",
                            "et",
                            " from",
                            " Sam",
                            "ana",
                            ",",
                            " but",
                            " in",
                            " 2012",
                            ",",
                            " Captain",
                            " fielded",
                            " his",
                            " son",
                            ",",
                            " Ran",
                            "inder",
                            " Singh",
                            ",",
                            " who",
                            " event",
                            "fully",
                            " lost",
                            " from",
                            " Sam",
                            "ana",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "A",
                            "mar",
                            "inder",
                            " didn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " keep",
                            " his",
                            " promise",
                            " and",
                            " favoured",
                            " own",
                            " family",
                            " over",
                            " party",
                            " workers",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Raj",
                            "la",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "I",
                            " am",
                            " not",
                            " going",
                            " to",
                            " the",
                            " AAP",
                            " for",
                            " a",
                            " ticket",
                            " or",
                            " to",
                            " contest",
                            " an",
                            " election",
                            ".",
                            " I",
                            " am",
                            " going",
                            " to",
                            " teach",
                            " a",
                            " lesson",
                            " to",
                            " the",
                            " corrupt",
                            " politicians",
                            " who",
                            " have",
                            " ruined",
                            " Punjab"
                        ],
                        "dataIndex": null,
                        "index": "11474",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 58.68,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            58.68,
                            11.624,
                            7.376,
                            0.514,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:18:41.456Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 48.609,
                        "binMax": 60.762,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4ucwgm8gzi6669qump2yq",
                        "tokens": [
                            "et",
                            " K",
                            "aur",
                            ",",
                            " faced",
                            " anti",
                            "-",
                            "inc",
                            "umb",
                            "ency",
                            ",",
                            " Amar",
                            "inder",
                            " had",
                            " ro",
                            "ped",
                            " in",
                            " T",
                            "oh",
                            "ra",
                            " loyal",
                            "ist",
                            " Raj",
                            "la",
                            " with",
                            " a",
                            " promise",
                            " of",
                            " election",
                            " ticket",
                            " in",
                            " 2012",
                            ".",
                            " Raj",
                            "la",
                            " ensured",
                            " lead",
                            " for",
                            " Pre",
                            "ne",
                            "et",
                            " from",
                            " Sam",
                            "ana",
                            ",",
                            " but",
                            " in",
                            " 2012",
                            ",",
                            " Captain",
                            " fielded",
                            " his",
                            " son",
                            ",",
                            " Ran",
                            "inder",
                            " Singh",
                            ",",
                            " who",
                            " event",
                            "fully",
                            " lost",
                            " from",
                            " Sam",
                            "ana",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "A",
                            "mar",
                            "inder",
                            " didn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " keep",
                            " his",
                            " promise",
                            " and",
                            " favoured",
                            " own",
                            " family",
                            " over",
                            " party",
                            " workers",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Raj",
                            "la",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "I",
                            " am",
                            " not",
                            " going",
                            " to",
                            " the",
                            " AAP",
                            " for",
                            " a",
                            " ticket",
                            " or",
                            " to",
                            " contest",
                            " an",
                            " election",
                            ".",
                            " I",
                            " am",
                            " going",
                            " to",
                            " teach",
                            " a",
                            " lesson",
                            " to",
                            " the",
                            " corrupt",
                            " politicians",
                            " who",
                            " have",
                            " ruined",
                            " Punjab"
                        ],
                        "dataIndex": null,
                        "index": "11474",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 58.68,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            58.68,
                            11.624,
                            7.376,
                            0.514,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:18:41.456Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 60.762,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "68287",
            "description": " words related to teaching and education",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5608433485031128,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "68287",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:56:56.587Z",
                "maxActApprox": 54.375,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    68287,
                    27303,
                    48216,
                    84880,
                    44064,
                    68269,
                    27016,
                    36129,
                    78484,
                    5909,
                    90381,
                    50443,
                    64882,
                    61552,
                    50465,
                    52515,
                    77660,
                    3189,
                    1477,
                    23900,
                    50431,
                    45929,
                    39551,
                    53622,
                    87134
                ],
                "topkCosSimValues": [
                    1,
                    0.8089,
                    0.6812,
                    0.5554,
                    0.5326,
                    0.5321,
                    0.5233,
                    0.5086,
                    0.4883,
                    0.4772,
                    0.4721,
                    0.4566,
                    0.4537,
                    0.4327,
                    0.4256,
                    0.4256,
                    0.4252,
                    0.4245,
                    0.4233,
                    0.4204,
                    0.4198,
                    0.4181,
                    0.4173,
                    0.4138,
                    0.4091
                ],
                "neuron_alignment_indices": [
                    679,
                    288,
                    108
                ],
                "neuron_alignment_values": [
                    0.113,
                    0.104,
                    0.103
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    108,
                    25,
                    510
                ],
                "correlated_neurons_pearson": [
                    0.021,
                    0.016,
                    0.016
                ],
                "correlated_neurons_l1": [
                    0.021,
                    0.015,
                    0.016
                ],
                "correlated_features_indices": [
                    68269,
                    68255,
                    68287
                ],
                "correlated_features_pearson": [
                    0.077,
                    0.004,
                    0
                ],
                "correlated_features_l1": [
                    0.077,
                    0.004,
                    0
                ],
                "neg_str": [
                    " sidx",
                    "tar",
                    "ilings",
                    "76561",
                    "\u00e3\u0124\u00bb",
                    "reens",
                    "ablished",
                    "rants",
                    "ogene",
                    " Ports"
                ],
                "neg_values": [
                    -0.814,
                    -0.66,
                    -0.624,
                    -0.622,
                    -0.613,
                    -0.592,
                    -0.588,
                    -0.584,
                    -0.579,
                    -0.571
                ],
                "pos_str": [
                    " students",
                    " kindergarten",
                    "ingly",
                    " undergrad",
                    "yout",
                    "classes",
                    " kids",
                    "girls",
                    " curriculum",
                    " seminars"
                ],
                "pos_values": [
                    0.91,
                    0.9,
                    0.895,
                    0.893,
                    0.866,
                    0.854,
                    0.847,
                    0.842,
                    0.831,
                    0.829
                ],
                "frac_nonzero": 0.00016,
                "freq_hist_data_bar_heights": [
                    103,
                    45,
                    40,
                    26,
                    24,
                    15,
                    10,
                    8,
                    9,
                    6,
                    5,
                    7,
                    10,
                    11,
                    8,
                    4,
                    7,
                    9,
                    7,
                    13,
                    6,
                    5,
                    7,
                    9,
                    5,
                    6,
                    10,
                    9,
                    6,
                    2,
                    6,
                    5,
                    4,
                    9,
                    6,
                    6,
                    4,
                    5,
                    1,
                    5,
                    8,
                    4,
                    1,
                    3,
                    2,
                    4,
                    3,
                    1,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.551,
                    1.638,
                    2.726,
                    3.813,
                    4.9,
                    5.988,
                    7.075,
                    8.162,
                    9.25,
                    10.337,
                    11.424,
                    12.512,
                    13.599,
                    14.687,
                    15.774,
                    16.861,
                    17.949,
                    19.036,
                    20.123,
                    21.211,
                    22.298,
                    23.385,
                    24.473,
                    25.56,
                    26.647,
                    27.735,
                    28.822,
                    29.909,
                    30.997,
                    32.084,
                    33.171,
                    34.259,
                    35.346,
                    36.434,
                    37.521,
                    38.608,
                    39.696,
                    40.783,
                    41.87,
                    42.958,
                    44.045,
                    45.132,
                    46.22,
                    47.307,
                    48.394,
                    49.482,
                    50.569,
                    51.656,
                    52.744,
                    53.831
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    0,
                    1,
                    3,
                    4,
                    13,
                    24,
                    35,
                    71,
                    124,
                    211,
                    309,
                    516,
                    850,
                    1209,
                    1848,
                    2390,
                    3012,
                    3707,
                    4216,
                    4505,
                    4565,
                    4397,
                    3935,
                    3444,
                    2751,
                    2268,
                    1678,
                    1254,
                    866,
                    666,
                    442,
                    305,
                    212,
                    121,
                    86,
                    60,
                    34,
                    32,
                    28,
                    18,
                    10,
                    17,
                    7,
                    1,
                    3,
                    4,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.797,
                    -0.762,
                    -0.728,
                    -0.693,
                    -0.659,
                    -0.624,
                    -0.59,
                    -0.555,
                    -0.521,
                    -0.486,
                    -0.452,
                    -0.418,
                    -0.383,
                    -0.349,
                    -0.314,
                    -0.28,
                    -0.245,
                    -0.211,
                    -0.176,
                    -0.142,
                    -0.107,
                    -0.073,
                    -0.038,
                    -0.004,
                    0.031,
                    0.065,
                    0.1,
                    0.134,
                    0.168,
                    0.203,
                    0.237,
                    0.272,
                    0.306,
                    0.341,
                    0.375,
                    0.41,
                    0.444,
                    0.479,
                    0.513,
                    0.548,
                    0.582,
                    0.617,
                    0.651,
                    0.686,
                    0.72,
                    0.754,
                    0.789,
                    0.823,
                    0.858,
                    0.892
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " words related to teaching and education",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi1skhr30a10exbig72s7b",
                        "tokens": [
                            " This",
                            " does",
                            " not",
                            " deny",
                            " that",
                            " there",
                            " are",
                            " local",
                            " decreases",
                            " in",
                            " entropy",
                            ",",
                            " like",
                            " the",
                            " growth",
                            " of",
                            " a",
                            " child",
                            ",",
                            " but",
                            " the",
                            " global",
                            " entropy",
                            " relentlessly",
                            " increases",
                            " with",
                            " time",
                            ".",
                            " For",
                            " several",
                            " years",
                            ",",
                            " I",
                            " taught",
                            " our",
                            " junior",
                            "-",
                            "sen",
                            "ior",
                            " level",
                            " course",
                            " on",
                            " statistical",
                            " physics",
                            ".",
                            " We",
                            " used",
                            " the",
                            " standard",
                            " textbook",
                            " and",
                            " followed",
                            " Bolt",
                            "z",
                            "mann",
                            "\u00c2",
                            "\u0134",
                            "s",
                            " deriv",
                            "ation",
                            " of",
                            " the",
                            " Second",
                            " Law",
                            " of",
                            " Ther",
                            "m",
                            "odynamics",
                            ",",
                            " with",
                            " the",
                            " appropriate",
                            " level",
                            " of",
                            " mathematical",
                            " sophistication",
                            ".",
                            " In",
                            " the",
                            " last",
                            " few",
                            " years",
                            ",",
                            " I",
                            " found",
                            " that",
                            " there",
                            " were",
                            " arguments",
                            " as",
                            " far",
                            " back",
                            " as",
                            " 18",
                            "77",
                            " that",
                            " showed",
                            " Bolt",
                            "z",
                            "mann",
                            " was",
                            " deeply",
                            " wrong",
                            ".",
                            " I",
                            " review",
                            " some",
                            " of",
                            " these",
                            " problems",
                            " elsewhere",
                            " in",
                            " non",
                            "technical",
                            " language",
                            "..",
                            "[",
                            "4",
                            "]",
                            " Here",
                            ",",
                            " I",
                            " take",
                            " a",
                            " different",
                            " approach",
                            " and"
                        ],
                        "dataIndex": null,
                        "index": "68287",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 54.375,
                        "maxValueTokenIndex": 33,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            54.375,
                            9.154,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:57:00.988Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 54.375,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi1skhr30b10ex7l6cn793",
                        "tokens": [
                            " thing",
                            " is",
                            " not",
                            " being",
                            " able",
                            " to",
                            " know",
                            " what",
                            " is",
                            " happening",
                            " just",
                            " 200",
                            " miles",
                            " away",
                            ".",
                            " What",
                            " we",
                            " hear",
                            " is",
                            " all",
                            " \"",
                            "he",
                            "ar",
                            "-",
                            "say",
                            ".\"",
                            " We",
                            " have",
                            " limited",
                            " internet",
                            ",",
                            " so",
                            " we",
                            " can",
                            "'t",
                            " even",
                            " check",
                            " many",
                            " news",
                            " sites",
                            ".",
                            " I",
                            " teach",
                            " 4",
                            "th",
                            " grade",
                            ",",
                            " and",
                            " many",
                            " (",
                            "if",
                            " not",
                            " most",
                            ")",
                            " of",
                            " my",
                            " students",
                            " have",
                            " some",
                            " family",
                            " that",
                            " they",
                            " can",
                            "'t",
                            " get",
                            " hold",
                            " of",
                            ".\"",
                            " Brooke",
                            " D",
                            "urb",
                            "in",
                            ",",
                            " a",
                            " teacher",
                            " in",
                            " Port",
                            "-",
                            "de",
                            "-",
                            "Pa",
                            "ix",
                            " in",
                            " northern",
                            " Haiti",
                            ",",
                            " e",
                            "-",
                            "mails",
                            ":",
                            " \"",
                            "The",
                            " worst",
                            " part",
                            " about",
                            " the",
                            " whole",
                            " thing",
                            " is",
                            " not",
                            " being",
                            " able",
                            " to",
                            " know",
                            " what",
                            " is",
                            " happening",
                            " just",
                            " 200",
                            " miles",
                            " away",
                            ".",
                            " What",
                            " we",
                            " hear",
                            " is",
                            " all",
                            " \"",
                            "he",
                            "ar",
                            "-",
                            "say",
                            ".\"",
                            " We",
                            " have",
                            " limited",
                            " internet"
                        ],
                        "dataIndex": null,
                        "index": "68287",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 52.826,
                        "maxValueTokenIndex": 42,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            52.826,
                            1.379,
                            0,
                            4.885,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.96,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.143,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:57:00.988Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 54.375,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi1skir30u10exxk785fsh",
                        "tokens": [
                            " thing",
                            " is",
                            " not",
                            " being",
                            " able",
                            " to",
                            " know",
                            " what",
                            " is",
                            " happening",
                            " just",
                            " 200",
                            " miles",
                            " away",
                            ".",
                            " What",
                            " we",
                            " hear",
                            " is",
                            " all",
                            " \"",
                            "he",
                            "ar",
                            "-",
                            "say",
                            ".\"",
                            " We",
                            " have",
                            " limited",
                            " internet",
                            ",",
                            " so",
                            " we",
                            " can",
                            "'t",
                            " even",
                            " check",
                            " many",
                            " news",
                            " sites",
                            ".",
                            " I",
                            " teach",
                            " 4",
                            "th",
                            " grade",
                            ",",
                            " and",
                            " many",
                            " (",
                            "if",
                            " not",
                            " most",
                            ")",
                            " of",
                            " my",
                            " students",
                            " have",
                            " some",
                            " family",
                            " that",
                            " they",
                            " can",
                            "'t",
                            " get",
                            " hold",
                            " of",
                            ".\"",
                            " Brooke",
                            " D",
                            "urb",
                            "in",
                            ",",
                            " a",
                            " teacher",
                            " in",
                            " Port",
                            "-",
                            "de",
                            "-",
                            "Pa",
                            "ix",
                            " in",
                            " northern",
                            " Haiti",
                            ",",
                            " e",
                            "-",
                            "mails",
                            ":",
                            " \"",
                            "The",
                            " worst",
                            " part",
                            " about",
                            " the",
                            " whole",
                            " thing",
                            " is",
                            " not",
                            " being",
                            " able",
                            " to",
                            " know",
                            " what",
                            " is",
                            " happening",
                            " just",
                            " 200",
                            " miles",
                            " away",
                            ".",
                            " What",
                            " we",
                            " hear",
                            " is",
                            " all",
                            " \"",
                            "he",
                            "ar",
                            "-",
                            "say",
                            ".\"",
                            " We",
                            " have",
                            " limited",
                            " internet"
                        ],
                        "dataIndex": null,
                        "index": "68287",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 52.826,
                        "maxValueTokenIndex": 42,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            52.826,
                            1.379,
                            0,
                            4.885,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.96,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.143,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:57:00.988Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 43.5,
                        "binMax": 54.375,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "27303",
            "description": " references to education or teaching concepts",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5554918216315458,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "27303",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:04:35.738Z",
                "maxActApprox": 35.141,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    27303,
                    68287,
                    48216,
                    44064,
                    84880,
                    39551,
                    68269,
                    78484,
                    90381,
                    1477,
                    32386,
                    27016,
                    5909,
                    61552,
                    45929,
                    62592,
                    77660,
                    13254,
                    45552,
                    50465,
                    77000,
                    25065,
                    87134,
                    36129,
                    64882
                ],
                "topkCosSimValues": [
                    1,
                    0.8089,
                    0.6288,
                    0.5568,
                    0.5379,
                    0.5377,
                    0.5313,
                    0.5177,
                    0.5094,
                    0.4993,
                    0.4828,
                    0.4798,
                    0.4715,
                    0.4608,
                    0.4488,
                    0.4444,
                    0.4384,
                    0.4343,
                    0.4311,
                    0.4283,
                    0.4261,
                    0.4242,
                    0.424,
                    0.4218,
                    0.4175
                ],
                "neuron_alignment_indices": [
                    679,
                    414,
                    575
                ],
                "neuron_alignment_values": [
                    0.115,
                    0.086,
                    0.086
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    108,
                    25,
                    119
                ],
                "correlated_neurons_pearson": [
                    0.018,
                    0.015,
                    0.015
                ],
                "correlated_neurons_l1": [
                    0.018,
                    0.014,
                    0.015
                ],
                "correlated_features_indices": [
                    27307,
                    27394,
                    27294
                ],
                "correlated_features_pearson": [
                    0.002,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.002,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    " Ports",
                    "ascus",
                    " busiest",
                    "atos",
                    "ablished",
                    " allotted",
                    " Seeking",
                    "FTWARE",
                    "etting",
                    " Launcher"
                ],
                "neg_values": [
                    -0.704,
                    -0.693,
                    -0.681,
                    -0.676,
                    -0.62,
                    -0.613,
                    -0.61,
                    -0.607,
                    -0.601,
                    -0.6
                ],
                "pos_str": [
                    "children",
                    " kids",
                    "yout",
                    "kids",
                    "fulness",
                    " lessons",
                    " students",
                    "ingly",
                    "tale",
                    "parents"
                ],
                "pos_values": [
                    0.924,
                    0.882,
                    0.846,
                    0.803,
                    0.789,
                    0.785,
                    0.782,
                    0.781,
                    0.779,
                    0.777
                ],
                "frac_nonzero": 0.00017,
                "freq_hist_data_bar_heights": [
                    119,
                    69,
                    47,
                    27,
                    16,
                    20,
                    10,
                    10,
                    10,
                    8,
                    5,
                    10,
                    5,
                    6,
                    5,
                    8,
                    9,
                    7,
                    9,
                    8,
                    8,
                    4,
                    8,
                    8,
                    5,
                    10,
                    4,
                    7,
                    4,
                    4,
                    10,
                    9,
                    7,
                    5,
                    5,
                    2,
                    5,
                    5,
                    4,
                    3,
                    6,
                    2,
                    1,
                    2,
                    1,
                    1,
                    1,
                    2,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.354,
                    1.057,
                    1.76,
                    2.462,
                    3.165,
                    3.868,
                    4.571,
                    5.273,
                    5.976,
                    6.679,
                    7.382,
                    8.084,
                    8.787,
                    9.49,
                    10.193,
                    10.895,
                    11.598,
                    12.301,
                    13.004,
                    13.706,
                    14.409,
                    15.112,
                    15.815,
                    16.518,
                    17.22,
                    17.923,
                    18.626,
                    19.329,
                    20.031,
                    20.734,
                    21.437,
                    22.14,
                    22.842,
                    23.545,
                    24.248,
                    24.951,
                    25.653,
                    26.356,
                    27.059,
                    27.762,
                    28.464,
                    29.167,
                    29.87,
                    30.573,
                    31.275,
                    31.978,
                    32.681,
                    33.384,
                    34.087,
                    34.789
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    0,
                    4,
                    8,
                    11,
                    11,
                    43,
                    48,
                    91,
                    156,
                    254,
                    397,
                    612,
                    967,
                    1343,
                    1904,
                    2390,
                    3001,
                    3566,
                    3911,
                    4238,
                    4424,
                    4207,
                    3746,
                    3358,
                    2819,
                    2309,
                    1763,
                    1341,
                    981,
                    743,
                    500,
                    355,
                    243,
                    168,
                    91,
                    74,
                    57,
                    33,
                    32,
                    12,
                    16,
                    5,
                    5,
                    4,
                    8,
                    1,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.687,
                    -0.655,
                    -0.622,
                    -0.59,
                    -0.557,
                    -0.525,
                    -0.492,
                    -0.46,
                    -0.427,
                    -0.394,
                    -0.362,
                    -0.329,
                    -0.297,
                    -0.264,
                    -0.232,
                    -0.199,
                    -0.167,
                    -0.134,
                    -0.102,
                    -0.069,
                    -0.036,
                    -0.004,
                    0.029,
                    0.061,
                    0.094,
                    0.126,
                    0.159,
                    0.191,
                    0.224,
                    0.256,
                    0.289,
                    0.322,
                    0.354,
                    0.387,
                    0.419,
                    0.452,
                    0.484,
                    0.517,
                    0.549,
                    0.582,
                    0.615,
                    0.647,
                    0.68,
                    0.712,
                    0.745,
                    0.777,
                    0.81,
                    0.842,
                    0.875,
                    0.907
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " references to education or teaching concepts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "instances of the word \"teach\" and its variations, indicating a focus on educational themes or instructional content",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygg6hoyvz8d10ex3kjt3d3y",
                        "tokens": [
                            ".\"",
                            " You",
                            " will",
                            " likely",
                            " feel",
                            " very",
                            " alone",
                            ".",
                            " Unfortunately",
                            ",",
                            " coming",
                            " out",
                            " of",
                            " the",
                            " fog",
                            " with",
                            " your",
                            " eyes",
                            " open",
                            " is",
                            " more",
                            " painful",
                            " than",
                            " slipping",
                            " into",
                            " one",
                            " without",
                            " noticing",
                            ".",
                            "\n",
                            "\n",
                            "But",
                            " remember",
                            ":",
                            " feelings",
                            " aren",
                            "'t",
                            " the",
                            " truth",
                            ".",
                            " You",
                            " aren",
                            "'t",
                            " the",
                            " worst",
                            " off",
                            " you",
                            "'ve",
                            " ever",
                            " been",
                            ".",
                            " Expect",
                            " the",
                            " sadness",
                            ".",
                            " It",
                            " sounds",
                            " crazy",
                            " but",
                            " welcome",
                            " it",
                            ".",
                            " That",
                            " sadness",
                            " is",
                            " going",
                            " to",
                            " live",
                            " in",
                            " you",
                            " for",
                            " a",
                            " long",
                            " time",
                            " and",
                            " it",
                            " will",
                            " teach",
                            " you",
                            " a",
                            " lot",
                            ".",
                            " I",
                            " know",
                            " you",
                            " don",
                            "'t",
                            " believe",
                            " me",
                            ",",
                            " but",
                            " that",
                            " sadness",
                            " is",
                            " your",
                            " friend",
                            ".",
                            " That",
                            " sadness",
                            " is",
                            " your",
                            " becoming",
                            ".",
                            "\n",
                            "\n",
                            "Not",
                            " everyone",
                            " you",
                            " lose",
                            " is",
                            " a",
                            " loss",
                            ".",
                            "\n",
                            "\n",
                            "Tell",
                            " your",
                            " story",
                            " no",
                            " matter",
                            " how",
                            " murky",
                            " the",
                            " details",
                            " seem",
                            " at",
                            " first"
                        ],
                        "dataIndex": null,
                        "index": "27303",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 35.141,
                        "maxValueTokenIndex": 77,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            35.141,
                            0,
                            3.522,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:04:40.934Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 35.141,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygg6hoyvz8e10excnfifv6x",
                        "tokens": [
                            " to",
                            " the",
                            " audience",
                            ".",
                            "\n",
                            "\n",
                            "#",
                            "2",
                            ":",
                            " Recre",
                            "ate",
                            " Photograph",
                            "s",
                            ":",
                            "\n",
                            "\n",
                            "One",
                            " of",
                            " the",
                            " things",
                            " that",
                            " will",
                            " help",
                            " you",
                            " be",
                            " a",
                            " great",
                            " V",
                            "FX",
                            " artist",
                            " is",
                            " to",
                            " recreate",
                            " photographs",
                            ".",
                            " Just",
                            " pick",
                            " some",
                            " that",
                            " have",
                            " different",
                            " shadows",
                            " and",
                            " lights",
                            " and",
                            " try",
                            " to",
                            " reproduce",
                            " them",
                            ".",
                            " This",
                            " will",
                            " help",
                            " you",
                            " to",
                            " see",
                            " the",
                            " difference",
                            " between",
                            " real",
                            " things",
                            " and",
                            " fake",
                            " ones",
                            ".",
                            " Despite",
                            " the",
                            " fact",
                            " that",
                            " the",
                            " first",
                            " ones",
                            " won",
                            "'t",
                            " be",
                            " that",
                            " good",
                            ",",
                            " it",
                            "'s",
                            " a",
                            " matter",
                            " of",
                            " practicing",
                            " and",
                            " experimenting",
                            ".",
                            "\n",
                            "\n",
                            "It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " working",
                            " on",
                            " making",
                            " CG",
                            " look",
                            " realistic",
                            " and",
                            " looking",
                            " at",
                            " real",
                            " world",
                            " references",
                            " will",
                            " teach",
                            " you",
                            " that",
                            " what",
                            " are",
                            " those",
                            " differences",
                            " in",
                            " the",
                            " render",
                            " you",
                            " have",
                            " in",
                            " front",
                            " of",
                            " you",
                            " compared",
                            " to",
                            " a",
                            " photograph",
                            " that"
                        ],
                        "dataIndex": null,
                        "index": "27303",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 34.402,
                        "maxValueTokenIndex": 106,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            34.402,
                            0.916,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:04:40.934Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 35.141,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygg6hoyvz8f10expdsbx3sa",
                        "tokens": [
                            " escape",
                            " pods",
                            ".",
                            " The",
                            " high",
                            "-",
                            "tech",
                            " lifestyle",
                            " the",
                            " Jets",
                            "ons",
                            " and",
                            " their",
                            " friends",
                            " enjoy",
                            " has",
                            " undoubtedly",
                            " come",
                            " at",
                            " a",
                            " great",
                            " cost",
                            ",",
                            " particularly",
                            " to",
                            " the",
                            " poor",
                            " and",
                            " marginalized",
                            " \u2014",
                            " already",
                            " at",
                            " the",
                            " doorstep",
                            " of",
                            " the",
                            " real",
                            "-",
                            "life",
                            " tech",
                            " industry",
                            ".",
                            " With",
                            " so",
                            " much",
                            " familiar",
                            " darkness",
                            " lurking",
                            " under",
                            " the",
                            " surface",
                            ",",
                            " here",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " hoping",
                            " the",
                            " ominous",
                            " origins",
                            " of",
                            " this",
                            " reim",
                            "ag",
                            "ined",
                            " Jets",
                            "ons",
                            " are",
                            " only",
                            " the",
                            " beginning",
                            ",",
                            " and",
                            " that",
                            " they",
                            " teach",
                            " us",
                            " to",
                            " think",
                            " twice",
                            " before",
                            " wishing",
                            " for",
                            " flying",
                            " cars",
                            " again",
                            ".",
                            "<|endoftext|>",
                            "Leon",
                            " Trotsky",
                            "\n",
                            "\n",
                            "For",
                            " Gry",
                            "ns",
                            "z",
                            "pan",
                            "\n",
                            "\n",
                            "Against",
                            " F",
                            "ascist",
                            " Pog",
                            "rom",
                            " Gang",
                            "s",
                            " and",
                            " Stalin",
                            "ist",
                            " Sc",
                            "ound",
                            "rel",
                            "s",
                            "\n",
                            "\n",
                            "(",
                            "19",
                            "39",
                            ")",
                            "\n",
                            "\n",
                            "Source",
                            ":",
                            " Socialist",
                            " Appeal",
                            " [",
                            "New"
                        ],
                        "dataIndex": null,
                        "index": "27303",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 33.195,
                        "maxValueTokenIndex": 75,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            33.195,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:04:40.934Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 35.141,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "23458",
            "description": " words related to teaching and learning opportunities",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5460662841796875,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "23458",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:14:52.693Z",
                "maxActApprox": 12.356,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    23458,
                    18015,
                    17236,
                    15729,
                    12323,
                    22304,
                    6400,
                    10074,
                    21850,
                    5546,
                    8499,
                    11003,
                    19525,
                    9646,
                    2161,
                    3604,
                    11022,
                    9284,
                    11262,
                    17459,
                    17195,
                    6052,
                    23217,
                    14024,
                    9517
                ],
                "topkCosSimValues": [
                    1,
                    0.5828,
                    0.5748,
                    0.5744,
                    0.5225,
                    0.5198,
                    0.5194,
                    0.5125,
                    0.504,
                    0.4991,
                    0.4826,
                    0.4764,
                    0.4744,
                    0.4678,
                    0.4658,
                    0.4559,
                    0.4543,
                    0.4539,
                    0.4397,
                    0.438,
                    0.4293,
                    0.4166,
                    0.3894,
                    0.3874,
                    0.3835
                ],
                "neuron_alignment_indices": [
                    447,
                    58,
                    67
                ],
                "neuron_alignment_values": [
                    0.153,
                    0.118,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    469,
                    58,
                    671
                ],
                "correlated_neurons_pearson": [
                    0.05,
                    0.049,
                    0.043
                ],
                "correlated_neurons_l1": [
                    0.04,
                    0.044,
                    0.039
                ],
                "correlated_features_indices": [
                    23464,
                    23452,
                    23472
                ],
                "correlated_features_pearson": [
                    0.028,
                    0.012,
                    0.01
                ],
                "correlated_features_l1": [
                    0.03,
                    0.016,
                    0.011
                ],
                "neg_str": [
                    "rather",
                    " [&",
                    "itton",
                    "pmwiki",
                    "Hope",
                    "LOS",
                    "hai",
                    "ingen",
                    "truth",
                    "hey"
                ],
                "neg_values": [
                    -0.753,
                    -0.665,
                    -0.629,
                    -0.625,
                    -0.612,
                    -0.605,
                    -0.584,
                    -0.575,
                    -0.567,
                    -0.566
                ],
                "pos_str": [
                    " nor",
                    " anymore",
                    " any",
                    " anything",
                    " anybody",
                    " necessarily",
                    " anywhere",
                    " whatsoever",
                    " anyone",
                    " slightest"
                ],
                "pos_values": [
                    1.589,
                    1.553,
                    1.175,
                    1.143,
                    1.036,
                    1.019,
                    1.002,
                    0.975,
                    0.969,
                    0.953
                ],
                "frac_nonzero": 0.005350000000000001,
                "freq_hist_data_bar_heights": [
                    2321,
                    2026,
                    1732,
                    1505,
                    1261,
                    1155,
                    953,
                    827,
                    692,
                    639,
                    564,
                    466,
                    393,
                    320,
                    313,
                    266,
                    244,
                    173,
                    182,
                    104,
                    114,
                    96,
                    81,
                    77,
                    56,
                    58,
                    38,
                    37,
                    29,
                    18,
                    14,
                    21,
                    7,
                    7,
                    4,
                    6,
                    9,
                    4,
                    4,
                    3,
                    3,
                    1,
                    1,
                    1,
                    2,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.124,
                    0.371,
                    0.618,
                    0.865,
                    1.112,
                    1.359,
                    1.607,
                    1.854,
                    2.101,
                    2.348,
                    2.595,
                    2.842,
                    3.089,
                    3.336,
                    3.583,
                    3.831,
                    4.078,
                    4.325,
                    4.572,
                    4.819,
                    5.066,
                    5.313,
                    5.56,
                    5.807,
                    6.055,
                    6.302,
                    6.549,
                    6.796,
                    7.043,
                    7.29,
                    7.537,
                    7.784,
                    8.031,
                    8.278,
                    8.526,
                    8.773,
                    9.02,
                    9.267,
                    9.514,
                    9.761,
                    10.008,
                    10.255,
                    10.502,
                    10.75,
                    10.997,
                    11.244,
                    11.491,
                    11.738,
                    11.985,
                    12.232
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    2,
                    7,
                    24,
                    53,
                    103,
                    229,
                    429,
                    845,
                    1339,
                    2177,
                    3084,
                    4375,
                    5298,
                    6168,
                    6443,
                    6012,
                    4938,
                    3647,
                    2346,
                    1321,
                    676,
                    354,
                    161,
                    83,
                    50,
                    32,
                    19,
                    8,
                    7,
                    3,
                    4,
                    1,
                    5,
                    1,
                    4,
                    2,
                    1,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.729,
                    -0.682,
                    -0.636,
                    -0.589,
                    -0.542,
                    -0.495,
                    -0.448,
                    -0.401,
                    -0.355,
                    -0.308,
                    -0.261,
                    -0.214,
                    -0.167,
                    -0.12,
                    -0.074,
                    -0.027,
                    0.02,
                    0.067,
                    0.114,
                    0.161,
                    0.207,
                    0.254,
                    0.301,
                    0.348,
                    0.395,
                    0.442,
                    0.488,
                    0.535,
                    0.582,
                    0.629,
                    0.676,
                    0.723,
                    0.769,
                    0.816,
                    0.863,
                    0.91,
                    0.957,
                    1.004,
                    1.05,
                    1.097,
                    1.144,
                    1.191,
                    1.238,
                    1.285,
                    1.331,
                    1.378,
                    1.425,
                    1.472,
                    1.519,
                    1.566
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " words related to teaching and learning opportunities",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdn30cfmap1i6666y65b76g",
                        "tokens": [
                            "The",
                            " Rogue",
                            " Film",
                            " School",
                            " will",
                            " be",
                            " in",
                            " the",
                            " form",
                            " of",
                            " weekend",
                            " seminars",
                            " held",
                            " by",
                            " Werner",
                            " Herz",
                            "og",
                            " in",
                            " person",
                            " at",
                            " varying",
                            " locations",
                            " and",
                            " at",
                            " inf",
                            "requent",
                            " intervals",
                            ".",
                            " The",
                            " number",
                            " of",
                            " participants",
                            " will",
                            " be",
                            " limited",
                            " to",
                            " a",
                            " maximum",
                            " of",
                            " 65",
                            ".",
                            " Locations",
                            " and",
                            " dates",
                            " will",
                            " be",
                            " announced",
                            " on",
                            " this",
                            " website",
                            " and",
                            " Werner",
                            " Herz",
                            "og",
                            "'s",
                            " website",
                            ":",
                            " www",
                            ".",
                            "wer",
                            "ner",
                            "her",
                            "z",
                            "og",
                            ".",
                            "com",
                            " approximately",
                            " 12",
                            " weeks",
                            " in",
                            " advance",
                            ".",
                            " The",
                            " Rogue",
                            " Film",
                            " School",
                            " will",
                            " not",
                            " teach",
                            " anything",
                            " technical",
                            " related",
                            " to",
                            " film",
                            "-",
                            "making",
                            ".",
                            " For",
                            " this",
                            " purpose",
                            ",",
                            " please",
                            " enroll",
                            " at",
                            " your",
                            " local",
                            " film",
                            " school",
                            ".",
                            " The",
                            " Rogue",
                            " Film",
                            " School",
                            " is",
                            " about",
                            " a",
                            " way",
                            " of",
                            " life",
                            ".",
                            " It",
                            " is",
                            " about",
                            " a",
                            " climate",
                            ",",
                            " the",
                            " excitement",
                            " that",
                            " makes",
                            " film",
                            " possible",
                            ".",
                            " It",
                            " will",
                            " be",
                            " about"
                        ],
                        "dataIndex": null,
                        "index": "23458",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 12.356,
                        "maxValueTokenIndex": 78,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.356,
                            9.123,
                            3.124,
                            1.749,
                            4.62,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:14:54.915Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 12.356,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn30cfmap2i666zkl3ztk1",
                        "tokens": [
                            "Our",
                            " School",
                            " P",
                            "ans",
                            "y",
                            " Kidd",
                            " Middle",
                            " School",
                            "--",
                            "The",
                            " name",
                            " of",
                            " our",
                            " school",
                            " originated",
                            " back",
                            " in",
                            " the",
                            " early",
                            " nineteen",
                            " hundreds",
                            ".",
                            " In",
                            " 1912",
                            " a",
                            " lady",
                            " named",
                            " P",
                            "ans",
                            "y",
                            " Ing",
                            "le",
                            " Kidd",
                            " came",
                            " to",
                            " P",
                            "ote",
                            "au",
                            ".",
                            " She",
                            " was",
                            " a",
                            " graduate",
                            " of",
                            " Indiana",
                            " University",
                            " with",
                            " a",
                            " Masters",
                            "'",
                            " Degree",
                            " in",
                            " English",
                            " and",
                            " Library",
                            " Science",
                            ".",
                            " P",
                            "ans",
                            "y",
                            " Ing",
                            "le",
                            " became",
                            " a",
                            " third",
                            " grade",
                            " teacher",
                            " until",
                            " 1915",
                            " when",
                            " she",
                            " married",
                            " Frank",
                            " Kidd",
                            ".",
                            " Since",
                            " a",
                            " regulation",
                            " of",
                            " the",
                            " 1915",
                            " school",
                            " board",
                            " was",
                            " not",
                            " to",
                            " hire",
                            " married",
                            " female",
                            " teachers",
                            ",",
                            " she",
                            " had",
                            " to",
                            " quit",
                            " teaching",
                            ".",
                            " P",
                            "ans",
                            "y",
                            " did",
                            " not",
                            " teach",
                            " again",
                            " until",
                            " 1921",
                            " when",
                            " the",
                            " regulation",
                            " was",
                            " finally",
                            " changed",
                            ".",
                            " For",
                            " 40",
                            " years",
                            " she",
                            " taught",
                            " with",
                            " all",
                            " her",
                            " heart",
                            ",",
                            " and",
                            " was",
                            " called",
                            " by"
                        ],
                        "dataIndex": null,
                        "index": "23458",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 11.567,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.682,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.567,
                            6,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:14:54.915Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 12.356,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdn30chmapoi666vhmx2d8m",
                        "tokens": [
                            "Our",
                            " School",
                            " P",
                            "ans",
                            "y",
                            " Kidd",
                            " Middle",
                            " School",
                            "--",
                            "The",
                            " name",
                            " of",
                            " our",
                            " school",
                            " originated",
                            " back",
                            " in",
                            " the",
                            " early",
                            " nineteen",
                            " hundreds",
                            ".",
                            " In",
                            " 1912",
                            " a",
                            " lady",
                            " named",
                            " P",
                            "ans",
                            "y",
                            " Ing",
                            "le",
                            " Kidd",
                            " came",
                            " to",
                            " P",
                            "ote",
                            "au",
                            ".",
                            " She",
                            " was",
                            " a",
                            " graduate",
                            " of",
                            " Indiana",
                            " University",
                            " with",
                            " a",
                            " Masters",
                            "'",
                            " Degree",
                            " in",
                            " English",
                            " and",
                            " Library",
                            " Science",
                            ".",
                            " P",
                            "ans",
                            "y",
                            " Ing",
                            "le",
                            " became",
                            " a",
                            " third",
                            " grade",
                            " teacher",
                            " until",
                            " 1915",
                            " when",
                            " she",
                            " married",
                            " Frank",
                            " Kidd",
                            ".",
                            " Since",
                            " a",
                            " regulation",
                            " of",
                            " the",
                            " 1915",
                            " school",
                            " board",
                            " was",
                            " not",
                            " to",
                            " hire",
                            " married",
                            " female",
                            " teachers",
                            ",",
                            " she",
                            " had",
                            " to",
                            " quit",
                            " teaching",
                            ".",
                            " P",
                            "ans",
                            "y",
                            " did",
                            " not",
                            " teach",
                            " again",
                            " until",
                            " 1921",
                            " when",
                            " the",
                            " regulation",
                            " was",
                            " finally",
                            " changed",
                            ".",
                            " For",
                            " 40",
                            " years",
                            " she",
                            " taught",
                            " with",
                            " all",
                            " her",
                            " heart",
                            ",",
                            " and",
                            " was",
                            " called",
                            " by"
                        ],
                        "dataIndex": null,
                        "index": "23458",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 11.567,
                        "maxValueTokenIndex": 102,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.682,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.567,
                            6,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:14:54.915Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 9.885,
                        "binMax": 12.356,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "17577",
            "description": "text related to children, students, and educational activities",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5450223955498708,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "17577",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:07:20.758Z",
                "maxActApprox": 59.885,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    17577,
                    7030,
                    2777,
                    11321,
                    12445,
                    4506,
                    23116,
                    7779,
                    15591,
                    246,
                    5493,
                    3514,
                    4799,
                    21916,
                    11072,
                    277,
                    4375,
                    20861,
                    7511,
                    23144,
                    8285,
                    13240,
                    23885,
                    11293,
                    8686
                ],
                "topkCosSimValues": [
                    1,
                    0.7913,
                    0.7509,
                    0.6205,
                    0.6038,
                    0.571,
                    0.5541,
                    0.5371,
                    0.5336,
                    0.5221,
                    0.5168,
                    0.5141,
                    0.4887,
                    0.4743,
                    0.4683,
                    0.4669,
                    0.466,
                    0.4603,
                    0.4576,
                    0.4148,
                    0.4073,
                    0.407,
                    0.4059,
                    0.4031,
                    0.3953
                ],
                "neuron_alignment_indices": [
                    575,
                    481,
                    383
                ],
                "neuron_alignment_values": [
                    0.112,
                    0.099,
                    0.089
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    575,
                    281,
                    657
                ],
                "correlated_neurons_pearson": [
                    0.037,
                    0.032,
                    0.029
                ],
                "correlated_neurons_l1": [
                    0.041,
                    0.03,
                    0.031
                ],
                "correlated_features_indices": [
                    17628,
                    17603,
                    17539
                ],
                "correlated_features_pearson": [
                    0.013,
                    0.008,
                    0.003
                ],
                "correlated_features_l1": [
                    0.014,
                    0.009,
                    0.004
                ],
                "neg_str": [
                    "\u00e2\u0138\u00ac",
                    "\u00e2\u0136\u0122\u00e2\u0136\u0122\u00e2\u0136\u0122\u00e2\u0136\u0122",
                    "ventory",
                    "PROV",
                    "ENCE",
                    "ATIVE",
                    "PORT",
                    "ATION",
                    " myster",
                    "Client"
                ],
                "neg_values": [
                    -0.675,
                    -0.659,
                    -0.653,
                    -0.649,
                    -0.642,
                    -0.629,
                    -0.617,
                    -0.615,
                    -0.609,
                    -0.608
                ],
                "pos_str": [
                    "children",
                    "ishly",
                    " ages",
                    "child",
                    "girls",
                    " born",
                    " aged",
                    "riages",
                    " orphan",
                    "sle"
                ],
                "pos_values": [
                    0.99,
                    0.984,
                    0.947,
                    0.9,
                    0.88,
                    0.88,
                    0.879,
                    0.875,
                    0.864,
                    0.861
                ],
                "frac_nonzero": 0.0005899999999999999,
                "freq_hist_data_bar_heights": [
                    266,
                    181,
                    111,
                    112,
                    82,
                    84,
                    64,
                    53,
                    51,
                    57,
                    37,
                    31,
                    31,
                    21,
                    15,
                    18,
                    18,
                    20,
                    15,
                    19,
                    16,
                    11,
                    13,
                    15,
                    13,
                    24,
                    19,
                    19,
                    26,
                    37,
                    28,
                    19,
                    27,
                    33,
                    36,
                    39,
                    37,
                    34,
                    31,
                    29,
                    17,
                    19,
                    16,
                    6,
                    2,
                    4,
                    1,
                    1,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.604,
                    1.802,
                    2.999,
                    4.197,
                    5.394,
                    6.592,
                    7.79,
                    8.987,
                    10.185,
                    11.382,
                    12.58,
                    13.777,
                    14.975,
                    16.173,
                    17.37,
                    18.568,
                    19.765,
                    20.963,
                    22.161,
                    23.358,
                    24.556,
                    25.753,
                    26.951,
                    28.149,
                    29.346,
                    30.544,
                    31.741,
                    32.939,
                    34.136,
                    35.334,
                    36.532,
                    37.729,
                    38.927,
                    40.124,
                    41.322,
                    42.52,
                    43.717,
                    44.915,
                    46.112,
                    47.31,
                    48.508,
                    49.705,
                    50.903,
                    52.1,
                    53.298,
                    54.495,
                    55.693,
                    56.891,
                    58.088,
                    59.286
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    4,
                    10,
                    9,
                    21,
                    27,
                    73,
                    111,
                    203,
                    347,
                    514,
                    804,
                    1136,
                    1587,
                    2143,
                    2678,
                    3238,
                    3694,
                    4037,
                    4220,
                    4171,
                    3846,
                    3501,
                    3084,
                    2543,
                    2095,
                    1580,
                    1285,
                    949,
                    654,
                    521,
                    357,
                    232,
                    181,
                    129,
                    84,
                    63,
                    40,
                    19,
                    10,
                    14,
                    8,
                    9,
                    2,
                    5,
                    4,
                    6,
                    1,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.658,
                    -0.625,
                    -0.592,
                    -0.558,
                    -0.525,
                    -0.492,
                    -0.458,
                    -0.425,
                    -0.392,
                    -0.359,
                    -0.325,
                    -0.292,
                    -0.259,
                    -0.225,
                    -0.192,
                    -0.159,
                    -0.125,
                    -0.092,
                    -0.059,
                    -0.026,
                    0.008,
                    0.041,
                    0.074,
                    0.108,
                    0.141,
                    0.174,
                    0.208,
                    0.241,
                    0.274,
                    0.308,
                    0.341,
                    0.374,
                    0.407,
                    0.441,
                    0.474,
                    0.507,
                    0.541,
                    0.574,
                    0.607,
                    0.641,
                    0.674,
                    0.707,
                    0.74,
                    0.774,
                    0.807,
                    0.84,
                    0.874,
                    0.907,
                    0.94,
                    0.974
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "text related to children, students, and educational activities",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmtc7fgpf5i666iqgea7ww",
                        "tokens": [
                            ",",
                            " which",
                            " includes",
                            " the",
                            " three",
                            " biggest",
                            " camps",
                            " in",
                            " the",
                            " world",
                            ",",
                            " was",
                            " constructed",
                            " in",
                            " the",
                            " early",
                            " 1990",
                            "s",
                            ".",
                            " The",
                            " largest",
                            " of",
                            " the",
                            " three",
                            ",",
                            " Hag",
                            "ader",
                            "a",
                            ",",
                            " houses",
                            " 138",
                            ",",
                            "102",
                            " refugees",
                            ",",
                            " which",
                            " is",
                            " equivalent",
                            " to",
                            " the",
                            " population",
                            " of",
                            " Pasadena",
                            ",",
                            " California",
                            ".",
                            " For",
                            " each",
                            " camp",
                            " on",
                            " the",
                            " map",
                            ",",
                            " a",
                            " comparable",
                            " American",
                            " city",
                            " is",
                            " listed",
                            " to",
                            " convey",
                            " size",
                            ".",
                            "\n",
                            "\n",
                            "World",
                            " Refugee",
                            " Day",
                            ",",
                            " recognized",
                            " each",
                            " year",
                            " on",
                            " June",
                            " 20",
                            ",",
                            " honors",
                            " the",
                            " millions",
                            " of",
                            " displaced",
                            " men",
                            ",",
                            " women",
                            " and",
                            " children",
                            " across",
                            " the",
                            " globe",
                            ".",
                            "<|endoftext|>",
                            "Children",
                            " in",
                            " lower",
                            "-",
                            "income",
                            " families",
                            " spend",
                            " more",
                            " time",
                            " watching",
                            " TV",
                            " and",
                            " using",
                            " electronic",
                            " devices",
                            " than",
                            " kids",
                            " in",
                            " more",
                            " affluent",
                            " homes",
                            ",",
                            " according",
                            " to",
                            " a",
                            " survey",
                            " released",
                            " Thursday",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " report",
                            " by",
                            " the",
                            " nonprofit"
                        ],
                        "dataIndex": null,
                        "index": "17577",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 59.885,
                        "maxValueTokenIndex": 91,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            30.583,
                            0,
                            0,
                            0,
                            0,
                            0,
                            59.885,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            14.502,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:23.748Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 59.885,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmtc7fgpf6i666xbwixhno",
                        "tokens": [
                            "\u2014",
                            "a",
                            " two",
                            "-",
                            "foot",
                            "-",
                            "tall",
                            " gu",
                            "ill",
                            "otine",
                            " was",
                            " popular",
                            " among",
                            " children",
                            ",",
                            " some",
                            " of",
                            " whom",
                            " used",
                            " it",
                            " to",
                            " decap",
                            "itate",
                            " rodents",
                            "\u2014",
                            "there",
                            " was",
                            " some",
                            " minor",
                            " fur",
                            "or",
                            " from",
                            " parents",
                            ",",
                            " and",
                            " Aurora",
                            " didn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " pursue",
                            " the",
                            " line",
                            ".",
                            "\n",
                            "\n",
                            "Six",
                            " years",
                            " later",
                            ",",
                            " the",
                            " company",
                            " felt",
                            " the",
                            " cultural",
                            " climate",
                            " was",
                            " ready",
                            " for",
                            " something",
                            " more",
                            " provocative",
                            ":",
                            " They",
                            " began",
                            " developing",
                            " a",
                            " line",
                            " dubbed",
                            " Monster",
                            " Scenes",
                            ".",
                            " Using",
                            " generic",
                            " characters",
                            " like",
                            " the",
                            " Victim",
                            ",",
                            " designers",
                            " concoct",
                            "ed",
                            " elaborate",
                            " scenarios",
                            " that",
                            " put",
                            " the",
                            " unfortunate",
                            " captives",
                            " in",
                            " mortal",
                            " peril",
                            ".",
                            "\n",
                            "\n",
                            "One",
                            " scenario",
                            " had",
                            " a",
                            " mad",
                            " scientist",
                            " hovering",
                            " over",
                            " his",
                            " captive",
                            " with",
                            " a",
                            " tray",
                            " full",
                            " of",
                            " hot",
                            " co",
                            "als",
                            " and",
                            " a",
                            " set",
                            " of",
                            " tong",
                            "s",
                            ";",
                            " another",
                            " designed",
                            " after",
                            " Edgar",
                            " Allan",
                            " Poe",
                            "\u00e2\u0122"
                        ],
                        "dataIndex": null,
                        "index": "17577",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 57.886,
                        "maxValueTokenIndex": 13,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            57.886,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:23.748Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 59.885,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmtc7fgpf7i666ihziey9y",
                        "tokens": [
                            " hundreds",
                            " of",
                            " restraints",
                            ",",
                            " which",
                            " can",
                            " include",
                            " anything",
                            " from",
                            " pin",
                            "ning",
                            " un",
                            "co",
                            "operative",
                            " children",
                            " face",
                            " down",
                            " on",
                            " the",
                            " floor",
                            " to",
                            " tying",
                            " them",
                            " up",
                            " with",
                            " straps",
                            ",",
                            " handcuffs",
                            " or",
                            " even",
                            " duct",
                            " tape",
                            ".",
                            " Three",
                            "-",
                            "quarters",
                            " of",
                            " students",
                            " who",
                            " were",
                            " restrained",
                            " had",
                            " physical",
                            ",",
                            " emotional",
                            " or",
                            " intellectual",
                            " disabilities",
                            ".",
                            "\n",
                            "\n",
                            "Children",
                            " have",
                            " suffered",
                            " countless",
                            " injuries",
                            " from",
                            " restraints",
                            ",",
                            " including",
                            " broken",
                            " bones",
                            ".",
                            " A",
                            " government",
                            " report",
                            " a",
                            " few",
                            " years",
                            " ago",
                            " detailed",
                            " hundreds",
                            " of",
                            " instances",
                            " of",
                            " abuse",
                            " and",
                            " several",
                            " deaths",
                            " over",
                            " two",
                            " decades",
                            ".",
                            "\n",
                            "\n",
                            "After",
                            " that",
                            " report",
                            ",",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " Department",
                            " of",
                            " Education",
                            "'s",
                            " Office",
                            " for",
                            " Civil",
                            " Rights",
                            " made",
                            " it",
                            " mandatory",
                            " for",
                            " school",
                            " districts",
                            " to",
                            " tell",
                            " to",
                            " the",
                            " government",
                            " how",
                            " many",
                            " times",
                            " they",
                            " have",
                            " used",
                            " restraints",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " Department",
                            " of",
                            " Education"
                        ],
                        "dataIndex": null,
                        "index": "17577",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 57.875,
                        "maxValueTokenIndex": 51,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            39.636,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            8.402,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            57.875,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:07:23.748Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 59.885,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "49874",
            "description": " words related to education or teaching",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5435985326766968,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "49874",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:36:59.275Z",
                "maxActApprox": 56.892,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    49874,
                    3632,
                    7591,
                    5461,
                    34732,
                    67495,
                    2521,
                    94620,
                    93617,
                    7810,
                    64569,
                    92646,
                    50512,
                    44509,
                    65211,
                    81022,
                    61020,
                    54775,
                    37078,
                    90537,
                    44026,
                    23457,
                    95193,
                    34795,
                    64891
                ],
                "topkCosSimValues": [
                    1,
                    0.434,
                    0.4197,
                    0.4146,
                    0.3884,
                    0.3699,
                    0.3596,
                    0.34,
                    0.3397,
                    0.3331,
                    0.3318,
                    0.3307,
                    0.3289,
                    0.3218,
                    0.3175,
                    0.313,
                    0.3111,
                    0.3096,
                    0.3081,
                    0.3079,
                    0.3073,
                    0.3023,
                    0.3009,
                    0.3009,
                    0.3001
                ],
                "neuron_alignment_indices": [
                    761,
                    1,
                    428
                ],
                "neuron_alignment_values": [
                    0.116,
                    0.107,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    1,
                    354,
                    654
                ],
                "correlated_neurons_pearson": [
                    0.003,
                    0.002,
                    0.002
                ],
                "correlated_neurons_l1": [
                    0.003,
                    0.002,
                    0.002
                ],
                "correlated_features_indices": [
                    49874,
                    49909,
                    49885
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "yip",
                    " kindred",
                    " filib",
                    "raltar",
                    "ERSON",
                    " eminent",
                    " illum",
                    "urat",
                    "ppel",
                    " Samar"
                ],
                "neg_values": [
                    -0.737,
                    -0.726,
                    -0.658,
                    -0.651,
                    -0.641,
                    -0.635,
                    -0.633,
                    -0.627,
                    -0.619,
                    -0.618
                ],
                "pos_str": [
                    "pedia",
                    "inator",
                    "report",
                    "dash",
                    " Report",
                    " stripe",
                    "meter",
                    " Alley",
                    "amboo",
                    "Report"
                ],
                "pos_values": [
                    0.805,
                    0.767,
                    0.742,
                    0.726,
                    0.721,
                    0.716,
                    0.701,
                    0.693,
                    0.682,
                    0.676
                ],
                "frac_nonzero": 2e-05,
                "freq_hist_data_bar_heights": [
                    38,
                    13,
                    6,
                    3,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.58,
                    1.718,
                    2.855,
                    3.993,
                    5.131,
                    6.268,
                    7.406,
                    8.543,
                    9.681,
                    10.819,
                    11.956,
                    13.094,
                    14.231,
                    15.369,
                    16.507,
                    17.644,
                    18.782,
                    19.92,
                    21.057,
                    22.195,
                    23.332,
                    24.47,
                    25.608,
                    26.745,
                    27.883,
                    29.02,
                    30.158,
                    31.296,
                    32.433,
                    33.571,
                    34.709,
                    35.846,
                    36.984,
                    38.121,
                    39.259,
                    40.397,
                    41.534,
                    42.672,
                    43.809,
                    44.947,
                    46.085,
                    47.222,
                    48.36,
                    49.497,
                    50.635,
                    51.773,
                    52.91,
                    54.048,
                    55.186,
                    56.323
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    0,
                    2,
                    8,
                    11,
                    16,
                    24,
                    28,
                    56,
                    106,
                    160,
                    225,
                    354,
                    560,
                    816,
                    1040,
                    1448,
                    1890,
                    2327,
                    2712,
                    3076,
                    3493,
                    3690,
                    3788,
                    3848,
                    3611,
                    3261,
                    2822,
                    2403,
                    2081,
                    1666,
                    1292,
                    952,
                    713,
                    561,
                    401,
                    251,
                    197,
                    127,
                    85,
                    43,
                    40,
                    29,
                    22,
                    8,
                    3,
                    3,
                    4,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.721,
                    -0.69,
                    -0.66,
                    -0.629,
                    -0.598,
                    -0.567,
                    -0.536,
                    -0.505,
                    -0.475,
                    -0.444,
                    -0.413,
                    -0.382,
                    -0.351,
                    -0.32,
                    -0.29,
                    -0.259,
                    -0.228,
                    -0.197,
                    -0.166,
                    -0.135,
                    -0.105,
                    -0.074,
                    -0.043,
                    -0.012,
                    0.019,
                    0.05,
                    0.08,
                    0.111,
                    0.142,
                    0.173,
                    0.204,
                    0.235,
                    0.265,
                    0.296,
                    0.327,
                    0.358,
                    0.389,
                    0.42,
                    0.45,
                    0.481,
                    0.512,
                    0.543,
                    0.574,
                    0.605,
                    0.635,
                    0.666,
                    0.697,
                    0.728,
                    0.759,
                    0.79
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to education or teaching roles",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " words related to education or teaching",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyghc6jdd3ha10exqkbepgd6",
                        "tokens": [
                            " The",
                            " Ble",
                            "acher",
                            " Report",
                            ",",
                            " The",
                            " New",
                            " York",
                            " Daily",
                            " News",
                            ",",
                            " and",
                            " The",
                            " Daily",
                            " Mail",
                            " (",
                            "which",
                            " you",
                            " could",
                            " call",
                            " the",
                            " R",
                            "umblr",
                            " of",
                            " newspapers",
                            " in",
                            " the",
                            " sense",
                            " that",
                            " it",
                            " is",
                            " ill",
                            "-",
                            "con",
                            "ceived",
                            ",",
                            " unnecessarily",
                            " antagon",
                            "istic",
                            ",",
                            " lowest",
                            " common",
                            "-",
                            "den",
                            "omin",
                            "ator",
                            "-",
                            "app",
                            "ealing",
                            ",",
                            " and",
                            " of",
                            " question",
                            "ably",
                            " ver",
                            "acity",
                            ").",
                            "\n",
                            "\n",
                            "The",
                            " attention",
                            " attracted",
                            " a",
                            " number",
                            " of",
                            " casual",
                            " warrior",
                            " hop",
                            "ef",
                            "uls",
                            ",",
                            " who",
                            " signed",
                            " up",
                            " for",
                            " the",
                            " chance",
                            " to",
                            " be",
                            " given",
                            " access",
                            " to",
                            " a",
                            " beta",
                            " version",
                            " of",
                            " the",
                            " app",
                            " on",
                            " the",
                            " R",
                            "umblr",
                            " site",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "More",
                            " than",
                            " 78",
                            ",",
                            "000",
                            " people",
                            " have",
                            " signed",
                            " up",
                            " for",
                            " beta",
                            " access",
                            ",",
                            " an",
                            " email",
                            " sent",
                            " out",
                            " to",
                            " the",
                            " lucky",
                            " early",
                            "-",
                            "bird",
                            " b",
                            "raw",
                            "lers",
                            " showed",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " The"
                        ],
                        "dataIndex": null,
                        "index": "49874",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.892,
                        "maxValueTokenIndex": 2,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            56.892,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:37:06.051Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 56.892,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghc6jfd3hu10exhp4l6h2u",
                        "tokens": [
                            " The",
                            " Ble",
                            "acher",
                            " Report",
                            ",",
                            " The",
                            " New",
                            " York",
                            " Daily",
                            " News",
                            ",",
                            " and",
                            " The",
                            " Daily",
                            " Mail",
                            " (",
                            "which",
                            " you",
                            " could",
                            " call",
                            " the",
                            " R",
                            "umblr",
                            " of",
                            " newspapers",
                            " in",
                            " the",
                            " sense",
                            " that",
                            " it",
                            " is",
                            " ill",
                            "-",
                            "con",
                            "ceived",
                            ",",
                            " unnecessarily",
                            " antagon",
                            "istic",
                            ",",
                            " lowest",
                            " common",
                            "-",
                            "den",
                            "omin",
                            "ator",
                            "-",
                            "app",
                            "ealing",
                            ",",
                            " and",
                            " of",
                            " question",
                            "ably",
                            " ver",
                            "acity",
                            ").",
                            "\n",
                            "\n",
                            "The",
                            " attention",
                            " attracted",
                            " a",
                            " number",
                            " of",
                            " casual",
                            " warrior",
                            " hop",
                            "ef",
                            "uls",
                            ",",
                            " who",
                            " signed",
                            " up",
                            " for",
                            " the",
                            " chance",
                            " to",
                            " be",
                            " given",
                            " access",
                            " to",
                            " a",
                            " beta",
                            " version",
                            " of",
                            " the",
                            " app",
                            " on",
                            " the",
                            " R",
                            "umblr",
                            " site",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "More",
                            " than",
                            " 78",
                            ",",
                            "000",
                            " people",
                            " have",
                            " signed",
                            " up",
                            " for",
                            " beta",
                            " access",
                            ",",
                            " an",
                            " email",
                            " sent",
                            " out",
                            " to",
                            " the",
                            " lucky",
                            " early",
                            "-",
                            "bird",
                            " b",
                            "raw",
                            "lers",
                            " showed",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " The"
                        ],
                        "dataIndex": null,
                        "index": "49874",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 56.892,
                        "maxValueTokenIndex": 2,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            56.892,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:37:06.051Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 45.514,
                        "binMax": 56.892,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyghc6jdd3hb10exxtpyvve1",
                        "tokens": [
                            "anners",
                            ":",
                            "\n",
                            "\n",
                            "S",
                            "ere",
                            "ph",
                            "im",
                            " (",
                            "h",
                            "alo",
                            " and",
                            " wings",
                            " of",
                            " fire",
                            ")",
                            "\n",
                            "\n",
                            "C",
                            "her",
                            "ub",
                            "im",
                            " (",
                            "h",
                            "alo",
                            " of",
                            " light",
                            " and",
                            " feat",
                            "hered",
                            " wings",
                            ")",
                            "\n",
                            "\n",
                            "Th",
                            "rone",
                            " (",
                            "h",
                            "alo",
                            " and",
                            " wings",
                            " of",
                            " gold",
                            ")",
                            "\n",
                            "\n",
                            "Pro",
                            "gen",
                            "y",
                            " -",
                            " Half",
                            "-",
                            "dem",
                            "ons",
                            " from",
                            " one",
                            " of",
                            " seven",
                            " unique",
                            " sin",
                            " nature",
                            " sub",
                            "-",
                            "types",
                            ",",
                            " each",
                            " providing",
                            " different",
                            " abilities",
                            " and",
                            " hind",
                            "r",
                            "ances",
                            ".",
                            " Additionally",
                            ",",
                            " the",
                            " race",
                            " selects",
                            " from",
                            " a",
                            " variety",
                            " of",
                            " physical",
                            " characteristics",
                            ".",
                            " Sin",
                            " nature",
                            " traits",
                            ":",
                            "\n",
                            "\n",
                            "L",
                            "ust",
                            ":",
                            " P",
                            "her",
                            "om",
                            "ones",
                            " &",
                            " Err",
                            "atic",
                            "\n",
                            "\n",
                            "Gl",
                            "utton",
                            "y",
                            ":",
                            " B",
                            "inge",
                            " &",
                            " Comp",
                            "ulsive",
                            "\n",
                            "\n",
                            "G",
                            "reed",
                            ":",
                            " Drain",
                            " &",
                            " Tre",
                            "acher",
                            "ous",
                            "\n",
                            "\n",
                            "Sl",
                            "oth"
                        ],
                        "dataIndex": null,
                        "index": "49874",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.448,
                        "maxValueTokenIndex": 121,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.448,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:37:06.051Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 56.892,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "36359",
            "description": "references to individuals or roles related to teaching or education",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5328082005026402,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "36359",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:16:46.428Z",
                "maxActApprox": 19.797,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    36359,
                    41292,
                    96930,
                    48113,
                    15907,
                    30525,
                    87100,
                    62107,
                    68170,
                    92153,
                    59805,
                    77921,
                    92730,
                    78400,
                    69699,
                    91624,
                    76166,
                    90061,
                    84733,
                    91090,
                    73129,
                    57008,
                    19609,
                    32381,
                    26546
                ],
                "topkCosSimValues": [
                    1,
                    0.6354,
                    0.5301,
                    0.4668,
                    0.4146,
                    0.4004,
                    0.3923,
                    0.3901,
                    0.3897,
                    0.3891,
                    0.3698,
                    0.3569,
                    0.3408,
                    0.3371,
                    0.3345,
                    0.3275,
                    0.3263,
                    0.3261,
                    0.3223,
                    0.3207,
                    0.3207,
                    0.3196,
                    0.3185,
                    0.3161,
                    0.3139
                ],
                "neuron_alignment_indices": [
                    497,
                    41,
                    63
                ],
                "neuron_alignment_values": [
                    0.14,
                    0.1,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    41,
                    284,
                    229
                ],
                "correlated_neurons_pearson": [
                    0.008,
                    0.008,
                    0.007
                ],
                "correlated_neurons_l1": [
                    0.008,
                    0.008,
                    0.007
                ],
                "correlated_features_indices": [
                    36267,
                    36359,
                    36303
                ],
                "correlated_features_pearson": [
                    0.015,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.015,
                    0,
                    0
                ],
                "neg_str": [
                    "alogue",
                    " sailors",
                    " Thames",
                    "foundland",
                    " mates",
                    " Greenpeace",
                    " Australians",
                    " sailor",
                    " juices",
                    " Auckland"
                ],
                "neg_values": [
                    -0.636,
                    -0.625,
                    -0.605,
                    -0.594,
                    -0.59,
                    -0.579,
                    -0.567,
                    -0.56,
                    -0.56,
                    -0.556
                ],
                "pos_str": [
                    "ki",
                    "kie",
                    "hower",
                    "ski",
                    "sky",
                    "cius",
                    "gaard",
                    "cht",
                    "hon",
                    "hips"
                ],
                "pos_values": [
                    1.117,
                    1.067,
                    0.998,
                    0.987,
                    0.972,
                    0.926,
                    0.922,
                    0.917,
                    0.911,
                    0.908
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    15,
                    10,
                    7,
                    7,
                    6,
                    5,
                    5,
                    1,
                    1,
                    3,
                    3,
                    2,
                    2,
                    2,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    2,
                    1,
                    1,
                    0,
                    0,
                    1,
                    1,
                    2,
                    2,
                    1,
                    2,
                    2,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.212,
                    0.608,
                    1.003,
                    1.399,
                    1.795,
                    2.19,
                    2.586,
                    2.982,
                    3.377,
                    3.773,
                    4.169,
                    4.564,
                    4.96,
                    5.356,
                    5.751,
                    6.147,
                    6.543,
                    6.938,
                    7.334,
                    7.73,
                    8.125,
                    8.521,
                    8.916,
                    9.312,
                    9.708,
                    10.103,
                    10.499,
                    10.895,
                    11.29,
                    11.686,
                    12.082,
                    12.477,
                    12.873,
                    13.269,
                    13.664,
                    14.06,
                    14.456,
                    14.851,
                    15.247,
                    15.643,
                    16.038,
                    16.434,
                    16.83,
                    17.225,
                    17.621,
                    18.017,
                    18.412,
                    18.808,
                    19.204,
                    19.599
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    4,
                    13,
                    21,
                    31,
                    88,
                    151,
                    260,
                    428,
                    708,
                    1028,
                    1642,
                    2189,
                    2925,
                    3519,
                    3986,
                    4399,
                    4599,
                    4388,
                    4032,
                    3470,
                    2849,
                    2198,
                    1734,
                    1399,
                    1007,
                    787,
                    597,
                    444,
                    360,
                    263,
                    209,
                    154,
                    111,
                    74,
                    60,
                    35,
                    26,
                    16,
                    13,
                    11,
                    7,
                    6,
                    3,
                    5,
                    1,
                    2,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.619,
                    -0.584,
                    -0.549,
                    -0.514,
                    -0.479,
                    -0.444,
                    -0.409,
                    -0.373,
                    -0.338,
                    -0.303,
                    -0.268,
                    -0.233,
                    -0.198,
                    -0.163,
                    -0.128,
                    -0.093,
                    -0.058,
                    -0.023,
                    0.012,
                    0.047,
                    0.082,
                    0.117,
                    0.152,
                    0.188,
                    0.223,
                    0.258,
                    0.293,
                    0.328,
                    0.363,
                    0.398,
                    0.433,
                    0.468,
                    0.503,
                    0.538,
                    0.573,
                    0.608,
                    0.643,
                    0.678,
                    0.713,
                    0.748,
                    0.784,
                    0.819,
                    0.854,
                    0.889,
                    0.924,
                    0.959,
                    0.994,
                    1.029,
                    1.064,
                    1.099
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " references to individuals in positions of authority or influence, particularly in educational or political contexts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to individuals or roles related to teaching or education",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggm6ta2utf10exq9b7o7ca",
                        "tokens": [
                            " House",
                            ",",
                            " she",
                            " often",
                            " chooses",
                            " sed",
                            "ate",
                            " h",
                            "ues",
                            ",",
                            " such",
                            " as",
                            " white",
                            " or",
                            " black",
                            ".",
                            " She",
                            " likes",
                            " American",
                            " designers",
                            " like",
                            " Ralph",
                            " Lauren",
                            " and",
                            " Michael",
                            " K",
                            "ors",
                            ",",
                            " and",
                            " her",
                            " dresses",
                            " carry",
                            " steep",
                            " price",
                            " tags",
                            " ($",
                            "9",
                            ",",
                            "500",
                            " for",
                            " the",
                            " glitter",
                            "y",
                            " ensemble",
                            " she",
                            " wore",
                            " to",
                            " her",
                            " husband",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " speech",
                            " to",
                            " Congress",
                            " alone",
                            ".)",
                            "\n",
                            "\n",
                            "That",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " despite",
                            " some",
                            " designers",
                            " refusing",
                            " to",
                            " dress",
                            " the",
                            " First",
                            " Lady",
                            ".",
                            "\n",
                            "\n",
                            "Here",
                            " are",
                            " some",
                            " of",
                            " the",
                            " First",
                            " Lady",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " looks",
                            " since",
                            " assuming",
                            " the",
                            " role",
                            ":",
                            "\n",
                            "\n",
                            "In",
                            " Florida",
                            "\n",
                            "\n",
                            "The",
                            " First",
                            " Lady",
                            " often",
                            " chooses",
                            " vibrant",
                            " colors",
                            " when",
                            " she",
                            " travels",
                            " to",
                            " the",
                            " Tr",
                            "umps",
                            "\u00e2\u0122",
                            "\u013b",
                            " Palm",
                            " Beach",
                            " vacation",
                            " palace",
                            ".",
                            "\n",
                            "\n",
                            "Here",
                            " are",
                            " other",
                            " views",
                            " of",
                            " those",
                            " looks"
                        ],
                        "dataIndex": null,
                        "index": "36359",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 19.797,
                        "maxValueTokenIndex": 26,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.797,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:16:53.341Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 19.797,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggm6tc2utz10ex1uljwgf5",
                        "tokens": [
                            " House",
                            ",",
                            " she",
                            " often",
                            " chooses",
                            " sed",
                            "ate",
                            " h",
                            "ues",
                            ",",
                            " such",
                            " as",
                            " white",
                            " or",
                            " black",
                            ".",
                            " She",
                            " likes",
                            " American",
                            " designers",
                            " like",
                            " Ralph",
                            " Lauren",
                            " and",
                            " Michael",
                            " K",
                            "ors",
                            ",",
                            " and",
                            " her",
                            " dresses",
                            " carry",
                            " steep",
                            " price",
                            " tags",
                            " ($",
                            "9",
                            ",",
                            "500",
                            " for",
                            " the",
                            " glitter",
                            "y",
                            " ensemble",
                            " she",
                            " wore",
                            " to",
                            " her",
                            " husband",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " speech",
                            " to",
                            " Congress",
                            " alone",
                            ".)",
                            "\n",
                            "\n",
                            "That",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " despite",
                            " some",
                            " designers",
                            " refusing",
                            " to",
                            " dress",
                            " the",
                            " First",
                            " Lady",
                            ".",
                            "\n",
                            "\n",
                            "Here",
                            " are",
                            " some",
                            " of",
                            " the",
                            " First",
                            " Lady",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " looks",
                            " since",
                            " assuming",
                            " the",
                            " role",
                            ":",
                            "\n",
                            "\n",
                            "In",
                            " Florida",
                            "\n",
                            "\n",
                            "The",
                            " First",
                            " Lady",
                            " often",
                            " chooses",
                            " vibrant",
                            " colors",
                            " when",
                            " she",
                            " travels",
                            " to",
                            " the",
                            " Tr",
                            "umps",
                            "\u00e2\u0122",
                            "\u013b",
                            " Palm",
                            " Beach",
                            " vacation",
                            " palace",
                            ".",
                            "\n",
                            "\n",
                            "Here",
                            " are",
                            " other",
                            " views",
                            " of",
                            " those",
                            " looks"
                        ],
                        "dataIndex": null,
                        "index": "36359",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 19.797,
                        "maxValueTokenIndex": 26,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.797,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:16:53.341Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 15.838,
                        "binMax": 19.797,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggm6ta2utg10exa0hd8t7l",
                        "tokens": [
                            " Maria",
                            " Shar",
                            "ap",
                            "ova",
                            ",",
                            " and",
                            " Venus",
                            " Williams",
                            ".",
                            " It",
                            " also",
                            " signed",
                            " up",
                            " an",
                            " array",
                            " of",
                            " fashion",
                            " designers",
                            " and",
                            " models",
                            ",",
                            " including",
                            " Michael",
                            " K",
                            "ors",
                            ",",
                            " Diane",
                            " von",
                            " Fur",
                            "st",
                            "enberg",
                            ",",
                            " G",
                            "ise",
                            "le",
                            " B",
                            "\u00c3\u00bc",
                            "nd",
                            "chen",
                            ",",
                            " and",
                            " Kate",
                            " Moss",
                            ".",
                            "\n",
                            "\n",
                            "For",
                            "st",
                            "mann",
                            "'s",
                            " high",
                            "-",
                            "profile",
                            " deals",
                            " made",
                            " Emanuel",
                            " want",
                            " IM",
                            "G",
                            " more",
                            " than",
                            " ever",
                            ".",
                            " According",
                            " to",
                            " a",
                            " June",
                            " 2009",
                            " article",
                            " in",
                            " The",
                            " New",
                            " York",
                            " Times",
                            ",",
                            " he",
                            " had",
                            " been",
                            " \u00e2\u0122",
                            "\u013e",
                            "sp",
                            "ending",
                            " time",
                            "\u00e2\u0122",
                            "\u013f",
                            " with",
                            " For",
                            "st",
                            "mann",
                            " in",
                            " Los",
                            " Angeles",
                            " \u00e2\u0122",
                            "\u013e",
                            "on",
                            " the",
                            " golf",
                            " course",
                            " and",
                            " off",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " and",
                            " speculation",
                            " heated",
                            " up",
                            " again",
                            " that",
                            " somehow",
                            " IM",
                            "G",
                            " and",
                            " W",
                            "ME",
                            " would",
                            " be",
                            " combined",
                            ".",
                            " But",
                            " Emanuel",
                            " still",
                            " could",
                            " not",
                            " crack",
                            " For",
                            "st"
                        ],
                        "dataIndex": null,
                        "index": "36359",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 19.659,
                        "maxValueTokenIndex": 24,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.659,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:16:53.341Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 19.797,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "44019",
            "description": "terms related to teaching and instructional practices",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.530700103363398,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "44019",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:17:27.501Z",
                "maxActApprox": 49.577,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    44019,
                    11474,
                    47724,
                    6722,
                    24835,
                    46953,
                    46531,
                    14407,
                    22854,
                    7269,
                    44382,
                    8748,
                    12106,
                    11447,
                    8181,
                    47808,
                    28235,
                    14863,
                    46946,
                    40112,
                    34244,
                    5198,
                    37022,
                    45441,
                    36846
                ],
                "topkCosSimValues": [
                    1,
                    0.7285,
                    0.6854,
                    0.5715,
                    0.55,
                    0.5474,
                    0.524,
                    0.5065,
                    0.47,
                    0.4667,
                    0.4652,
                    0.4423,
                    0.4398,
                    0.4272,
                    0.4173,
                    0.4162,
                    0.413,
                    0.408,
                    0.3971,
                    0.3909,
                    0.3897,
                    0.3863,
                    0.3851,
                    0.3777,
                    0.377
                ],
                "neuron_alignment_indices": [
                    679,
                    224,
                    288
                ],
                "neuron_alignment_values": [
                    0.117,
                    0.101,
                    0.1
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    108,
                    350,
                    90
                ],
                "correlated_neurons_pearson": [
                    0.012,
                    0.011,
                    0.011
                ],
                "correlated_neurons_l1": [
                    0.012,
                    0.011,
                    0.011
                ],
                "correlated_features_indices": [
                    43981,
                    43963,
                    44043
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.002,
                    0.001
                ],
                "correlated_features_l1": [
                    0.005,
                    0.003,
                    0.002
                ],
                "neg_str": [
                    "tar",
                    "axy",
                    "CLUD",
                    " Launcher",
                    "00200000",
                    " snapping",
                    "vous",
                    "rals",
                    " Scotia",
                    "leans"
                ],
                "neg_values": [
                    -0.796,
                    -0.755,
                    -0.714,
                    -0.699,
                    -0.696,
                    -0.68,
                    -0.675,
                    -0.671,
                    -0.659,
                    -0.659
                ],
                "pos_str": [
                    " assistants",
                    "piece",
                    "method",
                    " Practices",
                    " materials",
                    "pieces",
                    "material",
                    " profession",
                    " curriculum",
                    "room"
                ],
                "pos_values": [
                    0.925,
                    0.844,
                    0.821,
                    0.817,
                    0.793,
                    0.786,
                    0.78,
                    0.773,
                    0.758,
                    0.755
                ],
                "frac_nonzero": 0.0001,
                "freq_hist_data_bar_heights": [
                    69,
                    41,
                    25,
                    27,
                    16,
                    8,
                    11,
                    16,
                    6,
                    6,
                    12,
                    9,
                    6,
                    4,
                    5,
                    2,
                    3,
                    6,
                    1,
                    0,
                    0,
                    3,
                    0,
                    1,
                    4,
                    3,
                    1,
                    2,
                    2,
                    1,
                    2,
                    3,
                    0,
                    3,
                    3,
                    1,
                    0,
                    0,
                    2,
                    1,
                    1,
                    3,
                    2,
                    3,
                    2,
                    0,
                    0,
                    1,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.496,
                    1.488,
                    2.479,
                    3.471,
                    4.462,
                    5.454,
                    6.445,
                    7.437,
                    8.428,
                    9.42,
                    10.411,
                    11.403,
                    12.395,
                    13.386,
                    14.378,
                    15.369,
                    16.361,
                    17.352,
                    18.344,
                    19.335,
                    20.327,
                    21.318,
                    22.31,
                    23.301,
                    24.293,
                    25.284,
                    26.276,
                    27.268,
                    28.259,
                    29.251,
                    30.242,
                    31.234,
                    32.225,
                    33.217,
                    34.208,
                    35.2,
                    36.191,
                    37.183,
                    38.174,
                    39.166,
                    40.157,
                    41.149,
                    42.14,
                    43.132,
                    44.124,
                    45.115,
                    46.107,
                    47.098,
                    48.09,
                    49.081
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    3,
                    5,
                    7,
                    7,
                    18,
                    24,
                    46,
                    77,
                    150,
                    213,
                    330,
                    480,
                    739,
                    1050,
                    1476,
                    1992,
                    2585,
                    3163,
                    3887,
                    4105,
                    4561,
                    4380,
                    4123,
                    3796,
                    3196,
                    2634,
                    2045,
                    1618,
                    1102,
                    778,
                    535,
                    351,
                    244,
                    177,
                    116,
                    73,
                    53,
                    43,
                    21,
                    16,
                    15,
                    7,
                    4,
                    5,
                    3,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.779,
                    -0.744,
                    -0.71,
                    -0.675,
                    -0.641,
                    -0.606,
                    -0.572,
                    -0.538,
                    -0.503,
                    -0.469,
                    -0.434,
                    -0.4,
                    -0.366,
                    -0.331,
                    -0.297,
                    -0.262,
                    -0.228,
                    -0.194,
                    -0.159,
                    -0.125,
                    -0.09,
                    -0.056,
                    -0.021,
                    0.013,
                    0.047,
                    0.082,
                    0.116,
                    0.151,
                    0.185,
                    0.219,
                    0.254,
                    0.288,
                    0.323,
                    0.357,
                    0.392,
                    0.426,
                    0.46,
                    0.495,
                    0.529,
                    0.564,
                    0.598,
                    0.632,
                    0.667,
                    0.701,
                    0.736,
                    0.77,
                    0.805,
                    0.839,
                    0.873,
                    0.908
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to teaching and instructional practices",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk6y32rg806i666ezn2absn",
                        "tokens": [
                            " progressive",
                            " planners",
                            ".",
                            "\n",
                            "\n",
                            "This",
                            " suggests",
                            " that",
                            " we",
                            " should",
                            " be",
                            " concerned",
                            " about",
                            " the",
                            " ideas",
                            " that",
                            " are",
                            " being",
                            " transmitted",
                            " by",
                            " the",
                            " dominant",
                            " institutions",
                            " in",
                            " the",
                            " United",
                            " States",
                            " \u2014",
                            " the",
                            " media",
                            ",",
                            " higher",
                            " education",
                            ",",
                            " and",
                            " the",
                            " teaching",
                            " profession",
                            ".",
                            " These",
                            " institutions",
                            " tend",
                            " to",
                            " impose",
                            " strong",
                            " conformity",
                            " to",
                            " the",
                            " progressive",
                            " narrative",
                            ",",
                            " which",
                            " treats",
                            " our",
                            " culture",
                            " as",
                            " creating",
                            " large",
                            " classes",
                            " of",
                            " victims",
                            " and",
                            " views",
                            " expert",
                            " social",
                            " engineering",
                            " as",
                            " the",
                            " right",
                            " approach",
                            " for",
                            " solving",
                            " problems",
                            ".",
                            " If",
                            " our",
                            " leading",
                            " cultural",
                            " institutions",
                            " are",
                            " thus",
                            " geared",
                            " toward",
                            " suppressing",
                            " cultural",
                            " intelligence",
                            ",",
                            " we",
                            " need",
                            " to",
                            " think",
                            " about",
                            " how",
                            " to",
                            " change",
                            " them",
                            ".",
                            "\n",
                            "\n",
                            "That",
                            " effort",
                            " could",
                            " begin",
                            " by",
                            " taking",
                            " account",
                            " of",
                            " several",
                            " recent",
                            " books",
                            " \u2014",
                            " all",
                            " published",
                            " in",
                            " this",
                            " decade",
                            " and",
                            " intended",
                            " more",
                            " or",
                            " less",
                            " for",
                            " a",
                            " general",
                            " audience",
                            " beyond",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "44019",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.577,
                        "maxValueTokenIndex": 36,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.577,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:17:34.564Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.577,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6y32rg807i666p00xnjou",
                        "tokens": [
                            "'s",
                            " research",
                            ".",
                            " When",
                            " Gale",
                            "azz",
                            "i",
                            " died",
                            " in",
                            " 17",
                            "75",
                            ",",
                            " Gal",
                            "v",
                            "ani",
                            " was",
                            " appointed",
                            " professor",
                            " and",
                            " lecturer",
                            " in",
                            " Gale",
                            "azz",
                            "i",
                            "'s",
                            " place",
                            ".",
                            "\n",
                            "\n",
                            "Gal",
                            "v",
                            "ani",
                            " moved",
                            " from",
                            " the",
                            " position",
                            " of",
                            " lecturer",
                            " of",
                            " surgery",
                            " to",
                            " theoretical",
                            " anatomy",
                            " and",
                            " obtained",
                            " an",
                            " appointment",
                            " at",
                            " the",
                            " Academy",
                            " of",
                            " Sciences",
                            " in",
                            " 17",
                            "76",
                            ".",
                            " His",
                            " new",
                            " appointment",
                            " consisted",
                            " of",
                            " the",
                            " practical",
                            " teaching",
                            " of",
                            " anatomy",
                            ",",
                            " which",
                            " was",
                            " conducted",
                            " by",
                            " human",
                            " dis",
                            "section",
                            " and",
                            " the",
                            " use",
                            " of",
                            " the",
                            " famous",
                            " anatomical",
                            " wax",
                            "es",
                            ".",
                            "\n",
                            "\n",
                            "As",
                            " a",
                            " \"",
                            "B",
                            "ened",
                            "ect",
                            "ine",
                            " member",
                            "\"",
                            " of",
                            " the",
                            " Academy",
                            " of",
                            " Sciences",
                            ",",
                            " Gal",
                            "v",
                            "ani",
                            " had",
                            " specific",
                            " responsibilities",
                            ".",
                            " His",
                            " main",
                            " responsibility",
                            " was",
                            " to",
                            " present",
                            " at",
                            " least",
                            " one",
                            " research",
                            " paper",
                            " every",
                            " year",
                            " at",
                            " the",
                            " Academy",
                            ",",
                            " which",
                            " Gal"
                        ],
                        "dataIndex": null,
                        "index": "44019",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 48.585,
                        "maxValueTokenIndex": 63,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.557,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            48.585,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:17:34.564Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.577,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6y32ug80ui6662l0lk4h4",
                        "tokens": [
                            " by",
                            " China",
                            " as",
                            " a",
                            " way",
                            " to",
                            " spread",
                            " global",
                            " influence",
                            ".",
                            " Des",
                            "cribed",
                            " by",
                            " one",
                            " official",
                            " in",
                            " Beijing",
                            " as",
                            " \"",
                            "part",
                            " of",
                            " China",
                            "'s",
                            " foreign",
                            " propaganda",
                            " strategy",
                            ",\"",
                            " the",
                            " instit",
                            "utes",
                            " have",
                            " drawn",
                            " anger",
                            " for",
                            " interfering",
                            " with",
                            " academic",
                            " freedoms",
                            ".",
                            "\n",
                            "\n",
                            "And",
                            " outside",
                            " subsidized",
                            " instruction",
                            ",",
                            " teaching",
                            " Chinese",
                            " has",
                            " been",
                            " a",
                            " tough",
                            " sell",
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " 2012",
                            ",",
                            " Mandarin",
                            " teacher",
                            " Li",
                            " Ye",
                            " secured",
                            " a",
                            " teaching",
                            " position",
                            " at",
                            " a",
                            " Beijing",
                            " college",
                            " \u2013",
                            " only",
                            " to",
                            " have",
                            " the",
                            " entire",
                            " department",
                            " cut",
                            " a",
                            " year",
                            " later",
                            ".",
                            " Then",
                            " he",
                            " took",
                            " work",
                            " at",
                            " Beijing",
                            " Language",
                            " and",
                            " Culture",
                            " University",
                            " Press",
                            ",",
                            " which",
                            " publishes",
                            " Chinese",
                            " textbooks",
                            ".",
                            " But",
                            " sales",
                            " \"",
                            "were",
                            " not",
                            " good",
                            ",\"",
                            " he",
                            " said",
                            ",",
                            " estimating",
                            " a",
                            " 10",
                            "-",
                            "per",
                            "-",
                            "cent",
                            " drop",
                            " in",
                            " recent",
                            " years",
                            ".",
                            "\n",
                            "\n",
                            "Meanwhile",
                            ",",
                            " Chinese"
                        ],
                        "dataIndex": null,
                        "index": "44019",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 47.031,
                        "maxValueTokenIndex": 65,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.238,
                            0,
                            44.217,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            47.031,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:17:34.564Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 39.662,
                        "binMax": 49.577,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}