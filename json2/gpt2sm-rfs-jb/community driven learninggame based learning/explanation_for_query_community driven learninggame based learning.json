{
    "request": {
        "releaseName": "gpt2sm-rfs-jb",
        "query": "community driven learninggame based learning"
    },
    "results": [
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "83399",
            "description": "discussions about motivation and collaborative learning in educational settings",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5843110432810223,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "83399",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:13:16.516Z",
                "maxActApprox": 7.105,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    83399,
                    45264,
                    37869,
                    26707,
                    49613,
                    65325,
                    83479,
                    40522,
                    1730,
                    71574,
                    26774,
                    15189,
                    8445,
                    76152,
                    4199,
                    30861,
                    4334,
                    24950,
                    67841,
                    85418,
                    45803,
                    95922,
                    44877,
                    81076,
                    83568
                ],
                "topkCosSimValues": [
                    1,
                    0.5039,
                    0.5011,
                    0.4889,
                    0.4861,
                    0.4776,
                    0.4733,
                    0.4715,
                    0.4699,
                    0.4595,
                    0.4582,
                    0.4582,
                    0.4557,
                    0.4449,
                    0.4443,
                    0.441,
                    0.4396,
                    0.4357,
                    0.4338,
                    0.4315,
                    0.427,
                    0.4257,
                    0.4253,
                    0.4252,
                    0.4244
                ],
                "neuron_alignment_indices": [
                    480,
                    192,
                    654
                ],
                "neuron_alignment_values": [
                    0.414,
                    0.107,
                    0.099
                ],
                "neuron_alignment_l1": [
                    0.021,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    480,
                    351,
                    266
                ],
                "correlated_neurons_pearson": [
                    0.057,
                    0.054,
                    0.045
                ],
                "correlated_neurons_l1": [
                    0.002,
                    0.045,
                    0.071
                ],
                "correlated_features_indices": [
                    83479,
                    83475,
                    83421
                ],
                "correlated_features_pearson": [
                    0.056,
                    0.007,
                    0.005
                ],
                "correlated_features_l1": [
                    0.059,
                    0.008,
                    0.005
                ],
                "neg_str": [
                    "\u00d9\u012c",
                    "Nev",
                    "north",
                    " Belg",
                    " 1961",
                    "warning",
                    " Coulter",
                    " outlawed",
                    "upt",
                    "ahon"
                ],
                "neg_values": [
                    -0.651,
                    -0.613,
                    -0.611,
                    -0.61,
                    -0.607,
                    -0.599,
                    -0.598,
                    -0.595,
                    -0.593,
                    -0.589
                ],
                "pos_str": [
                    " iter",
                    " collabor",
                    " feedback",
                    " workflow",
                    " deadlines",
                    " improv",
                    " collaborate",
                    " interact",
                    " timelines",
                    " creatively"
                ],
                "pos_values": [
                    0.908,
                    0.883,
                    0.869,
                    0.814,
                    0.785,
                    0.773,
                    0.769,
                    0.759,
                    0.759,
                    0.752
                ],
                "frac_nonzero": 0.006979999999999999,
                "freq_hist_data_bar_heights": [
                    2675,
                    2416,
                    2115,
                    1934,
                    1638,
                    1462,
                    1297,
                    1172,
                    995,
                    800,
                    746,
                    676,
                    542,
                    498,
                    460,
                    405,
                    330,
                    308,
                    214,
                    218,
                    152,
                    137,
                    116,
                    129,
                    74,
                    87,
                    52,
                    58,
                    45,
                    40,
                    30,
                    21,
                    18,
                    24,
                    13,
                    10,
                    8,
                    4,
                    5,
                    4,
                    3,
                    5,
                    5,
                    2,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.071,
                    0.213,
                    0.355,
                    0.497,
                    0.639,
                    0.782,
                    0.924,
                    1.066,
                    1.208,
                    1.35,
                    1.492,
                    1.634,
                    1.776,
                    1.918,
                    2.06,
                    2.203,
                    2.345,
                    2.487,
                    2.629,
                    2.771,
                    2.913,
                    3.055,
                    3.197,
                    3.339,
                    3.481,
                    3.623,
                    3.766,
                    3.908,
                    4.05,
                    4.192,
                    4.334,
                    4.476,
                    4.618,
                    4.76,
                    4.902,
                    5.044,
                    5.187,
                    5.329,
                    5.471,
                    5.613,
                    5.755,
                    5.897,
                    6.039,
                    6.181,
                    6.323,
                    6.465,
                    6.608,
                    6.75,
                    6.892,
                    7.034
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    9,
                    21,
                    27,
                    51,
                    86,
                    140,
                    246,
                    355,
                    577,
                    788,
                    1031,
                    1405,
                    1766,
                    2058,
                    2479,
                    2811,
                    3138,
                    3048,
                    3278,
                    3248,
                    3107,
                    3001,
                    2767,
                    2493,
                    2272,
                    1891,
                    1700,
                    1327,
                    1190,
                    946,
                    702,
                    594,
                    483,
                    340,
                    273,
                    179,
                    137,
                    102,
                    63,
                    45,
                    23,
                    28,
                    16,
                    5,
                    5,
                    2,
                    0,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.636,
                    -0.605,
                    -0.573,
                    -0.542,
                    -0.511,
                    -0.48,
                    -0.449,
                    -0.418,
                    -0.386,
                    -0.355,
                    -0.324,
                    -0.293,
                    -0.262,
                    -0.23,
                    -0.199,
                    -0.168,
                    -0.137,
                    -0.106,
                    -0.074,
                    -0.043,
                    -0.012,
                    0.019,
                    0.05,
                    0.082,
                    0.113,
                    0.144,
                    0.175,
                    0.206,
                    0.238,
                    0.269,
                    0.3,
                    0.331,
                    0.362,
                    0.394,
                    0.425,
                    0.456,
                    0.487,
                    0.518,
                    0.549,
                    0.581,
                    0.612,
                    0.643,
                    0.674,
                    0.705,
                    0.737,
                    0.768,
                    0.799,
                    0.83,
                    0.861,
                    0.893
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " concepts related to project management and effective teamwork",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "discussions about motivation and collaborative learning in educational settings",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygimqez2jaj10exclclhntq",
                        "tokens": [
                            "\u013f",
                            " grants",
                            " whose",
                            " informational",
                            " value",
                            " comes",
                            " from",
                            " (",
                            "a",
                            ")",
                            " following",
                            " through",
                            " on",
                            " initial",
                            " expressions",
                            " of",
                            " interest",
                            ";",
                            " (",
                            "b",
                            ")",
                            " signaling",
                            " our",
                            " further",
                            " interests",
                            ";",
                            " and",
                            " (",
                            "c",
                            ")",
                            " giving",
                            " us",
                            " opportunities",
                            " to",
                            " follow",
                            " up",
                            " over",
                            " time",
                            " and",
                            " learn",
                            " about",
                            " the",
                            " relevant",
                            " people",
                            " and",
                            " organizations",
                            " and",
                            " their",
                            " progress",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " a",
                            " few",
                            " comments",
                            " that",
                            " we",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " seem",
                            " to",
                            " place",
                            " much",
                            " value",
                            " on",
                            " \u00e2\u0122",
                            "\u013e",
                            "value",
                            " of",
                            " information",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " since",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " primarily",
                            " funding",
                            " direct",
                            " work",
                            " of",
                            " various",
                            " kinds",
                            " rather",
                            " than",
                            " research",
                            " projects",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ".",
                            " I",
                            " disagree",
                            " with",
                            " comments",
                            " along",
                            " these",
                            " lines",
                            ".",
                            " Our",
                            " work",
                            " is",
                            " a",
                            " research",
                            " project",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ",",
                            " and",
                            " funding",
                            " projects"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.105,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            3.344,
                            1.85,
                            3.61,
                            2.098,
                            2.933,
                            2.859,
                            2.916,
                            3.892,
                            4.399,
                            7.105,
                            4.183,
                            3.765,
                            2.972,
                            1.324,
                            0,
                            1.929,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.105,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygimqf22jb410exu9dxomnj",
                        "tokens": [
                            "\u013f",
                            " grants",
                            " whose",
                            " informational",
                            " value",
                            " comes",
                            " from",
                            " (",
                            "a",
                            ")",
                            " following",
                            " through",
                            " on",
                            " initial",
                            " expressions",
                            " of",
                            " interest",
                            ";",
                            " (",
                            "b",
                            ")",
                            " signaling",
                            " our",
                            " further",
                            " interests",
                            ";",
                            " and",
                            " (",
                            "c",
                            ")",
                            " giving",
                            " us",
                            " opportunities",
                            " to",
                            " follow",
                            " up",
                            " over",
                            " time",
                            " and",
                            " learn",
                            " about",
                            " the",
                            " relevant",
                            " people",
                            " and",
                            " organizations",
                            " and",
                            " their",
                            " progress",
                            ".",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " seen",
                            " a",
                            " few",
                            " comments",
                            " that",
                            " we",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " seem",
                            " to",
                            " place",
                            " much",
                            " value",
                            " on",
                            " \u00e2\u0122",
                            "\u013e",
                            "value",
                            " of",
                            " information",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " since",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "re",
                            " primarily",
                            " funding",
                            " direct",
                            " work",
                            " of",
                            " various",
                            " kinds",
                            " rather",
                            " than",
                            " research",
                            " projects",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ".",
                            " I",
                            " disagree",
                            " with",
                            " comments",
                            " along",
                            " these",
                            " lines",
                            ".",
                            " Our",
                            " work",
                            " is",
                            " a",
                            " research",
                            " project",
                            " aiming",
                            " to",
                            " identify",
                            " the",
                            " best",
                            " causes",
                            ",",
                            " and",
                            " funding",
                            " projects"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.105,
                        "maxValueTokenIndex": 40,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.725,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.495,
                            3.344,
                            1.85,
                            3.61,
                            2.098,
                            2.933,
                            2.859,
                            2.916,
                            3.892,
                            4.399,
                            7.105,
                            4.183,
                            3.765,
                            2.972,
                            1.324,
                            0,
                            1.929,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 5.684,
                        "binMax": 7.105,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygimqez2jak10ex3wiuo4gq",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "In",
                            " the",
                            " end",
                            ",",
                            " doing",
                            " it",
                            " yourself",
                            " is",
                            " great",
                            ",",
                            " but",
                            " it",
                            "'s",
                            " also",
                            " good",
                            " to",
                            " know",
                            " when",
                            " a",
                            " project",
                            " is",
                            " over",
                            " your",
                            " head",
                            " and",
                            " it",
                            "'s",
                            " time",
                            " to",
                            " call",
                            " someone",
                            " else",
                            ".",
                            " In",
                            " addition",
                            ",",
                            " sometimes",
                            " it",
                            " actually",
                            " is",
                            " better",
                            " to",
                            " replace",
                            " your",
                            " gear",
                            " instead",
                            " of",
                            " fix",
                            " it",
                            ",",
                            " so",
                            " make",
                            " sure",
                            " you",
                            " aren",
                            "'t",
                            " on",
                            " a",
                            " fool",
                            "'s",
                            " err",
                            "and",
                            " trying",
                            " to",
                            " fix",
                            " a",
                            " gadget",
                            " that",
                            "'s",
                            " just",
                            " reached",
                            " its",
                            " time",
                            " to",
                            " die",
                            ".",
                            " Got",
                            " your",
                            " own",
                            " favorite",
                            " repair",
                            " project",
                            " that",
                            " you",
                            " did",
                            " on",
                            " your",
                            " own",
                            ",",
                            " or",
                            " a",
                            " skill",
                            " any",
                            " DIY",
                            "er",
                            " should",
                            " know",
                            " how",
                            " to",
                            " do",
                            "?",
                            " Share",
                            " it",
                            " with",
                            " us",
                            " in",
                            " the",
                            " comments",
                            ".",
                            "<|endoftext|>",
                            "So",
                            " i",
                            " opened",
                            " up",
                            " my",
                            " gift",
                            " that",
                            " came",
                            " earlier",
                            " on",
                            " tonight",
                            ".",
                            " The",
                            " post"
                        ],
                        "dataIndex": null,
                        "index": "83399",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 6.744,
                        "maxValueTokenIndex": 20,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.37,
                            1.73,
                            6.744,
                            4.1,
                            0.725,
                            2.35,
                            1.713,
                            0.702,
                            0.523,
                            0.642,
                            2.552,
                            1.152,
                            1.972,
                            2.65,
                            1.368,
                            1.601,
                            0.519,
                            0,
                            0,
                            0,
                            0,
                            0.865,
                            0,
                            0,
                            0,
                            0,
                            0.551,
                            0,
                            0.336,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.089,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:13:17.978Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.105,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "67437",
            "description": " actions associated with sharing, learning, and creating",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.554078221321106,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "67437",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:55:57.104Z",
                "maxActApprox": 16.775,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    67437,
                    20344,
                    82960,
                    51723,
                    201,
                    30390,
                    66426,
                    34190,
                    2922,
                    72289,
                    53029,
                    66794,
                    94072,
                    32648,
                    3113,
                    10428,
                    53797,
                    91010,
                    41901,
                    93241,
                    16621,
                    65571,
                    91347,
                    46610,
                    68613
                ],
                "topkCosSimValues": [
                    1,
                    0.4554,
                    0.4545,
                    0.4386,
                    0.4101,
                    0.3909,
                    0.3885,
                    0.3818,
                    0.378,
                    0.3769,
                    0.376,
                    0.3759,
                    0.3638,
                    0.3622,
                    0.347,
                    0.3453,
                    0.3425,
                    0.3371,
                    0.3369,
                    0.3363,
                    0.3321,
                    0.3317,
                    0.3299,
                    0.3297,
                    0.3282
                ],
                "neuron_alignment_indices": [
                    602,
                    500,
                    570
                ],
                "neuron_alignment_values": [
                    0.099,
                    0.093,
                    0.09
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    604,
                    738,
                    25
                ],
                "correlated_neurons_pearson": [
                    0.026,
                    0.026,
                    0.023
                ],
                "correlated_neurons_l1": [
                    0.023,
                    0.023,
                    0.021
                ],
                "correlated_features_indices": [
                    67317,
                    67332,
                    67335
                ],
                "correlated_features_pearson": [
                    0.007,
                    0.005,
                    0.002
                ],
                "correlated_features_l1": [
                    0.008,
                    0.005,
                    0.002
                ],
                "neg_str": [
                    " mishand",
                    " Historically",
                    "\u00e9\u00be\u012f\u00e5\u00a5\u0133\u00e5\u00a3\u00ab",
                    "COMPLE",
                    "currently",
                    "urnal",
                    "abama",
                    "\u0123\u0138",
                    "Eastern",
                    "ablished"
                ],
                "neg_values": [
                    -0.623,
                    -0.622,
                    -0.592,
                    -0.588,
                    -0.582,
                    -0.579,
                    -0.576,
                    -0.575,
                    -0.57,
                    -0.569
                ],
                "pos_str": [
                    " yourself",
                    " yourselves",
                    " yours",
                    "anooga",
                    " your",
                    " Yourself",
                    " ya",
                    "!'",
                    " whatever",
                    "oice"
                ],
                "pos_values": [
                    1.079,
                    0.921,
                    0.898,
                    0.798,
                    0.775,
                    0.752,
                    0.751,
                    0.742,
                    0.723,
                    0.721
                ],
                "frac_nonzero": 0.00094,
                "freq_hist_data_bar_heights": [
                    628,
                    432,
                    367,
                    300,
                    227,
                    182,
                    123,
                    110,
                    97,
                    78,
                    71,
                    50,
                    42,
                    39,
                    22,
                    29,
                    23,
                    19,
                    18,
                    13,
                    10,
                    10,
                    8,
                    7,
                    2,
                    7,
                    3,
                    4,
                    3,
                    0,
                    0,
                    1,
                    1,
                    1,
                    3,
                    2,
                    0,
                    2,
                    2,
                    0,
                    0,
                    1,
                    1,
                    0,
                    2,
                    0,
                    2,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.168,
                    0.504,
                    0.839,
                    1.175,
                    1.51,
                    1.846,
                    2.181,
                    2.517,
                    2.852,
                    3.188,
                    3.523,
                    3.859,
                    4.194,
                    4.53,
                    4.865,
                    5.201,
                    5.536,
                    5.872,
                    6.207,
                    6.542,
                    6.878,
                    7.213,
                    7.549,
                    7.884,
                    8.22,
                    8.555,
                    8.891,
                    9.226,
                    9.562,
                    9.897,
                    10.233,
                    10.568,
                    10.904,
                    11.239,
                    11.575,
                    11.91,
                    12.246,
                    12.581,
                    12.917,
                    13.252,
                    13.588,
                    13.923,
                    14.259,
                    14.594,
                    14.93,
                    15.265,
                    15.6,
                    15.936,
                    16.271,
                    16.607
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    8,
                    19,
                    18,
                    41,
                    87,
                    156,
                    290,
                    426,
                    647,
                    1098,
                    1493,
                    2095,
                    2523,
                    3182,
                    3691,
                    4000,
                    4423,
                    4377,
                    4098,
                    3841,
                    3321,
                    2787,
                    2187,
                    1700,
                    1204,
                    826,
                    598,
                    374,
                    270,
                    165,
                    123,
                    66,
                    43,
                    23,
                    20,
                    10,
                    5,
                    6,
                    5,
                    3,
                    2,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.606,
                    -0.572,
                    -0.537,
                    -0.503,
                    -0.469,
                    -0.435,
                    -0.401,
                    -0.367,
                    -0.333,
                    -0.299,
                    -0.265,
                    -0.231,
                    -0.197,
                    -0.163,
                    -0.129,
                    -0.095,
                    -0.061,
                    -0.027,
                    0.007,
                    0.041,
                    0.075,
                    0.109,
                    0.143,
                    0.177,
                    0.211,
                    0.245,
                    0.28,
                    0.314,
                    0.348,
                    0.382,
                    0.416,
                    0.45,
                    0.484,
                    0.518,
                    0.552,
                    0.586,
                    0.62,
                    0.654,
                    0.688,
                    0.722,
                    0.756,
                    0.79,
                    0.824,
                    0.858,
                    0.892,
                    0.926,
                    0.96,
                    0.994,
                    1.028,
                    1.062
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " actions associated with sharing, learning, and creating",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "actions related to sharing and engaging with content",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi0kzjqfos10ex9oe2q0k7",
                        "tokens": [
                            " Rel",
                            "ish",
                            " it",
                            ",",
                            " taste",
                            " it",
                            ",",
                            " roll",
                            " it",
                            " round",
                            " your",
                            " tongue",
                            " and",
                            " chew",
                            " it",
                            " over",
                            ",",
                            " because",
                            " these",
                            " moments",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " come",
                            " around",
                            " that",
                            " often",
                            ".",
                            " Then",
                            " think",
                            " back",
                            " to",
                            " February",
                            " or",
                            " March",
                            " last",
                            " year",
                            " and",
                            " tell",
                            " me",
                            " you",
                            " believed",
                            " that",
                            " was",
                            " possible",
                            ".",
                            " Be",
                            " honest",
                            ".",
                            "\n",
                            "\n",
                            "Yet",
                            " our",
                            " und",
                            "oubted",
                            " achievements",
                            " this",
                            " season",
                            " have",
                            " been",
                            " t",
                            "inged",
                            " with",
                            " regret",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " realistic",
                            " rather",
                            " than",
                            " greedy",
                            " to",
                            " say",
                            " we",
                            " could",
                            " have",
                            " done",
                            " so",
                            " much",
                            " more",
                            ".",
                            " Our",
                            " wo",
                            "eful",
                            " lack",
                            " of",
                            " firepower",
                            " up",
                            " front",
                            " has",
                            " been",
                            " the",
                            " main",
                            " problem",
                            " \u2013",
                            " the",
                            " strikers",
                            " have",
                            " been",
                            " downright",
                            " dreadful",
                            " for",
                            " much",
                            " of",
                            " the",
                            " time",
                            ".",
                            " Cou",
                            "pled",
                            " with",
                            " regular",
                            " disappearing",
                            " acts",
                            " from",
                            " our",
                            " defenders",
                            " and",
                            " keeper",
                            " (",
                            "where",
                            " the",
                            " hell",
                            " did",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "67437",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.775,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            16.775,
                            3.684,
                            1.34,
                            13.908,
                            2.604,
                            0,
                            0,
                            0,
                            0,
                            7.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:56:04.522Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 16.775,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi0kzjqfoy10exm0wixfaq",
                        "tokens": [
                            " Rel",
                            "ish",
                            " it",
                            ",",
                            " taste",
                            " it",
                            ",",
                            " roll",
                            " it",
                            " round",
                            " your",
                            " tongue",
                            " and",
                            " chew",
                            " it",
                            " over",
                            ",",
                            " because",
                            " these",
                            " moments",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " come",
                            " around",
                            " that",
                            " often",
                            ".",
                            " Then",
                            " think",
                            " back",
                            " to",
                            " February",
                            " or",
                            " March",
                            " last",
                            " year",
                            " and",
                            " tell",
                            " me",
                            " you",
                            " believed",
                            " that",
                            " was",
                            " possible",
                            ".",
                            " Be",
                            " honest",
                            ".",
                            "\n",
                            "\n",
                            "Yet",
                            " our",
                            " und",
                            "oubted",
                            " achievements",
                            " this",
                            " season",
                            " have",
                            " been",
                            " t",
                            "inged",
                            " with",
                            " regret",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " realistic",
                            " rather",
                            " than",
                            " greedy",
                            " to",
                            " say",
                            " we",
                            " could",
                            " have",
                            " done",
                            " so",
                            " much",
                            " more",
                            ".",
                            " Our",
                            " wo",
                            "eful",
                            " lack",
                            " of",
                            " firepower",
                            " up",
                            " front",
                            " has",
                            " been",
                            " the",
                            " main",
                            " problem",
                            " \u2013",
                            " the",
                            " strikers",
                            " have",
                            " been",
                            " downright",
                            " dreadful",
                            " for",
                            " much",
                            " of",
                            " the",
                            " time",
                            ".",
                            " Cou",
                            "pled",
                            " with",
                            " regular",
                            " disappearing",
                            " acts",
                            " from",
                            " our",
                            " defenders",
                            " and",
                            " keeper",
                            " (",
                            "where",
                            " the",
                            " hell",
                            " did",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "67437",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.775,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            16.775,
                            3.684,
                            1.34,
                            13.908,
                            2.604,
                            0,
                            0,
                            0,
                            0,
                            7.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:56:04.522Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 16.775,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi0kzlqfpe10exe96je5qi",
                        "tokens": [
                            " Rel",
                            "ish",
                            " it",
                            ",",
                            " taste",
                            " it",
                            ",",
                            " roll",
                            " it",
                            " round",
                            " your",
                            " tongue",
                            " and",
                            " chew",
                            " it",
                            " over",
                            ",",
                            " because",
                            " these",
                            " moments",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " come",
                            " around",
                            " that",
                            " often",
                            ".",
                            " Then",
                            " think",
                            " back",
                            " to",
                            " February",
                            " or",
                            " March",
                            " last",
                            " year",
                            " and",
                            " tell",
                            " me",
                            " you",
                            " believed",
                            " that",
                            " was",
                            " possible",
                            ".",
                            " Be",
                            " honest",
                            ".",
                            "\n",
                            "\n",
                            "Yet",
                            " our",
                            " und",
                            "oubted",
                            " achievements",
                            " this",
                            " season",
                            " have",
                            " been",
                            " t",
                            "inged",
                            " with",
                            " regret",
                            ".",
                            " It",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " realistic",
                            " rather",
                            " than",
                            " greedy",
                            " to",
                            " say",
                            " we",
                            " could",
                            " have",
                            " done",
                            " so",
                            " much",
                            " more",
                            ".",
                            " Our",
                            " wo",
                            "eful",
                            " lack",
                            " of",
                            " firepower",
                            " up",
                            " front",
                            " has",
                            " been",
                            " the",
                            " main",
                            " problem",
                            " \u2013",
                            " the",
                            " strikers",
                            " have",
                            " been",
                            " downright",
                            " dreadful",
                            " for",
                            " much",
                            " of",
                            " the",
                            " time",
                            ".",
                            " Cou",
                            "pled",
                            " with",
                            " regular",
                            " disappearing",
                            " acts",
                            " from",
                            " our",
                            " defenders",
                            " and",
                            " keeper",
                            " (",
                            "where",
                            " the",
                            " hell",
                            " did",
                            " they"
                        ],
                        "dataIndex": null,
                        "index": "67437",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.775,
                        "maxValueTokenIndex": 4,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            16.775,
                            3.684,
                            1.34,
                            13.908,
                            2.604,
                            0,
                            0,
                            0,
                            0,
                            7.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:56:04.522Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 13.42,
                        "binMax": 16.775,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "27759",
            "description": "discussions about community engagement and collaborative contributions",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5484978498819092,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "27759",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:05:14.770Z",
                "maxActApprox": 15.335,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    27759,
                    27724,
                    8879,
                    73985,
                    65908,
                    10213,
                    16772,
                    66535,
                    35717,
                    27703,
                    7479,
                    39698,
                    13327,
                    52487,
                    73554,
                    14749,
                    47652,
                    57292,
                    40721,
                    63735,
                    68385,
                    26120,
                    38341,
                    27911,
                    45044
                ],
                "topkCosSimValues": [
                    1,
                    0.5044,
                    0.4988,
                    0.4516,
                    0.4358,
                    0.4241,
                    0.4074,
                    0.4002,
                    0.3975,
                    0.3972,
                    0.3958,
                    0.3884,
                    0.3873,
                    0.383,
                    0.3813,
                    0.381,
                    0.3806,
                    0.3781,
                    0.3726,
                    0.3535,
                    0.3498,
                    0.3448,
                    0.3337,
                    0.3322,
                    0.3278
                ],
                "neuron_alignment_indices": [
                    459,
                    60,
                    588
                ],
                "neuron_alignment_values": [
                    0.126,
                    0.099,
                    0.097
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    588,
                    60,
                    510
                ],
                "correlated_neurons_pearson": [
                    0.024,
                    0.024,
                    0.022
                ],
                "correlated_neurons_l1": [
                    0.026,
                    0.023,
                    0.022
                ],
                "correlated_features_indices": [
                    27724,
                    27703,
                    27807
                ],
                "correlated_features_pearson": [
                    0.141,
                    0.037,
                    0.025
                ],
                "correlated_features_l1": [
                    0.141,
                    0.037,
                    0.025
                ],
                "neg_str": [
                    "phal",
                    "atories",
                    "vana",
                    "roots",
                    "imar",
                    "asers",
                    "prisingly",
                    "EStreamFrame",
                    "onest",
                    "reality"
                ],
                "neg_values": [
                    -0.702,
                    -0.699,
                    -0.661,
                    -0.64,
                    -0.637,
                    -0.637,
                    -0.623,
                    -0.619,
                    -0.613,
                    -0.609
                ],
                "pos_str": [
                    " please",
                    " Archdemon",
                    " bookmark",
                    "please",
                    " feature",
                    " deserves",
                    " improvement",
                    " featured",
                    "::::::::",
                    " inclusion"
                ],
                "pos_values": [
                    0.82,
                    0.809,
                    0.783,
                    0.737,
                    0.67,
                    0.656,
                    0.652,
                    0.647,
                    0.644,
                    0.644
                ],
                "frac_nonzero": 0.00123,
                "freq_hist_data_bar_heights": [
                    831,
                    594,
                    496,
                    377,
                    315,
                    228,
                    178,
                    152,
                    110,
                    93,
                    70,
                    69,
                    66,
                    35,
                    45,
                    40,
                    29,
                    20,
                    14,
                    20,
                    13,
                    11,
                    7,
                    10,
                    3,
                    7,
                    6,
                    5,
                    3,
                    1,
                    2,
                    0,
                    6,
                    2,
                    3,
                    2,
                    1,
                    0,
                    1,
                    1,
                    2,
                    1,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.154,
                    0.46,
                    0.767,
                    1.074,
                    1.38,
                    1.687,
                    1.994,
                    2.3,
                    2.607,
                    2.914,
                    3.221,
                    3.527,
                    3.834,
                    4.141,
                    4.447,
                    4.754,
                    5.061,
                    5.367,
                    5.674,
                    5.981,
                    6.288,
                    6.594,
                    6.901,
                    7.208,
                    7.514,
                    7.821,
                    8.128,
                    8.434,
                    8.741,
                    9.048,
                    9.354,
                    9.661,
                    9.968,
                    10.275,
                    10.581,
                    10.888,
                    11.195,
                    11.501,
                    11.808,
                    12.115,
                    12.421,
                    12.728,
                    13.035,
                    13.342,
                    13.648,
                    13.955,
                    14.262,
                    14.568,
                    14.875,
                    15.182
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    1,
                    6,
                    9,
                    12,
                    19,
                    26,
                    48,
                    84,
                    137,
                    225,
                    332,
                    495,
                    698,
                    1029,
                    1358,
                    1827,
                    2236,
                    2595,
                    3125,
                    3459,
                    3571,
                    3835,
                    3842,
                    3551,
                    3360,
                    2974,
                    2645,
                    2110,
                    1792,
                    1352,
                    1016,
                    749,
                    552,
                    407,
                    265,
                    186,
                    124,
                    71,
                    52,
                    33,
                    19,
                    12,
                    6,
                    5,
                    1,
                    0,
                    1,
                    1,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.687,
                    -0.657,
                    -0.626,
                    -0.596,
                    -0.565,
                    -0.535,
                    -0.504,
                    -0.474,
                    -0.443,
                    -0.413,
                    -0.383,
                    -0.352,
                    -0.322,
                    -0.291,
                    -0.261,
                    -0.23,
                    -0.2,
                    -0.169,
                    -0.139,
                    -0.109,
                    -0.078,
                    -0.048,
                    -0.017,
                    0.013,
                    0.044,
                    0.074,
                    0.105,
                    0.135,
                    0.165,
                    0.196,
                    0.226,
                    0.257,
                    0.287,
                    0.318,
                    0.348,
                    0.379,
                    0.409,
                    0.439,
                    0.47,
                    0.5,
                    0.531,
                    0.561,
                    0.592,
                    0.622,
                    0.652,
                    0.683,
                    0.713,
                    0.744,
                    0.774,
                    0.805
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases related to community engagement and shared experiences",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "discussions about community engagement and collaborative contributions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygg7c2owbvp10exqx8n6e4s",
                        "tokens": [
                            ",",
                            " we",
                            " threw",
                            " open",
                            " the",
                            " doors",
                            " for",
                            " any",
                            " tabletop",
                            " game",
                            " that",
                            " wanted",
                            " to",
                            " come",
                            " and",
                            " join",
                            " us",
                            "!",
                            " We",
                            " got",
                            " a",
                            " great",
                            " response",
                            ",",
                            " and",
                            " wound",
                            " up",
                            " running",
                            " tables",
                            " of",
                            " D",
                            "&",
                            "D",
                            ",",
                            " Savage",
                            " Worlds",
                            ",",
                            " Dread",
                            ",",
                            " Shadow",
                            "run",
                            ",",
                            " World",
                            " of",
                            " Darkness",
                            ",",
                            " and",
                            " more",
                            ".",
                            " Our",
                            " goal",
                            " is",
                            " to",
                            " add",
                            " more",
                            " variety",
                            " every",
                            " year",
                            ",",
                            " so",
                            " if",
                            " you",
                            " have",
                            " a",
                            " game",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " like",
                            " to",
                            " run",
                            " at",
                            " some",
                            " point",
                            ",",
                            " let",
                            " us",
                            " know",
                            "!",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " be",
                            " back",
                            " at",
                            " the",
                            " beautiful",
                            " Mont",
                            "reat",
                            " Convention",
                            " Center",
                            " again",
                            " this",
                            " year",
                            ",",
                            " from",
                            " October",
                            " 19",
                            "-",
                            "21",
                            ".",
                            " Tickets",
                            " will",
                            " go",
                            " on",
                            " sale",
                            " Tuesday",
                            ",",
                            " May",
                            " 29",
                            "th",
                            " for",
                            " the",
                            " bargain",
                            " price",
                            " of",
                            " $",
                            "35",
                            " for",
                            " the",
                            " weekend",
                            ".",
                            " Plus"
                        ],
                        "dataIndex": null,
                        "index": "27759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.335,
                        "maxValueTokenIndex": 65,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.836,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.564,
                            5.806,
                            6.091,
                            15.335,
                            0,
                            0,
                            3.08,
                            10.016,
                            8.717,
                            5.76,
                            4.11,
                            2.736,
                            7.553,
                            2.681,
                            1.248,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:05:20.318Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.335,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygg7c2mwbv810exhzr9a1ci",
                        "tokens": [
                            ",",
                            " we",
                            " threw",
                            " open",
                            " the",
                            " doors",
                            " for",
                            " any",
                            " tabletop",
                            " game",
                            " that",
                            " wanted",
                            " to",
                            " come",
                            " and",
                            " join",
                            " us",
                            "!",
                            " We",
                            " got",
                            " a",
                            " great",
                            " response",
                            ",",
                            " and",
                            " wound",
                            " up",
                            " running",
                            " tables",
                            " of",
                            " D",
                            "&",
                            "D",
                            ",",
                            " Savage",
                            " Worlds",
                            ",",
                            " Dread",
                            ",",
                            " Shadow",
                            "run",
                            ",",
                            " World",
                            " of",
                            " Darkness",
                            ",",
                            " and",
                            " more",
                            ".",
                            " Our",
                            " goal",
                            " is",
                            " to",
                            " add",
                            " more",
                            " variety",
                            " every",
                            " year",
                            ",",
                            " so",
                            " if",
                            " you",
                            " have",
                            " a",
                            " game",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " like",
                            " to",
                            " run",
                            " at",
                            " some",
                            " point",
                            ",",
                            " let",
                            " us",
                            " know",
                            "!",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " be",
                            " back",
                            " at",
                            " the",
                            " beautiful",
                            " Mont",
                            "reat",
                            " Convention",
                            " Center",
                            " again",
                            " this",
                            " year",
                            ",",
                            " from",
                            " October",
                            " 19",
                            "-",
                            "21",
                            ".",
                            " Tickets",
                            " will",
                            " go",
                            " on",
                            " sale",
                            " Tuesday",
                            ",",
                            " May",
                            " 29",
                            "th",
                            " for",
                            " the",
                            " bargain",
                            " price",
                            " of",
                            " $",
                            "35",
                            " for",
                            " the",
                            " weekend",
                            ".",
                            " Plus"
                        ],
                        "dataIndex": null,
                        "index": "27759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.335,
                        "maxValueTokenIndex": 65,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.836,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.564,
                            5.806,
                            6.091,
                            15.335,
                            0,
                            0,
                            3.08,
                            10.016,
                            8.717,
                            5.76,
                            4.11,
                            2.736,
                            7.553,
                            2.681,
                            1.248,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:05:20.318Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 15.335,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygg7c2owbvs10exiuguw95a",
                        "tokens": [
                            ",",
                            " we",
                            " threw",
                            " open",
                            " the",
                            " doors",
                            " for",
                            " any",
                            " tabletop",
                            " game",
                            " that",
                            " wanted",
                            " to",
                            " come",
                            " and",
                            " join",
                            " us",
                            "!",
                            " We",
                            " got",
                            " a",
                            " great",
                            " response",
                            ",",
                            " and",
                            " wound",
                            " up",
                            " running",
                            " tables",
                            " of",
                            " D",
                            "&",
                            "D",
                            ",",
                            " Savage",
                            " Worlds",
                            ",",
                            " Dread",
                            ",",
                            " Shadow",
                            "run",
                            ",",
                            " World",
                            " of",
                            " Darkness",
                            ",",
                            " and",
                            " more",
                            ".",
                            " Our",
                            " goal",
                            " is",
                            " to",
                            " add",
                            " more",
                            " variety",
                            " every",
                            " year",
                            ",",
                            " so",
                            " if",
                            " you",
                            " have",
                            " a",
                            " game",
                            " you",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " like",
                            " to",
                            " run",
                            " at",
                            " some",
                            " point",
                            ",",
                            " let",
                            " us",
                            " know",
                            "!",
                            "\n",
                            "\n",
                            "We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ll",
                            " be",
                            " back",
                            " at",
                            " the",
                            " beautiful",
                            " Mont",
                            "reat",
                            " Convention",
                            " Center",
                            " again",
                            " this",
                            " year",
                            ",",
                            " from",
                            " October",
                            " 19",
                            "-",
                            "21",
                            ".",
                            " Tickets",
                            " will",
                            " go",
                            " on",
                            " sale",
                            " Tuesday",
                            ",",
                            " May",
                            " 29",
                            "th",
                            " for",
                            " the",
                            " bargain",
                            " price",
                            " of",
                            " $",
                            "35",
                            " for",
                            " the",
                            " weekend",
                            ".",
                            " Plus"
                        ],
                        "dataIndex": null,
                        "index": "27759",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 15.335,
                        "maxValueTokenIndex": 65,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.836,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.564,
                            5.806,
                            6.091,
                            15.335,
                            0,
                            0,
                            3.08,
                            10.016,
                            8.717,
                            5.76,
                            4.11,
                            2.736,
                            7.553,
                            2.681,
                            1.248,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:05:20.318Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 12.268,
                        "binMax": 15.335,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "13957",
            "description": "discussions around community engagement and shared experiences",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5476313829421997,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "13957",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:45:24.414Z",
                "maxActApprox": 8.67,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    13957,
                    44976,
                    53445,
                    13735,
                    88973,
                    81612,
                    82087,
                    25348,
                    58210,
                    70808,
                    36307,
                    8765,
                    17278,
                    10459,
                    43341,
                    92515,
                    34947,
                    19260,
                    66198,
                    27096,
                    74367,
                    76745,
                    97736,
                    70016,
                    71300
                ],
                "topkCosSimValues": [
                    1,
                    0.4884,
                    0.4883,
                    0.4695,
                    0.4674,
                    0.4667,
                    0.4617,
                    0.4611,
                    0.4579,
                    0.4511,
                    0.4508,
                    0.4459,
                    0.4442,
                    0.4328,
                    0.432,
                    0.4315,
                    0.4282,
                    0.4271,
                    0.4256,
                    0.4251,
                    0.4251,
                    0.4245,
                    0.4242,
                    0.4213,
                    0.4207
                ],
                "neuron_alignment_indices": [
                    87,
                    756,
                    370
                ],
                "neuron_alignment_values": [
                    0.35,
                    0.097,
                    0.08
                ],
                "neuron_alignment_l1": [
                    0.018,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    87,
                    756,
                    393
                ],
                "correlated_neurons_pearson": [
                    0.052,
                    0.032,
                    0.025
                ],
                "correlated_neurons_l1": [
                    -0.008,
                    -0.012,
                    0.049
                ],
                "correlated_features_indices": [
                    13983,
                    13974,
                    13955
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.007,
                    0.004,
                    0.004
                ],
                "neg_str": [
                    " BASE",
                    "icide",
                    " tether",
                    "inventoryQuantity",
                    "aunder",
                    " starve",
                    " destroyer",
                    "AFP",
                    " ILCS",
                    "morrow"
                ],
                "neg_values": [
                    -0.649,
                    -0.641,
                    -0.605,
                    -0.592,
                    -0.589,
                    -0.587,
                    -0.582,
                    -0.579,
                    -0.578,
                    -0.576
                ],
                "pos_str": [
                    " respondents",
                    " varied",
                    " responses",
                    " testim",
                    " unanimous",
                    " insightful",
                    " informative",
                    " answered",
                    " queries",
                    " respondent"
                ],
                "pos_values": [
                    1.007,
                    0.908,
                    0.851,
                    0.828,
                    0.824,
                    0.787,
                    0.772,
                    0.772,
                    0.751,
                    0.747
                ],
                "frac_nonzero": 0.00347,
                "freq_hist_data_bar_heights": [
                    1737,
                    1431,
                    1249,
                    1068,
                    976,
                    725,
                    654,
                    535,
                    429,
                    364,
                    287,
                    275,
                    211,
                    173,
                    142,
                    94,
                    95,
                    75,
                    74,
                    53,
                    45,
                    32,
                    41,
                    33,
                    14,
                    21,
                    18,
                    14,
                    10,
                    9,
                    5,
                    7,
                    6,
                    1,
                    6,
                    3,
                    4,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.087,
                    0.26,
                    0.434,
                    0.607,
                    0.78,
                    0.954,
                    1.127,
                    1.3,
                    1.474,
                    1.647,
                    1.821,
                    1.994,
                    2.167,
                    2.341,
                    2.514,
                    2.688,
                    2.861,
                    3.034,
                    3.208,
                    3.381,
                    3.555,
                    3.728,
                    3.901,
                    4.075,
                    4.248,
                    4.421,
                    4.595,
                    4.768,
                    4.942,
                    5.115,
                    5.288,
                    5.462,
                    5.635,
                    5.809,
                    5.982,
                    6.155,
                    6.329,
                    6.502,
                    6.676,
                    6.849,
                    7.022,
                    7.196,
                    7.369,
                    7.542,
                    7.716,
                    7.889,
                    8.063,
                    8.236,
                    8.409,
                    8.583
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    4,
                    8,
                    14,
                    17,
                    35,
                    75,
                    128,
                    227,
                    378,
                    619,
                    967,
                    1441,
                    2025,
                    2589,
                    3293,
                    3723,
                    4008,
                    4226,
                    4313,
                    3961,
                    3602,
                    3036,
                    2832,
                    2130,
                    1647,
                    1301,
                    981,
                    687,
                    492,
                    402,
                    305,
                    219,
                    165,
                    120,
                    102,
                    63,
                    39,
                    31,
                    17,
                    12,
                    10,
                    5,
                    1,
                    2,
                    1,
                    0,
                    1,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.633,
                    -0.6,
                    -0.567,
                    -0.533,
                    -0.5,
                    -0.467,
                    -0.434,
                    -0.401,
                    -0.368,
                    -0.335,
                    -0.302,
                    -0.268,
                    -0.235,
                    -0.202,
                    -0.169,
                    -0.136,
                    -0.103,
                    -0.07,
                    -0.037,
                    -0.003,
                    0.03,
                    0.063,
                    0.096,
                    0.129,
                    0.162,
                    0.195,
                    0.228,
                    0.262,
                    0.295,
                    0.328,
                    0.361,
                    0.394,
                    0.427,
                    0.46,
                    0.493,
                    0.526,
                    0.56,
                    0.593,
                    0.626,
                    0.659,
                    0.692,
                    0.725,
                    0.758,
                    0.791,
                    0.825,
                    0.858,
                    0.891,
                    0.924,
                    0.957,
                    0.99
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "quantitative data and responses related to surveys or questions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "discussions around community engagement and shared experiences",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfhso9lvja10exkg85tr9g",
                        "tokens": [
                            ".",
                            " We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " included",
                            " several",
                            " pie",
                            " and",
                            " bar",
                            " graphs",
                            " to",
                            " make",
                            " the",
                            " data",
                            " a",
                            " bit",
                            " easier",
                            " to",
                            " digest",
                            ".",
                            "\n",
                            "\n",
                            "Feel",
                            " free",
                            " to",
                            " browse",
                            " through",
                            " the",
                            " results",
                            " and",
                            " compare",
                            " them",
                            " to",
                            " your",
                            " own",
                            " workout",
                            " experiences",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " may",
                            " be",
                            " shocked",
                            " by",
                            " how",
                            " you",
                            " and",
                            " your",
                            " friends",
                            " stack",
                            " up",
                            " to",
                            " the",
                            " numbers",
                            ".",
                            "\n",
                            "\n",
                            "Big",
                            "gest",
                            " challenges",
                            " when",
                            " working",
                            " out",
                            "\n",
                            "\n",
                            "Let",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " kick",
                            " things",
                            " off",
                            " by",
                            " discussing",
                            " the",
                            " biggest",
                            " challenges",
                            " you",
                            " all",
                            " face",
                            " when",
                            " it",
                            " comes",
                            " to",
                            " working",
                            " out",
                            ".",
                            " This",
                            " question",
                            " was",
                            " an",
                            " open",
                            " ended",
                            " question",
                            " and",
                            " we",
                            " received",
                            " thousands",
                            " of",
                            " replies",
                            ".",
                            " From",
                            " there",
                            ",",
                            " we",
                            " categorized",
                            " them",
                            " into",
                            " the",
                            " following",
                            ":",
                            "\n",
                            "\n",
                            "As",
                            " you",
                            " can",
                            " see",
                            ",",
                            " the",
                            " number",
                            " one",
                            " challenge",
                            " of",
                            " those",
                            " who"
                        ],
                        "dataIndex": null,
                        "index": "13957",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.67,
                        "maxValueTokenIndex": 103,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.008,
                            0,
                            1.717,
                            0,
                            1.594,
                            0.405,
                            0.992,
                            4.39,
                            4.554,
                            6.359,
                            5.46,
                            5.023,
                            8.67,
                            2.001,
                            4.906,
                            3.485,
                            3.667,
                            3.396,
                            2.03,
                            2.027,
                            2.324,
                            4.397,
                            4.955,
                            3.87,
                            4.208,
                            2.058,
                            0,
                            0,
                            4.15,
                            3.891,
                            4.064,
                            3.292,
                            0,
                            0,
                            0.561,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:45:28.754Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 8.669,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfhsoalvje10ex1z5ydakm",
                        "tokens": [
                            ".",
                            " We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " included",
                            " several",
                            " pie",
                            " and",
                            " bar",
                            " graphs",
                            " to",
                            " make",
                            " the",
                            " data",
                            " a",
                            " bit",
                            " easier",
                            " to",
                            " digest",
                            ".",
                            "\n",
                            "\n",
                            "Feel",
                            " free",
                            " to",
                            " browse",
                            " through",
                            " the",
                            " results",
                            " and",
                            " compare",
                            " them",
                            " to",
                            " your",
                            " own",
                            " workout",
                            " experiences",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " may",
                            " be",
                            " shocked",
                            " by",
                            " how",
                            " you",
                            " and",
                            " your",
                            " friends",
                            " stack",
                            " up",
                            " to",
                            " the",
                            " numbers",
                            ".",
                            "\n",
                            "\n",
                            "Big",
                            "gest",
                            " challenges",
                            " when",
                            " working",
                            " out",
                            "\n",
                            "\n",
                            "Let",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " kick",
                            " things",
                            " off",
                            " by",
                            " discussing",
                            " the",
                            " biggest",
                            " challenges",
                            " you",
                            " all",
                            " face",
                            " when",
                            " it",
                            " comes",
                            " to",
                            " working",
                            " out",
                            ".",
                            " This",
                            " question",
                            " was",
                            " an",
                            " open",
                            " ended",
                            " question",
                            " and",
                            " we",
                            " received",
                            " thousands",
                            " of",
                            " replies",
                            ".",
                            " From",
                            " there",
                            ",",
                            " we",
                            " categorized",
                            " them",
                            " into",
                            " the",
                            " following",
                            ":",
                            "\n",
                            "\n",
                            "As",
                            " you",
                            " can",
                            " see",
                            ",",
                            " the",
                            " number",
                            " one",
                            " challenge",
                            " of",
                            " those",
                            " who"
                        ],
                        "dataIndex": null,
                        "index": "13957",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.67,
                        "maxValueTokenIndex": 103,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.008,
                            0,
                            1.717,
                            0,
                            1.594,
                            0.405,
                            0.992,
                            4.39,
                            4.554,
                            6.359,
                            5.46,
                            5.023,
                            8.67,
                            2.001,
                            4.906,
                            3.485,
                            3.667,
                            3.396,
                            2.03,
                            2.027,
                            2.324,
                            4.397,
                            4.955,
                            3.87,
                            4.208,
                            2.058,
                            0,
                            0,
                            4.15,
                            3.891,
                            4.064,
                            3.292,
                            0,
                            0,
                            0.561,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:45:28.754Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 8.669,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfhsoblvju10exidlqx6ng",
                        "tokens": [
                            ".",
                            " We",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " included",
                            " several",
                            " pie",
                            " and",
                            " bar",
                            " graphs",
                            " to",
                            " make",
                            " the",
                            " data",
                            " a",
                            " bit",
                            " easier",
                            " to",
                            " digest",
                            ".",
                            "\n",
                            "\n",
                            "Feel",
                            " free",
                            " to",
                            " browse",
                            " through",
                            " the",
                            " results",
                            " and",
                            " compare",
                            " them",
                            " to",
                            " your",
                            " own",
                            " workout",
                            " experiences",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " may",
                            " be",
                            " shocked",
                            " by",
                            " how",
                            " you",
                            " and",
                            " your",
                            " friends",
                            " stack",
                            " up",
                            " to",
                            " the",
                            " numbers",
                            ".",
                            "\n",
                            "\n",
                            "Big",
                            "gest",
                            " challenges",
                            " when",
                            " working",
                            " out",
                            "\n",
                            "\n",
                            "Let",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " kick",
                            " things",
                            " off",
                            " by",
                            " discussing",
                            " the",
                            " biggest",
                            " challenges",
                            " you",
                            " all",
                            " face",
                            " when",
                            " it",
                            " comes",
                            " to",
                            " working",
                            " out",
                            ".",
                            " This",
                            " question",
                            " was",
                            " an",
                            " open",
                            " ended",
                            " question",
                            " and",
                            " we",
                            " received",
                            " thousands",
                            " of",
                            " replies",
                            ".",
                            " From",
                            " there",
                            ",",
                            " we",
                            " categorized",
                            " them",
                            " into",
                            " the",
                            " following",
                            ":",
                            "\n",
                            "\n",
                            "As",
                            " you",
                            " can",
                            " see",
                            ",",
                            " the",
                            " number",
                            " one",
                            " challenge",
                            " of",
                            " those",
                            " who"
                        ],
                        "dataIndex": null,
                        "index": "13957",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.67,
                        "maxValueTokenIndex": 103,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.008,
                            0,
                            1.717,
                            0,
                            1.594,
                            0.405,
                            0.992,
                            4.39,
                            4.554,
                            6.359,
                            5.46,
                            5.023,
                            8.67,
                            2.001,
                            4.906,
                            3.485,
                            3.667,
                            3.396,
                            2.03,
                            2.027,
                            2.324,
                            4.397,
                            4.955,
                            3.87,
                            4.208,
                            2.058,
                            0,
                            0,
                            4.15,
                            3.891,
                            4.064,
                            3.292,
                            0,
                            0,
                            0.561,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:45:28.754Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 6.936,
                        "binMax": 8.669,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "12693",
            "description": "elements suggesting a collaborative and instructional effort in the context of creative projects",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5441121783323404,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "12693",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:44:02.350Z",
                "maxActApprox": 14.074,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    12693,
                    10044,
                    15734,
                    48442,
                    61492,
                    50031,
                    48229,
                    82726,
                    33207,
                    55651,
                    42413,
                    90090,
                    4905,
                    84872,
                    26760,
                    68213,
                    37118,
                    93706,
                    91416,
                    36251,
                    82457,
                    12726,
                    35892,
                    80034,
                    80003
                ],
                "topkCosSimValues": [
                    1,
                    0.4613,
                    0.4309,
                    0.4161,
                    0.4134,
                    0.3796,
                    0.3731,
                    0.372,
                    0.3719,
                    0.358,
                    0.3567,
                    0.3547,
                    0.3531,
                    0.349,
                    0.3463,
                    0.3383,
                    0.3241,
                    0.3207,
                    0.3184,
                    0.3128,
                    0.3125,
                    0.3106,
                    0.3097,
                    0.3066,
                    0.3035
                ],
                "neuron_alignment_indices": [
                    481,
                    373,
                    598
                ],
                "neuron_alignment_values": [
                    0.156,
                    0.133,
                    0.11
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    49,
                    718,
                    393
                ],
                "correlated_neurons_pearson": [
                    0.029,
                    0.029,
                    0.028
                ],
                "correlated_neurons_l1": [
                    0.035,
                    0.036,
                    0.049
                ],
                "correlated_features_indices": [
                    12726,
                    12676,
                    12752
                ],
                "correlated_features_pearson": [
                    0.029,
                    0.004,
                    0.004
                ],
                "correlated_features_l1": [
                    0.03,
                    0.006,
                    0.004
                ],
                "neg_str": [
                    "ocaust",
                    "forts",
                    "antage",
                    "aund",
                    "reb",
                    " ISIL",
                    "ovych",
                    "\u00e3\u0125\u00a9\u00e3\u0125\u00b3",
                    "ilee",
                    "azeera"
                ],
                "neg_values": [
                    -0.77,
                    -0.641,
                    -0.629,
                    -0.622,
                    -0.616,
                    -0.615,
                    -0.607,
                    -0.606,
                    -0.596,
                    -0.589
                ],
                "pos_str": [
                    " possibilities",
                    " feasibility",
                    " feasible",
                    "earable",
                    " myster",
                    " Wouldn",
                    " needed",
                    "could",
                    " wanted",
                    " hadn"
                ],
                "pos_values": [
                    0.731,
                    0.719,
                    0.707,
                    0.707,
                    0.696,
                    0.696,
                    0.689,
                    0.683,
                    0.682,
                    0.68
                ],
                "frac_nonzero": 0.0034,
                "freq_hist_data_bar_heights": [
                    2306,
                    1781,
                    1380,
                    1117,
                    835,
                    689,
                    503,
                    387,
                    340,
                    263,
                    208,
                    152,
                    131,
                    104,
                    92,
                    81,
                    70,
                    46,
                    44,
                    22,
                    23,
                    19,
                    18,
                    20,
                    10,
                    8,
                    6,
                    6,
                    1,
                    2,
                    2,
                    4,
                    3,
                    0,
                    1,
                    2,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.141,
                    0.422,
                    0.704,
                    0.985,
                    1.267,
                    1.548,
                    1.83,
                    2.111,
                    2.393,
                    2.674,
                    2.956,
                    3.237,
                    3.519,
                    3.8,
                    4.082,
                    4.363,
                    4.645,
                    4.926,
                    5.208,
                    5.489,
                    5.771,
                    6.052,
                    6.334,
                    6.615,
                    6.896,
                    7.178,
                    7.459,
                    7.741,
                    8.022,
                    8.304,
                    8.585,
                    8.867,
                    9.148,
                    9.43,
                    9.711,
                    9.993,
                    10.274,
                    10.556,
                    10.837,
                    11.119,
                    11.4,
                    11.682,
                    11.963,
                    12.245,
                    12.526,
                    12.808,
                    13.089,
                    13.371,
                    13.652,
                    13.934
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    0,
                    3,
                    5,
                    13,
                    25,
                    35,
                    62,
                    89,
                    131,
                    188,
                    301,
                    510,
                    641,
                    861,
                    1295,
                    1575,
                    2025,
                    2347,
                    2776,
                    3188,
                    3498,
                    3626,
                    3685,
                    3477,
                    3357,
                    3104,
                    2674,
                    2318,
                    1926,
                    1618,
                    1262,
                    1030,
                    759,
                    597,
                    371,
                    311,
                    196,
                    141,
                    79,
                    58,
                    36,
                    17,
                    14,
                    8,
                    10,
                    10,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.755,
                    -0.725,
                    -0.695,
                    -0.665,
                    -0.635,
                    -0.605,
                    -0.575,
                    -0.545,
                    -0.515,
                    -0.485,
                    -0.455,
                    -0.425,
                    -0.395,
                    -0.365,
                    -0.335,
                    -0.305,
                    -0.275,
                    -0.245,
                    -0.215,
                    -0.185,
                    -0.155,
                    -0.125,
                    -0.095,
                    -0.065,
                    -0.035,
                    -0.005,
                    0.025,
                    0.055,
                    0.085,
                    0.115,
                    0.145,
                    0.176,
                    0.206,
                    0.236,
                    0.266,
                    0.296,
                    0.326,
                    0.356,
                    0.386,
                    0.416,
                    0.446,
                    0.476,
                    0.506,
                    0.536,
                    0.566,
                    0.596,
                    0.626,
                    0.656,
                    0.686,
                    0.716
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "conversations about collaboration and project planning",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "elements suggesting a collaborative and instructional effort in the context of creative projects",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygffzp0kxtg10ext9g36b9t",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygffzp0kxth10exsiwar37m",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygffzp1kxtk10exyuy3n35l",
                        "tokens": [
                            " great",
                            " costume",
                            " contests",
                            ",",
                            " and",
                            " everyone",
                            " had",
                            " a",
                            " lot",
                            " of",
                            " fun",
                            ".",
                            " In",
                            " fact",
                            ",",
                            " it",
                            " went",
                            " so",
                            " well",
                            " that",
                            " in",
                            " 2014",
                            " we",
                            " could",
                            " barely",
                            " fit",
                            " in",
                            " the",
                            " Wy",
                            "vern",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " Tale",
                            " (",
                            "our",
                            " FL",
                            "GS",
                            " \u2014",
                            " Friendly",
                            " Local",
                            " Gaming",
                            " Store",
                            ").",
                            " So",
                            " we",
                            " realized",
                            " that",
                            " we",
                            "\u00e2\u0122",
                            "\u013b",
                            "d",
                            " need",
                            " to",
                            " find",
                            " a",
                            " bigger",
                            " place",
                            ".",
                            " And",
                            " once",
                            " we",
                            " were",
                            " looking",
                            " for",
                            " a",
                            " bigger",
                            " place",
                            " it",
                            " occurred",
                            " to",
                            " us",
                            " that",
                            " there",
                            " was",
                            " no",
                            " reason",
                            " to",
                            " limit",
                            " ourselves",
                            " to",
                            " only",
                            " one",
                            " game",
                            ".",
                            " Most",
                            " of",
                            " us",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " only",
                            " play",
                            " one",
                            " game",
                            "\u00e2\u0122\u00a6",
                            "but",
                            " for",
                            " some",
                            " reason",
                            " the",
                            " different",
                            " gaming",
                            " groups",
                            " in",
                            " the",
                            " W",
                            "NC",
                            " area",
                            " rarely",
                            " wound",
                            " up",
                            " in",
                            " the",
                            " same",
                            " place",
                            " at",
                            " the",
                            " same",
                            " time",
                            ".",
                            "\n",
                            "\n",
                            "So",
                            " in",
                            " 2015"
                        ],
                        "dataIndex": null,
                        "index": "12693",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 14.074,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.225,
                            7.494,
                            0,
                            0.471,
                            6.129,
                            5.992,
                            4.39,
                            2.471,
                            3.889,
                            4.273,
                            0,
                            0.299,
                            0,
                            0.625,
                            0,
                            0,
                            0,
                            2.952,
                            3.975,
                            4.167,
                            0.168,
                            0.415,
                            0,
                            0,
                            0,
                            9.15,
                            14.074,
                            10.459,
                            12.236,
                            8.875,
                            3.658,
                            1.642,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.706,
                            1.066,
                            0.16,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.129,
                            1.116,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.342,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:44:04.532Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 14.074,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "5902",
            "description": "references to collaborative projects and educational initiatives",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5353785912805378,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "5902",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:08:27.998Z",
                "maxActApprox": 10.83,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    5902,
                    14080,
                    34669,
                    17734,
                    6915,
                    22948,
                    4605,
                    48747,
                    17249,
                    17660,
                    42876,
                    1682,
                    20454,
                    11952,
                    16080,
                    44792,
                    23791,
                    42073,
                    37253,
                    18052,
                    21215,
                    14605,
                    44365,
                    12560,
                    19672
                ],
                "topkCosSimValues": [
                    1,
                    0.524,
                    0.4349,
                    0.4323,
                    0.4295,
                    0.4262,
                    0.4206,
                    0.4151,
                    0.4143,
                    0.3911,
                    0.3876,
                    0.3861,
                    0.3834,
                    0.3829,
                    0.3811,
                    0.3773,
                    0.373,
                    0.3679,
                    0.3651,
                    0.3634,
                    0.3619,
                    0.3608,
                    0.3575,
                    0.3571,
                    0.3563
                ],
                "neuron_alignment_indices": [
                    87,
                    756,
                    626
                ],
                "neuron_alignment_values": [
                    0.153,
                    0.149,
                    0.089
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.007,
                    0.004
                ],
                "correlated_neurons_indices": [
                    558,
                    498,
                    220
                ],
                "correlated_neurons_pearson": [
                    0.035,
                    0.034,
                    0.033
                ],
                "correlated_neurons_l1": [
                    0.035,
                    0.037,
                    0.03
                ],
                "correlated_features_indices": [
                    5779,
                    5792,
                    5782
                ],
                "correlated_features_pearson": [
                    0.032,
                    0.025,
                    0.022
                ],
                "correlated_features_l1": [
                    0.033,
                    0.026,
                    0.024
                ],
                "neg_str": [
                    "inventoryQuantity",
                    "fax",
                    "soType",
                    "enough",
                    "needs",
                    " Salary",
                    "mother",
                    "66666666",
                    "Smith",
                    "errors"
                ],
                "neg_values": [
                    -0.877,
                    -0.68,
                    -0.631,
                    -0.608,
                    -0.603,
                    -0.602,
                    -0.581,
                    -0.579,
                    -0.578,
                    -0.572
                ],
                "pos_str": [
                    " acronym",
                    " themed",
                    " combining",
                    " loosely",
                    " curated",
                    " reim",
                    " revamped",
                    " pioneering",
                    " collaborative",
                    " innovative"
                ],
                "pos_values": [
                    0.853,
                    0.839,
                    0.831,
                    0.83,
                    0.805,
                    0.796,
                    0.789,
                    0.749,
                    0.745,
                    0.744
                ],
                "frac_nonzero": 0.00293,
                "freq_hist_data_bar_heights": [
                    1226,
                    1100,
                    934,
                    764,
                    623,
                    592,
                    487,
                    500,
                    411,
                    356,
                    263,
                    287,
                    200,
                    192,
                    181,
                    147,
                    117,
                    111,
                    101,
                    91,
                    85,
                    58,
                    52,
                    49,
                    51,
                    40,
                    36,
                    26,
                    24,
                    18,
                    15,
                    14,
                    17,
                    8,
                    8,
                    6,
                    5,
                    5,
                    4,
                    5,
                    3,
                    3,
                    1,
                    0,
                    1,
                    0,
                    1,
                    0,
                    3,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.108,
                    0.325,
                    0.542,
                    0.758,
                    0.975,
                    1.191,
                    1.408,
                    1.624,
                    1.841,
                    2.058,
                    2.274,
                    2.491,
                    2.707,
                    2.924,
                    3.141,
                    3.357,
                    3.574,
                    3.79,
                    4.007,
                    4.224,
                    4.44,
                    4.657,
                    4.873,
                    5.09,
                    5.307,
                    5.523,
                    5.74,
                    5.956,
                    6.173,
                    6.39,
                    6.606,
                    6.823,
                    7.039,
                    7.256,
                    7.473,
                    7.689,
                    7.906,
                    8.122,
                    8.339,
                    8.556,
                    8.772,
                    8.989,
                    9.205,
                    9.422,
                    9.639,
                    9.855,
                    10.072,
                    10.288,
                    10.505,
                    10.722
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    4,
                    6,
                    11,
                    32,
                    42,
                    93,
                    133,
                    264,
                    437,
                    682,
                    1088,
                    1486,
                    2036,
                    2647,
                    3354,
                    3836,
                    4158,
                    4307,
                    4236,
                    3995,
                    3565,
                    3145,
                    2646,
                    2066,
                    1515,
                    1270,
                    953,
                    657,
                    465,
                    363,
                    250,
                    182,
                    119,
                    72,
                    60,
                    32,
                    15,
                    14,
                    5,
                    7,
                    0,
                    3,
                    4
                ],
                "logits_hist_data_bar_values": [
                    -0.86,
                    -0.825,
                    -0.791,
                    -0.756,
                    -0.722,
                    -0.687,
                    -0.652,
                    -0.618,
                    -0.583,
                    -0.549,
                    -0.514,
                    -0.479,
                    -0.445,
                    -0.41,
                    -0.375,
                    -0.341,
                    -0.306,
                    -0.272,
                    -0.237,
                    -0.202,
                    -0.168,
                    -0.133,
                    -0.099,
                    -0.064,
                    -0.029,
                    0.005,
                    0.04,
                    0.074,
                    0.109,
                    0.144,
                    0.178,
                    0.213,
                    0.248,
                    0.282,
                    0.317,
                    0.351,
                    0.386,
                    0.421,
                    0.455,
                    0.49,
                    0.524,
                    0.559,
                    0.594,
                    0.628,
                    0.663,
                    0.698,
                    0.732,
                    0.767,
                    0.801,
                    0.836
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to collaborative projects and educational initiatives",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4heuqh37bi666m6l6lyza",
                        "tokens": [
                            " may",
                            " be",
                            " well",
                            " be",
                            " that",
                            " if",
                            " there",
                            " is",
                            " a",
                            " 2014",
                            " election",
                            ",",
                            " the",
                            " result",
                            " might",
                            " be",
                            " totally",
                            " different",
                            ",",
                            " but",
                            " that",
                            "'s",
                            " not",
                            " what",
                            " we",
                            " are",
                            " trying",
                            " to",
                            " do",
                            ".",
                            " We",
                            " had",
                            " a",
                            " general",
                            " election",
                            " in",
                            " September",
                            " 2013",
                            " and",
                            " we",
                            " are",
                            " trying",
                            " to",
                            " work",
                            " out",
                            " what",
                            " the",
                            " result",
                            " should",
                            " have",
                            " been",
                            ".\"",
                            " \"",
                            "We",
                            " would",
                            " pick",
                            " up",
                            " more",
                            " votes",
                            ",",
                            " no",
                            " doubt",
                            ",",
                            " the",
                            " ALP",
                            " would",
                            " do",
                            " much",
                            " better",
                            ".",
                            " But",
                            " that",
                            " doesn",
                            "'t",
                            " mean",
                            " I",
                            " think",
                            " we",
                            " should",
                            " have",
                            " one",
                            ".\"",
                            " with",
                            " Judith",
                            " Ireland",
                            " Follow",
                            " us",
                            " on",
                            " Twitter",
                            "<|endoftext|>",
                            "Who",
                            " the",
                            " Cl",
                            "ix",
                            "?",
                            " is",
                            " a",
                            " series",
                            " of",
                            " articles",
                            " featuring",
                            " information",
                            " on",
                            " comic",
                            " book",
                            " characters",
                            " that",
                            " have",
                            " been",
                            " made",
                            " into",
                            " figures",
                            " for",
                            " the",
                            " popular",
                            " tabletop",
                            " game",
                            " Her",
                            "ocl",
                            "ix",
                            ".",
                            " These",
                            " articles",
                            " are",
                            " meant",
                            " to",
                            " help"
                        ],
                        "dataIndex": null,
                        "index": "5902",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.83,
                        "maxValueTokenIndex": 98,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.183,
                            8.235,
                            10.83,
                            8.183,
                            5.62,
                            0.214,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.255,
                            0.453,
                            1.007,
                            0.858,
                            0.024,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:08:37.453Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 10.83,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4heuuh388i666aew2pu4t",
                        "tokens": [
                            " may",
                            " be",
                            " well",
                            " be",
                            " that",
                            " if",
                            " there",
                            " is",
                            " a",
                            " 2014",
                            " election",
                            ",",
                            " the",
                            " result",
                            " might",
                            " be",
                            " totally",
                            " different",
                            ",",
                            " but",
                            " that",
                            "'s",
                            " not",
                            " what",
                            " we",
                            " are",
                            " trying",
                            " to",
                            " do",
                            ".",
                            " We",
                            " had",
                            " a",
                            " general",
                            " election",
                            " in",
                            " September",
                            " 2013",
                            " and",
                            " we",
                            " are",
                            " trying",
                            " to",
                            " work",
                            " out",
                            " what",
                            " the",
                            " result",
                            " should",
                            " have",
                            " been",
                            ".\"",
                            " \"",
                            "We",
                            " would",
                            " pick",
                            " up",
                            " more",
                            " votes",
                            ",",
                            " no",
                            " doubt",
                            ",",
                            " the",
                            " ALP",
                            " would",
                            " do",
                            " much",
                            " better",
                            ".",
                            " But",
                            " that",
                            " doesn",
                            "'t",
                            " mean",
                            " I",
                            " think",
                            " we",
                            " should",
                            " have",
                            " one",
                            ".\"",
                            " with",
                            " Judith",
                            " Ireland",
                            " Follow",
                            " us",
                            " on",
                            " Twitter",
                            "<|endoftext|>",
                            "Who",
                            " the",
                            " Cl",
                            "ix",
                            "?",
                            " is",
                            " a",
                            " series",
                            " of",
                            " articles",
                            " featuring",
                            " information",
                            " on",
                            " comic",
                            " book",
                            " characters",
                            " that",
                            " have",
                            " been",
                            " made",
                            " into",
                            " figures",
                            " for",
                            " the",
                            " popular",
                            " tabletop",
                            " game",
                            " Her",
                            "ocl",
                            "ix",
                            ".",
                            " These",
                            " articles",
                            " are",
                            " meant",
                            " to",
                            " help"
                        ],
                        "dataIndex": null,
                        "index": "5902",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.83,
                        "maxValueTokenIndex": 98,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.183,
                            8.235,
                            10.83,
                            8.183,
                            5.62,
                            0.214,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.255,
                            0.453,
                            1.007,
                            0.858,
                            0.024,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:08:37.453Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 4.332,
                        "binMax": 6.498,
                        "binContains": 0.00014,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4heuqh37ci666gdc1fdp1",
                        "tokens": [
                            " space",
                            " and",
                            " a",
                            " three",
                            "-",
                            "day",
                            " sym",
                            "posium",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013a",
                            "I",
                            " have",
                            " written",
                            " a",
                            " wicked",
                            " book",
                            "\u00e2\u0122",
                            "\u013b",
                            ",",
                            " said",
                            " Mel",
                            "ville",
                            " when",
                            " his",
                            " novel",
                            " was",
                            " first",
                            " published",
                            " in",
                            " 18",
                            "51",
                            ",",
                            " \u00e2\u0122",
                            "\u013a",
                            "and",
                            " I",
                            " feel",
                            " as",
                            " spot",
                            "less",
                            " as",
                            " the",
                            " lamb",
                            "\u00e2\u0122",
                            "\u013b",
                            ".",
                            " Deep",
                            "ly",
                            " subversive",
                            ",",
                            " in",
                            " almost",
                            " every",
                            " way",
                            " imaginable",
                            ",",
                            " Mob",
                            "y",
                            "-",
                            "Dick",
                            " is",
                            " a",
                            " virtual",
                            ",",
                            " alternative",
                            " bible",
                            " \u2013",
                            " and",
                            " as",
                            " such",
                            ",",
                            " ripe",
                            " for",
                            " re",
                            "interpret",
                            "ation",
                            " in",
                            " this",
                            " new",
                            " world",
                            " of",
                            " new",
                            " media",
                            ".",
                            " Out",
                            " of",
                            " Dominion",
                            " was",
                            " born",
                            " its",
                            " bastard",
                            " child",
                            " \u2013",
                            " or",
                            " perhaps",
                            " its",
                            " imm",
                            "ac",
                            "ulate",
                            " conception",
                            " \u2013",
                            " the",
                            " Mob",
                            "y",
                            "-",
                            "Dick",
                            " Big",
                            " Read",
                            ":",
                            " an",
                            " online",
                            " version",
                            " of",
                            " Mel",
                            "ville",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " mag",
                            "ister",
                            "ial",
                            " to",
                            "me",
                            ":"
                        ],
                        "dataIndex": null,
                        "index": "5902",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.607,
                        "maxValueTokenIndex": 112,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.008,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.969,
                            10.607,
                            8.971,
                            3.062,
                            2.038,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.007,
                            0,
                            1.269,
                            0,
                            0,
                            2.09
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:08:37.453Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 10.83,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "68269",
            "description": "texts related to education and the sharing of knowledge",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5293476897089305,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "68269",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:56:56.587Z",
                "maxActApprox": 45.403,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    68269,
                    90381,
                    38082,
                    13891,
                    68287,
                    27303,
                    4045,
                    67551,
                    63993,
                    53622,
                    71497,
                    48368,
                    40088,
                    55801,
                    97672,
                    78484,
                    95659,
                    61552,
                    84172,
                    79161,
                    200,
                    21601,
                    36129,
                    67636,
                    92910
                ],
                "topkCosSimValues": [
                    1,
                    0.5593,
                    0.5463,
                    0.5461,
                    0.5321,
                    0.5313,
                    0.5305,
                    0.5125,
                    0.5092,
                    0.5076,
                    0.4921,
                    0.4901,
                    0.4862,
                    0.4681,
                    0.4655,
                    0.4647,
                    0.4599,
                    0.4571,
                    0.4561,
                    0.4553,
                    0.4462,
                    0.4426,
                    0.4413,
                    0.4365,
                    0.428
                ],
                "neuron_alignment_indices": [
                    679,
                    108,
                    255
                ],
                "neuron_alignment_values": [
                    0.131,
                    0.106,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    641,
                    108,
                    679
                ],
                "correlated_neurons_pearson": [
                    0.015,
                    0.014,
                    0.013
                ],
                "correlated_neurons_l1": [
                    0.016,
                    0.014,
                    0.016
                ],
                "correlated_features_indices": [
                    68287,
                    68278,
                    68255
                ],
                "correlated_features_pearson": [
                    0.077,
                    0.002,
                    0.002
                ],
                "correlated_features_l1": [
                    0.077,
                    0.002,
                    0.002
                ],
                "neg_str": [
                    "imposed",
                    " Mehran",
                    " Roses",
                    "same",
                    " odds",
                    " Amen",
                    "\u00e3\u0124\u00bb",
                    " fav",
                    " LIMITED",
                    " transporter"
                ],
                "neg_values": [
                    -0.668,
                    -0.612,
                    -0.609,
                    -0.583,
                    -0.571,
                    -0.545,
                    -0.544,
                    -0.541,
                    -0.538,
                    -0.528
                ],
                "pos_str": [
                    "ingly",
                    "yout",
                    " audiences",
                    "hetically",
                    " policymakers",
                    " consumers",
                    " youngsters",
                    "ADRA",
                    " viewers",
                    " everyone"
                ],
                "pos_values": [
                    0.97,
                    0.809,
                    0.803,
                    0.777,
                    0.772,
                    0.768,
                    0.762,
                    0.761,
                    0.76,
                    0.756
                ],
                "frac_nonzero": 0.00028,
                "freq_hist_data_bar_heights": [
                    236,
                    190,
                    104,
                    87,
                    54,
                    40,
                    26,
                    25,
                    16,
                    16,
                    9,
                    11,
                    14,
                    7,
                    1,
                    4,
                    0,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    2,
                    0,
                    0,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    2,
                    0,
                    2,
                    3,
                    3,
                    3,
                    2,
                    1,
                    3,
                    4,
                    3,
                    1,
                    1,
                    1,
                    1,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.456,
                    1.364,
                    2.272,
                    3.18,
                    4.088,
                    4.996,
                    5.904,
                    6.812,
                    7.72,
                    8.628,
                    9.536,
                    10.444,
                    11.352,
                    12.26,
                    13.168,
                    14.076,
                    14.984,
                    15.892,
                    16.8,
                    17.708,
                    18.616,
                    19.524,
                    20.432,
                    21.34,
                    22.248,
                    23.156,
                    24.064,
                    24.972,
                    25.88,
                    26.788,
                    27.696,
                    28.604,
                    29.512,
                    30.42,
                    31.328,
                    32.236,
                    33.144,
                    34.052,
                    34.96,
                    35.868,
                    36.776,
                    37.684,
                    38.592,
                    39.5,
                    40.409,
                    41.317,
                    42.225,
                    43.133,
                    44.041,
                    44.949
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    2,
                    2,
                    4,
                    12,
                    35,
                    59,
                    101,
                    192,
                    301,
                    487,
                    763,
                    1075,
                    1610,
                    2109,
                    2657,
                    3179,
                    3608,
                    4068,
                    4053,
                    4092,
                    3954,
                    3625,
                    3164,
                    2600,
                    2100,
                    1634,
                    1241,
                    988,
                    751,
                    506,
                    378,
                    288,
                    194,
                    131,
                    85,
                    71,
                    51,
                    34,
                    16,
                    10,
                    6,
                    9,
                    7,
                    2,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.652,
                    -0.619,
                    -0.586,
                    -0.554,
                    -0.521,
                    -0.488,
                    -0.455,
                    -0.423,
                    -0.39,
                    -0.357,
                    -0.324,
                    -0.291,
                    -0.259,
                    -0.226,
                    -0.193,
                    -0.16,
                    -0.128,
                    -0.095,
                    -0.062,
                    -0.029,
                    0.003,
                    0.036,
                    0.069,
                    0.102,
                    0.134,
                    0.167,
                    0.2,
                    0.233,
                    0.266,
                    0.298,
                    0.331,
                    0.364,
                    0.397,
                    0.429,
                    0.462,
                    0.495,
                    0.528,
                    0.56,
                    0.593,
                    0.626,
                    0.659,
                    0.691,
                    0.724,
                    0.757,
                    0.79,
                    0.823,
                    0.855,
                    0.888,
                    0.921,
                    0.954
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to education and the act of educating",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "texts related to education and the sharing of knowledge",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygi1rzcr2iw10exutkd0ahs",
                        "tokens": [
                            "ides",
                            "h",
                            "aring",
                            " Works",
                            " for",
                            " Austin",
                            ",",
                            " which",
                            " is",
                            " behind",
                            " the",
                            " effort",
                            ",",
                            " plans",
                            " to",
                            " set",
                            " up",
                            " a",
                            " way",
                            " for",
                            " individual",
                            " supporters",
                            " to",
                            " donate",
                            ".",
                            "\n",
                            "\n",
                            "On",
                            " Monday",
                            ",",
                            " Le",
                            "ff",
                            "ing",
                            "well",
                            " announced",
                            " he",
                            " was",
                            " partnering",
                            " with",
                            " the",
                            " campaign",
                            " to",
                            " support",
                            " the",
                            " May",
                            " 7",
                            " ballot",
                            " initiative",
                            ".",
                            " Le",
                            "ff",
                            "ing",
                            "well",
                            " said",
                            " he",
                            " wants",
                            " to",
                            " educate",
                            " the",
                            " public",
                            " due",
                            " to",
                            " what",
                            " he",
                            " calls",
                            " confusing",
                            " ballot",
                            " language",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " campaign",
                            " said",
                            " in",
                            " January",
                            " it",
                            " collected",
                            " more",
                            " than",
                            " 65",
                            ",",
                            "000",
                            " signatures",
                            " from",
                            " Austin",
                            " voters",
                            " to",
                            " support",
                            " its",
                            " petition",
                            ".",
                            " District",
                            " 5",
                            " Council",
                            " Member",
                            " Ann",
                            " Kitchen",
                            ",",
                            " who",
                            " authored",
                            " much",
                            " of",
                            " the",
                            " city",
                            "'s",
                            " pending",
                            " ordinance",
                            " regulating",
                            " T",
                            "NC",
                            "s",
                            ",",
                            " replaced",
                            " ballot",
                            " language",
                            " submitted",
                            " with",
                            " the",
                            " petition",
                            " because",
                            " it",
                            " did",
                            " not",
                            " refer",
                            " to",
                            " fingerprint"
                        ],
                        "dataIndex": null,
                        "index": "68269",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 45.403,
                        "maxValueTokenIndex": 57,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.403,
                            8.809,
                            7.063,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:57:00.234Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 45.403,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi1rzcr2ix10ex92083jtf",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "Mot",
                            "iv",
                            "ations",
                            " to",
                            " Build",
                            " the",
                            " Blockchain",
                            " Embassy",
                            " in",
                            " Panama",
                            "\n",
                            "\n",
                            "Bitcoin",
                            ".",
                            "com",
                            " reached",
                            " out",
                            " to",
                            " one",
                            " of",
                            " the",
                            " founders",
                            " of",
                            " the",
                            " Blockchain",
                            " Embassy",
                            " (",
                            "and",
                            " Crypt",
                            "ob",
                            "uy",
                            "er",
                            "),",
                            " Jorge",
                            " F",
                            "ari",
                            "as",
                            ",",
                            " to",
                            " get",
                            " some",
                            " insight",
                            " on",
                            " the",
                            " motivations",
                            " behind",
                            " setting",
                            " up",
                            " the",
                            " embassy",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "We",
                            " created",
                            " the",
                            " embassy",
                            " because",
                            " we",
                            " were",
                            " motivated",
                            " by",
                            " the",
                            " need",
                            " to",
                            " educate",
                            " the",
                            " people",
                            " not",
                            " only",
                            " of",
                            " Panama",
                            ",",
                            " but",
                            " also",
                            " of",
                            " the",
                            " world",
                            ".",
                            " Panama",
                            " is",
                            " a",
                            " tourist",
                            " site",
                            ",",
                            " and",
                            " at",
                            " the",
                            " same",
                            " time",
                            ",",
                            " a",
                            " major",
                            " financial",
                            " and",
                            " log",
                            "istic",
                            " center",
                            ".",
                            " We",
                            " believe",
                            " that",
                            " it",
                            " is",
                            " an",
                            " ideal",
                            " place",
                            " to",
                            " show",
                            " the",
                            " power",
                            " of",
                            " technology",
                            " in",
                            " a",
                            " real",
                            ",",
                            " palpable",
                            " way"
                        ],
                        "dataIndex": null,
                        "index": "68269",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.796,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.796,
                            11.788,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:57:00.234Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 45.403,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygi1rzer2jh10exh3vd9dpe",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "Mot",
                            "iv",
                            "ations",
                            " to",
                            " Build",
                            " the",
                            " Blockchain",
                            " Embassy",
                            " in",
                            " Panama",
                            "\n",
                            "\n",
                            "Bitcoin",
                            ".",
                            "com",
                            " reached",
                            " out",
                            " to",
                            " one",
                            " of",
                            " the",
                            " founders",
                            " of",
                            " the",
                            " Blockchain",
                            " Embassy",
                            " (",
                            "and",
                            " Crypt",
                            "ob",
                            "uy",
                            "er",
                            "),",
                            " Jorge",
                            " F",
                            "ari",
                            "as",
                            ",",
                            " to",
                            " get",
                            " some",
                            " insight",
                            " on",
                            " the",
                            " motivations",
                            " behind",
                            " setting",
                            " up",
                            " the",
                            " embassy",
                            ".",
                            "\n",
                            "\n",
                            "He",
                            " said",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "We",
                            " created",
                            " the",
                            " embassy",
                            " because",
                            " we",
                            " were",
                            " motivated",
                            " by",
                            " the",
                            " need",
                            " to",
                            " educate",
                            " the",
                            " people",
                            " not",
                            " only",
                            " of",
                            " Panama",
                            ",",
                            " but",
                            " also",
                            " of",
                            " the",
                            " world",
                            ".",
                            " Panama",
                            " is",
                            " a",
                            " tourist",
                            " site",
                            ",",
                            " and",
                            " at",
                            " the",
                            " same",
                            " time",
                            ",",
                            " a",
                            " major",
                            " financial",
                            " and",
                            " log",
                            "istic",
                            " center",
                            ".",
                            " We",
                            " believe",
                            " that",
                            " it",
                            " is",
                            " an",
                            " ideal",
                            " place",
                            " to",
                            " show",
                            " the",
                            " power",
                            " of",
                            " technology",
                            " in",
                            " a",
                            " real",
                            ",",
                            " palpable",
                            " way"
                        ],
                        "dataIndex": null,
                        "index": "68269",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.796,
                        "maxValueTokenIndex": 73,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.796,
                            11.788,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:57:00.234Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 36.322,
                        "binMax": 45.403,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "84558",
            "description": " concepts related to collaboration and community engagement",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5282019376754761,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "84558",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:14:39.970Z",
                "maxActApprox": 18.613,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    84558,
                    52796,
                    71218,
                    12191,
                    48302,
                    44525,
                    33893,
                    36889,
                    55282,
                    4955,
                    12473,
                    78051,
                    41525,
                    41799,
                    29743,
                    71213,
                    5400,
                    72209,
                    77178,
                    92155,
                    86622,
                    52687,
                    96045,
                    25087,
                    80336
                ],
                "topkCosSimValues": [
                    1,
                    0.5576,
                    0.5096,
                    0.5021,
                    0.4558,
                    0.4056,
                    0.4043,
                    0.397,
                    0.3829,
                    0.3811,
                    0.3768,
                    0.3711,
                    0.3691,
                    0.3656,
                    0.3614,
                    0.3485,
                    0.3459,
                    0.3409,
                    0.3342,
                    0.3297,
                    0.3297,
                    0.3289,
                    0.3187,
                    0.3156,
                    0.3086
                ],
                "neuron_alignment_indices": [
                    9,
                    454,
                    680
                ],
                "neuron_alignment_values": [
                    0.132,
                    0.108,
                    0.097
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    9,
                    163,
                    315
                ],
                "correlated_neurons_pearson": [
                    0.018,
                    0.017,
                    0.017
                ],
                "correlated_neurons_l1": [
                    0.018,
                    0.016,
                    0.014
                ],
                "correlated_features_indices": [
                    84670,
                    84601,
                    84620
                ],
                "correlated_features_pearson": [
                    0.009,
                    0.003,
                    0.003
                ],
                "correlated_features_l1": [
                    0.01,
                    0.004,
                    0.003
                ],
                "neg_str": [
                    "ridor",
                    "anwhile",
                    "anooga",
                    "hester",
                    "aeus",
                    "rahim",
                    "itone",
                    "kefeller",
                    "ockets",
                    "lah"
                ],
                "neg_values": [
                    -0.818,
                    -0.767,
                    -0.722,
                    -0.678,
                    -0.675,
                    -0.649,
                    -0.644,
                    -0.63,
                    -0.625,
                    -0.619
                ],
                "pos_str": [
                    " endeavor",
                    " endeavors",
                    " });",
                    " subject",
                    "pires",
                    " bulletin",
                    " journalism",
                    " revolves",
                    " Kickstarter",
                    " endeavour"
                ],
                "pos_values": [
                    0.738,
                    0.728,
                    0.716,
                    0.687,
                    0.654,
                    0.63,
                    0.623,
                    0.619,
                    0.615,
                    0.614
                ],
                "frac_nonzero": 0.00092,
                "freq_hist_data_bar_heights": [
                    622,
                    493,
                    368,
                    265,
                    233,
                    158,
                    126,
                    111,
                    73,
                    61,
                    51,
                    49,
                    32,
                    28,
                    35,
                    33,
                    27,
                    10,
                    12,
                    13,
                    6,
                    11,
                    6,
                    6,
                    8,
                    7,
                    6,
                    10,
                    5,
                    7,
                    2,
                    2,
                    1,
                    5,
                    0,
                    6,
                    2,
                    1,
                    1,
                    0,
                    3,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.186,
                    0.558,
                    0.931,
                    1.303,
                    1.675,
                    2.047,
                    2.42,
                    2.792,
                    3.164,
                    3.536,
                    3.909,
                    4.281,
                    4.653,
                    5.026,
                    5.398,
                    5.77,
                    6.142,
                    6.515,
                    6.887,
                    7.259,
                    7.631,
                    8.004,
                    8.376,
                    8.748,
                    9.12,
                    9.493,
                    9.865,
                    10.237,
                    10.61,
                    10.982,
                    11.354,
                    11.726,
                    12.099,
                    12.471,
                    12.843,
                    13.215,
                    13.588,
                    13.96,
                    14.332,
                    14.704,
                    15.077,
                    15.449,
                    15.821,
                    16.193,
                    16.566,
                    16.938,
                    17.31,
                    17.683,
                    18.055,
                    18.427
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    1,
                    0,
                    1,
                    2,
                    2,
                    7,
                    10,
                    20,
                    36,
                    35,
                    78,
                    118,
                    183,
                    277,
                    422,
                    619,
                    869,
                    1137,
                    1564,
                    2046,
                    2636,
                    3039,
                    3345,
                    3672,
                    3931,
                    3990,
                    3868,
                    3543,
                    3132,
                    2674,
                    2240,
                    1831,
                    1475,
                    1086,
                    803,
                    529,
                    380,
                    238,
                    169,
                    97,
                    55,
                    37,
                    26,
                    9,
                    14,
                    5,
                    1,
                    1,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.803,
                    -0.771,
                    -0.74,
                    -0.709,
                    -0.678,
                    -0.647,
                    -0.616,
                    -0.585,
                    -0.554,
                    -0.523,
                    -0.491,
                    -0.46,
                    -0.429,
                    -0.398,
                    -0.367,
                    -0.336,
                    -0.305,
                    -0.274,
                    -0.243,
                    -0.211,
                    -0.18,
                    -0.149,
                    -0.118,
                    -0.087,
                    -0.056,
                    -0.025,
                    0.006,
                    0.038,
                    0.069,
                    0.1,
                    0.131,
                    0.162,
                    0.193,
                    0.224,
                    0.255,
                    0.286,
                    0.318,
                    0.349,
                    0.38,
                    0.411,
                    0.442,
                    0.473,
                    0.504,
                    0.535,
                    0.566,
                    0.598,
                    0.629,
                    0.66,
                    0.691,
                    0.722
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "terms related to cooperation, collaboration, and the value of diversity",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " concepts related to collaboration and community engagement",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygioi5z3fez10exwib4bqxd",
                        "tokens": [
                            " ask",
                            " questions",
                            ",",
                            " make",
                            " purchases",
                            ",",
                            " book",
                            " travel",
                            " and",
                            " check",
                            " the",
                            " weather",
                            ".",
                            " Of",
                            " course",
                            ",",
                            " bots",
                            " also",
                            " send",
                            " promotional",
                            " messages",
                            ",",
                            " and",
                            " soon",
                            " they",
                            " may",
                            " serve",
                            " third",
                            "-",
                            "party",
                            " convers",
                            "ational",
                            " ads",
                            " through",
                            " program",
                            "matic",
                            " exchanges",
                            ".",
                            "\n",
                            "\n",
                            "As",
                            " with",
                            " any",
                            " new",
                            " technology",
                            ",",
                            " bots",
                            " need",
                            " to",
                            " build",
                            " trust",
                            " first",
                            ".",
                            " The",
                            " more",
                            " AI",
                            " seeks",
                            " to",
                            " imperson",
                            "ate",
                            " humans",
                            ",",
                            " the",
                            " more",
                            " the",
                            " technology",
                            " will",
                            " be",
                            " judged",
                            " by",
                            " human",
                            " standards",
                            " of",
                            " etiquette",
                            " and",
                            " emotional",
                            " intelligence",
                            ".",
                            " Re",
                            "lev",
                            "ance",
                            " will",
                            " be",
                            " critical",
                            ".",
                            " Over",
                            "whelming",
                            " consumers",
                            " with",
                            " promotional",
                            " messages",
                            " before",
                            " bots",
                            " have",
                            " proven",
                            " their",
                            " worth",
                            " risks",
                            " alien",
                            "ating",
                            " them",
                            ".",
                            " No",
                            " one",
                            " likes",
                            " to",
                            " start",
                            " a",
                            " new",
                            " relationship",
                            " only",
                            " to",
                            " find",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " been",
                            " tricked",
                            " into",
                            " a",
                            " sales",
                            " pitch",
                            ".",
                            "\n",
                            "\n",
                            "Better"
                        ],
                        "dataIndex": null,
                        "index": "84558",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.613,
                        "maxValueTokenIndex": 44,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.075,
                            13.513,
                            18.613,
                            2.814,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:40.617Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 18.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygioi5y3fep10ex0wylby20",
                        "tokens": [
                            " ask",
                            " questions",
                            ",",
                            " make",
                            " purchases",
                            ",",
                            " book",
                            " travel",
                            " and",
                            " check",
                            " the",
                            " weather",
                            ".",
                            " Of",
                            " course",
                            ",",
                            " bots",
                            " also",
                            " send",
                            " promotional",
                            " messages",
                            ",",
                            " and",
                            " soon",
                            " they",
                            " may",
                            " serve",
                            " third",
                            "-",
                            "party",
                            " convers",
                            "ational",
                            " ads",
                            " through",
                            " program",
                            "matic",
                            " exchanges",
                            ".",
                            "\n",
                            "\n",
                            "As",
                            " with",
                            " any",
                            " new",
                            " technology",
                            ",",
                            " bots",
                            " need",
                            " to",
                            " build",
                            " trust",
                            " first",
                            ".",
                            " The",
                            " more",
                            " AI",
                            " seeks",
                            " to",
                            " imperson",
                            "ate",
                            " humans",
                            ",",
                            " the",
                            " more",
                            " the",
                            " technology",
                            " will",
                            " be",
                            " judged",
                            " by",
                            " human",
                            " standards",
                            " of",
                            " etiquette",
                            " and",
                            " emotional",
                            " intelligence",
                            ".",
                            " Re",
                            "lev",
                            "ance",
                            " will",
                            " be",
                            " critical",
                            ".",
                            " Over",
                            "whelming",
                            " consumers",
                            " with",
                            " promotional",
                            " messages",
                            " before",
                            " bots",
                            " have",
                            " proven",
                            " their",
                            " worth",
                            " risks",
                            " alien",
                            "ating",
                            " them",
                            ".",
                            " No",
                            " one",
                            " likes",
                            " to",
                            " start",
                            " a",
                            " new",
                            " relationship",
                            " only",
                            " to",
                            " find",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " been",
                            " tricked",
                            " into",
                            " a",
                            " sales",
                            " pitch",
                            ".",
                            "\n",
                            "\n",
                            "Better"
                        ],
                        "dataIndex": null,
                        "index": "84558",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.613,
                        "maxValueTokenIndex": 44,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.075,
                            13.513,
                            18.613,
                            2.814,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:40.617Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 18.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygioi603ff210exvhz0le0q",
                        "tokens": [
                            " ask",
                            " questions",
                            ",",
                            " make",
                            " purchases",
                            ",",
                            " book",
                            " travel",
                            " and",
                            " check",
                            " the",
                            " weather",
                            ".",
                            " Of",
                            " course",
                            ",",
                            " bots",
                            " also",
                            " send",
                            " promotional",
                            " messages",
                            ",",
                            " and",
                            " soon",
                            " they",
                            " may",
                            " serve",
                            " third",
                            "-",
                            "party",
                            " convers",
                            "ational",
                            " ads",
                            " through",
                            " program",
                            "matic",
                            " exchanges",
                            ".",
                            "\n",
                            "\n",
                            "As",
                            " with",
                            " any",
                            " new",
                            " technology",
                            ",",
                            " bots",
                            " need",
                            " to",
                            " build",
                            " trust",
                            " first",
                            ".",
                            " The",
                            " more",
                            " AI",
                            " seeks",
                            " to",
                            " imperson",
                            "ate",
                            " humans",
                            ",",
                            " the",
                            " more",
                            " the",
                            " technology",
                            " will",
                            " be",
                            " judged",
                            " by",
                            " human",
                            " standards",
                            " of",
                            " etiquette",
                            " and",
                            " emotional",
                            " intelligence",
                            ".",
                            " Re",
                            "lev",
                            "ance",
                            " will",
                            " be",
                            " critical",
                            ".",
                            " Over",
                            "whelming",
                            " consumers",
                            " with",
                            " promotional",
                            " messages",
                            " before",
                            " bots",
                            " have",
                            " proven",
                            " their",
                            " worth",
                            " risks",
                            " alien",
                            "ating",
                            " them",
                            ".",
                            " No",
                            " one",
                            " likes",
                            " to",
                            " start",
                            " a",
                            " new",
                            " relationship",
                            " only",
                            " to",
                            " find",
                            " they",
                            "\u00e2\u0122",
                            "\u013b",
                            "ve",
                            " been",
                            " tricked",
                            " into",
                            " a",
                            " sales",
                            " pitch",
                            ".",
                            "\n",
                            "\n",
                            "Better"
                        ],
                        "dataIndex": null,
                        "index": "84558",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.613,
                        "maxValueTokenIndex": 44,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            13.075,
                            13.513,
                            18.613,
                            2.814,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:14:40.617Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 18.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "11880",
            "description": "references to technological tools and platforms designed for support and training",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5254173874855042,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "11880",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:42:58.026Z",
                "maxActApprox": 13.871,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    11880,
                    15342,
                    37676,
                    89463,
                    28285,
                    14543,
                    83012,
                    30111,
                    90869,
                    62878,
                    37558,
                    58066,
                    29413,
                    11770,
                    85854,
                    68635,
                    27487,
                    69020,
                    72239,
                    17285,
                    73558,
                    22799,
                    29873,
                    92410,
                    3910
                ],
                "topkCosSimValues": [
                    1,
                    0.4256,
                    0.4049,
                    0.4038,
                    0.3979,
                    0.3931,
                    0.3927,
                    0.3911,
                    0.3893,
                    0.3779,
                    0.375,
                    0.3745,
                    0.3742,
                    0.3722,
                    0.3686,
                    0.3586,
                    0.355,
                    0.3539,
                    0.347,
                    0.3451,
                    0.3441,
                    0.3431,
                    0.3402,
                    0.3374,
                    0.3359
                ],
                "neuron_alignment_indices": [
                    398,
                    679,
                    50
                ],
                "neuron_alignment_values": [
                    0.114,
                    0.109,
                    0.107
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    679,
                    508,
                    680
                ],
                "correlated_neurons_pearson": [
                    0.026,
                    0.025,
                    0.024
                ],
                "correlated_neurons_l1": [
                    0.036,
                    0.025,
                    0.019
                ],
                "correlated_features_indices": [
                    11770,
                    11772,
                    11748
                ],
                "correlated_features_pearson": [
                    0.059,
                    0.012,
                    0.011
                ],
                "correlated_features_l1": [
                    0.059,
                    0.013,
                    0.011
                ],
                "neg_str": [
                    " sudden",
                    " hating",
                    " retaliate",
                    "OOOO",
                    "esson",
                    "Strength",
                    "lord",
                    " dearly",
                    "aeda",
                    "\u00e7\u0136\u00b0"
                ],
                "neg_values": [
                    -0.777,
                    -0.724,
                    -0.718,
                    -0.716,
                    -0.698,
                    -0.694,
                    -0.685,
                    -0.681,
                    -0.679,
                    -0.678
                ],
                "pos_str": [
                    " broch",
                    " downloadable",
                    "accessible",
                    " outlining",
                    " PDF",
                    " guides",
                    " accessible",
                    "pages",
                    " detailing",
                    "PDF"
                ],
                "pos_values": [
                    1.178,
                    1.109,
                    1.052,
                    0.999,
                    0.992,
                    0.984,
                    0.975,
                    0.961,
                    0.949,
                    0.948
                ],
                "frac_nonzero": 0.00156,
                "freq_hist_data_bar_heights": [
                    1031,
                    779,
                    664,
                    520,
                    386,
                    297,
                    261,
                    204,
                    150,
                    114,
                    96,
                    75,
                    67,
                    36,
                    47,
                    36,
                    22,
                    18,
                    23,
                    13,
                    18,
                    10,
                    10,
                    5,
                    6,
                    4,
                    2,
                    2,
                    1,
                    4,
                    2,
                    2,
                    4,
                    0,
                    1,
                    0,
                    1,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.139,
                    0.416,
                    0.694,
                    0.971,
                    1.248,
                    1.526,
                    1.803,
                    2.081,
                    2.358,
                    2.635,
                    2.913,
                    3.19,
                    3.468,
                    3.745,
                    4.023,
                    4.3,
                    4.577,
                    4.855,
                    5.132,
                    5.41,
                    5.687,
                    5.964,
                    6.242,
                    6.519,
                    6.797,
                    7.074,
                    7.351,
                    7.629,
                    7.906,
                    8.184,
                    8.461,
                    8.739,
                    9.016,
                    9.293,
                    9.571,
                    9.848,
                    10.126,
                    10.403,
                    10.68,
                    10.958,
                    11.235,
                    11.513,
                    11.79,
                    12.067,
                    12.345,
                    12.622,
                    12.9,
                    13.177,
                    13.455,
                    13.732
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    3,
                    7,
                    12,
                    27,
                    50,
                    88,
                    154,
                    257,
                    399,
                    626,
                    917,
                    1286,
                    1741,
                    2302,
                    2852,
                    3566,
                    4066,
                    4251,
                    4324,
                    4069,
                    3667,
                    3364,
                    2717,
                    2265,
                    1728,
                    1321,
                    1014,
                    769,
                    638,
                    499,
                    360,
                    257,
                    184,
                    146,
                    99,
                    67,
                    43,
                    41,
                    22,
                    17,
                    9,
                    15,
                    5,
                    6,
                    3,
                    1,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.757,
                    -0.718,
                    -0.679,
                    -0.64,
                    -0.601,
                    -0.562,
                    -0.523,
                    -0.484,
                    -0.445,
                    -0.406,
                    -0.367,
                    -0.327,
                    -0.288,
                    -0.249,
                    -0.21,
                    -0.171,
                    -0.132,
                    -0.093,
                    -0.054,
                    -0.015,
                    0.024,
                    0.063,
                    0.103,
                    0.142,
                    0.181,
                    0.22,
                    0.259,
                    0.298,
                    0.337,
                    0.376,
                    0.415,
                    0.454,
                    0.493,
                    0.533,
                    0.572,
                    0.611,
                    0.65,
                    0.689,
                    0.728,
                    0.767,
                    0.806,
                    0.845,
                    0.884,
                    0.923,
                    0.963,
                    1.002,
                    1.041,
                    1.08,
                    1.119,
                    1.158
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " references to resources and tools for employers and veterans",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to technological tools and platforms designed for support and training",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfeqitkbuk10exvxn1n7mf",
                        "tokens": [
                            " after",
                            " 2019",
                            ".",
                            "\n",
                            "\n",
                            "That",
                            " comes",
                            " after",
                            " Norway",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " sovereign",
                            " fund",
                            " said",
                            " recently",
                            " it",
                            " is",
                            " recommending",
                            " to",
                            " its",
                            " government",
                            " a",
                            " divest",
                            "ment",
                            " from",
                            " fossil",
                            " fuels",
                            ".",
                            "\n",
                            "\n",
                            "Companies",
                            " are",
                            " expected",
                            " to",
                            " start",
                            " making",
                            " the",
                            " first",
                            " disclosures",
                            " in",
                            " the",
                            " coming",
                            " year",
                            " and",
                            " the",
                            " TC",
                            "FD",
                            " will",
                            " report",
                            " on",
                            " their",
                            " progress",
                            " this",
                            " time",
                            " next",
                            " year",
                            " at",
                            " the",
                            " G",
                            "-",
                            "20",
                            " summit",
                            " in",
                            " Argentina",
                            ",",
                            " said",
                            " Carney",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " task",
                            " force",
                            " is",
                            " also",
                            " planning",
                            " to",
                            " launch",
                            " a",
                            " web",
                            "-",
                            "based",
                            " platform",
                            " to",
                            " further",
                            " support",
                            " companies",
                            " that",
                            " are",
                            " interested",
                            " in",
                            " implementing",
                            " its",
                            " recommendations",
                            ".",
                            " The",
                            " TC",
                            "FD",
                            " Knowledge",
                            " Hub",
                            " will",
                            " go",
                            " live",
                            " in",
                            " the",
                            " first",
                            " quarter",
                            " and",
                            " be",
                            " available",
                            " via",
                            " 222",
                            ".",
                            "t",
                            "cf",
                            "dh",
                            "ub",
                            ".",
                            "org",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " S",
                            "&",
                            "P"
                        ],
                        "dataIndex": null,
                        "index": "11880",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.871,
                        "maxValueTokenIndex": 100,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.556,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.681,
                            0,
                            0,
                            1.284,
                            10.3,
                            9.041,
                            10.013,
                            8.389,
                            8.141,
                            2.688,
                            3.496,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.74,
                            1.058,
                            0,
                            0,
                            3.53,
                            13.871,
                            8.982,
                            5.002,
                            7.074,
                            5.345,
                            4.397,
                            0.104,
                            0,
                            1.986,
                            3.796,
                            6.948,
                            2.489,
                            0.52,
                            0.827,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.315,
                            2.35,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:43:06.001Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.871,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfeqitkbui10exjshbflj8",
                        "tokens": [
                            " after",
                            " 2019",
                            ".",
                            "\n",
                            "\n",
                            "That",
                            " comes",
                            " after",
                            " Norway",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " sovereign",
                            " fund",
                            " said",
                            " recently",
                            " it",
                            " is",
                            " recommending",
                            " to",
                            " its",
                            " government",
                            " a",
                            " divest",
                            "ment",
                            " from",
                            " fossil",
                            " fuels",
                            ".",
                            "\n",
                            "\n",
                            "Companies",
                            " are",
                            " expected",
                            " to",
                            " start",
                            " making",
                            " the",
                            " first",
                            " disclosures",
                            " in",
                            " the",
                            " coming",
                            " year",
                            " and",
                            " the",
                            " TC",
                            "FD",
                            " will",
                            " report",
                            " on",
                            " their",
                            " progress",
                            " this",
                            " time",
                            " next",
                            " year",
                            " at",
                            " the",
                            " G",
                            "-",
                            "20",
                            " summit",
                            " in",
                            " Argentina",
                            ",",
                            " said",
                            " Carney",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " task",
                            " force",
                            " is",
                            " also",
                            " planning",
                            " to",
                            " launch",
                            " a",
                            " web",
                            "-",
                            "based",
                            " platform",
                            " to",
                            " further",
                            " support",
                            " companies",
                            " that",
                            " are",
                            " interested",
                            " in",
                            " implementing",
                            " its",
                            " recommendations",
                            ".",
                            " The",
                            " TC",
                            "FD",
                            " Knowledge",
                            " Hub",
                            " will",
                            " go",
                            " live",
                            " in",
                            " the",
                            " first",
                            " quarter",
                            " and",
                            " be",
                            " available",
                            " via",
                            " 222",
                            ".",
                            "t",
                            "cf",
                            "dh",
                            "ub",
                            ".",
                            "org",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " S",
                            "&",
                            "P"
                        ],
                        "dataIndex": null,
                        "index": "11880",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.871,
                        "maxValueTokenIndex": 100,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.556,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.681,
                            0,
                            0,
                            1.284,
                            10.3,
                            9.041,
                            10.013,
                            8.389,
                            8.141,
                            2.688,
                            3.496,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.74,
                            1.058,
                            0,
                            0,
                            3.53,
                            13.871,
                            8.982,
                            5.002,
                            7.074,
                            5.345,
                            4.397,
                            0.104,
                            0,
                            1.986,
                            3.796,
                            6.948,
                            2.489,
                            0.52,
                            0.827,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.315,
                            2.35,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:43:06.001Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.871,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfeqiukbum10ex65mlnrx7",
                        "tokens": [
                            " after",
                            " 2019",
                            ".",
                            "\n",
                            "\n",
                            "That",
                            " comes",
                            " after",
                            " Norway",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " sovereign",
                            " fund",
                            " said",
                            " recently",
                            " it",
                            " is",
                            " recommending",
                            " to",
                            " its",
                            " government",
                            " a",
                            " divest",
                            "ment",
                            " from",
                            " fossil",
                            " fuels",
                            ".",
                            "\n",
                            "\n",
                            "Companies",
                            " are",
                            " expected",
                            " to",
                            " start",
                            " making",
                            " the",
                            " first",
                            " disclosures",
                            " in",
                            " the",
                            " coming",
                            " year",
                            " and",
                            " the",
                            " TC",
                            "FD",
                            " will",
                            " report",
                            " on",
                            " their",
                            " progress",
                            " this",
                            " time",
                            " next",
                            " year",
                            " at",
                            " the",
                            " G",
                            "-",
                            "20",
                            " summit",
                            " in",
                            " Argentina",
                            ",",
                            " said",
                            " Carney",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " task",
                            " force",
                            " is",
                            " also",
                            " planning",
                            " to",
                            " launch",
                            " a",
                            " web",
                            "-",
                            "based",
                            " platform",
                            " to",
                            " further",
                            " support",
                            " companies",
                            " that",
                            " are",
                            " interested",
                            " in",
                            " implementing",
                            " its",
                            " recommendations",
                            ".",
                            " The",
                            " TC",
                            "FD",
                            " Knowledge",
                            " Hub",
                            " will",
                            " go",
                            " live",
                            " in",
                            " the",
                            " first",
                            " quarter",
                            " and",
                            " be",
                            " available",
                            " via",
                            " 222",
                            ".",
                            "t",
                            "cf",
                            "dh",
                            "ub",
                            ".",
                            "org",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " S",
                            "&",
                            "P"
                        ],
                        "dataIndex": null,
                        "index": "11880",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.871,
                        "maxValueTokenIndex": 100,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.556,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.681,
                            0,
                            0,
                            1.284,
                            10.3,
                            9.041,
                            10.013,
                            8.389,
                            8.141,
                            2.688,
                            3.496,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.74,
                            1.058,
                            0,
                            0,
                            3.53,
                            13.871,
                            8.982,
                            5.002,
                            7.074,
                            5.345,
                            4.397,
                            0.104,
                            0,
                            1.986,
                            3.796,
                            6.948,
                            2.489,
                            0.52,
                            0.827,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.315,
                            2.35,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:43:06.001Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 13.871,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "11112",
            "description": " activities related to collaborating and problem-solving within a community context",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5239567444350285,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "11112",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T08:17:52.028Z",
                "maxActApprox": 13.334,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    11112,
                    26277,
                    35497,
                    29464,
                    18712,
                    12490,
                    14283,
                    4888,
                    20237,
                    4587,
                    25329,
                    8294,
                    42247,
                    45084,
                    5093,
                    273,
                    22486,
                    9252,
                    25952,
                    6075,
                    23732,
                    14706,
                    17939,
                    47254,
                    47419
                ],
                "topkCosSimValues": [
                    1,
                    0.4588,
                    0.4405,
                    0.3959,
                    0.3902,
                    0.3892,
                    0.38,
                    0.3691,
                    0.36,
                    0.3569,
                    0.3562,
                    0.3446,
                    0.3445,
                    0.3432,
                    0.3394,
                    0.3337,
                    0.3306,
                    0.32,
                    0.3184,
                    0.318,
                    0.317,
                    0.3153,
                    0.3144,
                    0.3138,
                    0.3136
                ],
                "neuron_alignment_indices": [
                    204,
                    753,
                    278
                ],
                "neuron_alignment_values": [
                    0.117,
                    0.114,
                    0.091
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    244,
                    295,
                    172
                ],
                "correlated_neurons_pearson": [
                    0.034,
                    0.031,
                    0.03
                ],
                "correlated_neurons_l1": [
                    0.034,
                    0.027,
                    0.03
                ],
                "correlated_features_indices": [
                    11050,
                    11143,
                    11092
                ],
                "correlated_features_pearson": [
                    0.037,
                    0.011,
                    0.01
                ],
                "correlated_features_l1": [
                    0.039,
                    0.013,
                    0.01
                ],
                "neg_str": [
                    " Pastebin",
                    "pite",
                    "selves",
                    "defense",
                    "\u2014\u2014\u2014\u2014",
                    "alia",
                    " Governors",
                    "yip",
                    "Statement",
                    "minus"
                ],
                "neg_values": [
                    -0.81,
                    -0.731,
                    -0.729,
                    -0.695,
                    -0.652,
                    -0.615,
                    -0.605,
                    -0.6,
                    -0.597,
                    -0.583
                ],
                "pos_str": [
                    " firsthand",
                    " himself",
                    " inspiration",
                    " intrigued",
                    " envision",
                    " designing",
                    " muse",
                    " ambitious",
                    " researching",
                    " entrepreneurial"
                ],
                "pos_values": [
                    0.968,
                    0.919,
                    0.836,
                    0.767,
                    0.721,
                    0.719,
                    0.706,
                    0.695,
                    0.685,
                    0.684
                ],
                "frac_nonzero": 0.0031,
                "freq_hist_data_bar_heights": [
                    1724,
                    1417,
                    1147,
                    962,
                    757,
                    622,
                    566,
                    426,
                    379,
                    281,
                    223,
                    222,
                    178,
                    164,
                    120,
                    91,
                    72,
                    51,
                    53,
                    47,
                    31,
                    39,
                    29,
                    16,
                    26,
                    13,
                    17,
                    11,
                    12,
                    7,
                    12,
                    7,
                    8,
                    6,
                    4,
                    4,
                    1,
                    0,
                    2,
                    1,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.133,
                    0.4,
                    0.667,
                    0.934,
                    1.2,
                    1.467,
                    1.734,
                    2,
                    2.267,
                    2.534,
                    2.8,
                    3.067,
                    3.334,
                    3.6,
                    3.867,
                    4.134,
                    4.4,
                    4.667,
                    4.934,
                    5.2,
                    5.467,
                    5.734,
                    6.001,
                    6.267,
                    6.534,
                    6.801,
                    7.067,
                    7.334,
                    7.601,
                    7.867,
                    8.134,
                    8.401,
                    8.667,
                    8.934,
                    9.201,
                    9.467,
                    9.734,
                    10.001,
                    10.267,
                    10.534,
                    10.801,
                    11.067,
                    11.334,
                    11.601,
                    11.868,
                    12.134,
                    12.401,
                    12.668,
                    12.934,
                    13.201
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    0,
                    2,
                    1,
                    1,
                    4,
                    9,
                    29,
                    43,
                    75,
                    148,
                    253,
                    363,
                    619,
                    855,
                    1217,
                    1688,
                    2277,
                    2774,
                    3354,
                    3929,
                    4282,
                    4356,
                    4360,
                    4070,
                    3548,
                    3103,
                    2435,
                    1860,
                    1395,
                    1012,
                    737,
                    496,
                    368,
                    229,
                    142,
                    87,
                    58,
                    31,
                    13,
                    18,
                    5,
                    5,
                    1,
                    1,
                    0,
                    1,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.793,
                    -0.757,
                    -0.721,
                    -0.686,
                    -0.65,
                    -0.615,
                    -0.579,
                    -0.544,
                    -0.508,
                    -0.472,
                    -0.437,
                    -0.401,
                    -0.366,
                    -0.33,
                    -0.295,
                    -0.259,
                    -0.223,
                    -0.188,
                    -0.152,
                    -0.117,
                    -0.081,
                    -0.046,
                    -0.01,
                    0.026,
                    0.061,
                    0.097,
                    0.132,
                    0.168,
                    0.203,
                    0.239,
                    0.275,
                    0.31,
                    0.346,
                    0.381,
                    0.417,
                    0.452,
                    0.488,
                    0.524,
                    0.559,
                    0.595,
                    0.63,
                    0.666,
                    0.701,
                    0.737,
                    0.772,
                    0.808,
                    0.844,
                    0.879,
                    0.915,
                    0.95
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " activities related to collaborating and problem-solving within a community context",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk4tft5lwh5i666tmg6f5p9",
                        "tokens": [
                            " O",
                            "ol",
                            "u",
                            ",",
                            " Rosa",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " co",
                            "-",
                            "founder",
                            " Nil",
                            "mi",
                            " Sen",
                            "arat",
                            "na",
                            " worked",
                            " with",
                            " children",
                            " in",
                            " a",
                            " rural",
                            " region",
                            " of",
                            " Senegal",
                            " through",
                            " the",
                            " Canadian",
                            " International",
                            " Development",
                            " Agency",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "We",
                            " were",
                            " tut",
                            "oring",
                            " these",
                            " kids",
                            " at",
                            " night",
                            ",",
                            " using",
                            " flash",
                            "lights",
                            " and",
                            " very",
                            " bad",
                            " quality",
                            " lantern",
                            "s",
                            " and",
                            " candles",
                            " to",
                            " study",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Sen",
                            "arat",
                            "na",
                            " says",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "We",
                            " would",
                            " even",
                            " use",
                            " the",
                            " dim",
                            " light",
                            " of",
                            " a",
                            " cellphone",
                            " to",
                            " study",
                            " at",
                            " night",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Sen",
                            "arat",
                            "na",
                            " began",
                            " thinking",
                            " about",
                            " ways",
                            " to",
                            " bring",
                            " modern",
                            " technology",
                            " to",
                            " communities",
                            " that",
                            " are",
                            " very",
                            " hesitant",
                            " to",
                            " trust",
                            " outsiders",
                            ".",
                            " That",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " why",
                            " the",
                            " company",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " name",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "O",
                            "ol",
                            "u",
                            ",",
                            "\u00e2\u0122"
                        ],
                        "dataIndex": null,
                        "index": "11112",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.334,
                        "maxValueTokenIndex": 91,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.653,
                            2.156,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.03,
                            13.334,
                            8.257,
                            1.528,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.404,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:17:58.537Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 13.334,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4tft7lwhpi666kctri9qr",
                        "tokens": [
                            " O",
                            "ol",
                            "u",
                            ",",
                            " Rosa",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " co",
                            "-",
                            "founder",
                            " Nil",
                            "mi",
                            " Sen",
                            "arat",
                            "na",
                            " worked",
                            " with",
                            " children",
                            " in",
                            " a",
                            " rural",
                            " region",
                            " of",
                            " Senegal",
                            " through",
                            " the",
                            " Canadian",
                            " International",
                            " Development",
                            " Agency",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "We",
                            " were",
                            " tut",
                            "oring",
                            " these",
                            " kids",
                            " at",
                            " night",
                            ",",
                            " using",
                            " flash",
                            "lights",
                            " and",
                            " very",
                            " bad",
                            " quality",
                            " lantern",
                            "s",
                            " and",
                            " candles",
                            " to",
                            " study",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Sen",
                            "arat",
                            "na",
                            " says",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "We",
                            " would",
                            " even",
                            " use",
                            " the",
                            " dim",
                            " light",
                            " of",
                            " a",
                            " cellphone",
                            " to",
                            " study",
                            " at",
                            " night",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Sen",
                            "arat",
                            "na",
                            " began",
                            " thinking",
                            " about",
                            " ways",
                            " to",
                            " bring",
                            " modern",
                            " technology",
                            " to",
                            " communities",
                            " that",
                            " are",
                            " very",
                            " hesitant",
                            " to",
                            " trust",
                            " outsiders",
                            ".",
                            " That",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " why",
                            " the",
                            " company",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " name",
                            ",",
                            " \u00e2\u0122",
                            "\u013e",
                            "O",
                            "ol",
                            "u",
                            ",",
                            "\u00e2\u0122"
                        ],
                        "dataIndex": null,
                        "index": "11112",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 13.334,
                        "maxValueTokenIndex": 91,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.653,
                            2.156,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.03,
                            13.334,
                            8.257,
                            1.528,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.404,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:17:58.537Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 10.667,
                        "binMax": 13.334,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk4tft5lwh6i6661z2r4k4j",
                        "tokens": [
                            ".",
                            "mass",
                            ".",
                            "gov",
                            "/",
                            "df",
                            "we",
                            "le",
                            "/",
                            "df",
                            "w",
                            "/",
                            "df",
                            "w",
                            "_",
                            "p",
                            "ond",
                            "/",
                            "df",
                            "w",
                            "web",
                            "st",
                            ".",
                            "pdf",
                            " Memorial",
                            " Beach",
                            " The",
                            " idea",
                            " of",
                            " taking",
                            " the",
                            " lake",
                            " beach",
                            " as",
                            " a",
                            " memorial",
                            " to",
                            " World",
                            " War",
                            " II",
                            " veterans",
                            " was",
                            " promulg",
                            "ated",
                            " by",
                            " Webster",
                            " TIM",
                            "ES",
                            " Editor",
                            " Laure",
                            "nce",
                            " Daly",
                            ",",
                            " through",
                            " the",
                            " pages",
                            " of",
                            " the",
                            " newspaper",
                            ".",
                            "\n",
                            "\n",
                            "Residents",
                            " were",
                            " eager",
                            " to",
                            " pay",
                            " tribute",
                            " to",
                            " the",
                            " boys",
                            " in",
                            " service",
                            ",",
                            " and",
                            " several",
                            " ideas",
                            " were",
                            " suggested",
                            ",",
                            " including",
                            " a",
                            " half",
                            "-",
                            "million",
                            " dollar",
                            " civic",
                            " center",
                            " in",
                            " the",
                            " middle",
                            " of",
                            " town",
                            ".",
                            " However",
                            ",",
                            " scores",
                            " of",
                            " servic",
                            "emen",
                            " correspond",
                            "ed",
                            " from",
                            " time",
                            " to",
                            " time",
                            " with",
                            " the",
                            " popular",
                            " editor",
                            ".",
                            " Mr",
                            ".",
                            " Daly",
                            " soon",
                            " noticed",
                            " how",
                            " frequently",
                            " these",
                            " men",
                            ",",
                            " stationed",
                            " in",
                            " all",
                            " parts",
                            " of",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "11112",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 12.704,
                        "maxValueTokenIndex": 115,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.412,
                            12.704,
                            5.128,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T08:17:58.537Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 13.334,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "14874",
            "description": "references to community support and collaboration",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5126497149467468,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "14874",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:46:28.092Z",
                "maxActApprox": 7.24,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    14874,
                    11380,
                    56523,
                    90378,
                    37945,
                    23397,
                    55573,
                    14104,
                    94522,
                    46015,
                    76,
                    35576,
                    62420,
                    66492,
                    49495,
                    58263,
                    80228,
                    1031,
                    34989,
                    71568,
                    15474,
                    68509,
                    76043,
                    85498,
                    54085
                ],
                "topkCosSimValues": [
                    1,
                    0.5361,
                    0.4852,
                    0.4355,
                    0.4267,
                    0.4157,
                    0.413,
                    0.4087,
                    0.4076,
                    0.395,
                    0.3851,
                    0.3827,
                    0.3825,
                    0.3784,
                    0.3657,
                    0.3639,
                    0.3616,
                    0.3601,
                    0.3567,
                    0.3531,
                    0.353,
                    0.3511,
                    0.3504,
                    0.3476,
                    0.3461
                ],
                "neuron_alignment_indices": [
                    627,
                    98,
                    240
                ],
                "neuron_alignment_values": [
                    0.106,
                    0.096,
                    0.089
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_indices": [
                    477,
                    470,
                    566
                ],
                "correlated_neurons_pearson": [
                    0.005,
                    0.004,
                    0.004
                ],
                "correlated_neurons_l1": [
                    0.004,
                    0.003,
                    0.004
                ],
                "correlated_features_indices": [
                    14877,
                    14849,
                    14860
                ],
                "correlated_features_pearson": [
                    0.006,
                    0.001,
                    0
                ],
                "correlated_features_l1": [
                    0.006,
                    0.001,
                    0
                ],
                "neg_str": [
                    "EVA",
                    "olt",
                    "zbek",
                    "Quantity",
                    "ocene",
                    "ydia",
                    "dfx",
                    "lyak",
                    "alog",
                    "zech"
                ],
                "neg_values": [
                    -0.778,
                    -0.768,
                    -0.753,
                    -0.678,
                    -0.656,
                    -0.65,
                    -0.65,
                    -0.648,
                    -0.648,
                    -0.646
                ],
                "pos_str": [
                    " journalism",
                    " charities",
                    " sponsors",
                    " endeavors",
                    " tirelessly",
                    " nonprofits",
                    "\u00e0\u00a4",
                    " flourished",
                    " strives",
                    " donors"
                ],
                "pos_values": [
                    0.755,
                    0.751,
                    0.747,
                    0.691,
                    0.662,
                    0.656,
                    0.641,
                    0.635,
                    0.634,
                    0.626
                ],
                "frac_nonzero": 3e-05,
                "freq_hist_data_bar_heights": [
                    13,
                    10,
                    6,
                    8,
                    7,
                    10,
                    6,
                    2,
                    7,
                    4,
                    2,
                    1,
                    4,
                    2,
                    0,
                    2,
                    4,
                    1,
                    1,
                    2,
                    1,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.083,
                    0.228,
                    0.373,
                    0.517,
                    0.662,
                    0.806,
                    0.951,
                    1.095,
                    1.24,
                    1.385,
                    1.529,
                    1.674,
                    1.818,
                    1.963,
                    2.107,
                    2.252,
                    2.397,
                    2.541,
                    2.686,
                    2.83,
                    2.975,
                    3.119,
                    3.264,
                    3.409,
                    3.553,
                    3.698,
                    3.842,
                    3.987,
                    4.131,
                    4.276,
                    4.421,
                    4.565,
                    4.71,
                    4.854,
                    4.999,
                    5.143,
                    5.288,
                    5.433,
                    5.577,
                    5.722,
                    5.866,
                    6.011,
                    6.155,
                    6.3,
                    6.445,
                    6.589,
                    6.734,
                    6.878,
                    7.023,
                    7.168
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    0,
                    0,
                    2,
                    13,
                    18,
                    28,
                    36,
                    45,
                    58,
                    108,
                    224,
                    278,
                    343,
                    495,
                    767,
                    984,
                    1194,
                    1553,
                    1970,
                    2311,
                    2705,
                    3078,
                    3405,
                    3711,
                    3720,
                    3563,
                    3505,
                    3324,
                    2968,
                    2413,
                    2033,
                    1575,
                    1171,
                    910,
                    590,
                    396,
                    271,
                    167,
                    138,
                    80,
                    46,
                    25,
                    16,
                    6,
                    2,
                    5,
                    1,
                    0,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.762,
                    -0.732,
                    -0.701,
                    -0.67,
                    -0.64,
                    -0.609,
                    -0.578,
                    -0.548,
                    -0.517,
                    -0.486,
                    -0.456,
                    -0.425,
                    -0.395,
                    -0.364,
                    -0.333,
                    -0.303,
                    -0.272,
                    -0.241,
                    -0.211,
                    -0.18,
                    -0.149,
                    -0.119,
                    -0.088,
                    -0.057,
                    -0.027,
                    0.004,
                    0.035,
                    0.065,
                    0.096,
                    0.127,
                    0.157,
                    0.188,
                    0.219,
                    0.249,
                    0.28,
                    0.311,
                    0.341,
                    0.372,
                    0.403,
                    0.433,
                    0.464,
                    0.494,
                    0.525,
                    0.556,
                    0.586,
                    0.617,
                    0.648,
                    0.678,
                    0.709,
                    0.74
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "elements related to collective action and community involvement",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to community support and collaboration",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfj756mkor10exz7pam2nt",
                        "tokens": [
                            " Bihar",
                            " J",
                            "h",
                            "ark",
                            "hand",
                            " Or",
                            "issa",
                            " West",
                            " Bengal",
                            " NOR",
                            "TH",
                            " H",
                            "ary",
                            "ana",
                            " Him",
                            "ach",
                            "al",
                            " Pradesh",
                            " J",
                            "ammu",
                            " &",
                            " Kashmir",
                            " New",
                            " Delhi",
                            " Punjab",
                            " Raj",
                            "as",
                            "than",
                            " Uttar",
                            " Pradesh",
                            " Utt",
                            "arak",
                            "hand",
                            " NOR",
                            "TH",
                            " E",
                            "AST",
                            " Ar",
                            "un",
                            "ach",
                            "al",
                            " Pradesh",
                            " Ass",
                            "am",
                            " Manip",
                            "ur",
                            " Me",
                            "gh",
                            "al",
                            "aya",
                            " Miz",
                            "or",
                            "am",
                            " Nag",
                            "al",
                            "and",
                            " Sik",
                            "k",
                            "im",
                            " Trip",
                            "ura",
                            " SOU",
                            "TH",
                            " And",
                            "hra",
                            " Pradesh",
                            " Karn",
                            "ataka",
                            " Kerala",
                            " Tamil",
                            " Nadu",
                            " W",
                            "EST",
                            " Go",
                            "a",
                            " Gujarat",
                            " Maharashtra",
                            " Story",
                            " In",
                            " A",
                            " Minute",
                            " The",
                            " Air",
                            " We",
                            " #",
                            "B",
                            "reat",
                            "he",
                            " The",
                            " Road",
                            " To",
                            " Delhi",
                            ":",
                            " Elections",
                            " 2015",
                            " The",
                            " Transition",
                            ":",
                            " 2015",
                            "-",
                            "2016",
                            " Unc",
                            "ategor",
                            "ized",
                            " Viz",
                            "nom",
                            "ics",
                            ":",
                            " A",
                            " Quick",
                            " Gl",
                            "ance",
                            " At",
                            " Big",
                            " Issues",
                            " Welfare",
                            " Women",
                            " Women",
                            "@",
                            "Work",
                            " Search",
                            " with",
                            " Google",
                            "\n",
                            "\n",
                            "National",
                            " Library"
                        ],
                        "dataIndex": null,
                        "index": "14874",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.24,
                        "maxValueTokenIndex": 84,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.24,
                            0,
                            0,
                            0,
                            0,
                            1.797,
                            0.917,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:34.196Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 5.792,
                        "binMax": 7.24,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfj754mko710exa9j7alqq",
                        "tokens": [
                            " Bihar",
                            " J",
                            "h",
                            "ark",
                            "hand",
                            " Or",
                            "issa",
                            " West",
                            " Bengal",
                            " NOR",
                            "TH",
                            " H",
                            "ary",
                            "ana",
                            " Him",
                            "ach",
                            "al",
                            " Pradesh",
                            " J",
                            "ammu",
                            " &",
                            " Kashmir",
                            " New",
                            " Delhi",
                            " Punjab",
                            " Raj",
                            "as",
                            "than",
                            " Uttar",
                            " Pradesh",
                            " Utt",
                            "arak",
                            "hand",
                            " NOR",
                            "TH",
                            " E",
                            "AST",
                            " Ar",
                            "un",
                            "ach",
                            "al",
                            " Pradesh",
                            " Ass",
                            "am",
                            " Manip",
                            "ur",
                            " Me",
                            "gh",
                            "al",
                            "aya",
                            " Miz",
                            "or",
                            "am",
                            " Nag",
                            "al",
                            "and",
                            " Sik",
                            "k",
                            "im",
                            " Trip",
                            "ura",
                            " SOU",
                            "TH",
                            " And",
                            "hra",
                            " Pradesh",
                            " Karn",
                            "ataka",
                            " Kerala",
                            " Tamil",
                            " Nadu",
                            " W",
                            "EST",
                            " Go",
                            "a",
                            " Gujarat",
                            " Maharashtra",
                            " Story",
                            " In",
                            " A",
                            " Minute",
                            " The",
                            " Air",
                            " We",
                            " #",
                            "B",
                            "reat",
                            "he",
                            " The",
                            " Road",
                            " To",
                            " Delhi",
                            ":",
                            " Elections",
                            " 2015",
                            " The",
                            " Transition",
                            ":",
                            " 2015",
                            "-",
                            "2016",
                            " Unc",
                            "ategor",
                            "ized",
                            " Viz",
                            "nom",
                            "ics",
                            ":",
                            " A",
                            " Quick",
                            " Gl",
                            "ance",
                            " At",
                            " Big",
                            " Issues",
                            " Welfare",
                            " Women",
                            " Women",
                            "@",
                            "Work",
                            " Search",
                            " with",
                            " Google",
                            "\n",
                            "\n",
                            "National",
                            " Library"
                        ],
                        "dataIndex": null,
                        "index": "14874",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 7.24,
                        "maxValueTokenIndex": 84,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            7.24,
                            0,
                            0,
                            0,
                            0,
                            1.797,
                            0.917,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:34.196Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.24,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfj754mko810exq1ty1ru5",
                        "tokens": [
                            ".",
                            "\n",
                            "\n",
                            "H",
                            "ear",
                            " from",
                            " @",
                            "m",
                            "oses",
                            "bread",
                            "72",
                            "...",
                            " pic",
                            ".",
                            "twitter",
                            ".",
                            "com",
                            "/",
                            "BC",
                            "kg",
                            "64",
                            "d",
                            "G",
                            "5",
                            "x",
                            " \u2014",
                            " NFL",
                            " Network",
                            " (@",
                            "n",
                            "fl",
                            "network",
                            ")",
                            " September",
                            " 25",
                            ",",
                            " 2017",
                            "\n",
                            "\n",
                            "Trump",
                            ",",
                            " however",
                            ",",
                            " had",
                            " no",
                            " sympathy",
                            " for",
                            " him",
                            " or",
                            " anyone",
                            " else",
                            " engaging",
                            " in",
                            " the",
                            " protest",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "Would",
                            "n",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " you",
                            " love",
                            " to",
                            " see",
                            " one",
                            " of",
                            " these",
                            " NFL",
                            " owners",
                            ",",
                            " when",
                            " somebody",
                            " disrespect",
                            "s",
                            " our",
                            " flag",
                            ",",
                            " to",
                            " say",
                            ",",
                            " \u00e2\u0122",
                            "\u013a",
                            "Get",
                            " that",
                            " son",
                            " of",
                            " a",
                            " bitch",
                            " off",
                            " the",
                            " field",
                            " right",
                            " now",
                            ".",
                            " Out",
                            "!",
                            " He",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " fired",
                            ".",
                            " He",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " fired",
                            "!",
                            "\u00e2\u0122",
                            "\u013b",
                            "\u00e2\u0122",
                            "\u013f",
                            " he",
                            " said",
                            " at",
                            " a",
                            " rally",
                            " for",
                            " Republican",
                            " Senator",
                            " Luther",
                            " Strange"
                        ],
                        "dataIndex": null,
                        "index": "14874",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 5.671,
                        "maxValueTokenIndex": 79,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.671,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:46:34.196Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 7.24,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "23242",
            "description": "terms or phrases related to education and knowledge-sharing",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5114758167110629,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "23242",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:58:22.551Z",
                "maxActApprox": 5.808,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    23242,
                    95491,
                    56642,
                    17073,
                    65827,
                    91459,
                    45812,
                    41118,
                    1065,
                    39866,
                    13457,
                    97784,
                    24073,
                    5120,
                    35629,
                    72583,
                    33632,
                    97185,
                    26317,
                    50837,
                    23345,
                    74039,
                    69847,
                    15826,
                    26771
                ],
                "topkCosSimValues": [
                    1,
                    0.3608,
                    0.3221,
                    0.3185,
                    0.3045,
                    0.3019,
                    0.2901,
                    0.288,
                    0.2829,
                    0.281,
                    0.2786,
                    0.2634,
                    0.2633,
                    0.2493,
                    0.2464,
                    0.2444,
                    0.2436,
                    0.2419,
                    0.2404,
                    0.2402,
                    0.24,
                    0.238,
                    0.2375,
                    0.237,
                    0.2359
                ],
                "neuron_alignment_indices": [
                    373,
                    13,
                    280
                ],
                "neuron_alignment_values": [
                    0.118,
                    0.116,
                    0.115
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    138,
                    447,
                    64
                ],
                "correlated_neurons_pearson": [
                    0.971,
                    0.97,
                    0.694
                ],
                "correlated_neurons_l1": [
                    0.971,
                    0.959,
                    -0.008
                ],
                "correlated_features_indices": [
                    23242,
                    23244,
                    23221
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0,
                    0,
                    0
                ],
                "neg_str": [
                    "staking",
                    " calibr",
                    "obar",
                    "\u00d6\u00bc",
                    "querque",
                    "%%%%",
                    "DAQ",
                    " incent",
                    "inton",
                    " algorithm"
                ],
                "neg_values": [
                    -0.627,
                    -0.625,
                    -0.601,
                    -0.601,
                    -0.577,
                    -0.572,
                    -0.566,
                    -0.561,
                    -0.548,
                    -0.546
                ],
                "pos_str": [
                    "itars",
                    "ept",
                    "allowed",
                    "amins",
                    "jured",
                    "itarian",
                    " \u00e8\u00a3\u0131\u00e7",
                    "atural",
                    "Wiki",
                    "ppa"
                ],
                "pos_values": [
                    0.827,
                    0.688,
                    0.681,
                    0.67,
                    0.655,
                    0.651,
                    0.639,
                    0.632,
                    0.629,
                    0.626
                ],
                "frac_nonzero": 0.00793,
                "freq_hist_data_bar_heights": [
                    76,
                    51,
                    41,
                    41,
                    24606,
                    26,
                    18,
                    11,
                    12,
                    6,
                    8,
                    9,
                    3,
                    6,
                    2,
                    3,
                    2,
                    4,
                    3,
                    1,
                    3,
                    1,
                    2,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2,
                    0,
                    2,
                    3,
                    1,
                    0,
                    1,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    2
                ],
                "freq_hist_data_bar_values": [
                    0.062,
                    0.178,
                    0.294,
                    0.41,
                    0.526,
                    0.642,
                    0.759,
                    0.875,
                    0.991,
                    1.107,
                    1.223,
                    1.339,
                    1.455,
                    1.571,
                    1.687,
                    1.803,
                    1.919,
                    2.035,
                    2.152,
                    2.268,
                    2.384,
                    2.5,
                    2.616,
                    2.732,
                    2.848,
                    2.964,
                    3.08,
                    3.196,
                    3.312,
                    3.428,
                    3.545,
                    3.661,
                    3.777,
                    3.893,
                    4.009,
                    4.125,
                    4.241,
                    4.357,
                    4.473,
                    4.589,
                    4.705,
                    4.821,
                    4.938,
                    5.054,
                    5.17,
                    5.286,
                    5.402,
                    5.518,
                    5.634,
                    5.75
                ],
                "logits_hist_data_bar_heights": [
                    4,
                    2,
                    5,
                    15,
                    31,
                    49,
                    88,
                    150,
                    189,
                    327,
                    460,
                    645,
                    914,
                    1263,
                    1576,
                    2062,
                    2388,
                    2843,
                    3119,
                    3478,
                    3687,
                    3636,
                    3651,
                    3364,
                    3108,
                    2840,
                    2378,
                    2036,
                    1532,
                    1243,
                    932,
                    663,
                    493,
                    392,
                    243,
                    172,
                    124,
                    55,
                    37,
                    30,
                    11,
                    5,
                    6,
                    6,
                    3,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.613,
                    -0.583,
                    -0.554,
                    -0.525,
                    -0.496,
                    -0.467,
                    -0.438,
                    -0.409,
                    -0.38,
                    -0.351,
                    -0.322,
                    -0.293,
                    -0.264,
                    -0.234,
                    -0.205,
                    -0.176,
                    -0.147,
                    -0.118,
                    -0.089,
                    -0.06,
                    -0.031,
                    -0.002,
                    0.027,
                    0.056,
                    0.086,
                    0.115,
                    0.144,
                    0.173,
                    0.202,
                    0.231,
                    0.26,
                    0.289,
                    0.318,
                    0.347,
                    0.376,
                    0.405,
                    0.435,
                    0.464,
                    0.493,
                    0.522,
                    0.551,
                    0.58,
                    0.609,
                    0.638,
                    0.667,
                    0.696,
                    0.725,
                    0.754,
                    0.784,
                    0.813
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases or references related to significant titles or positions",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " textual references that denote specific subjects or entities, such as titles, terms, or names",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "terms or phrases related to education and knowledge-sharing",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygfyhopsx9h10ext3zlckhx",
                        "tokens": [
                            " elephants",
                            " stuck",
                            " their",
                            " tr",
                            "unks",
                            " in",
                            " the",
                            " buckets",
                            " at",
                            " random",
                            ".",
                            "\n",
                            "\n",
                            "Ms",
                            ".",
                            " Sm",
                            "et",
                            " and",
                            " Dr",
                            ".",
                            " Byrne",
                            " published",
                            " their",
                            " results",
                            " Thursday",
                            " in",
                            " the",
                            " journal",
                            " Current",
                            " Biology",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " scientists",
                            " were",
                            " able",
                            " to",
                            " rule",
                            " out",
                            " the",
                            " possibility",
                            " that",
                            " the",
                            " elephants",
                            " learned",
                            " to",
                            " associate",
                            " pointing",
                            " with",
                            " food",
                            " over",
                            " the",
                            " course",
                            " of",
                            " the",
                            " experiments",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "They",
                            " were",
                            " just",
                            " as",
                            " good",
                            " on",
                            " Trial",
                            " 1",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Dr",
                            ".",
                            " Byrne",
                            ".",
                            "<|endoftext|>",
                            "The",
                            " title",
                            " of",
                            " this",
                            " article",
                            " is",
                            " conject",
                            "ural",
                            ".",
                            " Though",
                            " the",
                            " topic",
                            " is",
                            " found",
                            " within",
                            " The",
                            " Simpsons",
                            " universe",
                            ",",
                            " a",
                            " proper",
                            " name",
                            " is",
                            " not",
                            " available",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " Blue",
                            "-",
                            "H",
                            "aired",
                            " Law",
                            "yer",
                            ",",
                            " is",
                            " Springfield",
                            "'s",
                            " most",
                            " prominent",
                            " lawyer",
                            " known",
                            " for",
                            " his",
                            " past",
                            "y",
                            " face",
                            ",",
                            " blue"
                        ],
                        "dataIndex": null,
                        "index": "23242",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 5.808,
                        "maxValueTokenIndex": 103,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.551,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.808,
                            4.32,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:58:27.678Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 5.808,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfyhopsx9j10exn44j4545",
                        "tokens": [
                            " elephants",
                            " stuck",
                            " their",
                            " tr",
                            "unks",
                            " in",
                            " the",
                            " buckets",
                            " at",
                            " random",
                            ".",
                            "\n",
                            "\n",
                            "Ms",
                            ".",
                            " Sm",
                            "et",
                            " and",
                            " Dr",
                            ".",
                            " Byrne",
                            " published",
                            " their",
                            " results",
                            " Thursday",
                            " in",
                            " the",
                            " journal",
                            " Current",
                            " Biology",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " scientists",
                            " were",
                            " able",
                            " to",
                            " rule",
                            " out",
                            " the",
                            " possibility",
                            " that",
                            " the",
                            " elephants",
                            " learned",
                            " to",
                            " associate",
                            " pointing",
                            " with",
                            " food",
                            " over",
                            " the",
                            " course",
                            " of",
                            " the",
                            " experiments",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "They",
                            " were",
                            " just",
                            " as",
                            " good",
                            " on",
                            " Trial",
                            " 1",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Dr",
                            ".",
                            " Byrne",
                            ".",
                            "<|endoftext|>",
                            "The",
                            " title",
                            " of",
                            " this",
                            " article",
                            " is",
                            " conject",
                            "ural",
                            ".",
                            " Though",
                            " the",
                            " topic",
                            " is",
                            " found",
                            " within",
                            " The",
                            " Simpsons",
                            " universe",
                            ",",
                            " a",
                            " proper",
                            " name",
                            " is",
                            " not",
                            " available",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " Blue",
                            "-",
                            "H",
                            "aired",
                            " Law",
                            "yer",
                            ",",
                            " is",
                            " Springfield",
                            "'s",
                            " most",
                            " prominent",
                            " lawyer",
                            " known",
                            " for",
                            " his",
                            " past",
                            "y",
                            " face",
                            ",",
                            " blue"
                        ],
                        "dataIndex": null,
                        "index": "23242",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 5.808,
                        "maxValueTokenIndex": 103,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.551,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.808,
                            4.32,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:58:27.678Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 5.808,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygfyhorsxa210ex6aww85l2",
                        "tokens": [
                            " elephants",
                            " stuck",
                            " their",
                            " tr",
                            "unks",
                            " in",
                            " the",
                            " buckets",
                            " at",
                            " random",
                            ".",
                            "\n",
                            "\n",
                            "Ms",
                            ".",
                            " Sm",
                            "et",
                            " and",
                            " Dr",
                            ".",
                            " Byrne",
                            " published",
                            " their",
                            " results",
                            " Thursday",
                            " in",
                            " the",
                            " journal",
                            " Current",
                            " Biology",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " scientists",
                            " were",
                            " able",
                            " to",
                            " rule",
                            " out",
                            " the",
                            " possibility",
                            " that",
                            " the",
                            " elephants",
                            " learned",
                            " to",
                            " associate",
                            " pointing",
                            " with",
                            " food",
                            " over",
                            " the",
                            " course",
                            " of",
                            " the",
                            " experiments",
                            ".",
                            " \u00e2\u0122",
                            "\u013e",
                            "They",
                            " were",
                            " just",
                            " as",
                            " good",
                            " on",
                            " Trial",
                            " 1",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " said",
                            " Dr",
                            ".",
                            " Byrne",
                            ".",
                            "<|endoftext|>",
                            "The",
                            " title",
                            " of",
                            " this",
                            " article",
                            " is",
                            " conject",
                            "ural",
                            ".",
                            " Though",
                            " the",
                            " topic",
                            " is",
                            " found",
                            " within",
                            " The",
                            " Simpsons",
                            " universe",
                            ",",
                            " a",
                            " proper",
                            " name",
                            " is",
                            " not",
                            " available",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " Blue",
                            "-",
                            "H",
                            "aired",
                            " Law",
                            "yer",
                            ",",
                            " is",
                            " Springfield",
                            "'s",
                            " most",
                            " prominent",
                            " lawyer",
                            " known",
                            " for",
                            " his",
                            " past",
                            "y",
                            " face",
                            ",",
                            " blue"
                        ],
                        "dataIndex": null,
                        "index": "23242",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 5.808,
                        "maxValueTokenIndex": 103,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.551,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.808,
                            4.32,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:58:27.678Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 4.647,
                        "binMax": 5.808,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "38931",
            "description": " references to collaborative methods and approaches",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.5000258684158325,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "38931",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:20:13.841Z",
                "maxActApprox": 12.776,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    38931,
                    82176,
                    81434,
                    5878,
                    66835,
                    54473,
                    24201,
                    26110,
                    21676,
                    44328,
                    36723,
                    54107,
                    86339,
                    61109,
                    67613,
                    53982,
                    45941,
                    81386,
                    64990,
                    21393,
                    51517,
                    51083,
                    94753,
                    62986,
                    94980
                ],
                "topkCosSimValues": [
                    1,
                    0.5697,
                    0.5071,
                    0.4743,
                    0.4564,
                    0.4543,
                    0.4111,
                    0.4058,
                    0.3861,
                    0.3776,
                    0.3733,
                    0.3606,
                    0.36,
                    0.3552,
                    0.3544,
                    0.3448,
                    0.3392,
                    0.3381,
                    0.3379,
                    0.336,
                    0.3339,
                    0.3338,
                    0.3282,
                    0.3281,
                    0.3246
                ],
                "neuron_alignment_indices": [
                    732,
                    408,
                    106
                ],
                "neuron_alignment_values": [
                    0.132,
                    0.107,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    732,
                    393,
                    73
                ],
                "correlated_neurons_pearson": [
                    0.031,
                    0.029,
                    0.028
                ],
                "correlated_neurons_l1": [
                    0.024,
                    0.038,
                    0.028
                ],
                "correlated_features_indices": [
                    38942,
                    38927,
                    38888
                ],
                "correlated_features_pearson": [
                    0.003,
                    0.002,
                    0.002
                ],
                "correlated_features_l1": [
                    0.004,
                    0.002,
                    0.002
                ],
                "neg_str": [
                    "bernatorial",
                    "ital",
                    "ipient",
                    "\"]=>",
                    "ropolis",
                    "lees",
                    "minent",
                    "ilyn",
                    "iors",
                    "livion"
                ],
                "neg_values": [
                    -0.825,
                    -0.791,
                    -0.773,
                    -0.766,
                    -0.759,
                    -0.737,
                    -0.737,
                    -0.728,
                    -0.724,
                    -0.722
                ],
                "pos_str": [
                    " techniques",
                    " incorporates",
                    " borrowed",
                    " avoids",
                    " pioneered",
                    " levers",
                    " implements",
                    " specially",
                    " patented",
                    " ingenuity"
                ],
                "pos_values": [
                    1.078,
                    0.849,
                    0.848,
                    0.839,
                    0.825,
                    0.81,
                    0.793,
                    0.791,
                    0.775,
                    0.77
                ],
                "frac_nonzero": 0.00154,
                "freq_hist_data_bar_heights": [
                    887,
                    728,
                    571,
                    466,
                    355,
                    287,
                    235,
                    221,
                    140,
                    134,
                    116,
                    103,
                    88,
                    67,
                    42,
                    47,
                    40,
                    35,
                    39,
                    30,
                    26,
                    17,
                    20,
                    19,
                    15,
                    6,
                    14,
                    15,
                    16,
                    10,
                    10,
                    4,
                    7,
                    1,
                    3,
                    4,
                    3,
                    5,
                    5,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.128,
                    0.383,
                    0.639,
                    0.894,
                    1.15,
                    1.405,
                    1.661,
                    1.916,
                    2.172,
                    2.428,
                    2.683,
                    2.939,
                    3.194,
                    3.45,
                    3.705,
                    3.961,
                    4.216,
                    4.472,
                    4.727,
                    4.983,
                    5.238,
                    5.494,
                    5.749,
                    6.005,
                    6.26,
                    6.516,
                    6.771,
                    7.027,
                    7.282,
                    7.538,
                    7.793,
                    8.049,
                    8.304,
                    8.56,
                    8.815,
                    9.071,
                    9.326,
                    9.582,
                    9.837,
                    10.093,
                    10.348,
                    10.604,
                    10.86,
                    11.115,
                    11.371,
                    11.626,
                    11.882,
                    12.137,
                    12.393,
                    12.648
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    3,
                    5,
                    5,
                    10,
                    28,
                    34,
                    60,
                    87,
                    187,
                    282,
                    427,
                    667,
                    923,
                    1432,
                    1837,
                    2453,
                    3026,
                    3519,
                    3950,
                    4116,
                    4078,
                    3913,
                    3733,
                    3307,
                    2818,
                    2405,
                    1792,
                    1444,
                    1052,
                    821,
                    577,
                    429,
                    295,
                    204,
                    148,
                    66,
                    39,
                    28,
                    21,
                    18,
                    7,
                    4,
                    4,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.806,
                    -0.767,
                    -0.729,
                    -0.691,
                    -0.653,
                    -0.615,
                    -0.577,
                    -0.539,
                    -0.501,
                    -0.463,
                    -0.425,
                    -0.387,
                    -0.349,
                    -0.311,
                    -0.273,
                    -0.235,
                    -0.197,
                    -0.159,
                    -0.121,
                    -0.083,
                    -0.045,
                    -0.007,
                    0.031,
                    0.069,
                    0.108,
                    0.146,
                    0.184,
                    0.222,
                    0.26,
                    0.298,
                    0.336,
                    0.374,
                    0.412,
                    0.45,
                    0.488,
                    0.526,
                    0.564,
                    0.602,
                    0.64,
                    0.678,
                    0.716,
                    0.754,
                    0.792,
                    0.83,
                    0.868,
                    0.906,
                    0.944,
                    0.982,
                    1.021,
                    1.059
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " references to collaborative methods and approaches",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " instances of pairs and relationships between elements in a text",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggqofe4so710exosu2lvdf",
                        "tokens": [
                            ".",
                            " Instead",
                            ",",
                            " the",
                            " study",
                            " uses",
                            " the",
                            " methods",
                            " that",
                            " are",
                            " usually",
                            " employed",
                            " by",
                            " Ne",
                            "um",
                            "ark",
                            " and",
                            " Was",
                            "cher",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " method",
                            " has",
                            " also",
                            " been",
                            " extended",
                            " beyond",
                            " standard",
                            " employment",
                            " outcomes",
                            " for",
                            " the",
                            " United",
                            " States",
                            ".",
                            " Couch",
                            " and",
                            " W",
                            "itten",
                            "burg",
                            " (",
                            "2001",
                            ")",
                            " use",
                            " a",
                            " fixed",
                            "-",
                            "effects",
                            " model",
                            " to",
                            " assess",
                            " the",
                            " impact",
                            " of",
                            " the",
                            " minimum",
                            " wage",
                            " on",
                            " hours",
                            " worked",
                            ",",
                            " while",
                            " Ne",
                            "um",
                            "ark",
                            " and",
                            " Was",
                            "cher",
                            " (",
                            "2004",
                            ")",
                            " use",
                            " these",
                            " techniques",
                            " to",
                            " understand",
                            " how",
                            " labor",
                            " market",
                            " institutions",
                            " are",
                            " relevant",
                            " for",
                            " international",
                            " differences",
                            " in",
                            " the",
                            " effect",
                            " of",
                            " the",
                            " minimum",
                            " wage",
                            ".",
                            " Both",
                            " studies",
                            " find",
                            " the",
                            " traditional",
                            " negative",
                            " impact",
                            ".",
                            " Me",
                            "er",
                            " and",
                            " West",
                            " (",
                            "2013",
                            ")",
                            " use",
                            " state",
                            " fixed",
                            "-",
                            "effects",
                            " models",
                            " and",
                            " numerical",
                            " examples",
                            " to",
                            " argue",
                            " that",
                            " matching",
                            " studies",
                            " that",
                            " include",
                            " location"
                        ],
                        "dataIndex": null,
                        "index": "38931",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 12.776,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.747,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.084,
                            0,
                            0,
                            0.92,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.776,
                            0,
                            3.206,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:20:22.771Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 10.221,
                        "binMax": 12.776,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggqofc4snn10exl66y8r9h",
                        "tokens": [
                            ".",
                            " Instead",
                            ",",
                            " the",
                            " study",
                            " uses",
                            " the",
                            " methods",
                            " that",
                            " are",
                            " usually",
                            " employed",
                            " by",
                            " Ne",
                            "um",
                            "ark",
                            " and",
                            " Was",
                            "cher",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " method",
                            " has",
                            " also",
                            " been",
                            " extended",
                            " beyond",
                            " standard",
                            " employment",
                            " outcomes",
                            " for",
                            " the",
                            " United",
                            " States",
                            ".",
                            " Couch",
                            " and",
                            " W",
                            "itten",
                            "burg",
                            " (",
                            "2001",
                            ")",
                            " use",
                            " a",
                            " fixed",
                            "-",
                            "effects",
                            " model",
                            " to",
                            " assess",
                            " the",
                            " impact",
                            " of",
                            " the",
                            " minimum",
                            " wage",
                            " on",
                            " hours",
                            " worked",
                            ",",
                            " while",
                            " Ne",
                            "um",
                            "ark",
                            " and",
                            " Was",
                            "cher",
                            " (",
                            "2004",
                            ")",
                            " use",
                            " these",
                            " techniques",
                            " to",
                            " understand",
                            " how",
                            " labor",
                            " market",
                            " institutions",
                            " are",
                            " relevant",
                            " for",
                            " international",
                            " differences",
                            " in",
                            " the",
                            " effect",
                            " of",
                            " the",
                            " minimum",
                            " wage",
                            ".",
                            " Both",
                            " studies",
                            " find",
                            " the",
                            " traditional",
                            " negative",
                            " impact",
                            ".",
                            " Me",
                            "er",
                            " and",
                            " West",
                            " (",
                            "2013",
                            ")",
                            " use",
                            " state",
                            " fixed",
                            "-",
                            "effects",
                            " models",
                            " and",
                            " numerical",
                            " examples",
                            " to",
                            " argue",
                            " that",
                            " matching",
                            " studies",
                            " that",
                            " include",
                            " location"
                        ],
                        "dataIndex": null,
                        "index": "38931",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 12.776,
                        "maxValueTokenIndex": 116,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.747,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.084,
                            0,
                            0,
                            0.92,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.776,
                            0,
                            3.206,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:20:22.771Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 12.776,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggqofc4sno10exkjnk56rx",
                        "tokens": [
                            " by",
                            " donating",
                            " his",
                            " time",
                            " and",
                            " holiday",
                            " gifts",
                            " for",
                            " youth",
                            " in",
                            " need",
                            ".",
                            " For",
                            " more",
                            " information",
                            " on",
                            " the",
                            " LA",
                            " Galaxy",
                            " Toy",
                            " Drive",
                            ",",
                            " please",
                            " visit",
                            " www",
                            ".",
                            "lag",
                            "al",
                            "axy",
                            ".",
                            "com",
                            "/",
                            "community",
                            ".",
                            "<|endoftext|>",
                            "Press",
                            " Release",
                            "\n",
                            "\n",
                            "Blue",
                            " Light",
                            " Observ",
                            "ations",
                            " Ind",
                            "icate",
                            " Water",
                            "-",
                            "Rich",
                            " Atmosp",
                            "here",
                            " of",
                            " a",
                            " Super",
                            "-",
                            "Earth",
                            "\n",
                            "\n",
                            "September",
                            " 3",
                            ",",
                            " 2013",
                            "\n",
                            "\n",
                            "A",
                            " Japanese",
                            " research",
                            " team",
                            " of",
                            " astronomers",
                            " and",
                            " planetary",
                            " scientists",
                            " has",
                            " used",
                            " Subaru",
                            " Telescope",
                            "'s",
                            " two",
                            " optical",
                            " cameras",
                            ",",
                            " Sup",
                            "r",
                            "ime",
                            "-",
                            "Cam",
                            " and",
                            " the",
                            " F",
                            "aint",
                            " Object",
                            " Camera",
                            " and",
                            " Spect",
                            "rog",
                            "raph",
                            " (",
                            "F",
                            "OC",
                            "AS",
                            "),",
                            " with",
                            " a",
                            " blue",
                            " transmission",
                            " filter",
                            " to",
                            " observe",
                            " planetary",
                            " trans",
                            "its",
                            " of",
                            " super",
                            "-",
                            "Earth",
                            " G",
                            "J",
                            " 12",
                            "14",
                            " b",
                            " (",
                            "Gil",
                            "ese",
                            " 12",
                            "14",
                            " b",
                            ")"
                        ],
                        "dataIndex": null,
                        "index": "38931",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 10.978,
                        "maxValueTokenIndex": 80,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            10.978,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.542,
                            2.867,
                            0,
                            0,
                            0,
                            0,
                            8.308,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            6.359,
                            7.766,
                            0.628,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:20:22.771Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 12.776,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs24576-jb",
            "index": "12849",
            "description": "content related to educational psychology and learning experiences",
            "explanationModelName": "gpt-3.5-turbo",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.492338627576828,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs24576-jb",
                "index": "12849",
                "sourceSetName": "res_fs24576-jb",
                "creatorId": null,
                "createdAt": "2024-06-13T19:01:13.921Z",
                "maxActApprox": 49.117,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    12849,
                    20008,
                    13240,
                    8581,
                    7804,
                    3969,
                    9365,
                    7187,
                    9709,
                    7511,
                    8895,
                    2951,
                    4849,
                    1353,
                    4375,
                    2878,
                    15591,
                    19680,
                    10990,
                    8921,
                    15005,
                    1833,
                    12980,
                    19318,
                    14797
                ],
                "topkCosSimValues": [
                    1,
                    0.7413,
                    0.5438,
                    0.4984,
                    0.4831,
                    0.4655,
                    0.4593,
                    0.4568,
                    0.4064,
                    0.3952,
                    0.3851,
                    0.3757,
                    0.3671,
                    0.3625,
                    0.3492,
                    0.3279,
                    0.3268,
                    0.322,
                    0.322,
                    0.3211,
                    0.319,
                    0.3172,
                    0.3168,
                    0.3154,
                    0.311
                ],
                "neuron_alignment_indices": [
                    271,
                    62,
                    575
                ],
                "neuron_alignment_values": [
                    0.16,
                    0.119,
                    0.105
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    271,
                    62,
                    119
                ],
                "correlated_neurons_pearson": [
                    0.022,
                    0.019,
                    0.016
                ],
                "correlated_neurons_l1": [
                    0.022,
                    0.018,
                    0.015
                ],
                "correlated_features_indices": [
                    12860,
                    12818,
                    12899
                ],
                "correlated_features_pearson": [
                    0.007,
                    0.006,
                    0.004
                ],
                "correlated_features_l1": [
                    0.008,
                    0.006,
                    0.004
                ],
                "neg_str": [
                    "zzi",
                    "pard",
                    "\u0124\u00aa",
                    "vati",
                    " Shipping",
                    "swick",
                    "senal",
                    "een",
                    " spraying",
                    "tar"
                ],
                "neg_values": [
                    -0.754,
                    -0.694,
                    -0.691,
                    -0.688,
                    -0.684,
                    -0.641,
                    -0.64,
                    -0.636,
                    -0.628,
                    -0.619
                ],
                "pos_str": [
                    " disabilities",
                    " Curve",
                    " curve",
                    " disability",
                    "icult",
                    " aids",
                    "learn",
                    " lessons",
                    " Clicker",
                    " disabled"
                ],
                "pos_values": [
                    1.068,
                    0.925,
                    0.915,
                    0.866,
                    0.768,
                    0.762,
                    0.754,
                    0.738,
                    0.737,
                    0.731
                ],
                "frac_nonzero": 0.00017,
                "freq_hist_data_bar_heights": [
                    115,
                    76,
                    57,
                    36,
                    28,
                    20,
                    12,
                    15,
                    12,
                    11,
                    11,
                    9,
                    12,
                    8,
                    3,
                    5,
                    3,
                    4,
                    6,
                    4,
                    6,
                    13,
                    3,
                    2,
                    3,
                    3,
                    0,
                    4,
                    2,
                    3,
                    1,
                    3,
                    3,
                    3,
                    3,
                    1,
                    3,
                    6,
                    4,
                    1,
                    3,
                    5,
                    5,
                    0,
                    5,
                    1,
                    2,
                    1,
                    2,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.5,
                    1.483,
                    2.465,
                    3.447,
                    4.429,
                    5.411,
                    6.393,
                    7.376,
                    8.358,
                    9.34,
                    10.322,
                    11.304,
                    12.286,
                    13.268,
                    14.251,
                    15.233,
                    16.215,
                    17.197,
                    18.179,
                    19.161,
                    20.144,
                    21.126,
                    22.108,
                    23.09,
                    24.072,
                    25.054,
                    26.036,
                    27.019,
                    28.001,
                    28.983,
                    29.965,
                    30.947,
                    31.929,
                    32.912,
                    33.894,
                    34.876,
                    35.858,
                    36.84,
                    37.822,
                    38.804,
                    39.787,
                    40.769,
                    41.751,
                    42.733,
                    43.715,
                    44.697,
                    45.68,
                    46.662,
                    47.644,
                    48.626
                ],
                "logits_hist_data_bar_heights": [
                    1,
                    4,
                    0,
                    11,
                    21,
                    13,
                    37,
                    71,
                    116,
                    209,
                    346,
                    499,
                    780,
                    1207,
                    1642,
                    2322,
                    2971,
                    3658,
                    4074,
                    4494,
                    4561,
                    4454,
                    4010,
                    3528,
                    2942,
                    2309,
                    1782,
                    1323,
                    892,
                    664,
                    474,
                    313,
                    184,
                    107,
                    88,
                    50,
                    28,
                    24,
                    16,
                    15,
                    10,
                    3,
                    0,
                    0,
                    1,
                    1,
                    1,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.735,
                    -0.699,
                    -0.662,
                    -0.626,
                    -0.59,
                    -0.553,
                    -0.517,
                    -0.48,
                    -0.444,
                    -0.408,
                    -0.371,
                    -0.335,
                    -0.298,
                    -0.262,
                    -0.225,
                    -0.189,
                    -0.153,
                    -0.116,
                    -0.08,
                    -0.043,
                    -0.007,
                    0.03,
                    0.066,
                    0.102,
                    0.139,
                    0.175,
                    0.212,
                    0.248,
                    0.285,
                    0.321,
                    0.357,
                    0.394,
                    0.43,
                    0.467,
                    0.503,
                    0.539,
                    0.576,
                    0.612,
                    0.649,
                    0.685,
                    0.722,
                    0.758,
                    0.794,
                    0.831,
                    0.867,
                    0.904,
                    0.94,
                    0.977,
                    1.013,
                    1.049
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "content related to educational psychology and learning experiences",
                        "explanationModelName": "gpt-3.5-turbo",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxdmlhmzc7l2i666fxbcpcsw",
                        "tokens": [
                            " can",
                            " watch",
                            " the",
                            " full",
                            " presentation",
                            " below",
                            ":",
                            "\n",
                            "\n",
                            "Games",
                            " and",
                            " Meaning",
                            "ful",
                            " Student",
                            " Eng",
                            "agement",
                            "\n",
                            "\n",
                            "Length",
                            ":",
                            "39",
                            ":",
                            "29",
                            "\n",
                            "\n",
                            "M",
                            "IND",
                            "'s",
                            " Director",
                            " of",
                            " ST",
                            " Math",
                            " Content",
                            " Ki",
                            " Kar",
                            "ou",
                            " knows",
                            " that",
                            " for",
                            " games",
                            " to",
                            " provide",
                            " a",
                            " true",
                            " learning",
                            " experience",
                            ",",
                            " they",
                            " must",
                            " offer",
                            " meaningful",
                            " engagement",
                            ".",
                            " In",
                            " the",
                            " latest",
                            " episode",
                            " of",
                            " the",
                            " Inside",
                            " Our",
                            " M",
                            "IND",
                            " podcast",
                            ",",
                            " Ki",
                            " Kar",
                            "ou",
                            " offered",
                            " some",
                            " insights",
                            " from",
                            " his",
                            " recent",
                            " trip",
                            " to",
                            " the",
                            " 2018",
                            " Game",
                            " Developers",
                            " Conference",
                            ".",
                            "\n",
                            "\n",
                            "K",
                            "i",
                            " talked",
                            " about",
                            " the",
                            " difference",
                            " between",
                            " gam",
                            "ification",
                            " and",
                            " meaningful",
                            " engagement",
                            ",",
                            " and",
                            " offered",
                            " some",
                            " ways",
                            " educators",
                            " and",
                            " administrators",
                            " can",
                            " ascertain",
                            " whether",
                            " an",
                            " educational",
                            " product",
                            " is",
                            " offering",
                            " a",
                            " true",
                            " game",
                            "-",
                            "based",
                            " learning",
                            " experience",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " can",
                            " listen",
                            " to",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "12849",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.117,
                        "maxValueTokenIndex": 44,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.117,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.869,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.798,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:01:17.558Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.117,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmlhn0c7l6i666zbaenjoe",
                        "tokens": [
                            " can",
                            " watch",
                            " the",
                            " full",
                            " presentation",
                            " below",
                            ":",
                            "\n",
                            "\n",
                            "Games",
                            " and",
                            " Meaning",
                            "ful",
                            " Student",
                            " Eng",
                            "agement",
                            "\n",
                            "\n",
                            "Length",
                            ":",
                            "39",
                            ":",
                            "29",
                            "\n",
                            "\n",
                            "M",
                            "IND",
                            "'s",
                            " Director",
                            " of",
                            " ST",
                            " Math",
                            " Content",
                            " Ki",
                            " Kar",
                            "ou",
                            " knows",
                            " that",
                            " for",
                            " games",
                            " to",
                            " provide",
                            " a",
                            " true",
                            " learning",
                            " experience",
                            ",",
                            " they",
                            " must",
                            " offer",
                            " meaningful",
                            " engagement",
                            ".",
                            " In",
                            " the",
                            " latest",
                            " episode",
                            " of",
                            " the",
                            " Inside",
                            " Our",
                            " M",
                            "IND",
                            " podcast",
                            ",",
                            " Ki",
                            " Kar",
                            "ou",
                            " offered",
                            " some",
                            " insights",
                            " from",
                            " his",
                            " recent",
                            " trip",
                            " to",
                            " the",
                            " 2018",
                            " Game",
                            " Developers",
                            " Conference",
                            ".",
                            "\n",
                            "\n",
                            "K",
                            "i",
                            " talked",
                            " about",
                            " the",
                            " difference",
                            " between",
                            " gam",
                            "ification",
                            " and",
                            " meaningful",
                            " engagement",
                            ",",
                            " and",
                            " offered",
                            " some",
                            " ways",
                            " educators",
                            " and",
                            " administrators",
                            " can",
                            " ascertain",
                            " whether",
                            " an",
                            " educational",
                            " product",
                            " is",
                            " offering",
                            " a",
                            " true",
                            " game",
                            "-",
                            "based",
                            " learning",
                            " experience",
                            ".",
                            "\n",
                            "\n",
                            "You",
                            " can",
                            " listen",
                            " to",
                            " the"
                        ],
                        "dataIndex": null,
                        "index": "12849",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 49.117,
                        "maxValueTokenIndex": 44,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            49.117,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.869,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            45.798,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:01:17.558Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.117,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxdmlhmzc7l3i66681yibbcr",
                        "tokens": [
                            " on",
                            " comparative",
                            " psychology",
                            " and",
                            " the",
                            " learning",
                            " process",
                            " led",
                            " to",
                            " the",
                            " theory",
                            " of",
                            " connection",
                            "ism",
                            " and",
                            " helped",
                            " lay",
                            " the",
                            " scientific",
                            " foundation",
                            " for",
                            " educational",
                            " psychology",
                            ".",
                            " He",
                            " also",
                            " worked",
                            " on",
                            " solving",
                            " industrial",
                            " problems",
                            ",",
                            " such",
                            " as",
                            " employee",
                            " exams",
                            " and",
                            " testing",
                            ".",
                            " He",
                            " was",
                            " a",
                            " member",
                            " of",
                            " the",
                            " board",
                            " of",
                            " the",
                            " Psychological",
                            " Corporation",
                            " and",
                            " served",
                            " as",
                            " president",
                            " of",
                            " the",
                            " American",
                            " Psychological",
                            " Association",
                            " in",
                            " 1912",
                            ".[",
                            "1",
                            "][",
                            "2",
                            "]",
                            " A",
                            " Review",
                            " of",
                            " General",
                            " Psychology",
                            " survey",
                            ",",
                            " published",
                            " in",
                            " 2002",
                            ",",
                            " ranked",
                            " Thor",
                            "nd",
                            "ike",
                            " as",
                            " the",
                            " ninth",
                            "-",
                            "most",
                            " cited",
                            " psychologist",
                            " of",
                            " the",
                            " 20",
                            "th",
                            " century",
                            ".[",
                            "3",
                            "]",
                            " Edward",
                            " Thor",
                            "nd",
                            "ike",
                            " had",
                            " a",
                            " powerful",
                            " impact",
                            " on",
                            " reinforcement",
                            " theory",
                            " and",
                            " behavior",
                            " analysis",
                            ",",
                            " providing",
                            " the",
                            " basic",
                            " framework",
                            " for",
                            " empirical",
                            " laws",
                            " in",
                            " behavior",
                            " psychology",
                            " with",
                            " his",
                            " law",
                            " of",
                            " effect",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "12849",
                        "layer": "8-res_fs24576-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 47.626,
                        "maxValueTokenIndex": 5,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            47.626,
                            2.354,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-13T19:01:17.558Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 49.117,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs49152-jb",
            "index": "39454",
            "description": "references to educational initiatives and community engagement activities",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.48861372470855713,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs49152-jb",
                "index": "39454",
                "sourceSetName": "res_fs49152-jb",
                "creatorId": null,
                "createdAt": "2024-06-18T09:09:39.304Z",
                "maxActApprox": 18.089,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    39454,
                    28625,
                    40295,
                    16757,
                    32123,
                    25329,
                    1331,
                    40573,
                    32403,
                    47263,
                    27758,
                    19966,
                    18253,
                    29292,
                    28290,
                    22814,
                    36713,
                    46649,
                    9914,
                    46570,
                    19358,
                    31884,
                    28012,
                    43286,
                    42710
                ],
                "topkCosSimValues": [
                    1,
                    0.545,
                    0.5321,
                    0.5044,
                    0.469,
                    0.4212,
                    0.4116,
                    0.4026,
                    0.4012,
                    0.3913,
                    0.3731,
                    0.3647,
                    0.3564,
                    0.3541,
                    0.3497,
                    0.347,
                    0.3374,
                    0.3243,
                    0.3236,
                    0.3224,
                    0.3145,
                    0.3116,
                    0.311,
                    0.3053,
                    0.2956
                ],
                "neuron_alignment_indices": [
                    514,
                    186,
                    281
                ],
                "neuron_alignment_values": [
                    0.114,
                    0.104,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    566,
                    685,
                    8
                ],
                "correlated_neurons_pearson": [
                    0.03,
                    0.028,
                    0.027
                ],
                "correlated_neurons_l1": [
                    0.031,
                    0.02,
                    0.03
                ],
                "correlated_features_indices": [
                    39494,
                    39518,
                    39504
                ],
                "correlated_features_pearson": [
                    0.006,
                    0.003,
                    0.002
                ],
                "correlated_features_l1": [
                    0.007,
                    0.003,
                    0.004
                ],
                "neg_str": [
                    "ciating",
                    "opoly",
                    "ilty",
                    "htaking",
                    " enjoyment",
                    "amental",
                    " Lives",
                    " disapprove",
                    "ocre",
                    "iban"
                ],
                "neg_values": [
                    -0.702,
                    -0.685,
                    -0.674,
                    -0.624,
                    -0.623,
                    -0.608,
                    -0.6,
                    -0.6,
                    -0.583,
                    -0.558
                ],
                "pos_str": [
                    " devised",
                    " resorted",
                    " teamed",
                    "pmwiki",
                    " collaborated",
                    " partnered",
                    " opted",
                    " devise",
                    " enlisted",
                    " instituted"
                ],
                "pos_values": [
                    0.919,
                    0.896,
                    0.781,
                    0.778,
                    0.76,
                    0.725,
                    0.707,
                    0.704,
                    0.694,
                    0.694
                ],
                "frac_nonzero": 0.0017,
                "freq_hist_data_bar_heights": [
                    978,
                    790,
                    565,
                    466,
                    364,
                    276,
                    263,
                    230,
                    182,
                    151,
                    118,
                    105,
                    93,
                    67,
                    79,
                    54,
                    62,
                    52,
                    35,
                    38,
                    35,
                    45,
                    24,
                    27,
                    26,
                    15,
                    26,
                    10,
                    20,
                    19,
                    24,
                    20,
                    12,
                    8,
                    4,
                    7,
                    5,
                    5,
                    6,
                    3,
                    5,
                    6,
                    2,
                    6,
                    3,
                    4,
                    2,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.181,
                    0.543,
                    0.905,
                    1.267,
                    1.628,
                    1.99,
                    2.352,
                    2.714,
                    3.075,
                    3.437,
                    3.799,
                    4.161,
                    4.522,
                    4.884,
                    5.246,
                    5.608,
                    5.97,
                    6.331,
                    6.693,
                    7.055,
                    7.417,
                    7.778,
                    8.14,
                    8.502,
                    8.864,
                    9.225,
                    9.587,
                    9.949,
                    10.311,
                    10.672,
                    11.034,
                    11.396,
                    11.758,
                    12.119,
                    12.481,
                    12.843,
                    13.205,
                    13.567,
                    13.928,
                    14.29,
                    14.652,
                    15.014,
                    15.375,
                    15.737,
                    16.099,
                    16.461,
                    16.822,
                    17.184,
                    17.546,
                    17.908
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    0,
                    3,
                    3,
                    7,
                    22,
                    31,
                    63,
                    98,
                    161,
                    314,
                    424,
                    660,
                    974,
                    1411,
                    1895,
                    2406,
                    2869,
                    3449,
                    3855,
                    4159,
                    4226,
                    4041,
                    3808,
                    3427,
                    2812,
                    2317,
                    1934,
                    1473,
                    1018,
                    802,
                    539,
                    377,
                    259,
                    149,
                    104,
                    65,
                    31,
                    26,
                    21,
                    2,
                    3,
                    6,
                    4,
                    1,
                    3,
                    0,
                    0,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.685,
                    -0.653,
                    -0.621,
                    -0.588,
                    -0.556,
                    -0.523,
                    -0.491,
                    -0.458,
                    -0.426,
                    -0.394,
                    -0.361,
                    -0.329,
                    -0.296,
                    -0.264,
                    -0.232,
                    -0.199,
                    -0.167,
                    -0.134,
                    -0.102,
                    -0.07,
                    -0.037,
                    -0.005,
                    0.028,
                    0.06,
                    0.092,
                    0.125,
                    0.157,
                    0.19,
                    0.222,
                    0.255,
                    0.287,
                    0.319,
                    0.352,
                    0.384,
                    0.417,
                    0.449,
                    0.481,
                    0.514,
                    0.546,
                    0.579,
                    0.611,
                    0.643,
                    0.676,
                    0.708,
                    0.741,
                    0.773,
                    0.806,
                    0.838,
                    0.87,
                    0.903
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "references to educational initiatives and community engagement activities",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clxk6nwvvc08xi666ngxhc4pq",
                        "tokens": [
                            " got",
                            " 10",
                            " billion",
                            " creatures",
                            " living",
                            " in",
                            " it",
                            ",\"",
                            " Kr",
                            "ue",
                            "ger",
                            " said",
                            ".",
                            " \"",
                            "So",
                            " if",
                            " we",
                            " can",
                            " put",
                            " something",
                            " in",
                            " the",
                            " soil",
                            ",",
                            " some",
                            " kind",
                            " of",
                            " a",
                            " root",
                            " structure",
                            " to",
                            " keep",
                            " it",
                            " there",
                            ",",
                            " it",
                            " just",
                            " makes",
                            " my",
                            " 10",
                            " billion",
                            " animals",
                            " a",
                            " lot",
                            " happier",
                            ",",
                            " because",
                            " they",
                            "'re",
                            " the",
                            " ones",
                            " that",
                            " break",
                            " down",
                            " the",
                            " nutrients",
                            " and",
                            " make",
                            " them",
                            " available",
                            " for",
                            " the",
                            " plants",
                            " to",
                            " grow",
                            ".\"",
                            "\n",
                            "\n",
                            "To",
                            " preserve",
                            " root",
                            " structure",
                            " and",
                            " stop",
                            " erosion",
                            ",",
                            " the",
                            " Agriculture",
                            " Center",
                            " is",
                            " teaching",
                            " the",
                            " farmers",
                            " of",
                            " tomorrow",
                            " about",
                            " no",
                            "-",
                            "t",
                            "ill",
                            " and",
                            " cover",
                            " crop",
                            " agriculture",
                            ".",
                            " With",
                            " no",
                            "-",
                            "t",
                            "ill",
                            " farming",
                            ",",
                            " the",
                            " soil",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " pl",
                            "owed",
                            " between",
                            " har",
                            "v",
                            "ests",
                            " from",
                            " year",
                            " to",
                            " year",
                            ".",
                            " Instead",
                            " farmers",
                            " use",
                            " special",
                            " tools",
                            " to",
                            " plant",
                            " seeds"
                        ],
                        "dataIndex": null,
                        "index": "39454",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.089,
                        "maxValueTokenIndex": 79,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.433,
                            0,
                            7.011,
                            18.089,
                            9.068,
                            1.01,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:09:39.963Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": 14.471,
                        "binMax": 18.089,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6nwvtc08bi666uik52o6l",
                        "tokens": [
                            " got",
                            " 10",
                            " billion",
                            " creatures",
                            " living",
                            " in",
                            " it",
                            ",\"",
                            " Kr",
                            "ue",
                            "ger",
                            " said",
                            ".",
                            " \"",
                            "So",
                            " if",
                            " we",
                            " can",
                            " put",
                            " something",
                            " in",
                            " the",
                            " soil",
                            ",",
                            " some",
                            " kind",
                            " of",
                            " a",
                            " root",
                            " structure",
                            " to",
                            " keep",
                            " it",
                            " there",
                            ",",
                            " it",
                            " just",
                            " makes",
                            " my",
                            " 10",
                            " billion",
                            " animals",
                            " a",
                            " lot",
                            " happier",
                            ",",
                            " because",
                            " they",
                            "'re",
                            " the",
                            " ones",
                            " that",
                            " break",
                            " down",
                            " the",
                            " nutrients",
                            " and",
                            " make",
                            " them",
                            " available",
                            " for",
                            " the",
                            " plants",
                            " to",
                            " grow",
                            ".\"",
                            "\n",
                            "\n",
                            "To",
                            " preserve",
                            " root",
                            " structure",
                            " and",
                            " stop",
                            " erosion",
                            ",",
                            " the",
                            " Agriculture",
                            " Center",
                            " is",
                            " teaching",
                            " the",
                            " farmers",
                            " of",
                            " tomorrow",
                            " about",
                            " no",
                            "-",
                            "t",
                            "ill",
                            " and",
                            " cover",
                            " crop",
                            " agriculture",
                            ".",
                            " With",
                            " no",
                            "-",
                            "t",
                            "ill",
                            " farming",
                            ",",
                            " the",
                            " soil",
                            " isn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " pl",
                            "owed",
                            " between",
                            " har",
                            "v",
                            "ests",
                            " from",
                            " year",
                            " to",
                            " year",
                            ".",
                            " Instead",
                            " farmers",
                            " use",
                            " special",
                            " tools",
                            " to",
                            " plant",
                            " seeds"
                        ],
                        "dataIndex": null,
                        "index": "39454",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 18.089,
                        "maxValueTokenIndex": 79,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            4.433,
                            0,
                            7.011,
                            18.089,
                            9.068,
                            1.01,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:09:39.963Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 18.089,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clxk6nwvtc08ci666uw7foeds",
                        "tokens": [
                            "School",
                            " is",
                            " back",
                            " in",
                            " session",
                            ",",
                            " college",
                            " and",
                            " pro",
                            " football",
                            " is",
                            " upon",
                            " us",
                            ",",
                            " and",
                            " in",
                            " some",
                            " places",
                            " that",
                            " means",
                            " fall",
                            " is",
                            " right",
                            " around",
                            " the",
                            " corner",
                            ".",
                            " Cool",
                            "er",
                            " weather",
                            ",",
                            " heart",
                            "ier",
                            " food",
                            ",",
                            " swe",
                            "aters",
                            " (",
                            "though",
                            " we",
                            " hear",
                            " sweater",
                            " v",
                            "ests",
                            " are",
                            " out",
                            " this",
                            " season",
                            "),",
                            " and",
                            " a",
                            " decreased",
                            " need",
                            " for",
                            " cold",
                            " beer",
                            ".",
                            " Here",
                            ",",
                            " however",
                            ",",
                            " we",
                            "'re",
                            " getting",
                            " hit",
                            " by",
                            " wave",
                            " after",
                            " wave",
                            " of",
                            " heat",
                            ",",
                            " and",
                            " September",
                            " doesn",
                            "'t",
                            " mean",
                            " much",
                            " beyond",
                            " more",
                            " weekend",
                            " hours",
                            " spent",
                            " indoors",
                            " watching",
                            " football",
                            ".",
                            " To",
                            " help",
                            " you",
                            " beat",
                            " the",
                            " heat",
                            " and",
                            " kick",
                            " your",
                            " g",
                            "amed",
                            "ays",
                            " up",
                            " a",
                            " notch",
                            ",",
                            " we",
                            "'re",
                            " prepared",
                            " to",
                            " share",
                            " with",
                            " you",
                            " our",
                            " latest",
                            " discovery",
                            ":",
                            " beer",
                            " pops",
                            "icles",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " you",
                            " ever",
                            " turned",
                            " juice",
                            " into",
                            " pops"
                        ],
                        "dataIndex": null,
                        "index": "39454",
                        "layer": "8-res_fs49152-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 16.97,
                        "maxValueTokenIndex": 104,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0.008,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.416,
                            3.508,
                            15.904,
                            16.97,
                            10.272,
                            4.032,
                            3.605,
                            0,
                            2.016,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-06-18T09:09:39.963Z",
                        "lossValues": [],
                        "logitContributions": "{\"pos\": [], \"neg\": []}",
                        "binMin": -1,
                        "binMax": 18.089,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "26042",
            "description": "elements of community engagement and the sharing of experiences",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4867713451385498,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "26042",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:02:05.770Z",
                "maxActApprox": 19.514,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    26042,
                    67711,
                    64626,
                    11130,
                    11297,
                    13612,
                    70229,
                    67492,
                    42974,
                    48970,
                    30798,
                    45820,
                    4520,
                    14442,
                    35412,
                    72391,
                    18846,
                    13955,
                    49301,
                    43975,
                    87612,
                    27879,
                    35115,
                    90858,
                    66777
                ],
                "topkCosSimValues": [
                    1,
                    0.5922,
                    0.5588,
                    0.5394,
                    0.5099,
                    0.4771,
                    0.4515,
                    0.4509,
                    0.4446,
                    0.4372,
                    0.433,
                    0.4311,
                    0.4295,
                    0.4276,
                    0.4273,
                    0.4244,
                    0.4223,
                    0.4201,
                    0.417,
                    0.4164,
                    0.4007,
                    0.3931,
                    0.3898,
                    0.3879,
                    0.3875
                ],
                "neuron_alignment_indices": [
                    393,
                    447,
                    427
                ],
                "neuron_alignment_values": [
                    0.117,
                    0.105,
                    0.102
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    43,
                    297,
                    720
                ],
                "correlated_neurons_pearson": [
                    0.071,
                    0.062,
                    0.056
                ],
                "correlated_neurons_l1": [
                    0.064,
                    0.06,
                    0.06
                ],
                "correlated_features_indices": [
                    25961,
                    25920,
                    25968
                ],
                "correlated_features_pearson": [
                    0.005,
                    0.002,
                    0.002
                ],
                "correlated_features_l1": [
                    0.006,
                    0.003,
                    0.003
                ],
                "neg_str": [
                    "uscript",
                    ")\u2014",
                    "\u2014",
                    "\"\u2014",
                    "\u00c5\u00ab",
                    "\u2014\"",
                    " Rodham",
                    "Enlarge",
                    "Newsletter",
                    " \u00c2\u0143"
                ],
                "neg_values": [
                    -0.786,
                    -0.772,
                    -0.771,
                    -0.711,
                    -0.689,
                    -0.68,
                    -0.662,
                    -0.641,
                    -0.641,
                    -0.639
                ],
                "pos_str": [
                    " ie",
                    " haha",
                    " etc",
                    " namely",
                    " Whilst",
                    " thats",
                    " BUT",
                    " whilst",
                    " whereas",
                    " whats"
                ],
                "pos_values": [
                    1.153,
                    1.123,
                    1.115,
                    1.082,
                    1.069,
                    1.063,
                    1.033,
                    1.029,
                    0.978,
                    0.951
                ],
                "frac_nonzero": 0.00368,
                "freq_hist_data_bar_heights": [
                    2147,
                    1779,
                    1415,
                    1157,
                    935,
                    789,
                    600,
                    513,
                    418,
                    330,
                    259,
                    185,
                    200,
                    132,
                    105,
                    118,
                    95,
                    55,
                    68,
                    51,
                    39,
                    31,
                    29,
                    24,
                    21,
                    16,
                    14,
                    10,
                    9,
                    5,
                    3,
                    4,
                    4,
                    3,
                    2,
                    1,
                    0,
                    3,
                    2,
                    2,
                    0,
                    1,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.195,
                    0.585,
                    0.976,
                    1.366,
                    1.756,
                    2.147,
                    2.537,
                    2.927,
                    3.317,
                    3.708,
                    4.098,
                    4.488,
                    4.878,
                    5.269,
                    5.659,
                    6.049,
                    6.44,
                    6.83,
                    7.22,
                    7.61,
                    8.001,
                    8.391,
                    8.781,
                    9.172,
                    9.562,
                    9.952,
                    10.342,
                    10.733,
                    11.123,
                    11.513,
                    11.903,
                    12.294,
                    12.684,
                    13.074,
                    13.465,
                    13.855,
                    14.245,
                    14.635,
                    15.026,
                    15.416,
                    15.806,
                    16.196,
                    16.587,
                    16.977,
                    17.367,
                    17.758,
                    18.148,
                    18.538,
                    18.928,
                    19.319
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    1,
                    2,
                    5,
                    6,
                    11,
                    19,
                    34,
                    45,
                    139,
                    268,
                    469,
                    821,
                    1261,
                    1856,
                    2645,
                    3403,
                    4156,
                    4728,
                    4941,
                    4737,
                    4389,
                    3968,
                    3356,
                    2572,
                    2018,
                    1395,
                    1009,
                    635,
                    432,
                    324,
                    195,
                    120,
                    89,
                    61,
                    31,
                    36,
                    20,
                    11,
                    10,
                    13,
                    2,
                    5,
                    4,
                    3,
                    1,
                    2,
                    2,
                    1,
                    3
                ],
                "logits_hist_data_bar_values": [
                    -0.766,
                    -0.727,
                    -0.689,
                    -0.65,
                    -0.611,
                    -0.572,
                    -0.534,
                    -0.495,
                    -0.456,
                    -0.417,
                    -0.379,
                    -0.34,
                    -0.301,
                    -0.262,
                    -0.224,
                    -0.185,
                    -0.146,
                    -0.107,
                    -0.068,
                    -0.03,
                    0.009,
                    0.048,
                    0.087,
                    0.125,
                    0.164,
                    0.203,
                    0.242,
                    0.28,
                    0.319,
                    0.358,
                    0.397,
                    0.436,
                    0.474,
                    0.513,
                    0.552,
                    0.591,
                    0.629,
                    0.668,
                    0.707,
                    0.746,
                    0.784,
                    0.823,
                    0.862,
                    0.901,
                    0.939,
                    0.978,
                    1.017,
                    1.056,
                    1.095,
                    1.133
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": "phrases indicating various states of development and communication issues within a community",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "elements of community engagement and the sharing of experiences",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygg3df6v0um10exb9vo5xq3",
                        "tokens": [
                            " be",
                            " more",
                            " commun",
                            "icative",
                            " on",
                            " what",
                            " is",
                            " going",
                            " on",
                            " with",
                            " the",
                            " community",
                            ",",
                            " right",
                            " now",
                            ",",
                            " all",
                            " del",
                            "phi",
                            " user",
                            " never",
                            " get",
                            " any",
                            " information",
                            " on",
                            " what",
                            " will",
                            " be",
                            " planned",
                            " on",
                            " the",
                            " next",
                            " release",
                            " until",
                            " near",
                            " the",
                            " release",
                            " date",
                            ",",
                            " well",
                            " it",
                            " is",
                            " impossible",
                            " to",
                            " develop",
                            " del",
                            "phi",
                            " only",
                            " within",
                            " a",
                            " month",
                            " or",
                            " two",
                            " before",
                            " release",
                            " right",
                            "?",
                            " so",
                            " i",
                            "'m",
                            " pretty",
                            " sure",
                            " you",
                            " have",
                            " a",
                            " release",
                            " plan",
                            " list",
                            ",",
                            " right",
                            " now",
                            " del",
                            "phi",
                            " still",
                            " have",
                            " a",
                            " lot",
                            " of",
                            " bugs",
                            " and",
                            " IDE",
                            " stability",
                            " issues",
                            ",",
                            " at",
                            " least",
                            " please",
                            " tell",
                            " us",
                            " what",
                            " bugs",
                            " is",
                            " planned",
                            " to",
                            " be",
                            " fixed",
                            ".",
                            " it",
                            " is",
                            " a",
                            " start",
                            " Well",
                            " sorry",
                            " for",
                            " long",
                            " comment",
                            ",",
                            " but",
                            " i",
                            " will",
                            " send",
                            " you",
                            " an",
                            " email",
                            " if",
                            " i",
                            "'ve",
                            " gathered",
                            " more",
                            " thought",
                            ".",
                            " Success",
                            " to",
                            " you",
                            ",",
                            " del",
                            "phi"
                        ],
                        "dataIndex": null,
                        "index": "26042",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 19.514,
                        "maxValueTokenIndex": 83,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.478,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.511,
                            0.357,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.31,
                            14.876,
                            0,
                            1.553,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.514,
                            4.788,
                            1.804,
                            0,
                            0,
                            0,
                            0,
                            0.597,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            8.081,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.941,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:02:15.435Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 19.514,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygg3df7v0ur10exsk4atg8u",
                        "tokens": [
                            " be",
                            " more",
                            " commun",
                            "icative",
                            " on",
                            " what",
                            " is",
                            " going",
                            " on",
                            " with",
                            " the",
                            " community",
                            ",",
                            " right",
                            " now",
                            ",",
                            " all",
                            " del",
                            "phi",
                            " user",
                            " never",
                            " get",
                            " any",
                            " information",
                            " on",
                            " what",
                            " will",
                            " be",
                            " planned",
                            " on",
                            " the",
                            " next",
                            " release",
                            " until",
                            " near",
                            " the",
                            " release",
                            " date",
                            ",",
                            " well",
                            " it",
                            " is",
                            " impossible",
                            " to",
                            " develop",
                            " del",
                            "phi",
                            " only",
                            " within",
                            " a",
                            " month",
                            " or",
                            " two",
                            " before",
                            " release",
                            " right",
                            "?",
                            " so",
                            " i",
                            "'m",
                            " pretty",
                            " sure",
                            " you",
                            " have",
                            " a",
                            " release",
                            " plan",
                            " list",
                            ",",
                            " right",
                            " now",
                            " del",
                            "phi",
                            " still",
                            " have",
                            " a",
                            " lot",
                            " of",
                            " bugs",
                            " and",
                            " IDE",
                            " stability",
                            " issues",
                            ",",
                            " at",
                            " least",
                            " please",
                            " tell",
                            " us",
                            " what",
                            " bugs",
                            " is",
                            " planned",
                            " to",
                            " be",
                            " fixed",
                            ".",
                            " it",
                            " is",
                            " a",
                            " start",
                            " Well",
                            " sorry",
                            " for",
                            " long",
                            " comment",
                            ",",
                            " but",
                            " i",
                            " will",
                            " send",
                            " you",
                            " an",
                            " email",
                            " if",
                            " i",
                            "'ve",
                            " gathered",
                            " more",
                            " thought",
                            ".",
                            " Success",
                            " to",
                            " you",
                            ",",
                            " del",
                            "phi"
                        ],
                        "dataIndex": null,
                        "index": "26042",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 19.514,
                        "maxValueTokenIndex": 83,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.478,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.511,
                            0.357,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.31,
                            14.876,
                            0,
                            1.553,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.514,
                            4.788,
                            1.804,
                            0,
                            0,
                            0,
                            0,
                            0.597,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            8.081,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.941,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:02:15.435Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 19.514,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygg3df8v0v610ex4cvxwv1k",
                        "tokens": [
                            " be",
                            " more",
                            " commun",
                            "icative",
                            " on",
                            " what",
                            " is",
                            " going",
                            " on",
                            " with",
                            " the",
                            " community",
                            ",",
                            " right",
                            " now",
                            ",",
                            " all",
                            " del",
                            "phi",
                            " user",
                            " never",
                            " get",
                            " any",
                            " information",
                            " on",
                            " what",
                            " will",
                            " be",
                            " planned",
                            " on",
                            " the",
                            " next",
                            " release",
                            " until",
                            " near",
                            " the",
                            " release",
                            " date",
                            ",",
                            " well",
                            " it",
                            " is",
                            " impossible",
                            " to",
                            " develop",
                            " del",
                            "phi",
                            " only",
                            " within",
                            " a",
                            " month",
                            " or",
                            " two",
                            " before",
                            " release",
                            " right",
                            "?",
                            " so",
                            " i",
                            "'m",
                            " pretty",
                            " sure",
                            " you",
                            " have",
                            " a",
                            " release",
                            " plan",
                            " list",
                            ",",
                            " right",
                            " now",
                            " del",
                            "phi",
                            " still",
                            " have",
                            " a",
                            " lot",
                            " of",
                            " bugs",
                            " and",
                            " IDE",
                            " stability",
                            " issues",
                            ",",
                            " at",
                            " least",
                            " please",
                            " tell",
                            " us",
                            " what",
                            " bugs",
                            " is",
                            " planned",
                            " to",
                            " be",
                            " fixed",
                            ".",
                            " it",
                            " is",
                            " a",
                            " start",
                            " Well",
                            " sorry",
                            " for",
                            " long",
                            " comment",
                            ",",
                            " but",
                            " i",
                            " will",
                            " send",
                            " you",
                            " an",
                            " email",
                            " if",
                            " i",
                            "'ve",
                            " gathered",
                            " more",
                            " thought",
                            ".",
                            " Success",
                            " to",
                            " you",
                            ",",
                            " del",
                            "phi"
                        ],
                        "dataIndex": null,
                        "index": "26042",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 19.514,
                        "maxValueTokenIndex": 83,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            12.478,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.511,
                            0.357,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.31,
                            14.876,
                            0,
                            1.553,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            19.514,
                            4.788,
                            1.804,
                            0,
                            0,
                            0,
                            0,
                            0.597,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            8.081,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            3.941,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:02:15.435Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 15.611,
                        "binMax": 19.514,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "1881",
            "description": "collaborative efforts and teamwork",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.48050636053085327,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "1881",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T22:30:45.907Z",
                "maxActApprox": 23.408,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    1881,
                    6549,
                    26699,
                    46943,
                    97502,
                    27187,
                    59586,
                    34786,
                    51949,
                    37238,
                    86175,
                    79432,
                    29464,
                    79049,
                    15976,
                    59732,
                    77394,
                    72454,
                    29878,
                    52518,
                    16594,
                    42297,
                    51037,
                    20674,
                    27567
                ],
                "topkCosSimValues": [
                    1,
                    0.5331,
                    0.5065,
                    0.4959,
                    0.4838,
                    0.4802,
                    0.4543,
                    0.4208,
                    0.409,
                    0.4063,
                    0.4057,
                    0.4023,
                    0.393,
                    0.3885,
                    0.3827,
                    0.3778,
                    0.3759,
                    0.3739,
                    0.3725,
                    0.3707,
                    0.3625,
                    0.3602,
                    0.3545,
                    0.3538,
                    0.3506
                ],
                "neuron_alignment_indices": [
                    295,
                    656,
                    317
                ],
                "neuron_alignment_values": [
                    0.113,
                    0.106,
                    0.095
                ],
                "neuron_alignment_l1": [
                    0.005,
                    0.005,
                    0.004
                ],
                "correlated_neurons_indices": [
                    391,
                    295,
                    765
                ],
                "correlated_neurons_pearson": [
                    0.016,
                    0.015,
                    0.013
                ],
                "correlated_neurons_l1": [
                    0.012,
                    0.014,
                    0.014
                ],
                "correlated_features_indices": [
                    1857,
                    1915,
                    1938
                ],
                "correlated_features_pearson": [
                    0.003,
                    0.001,
                    0.001
                ],
                "correlated_features_l1": [
                    0.003,
                    0.002,
                    0.001
                ],
                "neg_str": [
                    " purity",
                    "dos",
                    " unanswered",
                    "void",
                    "going",
                    " equival",
                    "arer",
                    " consequence",
                    " Errors",
                    " consequences"
                ],
                "neg_values": [
                    -0.7,
                    -0.695,
                    -0.683,
                    -0.648,
                    -0.626,
                    -0.611,
                    -0.609,
                    -0.607,
                    -0.605,
                    -0.604
                ],
                "pos_str": [
                    " teamed",
                    " together",
                    " jointly",
                    "ortium",
                    " hatched",
                    " forces",
                    "raft",
                    " collabor",
                    " collaborated",
                    " brainstorm"
                ],
                "pos_values": [
                    0.847,
                    0.803,
                    0.759,
                    0.726,
                    0.702,
                    0.698,
                    0.697,
                    0.677,
                    0.674,
                    0.667
                ],
                "frac_nonzero": 0.00022,
                "freq_hist_data_bar_heights": [
                    147,
                    123,
                    86,
                    49,
                    45,
                    47,
                    25,
                    24,
                    26,
                    17,
                    11,
                    11,
                    3,
                    7,
                    6,
                    3,
                    8,
                    4,
                    2,
                    1,
                    1,
                    1,
                    3,
                    2,
                    2,
                    2,
                    3,
                    1,
                    5,
                    3,
                    1,
                    2,
                    2,
                    1,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    0,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.239,
                    0.707,
                    1.175,
                    1.643,
                    2.111,
                    2.579,
                    3.047,
                    3.515,
                    3.983,
                    4.452,
                    4.92,
                    5.388,
                    5.856,
                    6.324,
                    6.792,
                    7.26,
                    7.728,
                    8.196,
                    8.664,
                    9.132,
                    9.6,
                    10.068,
                    10.536,
                    11.004,
                    11.472,
                    11.94,
                    12.409,
                    12.877,
                    13.345,
                    13.813,
                    14.281,
                    14.749,
                    15.217,
                    15.685,
                    16.153,
                    16.621,
                    17.089,
                    17.557,
                    18.025,
                    18.493,
                    18.961,
                    19.429,
                    19.897,
                    20.366,
                    20.834,
                    21.302,
                    21.77,
                    22.238,
                    22.706,
                    23.174
                ],
                "logits_hist_data_bar_heights": [
                    3,
                    1,
                    3,
                    10,
                    18,
                    28,
                    59,
                    65,
                    123,
                    196,
                    339,
                    443,
                    612,
                    822,
                    1120,
                    1486,
                    1801,
                    2302,
                    2752,
                    3122,
                    3475,
                    3752,
                    3898,
                    3915,
                    3622,
                    3347,
                    2943,
                    2522,
                    1909,
                    1580,
                    1249,
                    796,
                    619,
                    463,
                    302,
                    198,
                    139,
                    71,
                    44,
                    38,
                    29,
                    17,
                    8,
                    5,
                    4,
                    3,
                    1,
                    1,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.684,
                    -0.654,
                    -0.623,
                    -0.592,
                    -0.561,
                    -0.53,
                    -0.499,
                    -0.468,
                    -0.437,
                    -0.406,
                    -0.375,
                    -0.344,
                    -0.313,
                    -0.282,
                    -0.251,
                    -0.22,
                    -0.189,
                    -0.158,
                    -0.127,
                    -0.096,
                    -0.066,
                    -0.035,
                    -0.004,
                    0.027,
                    0.058,
                    0.089,
                    0.12,
                    0.151,
                    0.182,
                    0.213,
                    0.244,
                    0.275,
                    0.306,
                    0.337,
                    0.368,
                    0.399,
                    0.43,
                    0.461,
                    0.492,
                    0.522,
                    0.553,
                    0.584,
                    0.615,
                    0.646,
                    0.677,
                    0.708,
                    0.739,
                    0.77,
                    0.801,
                    0.832
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " cooperative actions and collaborations between different groups or individuals",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "collaborative efforts and teamwork",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygeyxy4cr5n10exmuupvcyd",
                        "tokens": [
                            " wonderful",
                            " things",
                            " happened",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Hughes",
                            " told",
                            " Autom",
                            "otive",
                            " News",
                            ".",
                            "\n",
                            "\n",
                            "Car",
                            " News",
                            " Jaguar",
                            " and",
                            " Land",
                            " Rover",
                            " want",
                            " to",
                            " make",
                            " paying",
                            " for",
                            " gas",
                            " easier",
                            " with",
                            " in",
                            "-",
                            "car",
                            " app",
                            " Pay",
                            "ing",
                            " for",
                            " gas",
                            " usually",
                            " isn",
                            "'t",
                            " a",
                            " huge",
                            " hassle",
                            " (",
                            "unless",
                            " you",
                            " have",
                            " to",
                            " stand",
                            " in",
                            " line",
                            " behind",
                            " someone",
                            " who",
                            "'s",
                            " buying",
                            " dozens",
                            " of",
                            " lottery",
                            " tickets",
                            ")",
                            " but",
                            " Jaguar",
                            " and",
                            " Shell",
                            " have",
                            " teamed",
                            " up",
                            " to",
                            " allow",
                            " drivers",
                            " to",
                            " make",
                            " ...",
                            "\n",
                            "\n",
                            "T",
                            "ough",
                            " odds",
                            "\n",
                            "\n",
                            "The",
                            " Rover",
                            " name",
                            " was",
                            " somewhat",
                            " tarn",
                            "ished",
                            " with",
                            " American",
                            " buyers",
                            ".",
                            " In",
                            " 1973",
                            ",",
                            " British",
                            " Ley",
                            "land",
                            ",",
                            " then",
                            " owner",
                            " of",
                            " Land",
                            " Rover",
                            ",",
                            " suddenly",
                            " pulled",
                            " the",
                            " brand",
                            " out",
                            " of",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " market",
                            ",",
                            " leaving",
                            " many",
                            " of",
                            " its",
                            " dealers",
                            " with",
                            " nothing",
                            " to",
                            " sell",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "1881",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 23.408,
                        "maxValueTokenIndex": 66,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.598,
                            23.408,
                            3.317,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:30:49.150Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 18.726,
                        "binMax": 23.408,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygeyxy2cr5210exp5m80lzm",
                        "tokens": [
                            " wonderful",
                            " things",
                            " happened",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Hughes",
                            " told",
                            " Autom",
                            "otive",
                            " News",
                            ".",
                            "\n",
                            "\n",
                            "Car",
                            " News",
                            " Jaguar",
                            " and",
                            " Land",
                            " Rover",
                            " want",
                            " to",
                            " make",
                            " paying",
                            " for",
                            " gas",
                            " easier",
                            " with",
                            " in",
                            "-",
                            "car",
                            " app",
                            " Pay",
                            "ing",
                            " for",
                            " gas",
                            " usually",
                            " isn",
                            "'t",
                            " a",
                            " huge",
                            " hassle",
                            " (",
                            "unless",
                            " you",
                            " have",
                            " to",
                            " stand",
                            " in",
                            " line",
                            " behind",
                            " someone",
                            " who",
                            "'s",
                            " buying",
                            " dozens",
                            " of",
                            " lottery",
                            " tickets",
                            ")",
                            " but",
                            " Jaguar",
                            " and",
                            " Shell",
                            " have",
                            " teamed",
                            " up",
                            " to",
                            " allow",
                            " drivers",
                            " to",
                            " make",
                            " ...",
                            "\n",
                            "\n",
                            "T",
                            "ough",
                            " odds",
                            "\n",
                            "\n",
                            "The",
                            " Rover",
                            " name",
                            " was",
                            " somewhat",
                            " tarn",
                            "ished",
                            " with",
                            " American",
                            " buyers",
                            ".",
                            " In",
                            " 1973",
                            ",",
                            " British",
                            " Ley",
                            "land",
                            ",",
                            " then",
                            " owner",
                            " of",
                            " Land",
                            " Rover",
                            ",",
                            " suddenly",
                            " pulled",
                            " the",
                            " brand",
                            " out",
                            " of",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " market",
                            ",",
                            " leaving",
                            " many",
                            " of",
                            " its",
                            " dealers",
                            " with",
                            " nothing",
                            " to",
                            " sell",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "1881",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 23.408,
                        "maxValueTokenIndex": 66,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.598,
                            23.408,
                            3.317,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:30:49.150Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 23.408,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygeyxy5cr5w10ex5al8jxsf",
                        "tokens": [
                            " wonderful",
                            " things",
                            " happened",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " Hughes",
                            " told",
                            " Autom",
                            "otive",
                            " News",
                            ".",
                            "\n",
                            "\n",
                            "Car",
                            " News",
                            " Jaguar",
                            " and",
                            " Land",
                            " Rover",
                            " want",
                            " to",
                            " make",
                            " paying",
                            " for",
                            " gas",
                            " easier",
                            " with",
                            " in",
                            "-",
                            "car",
                            " app",
                            " Pay",
                            "ing",
                            " for",
                            " gas",
                            " usually",
                            " isn",
                            "'t",
                            " a",
                            " huge",
                            " hassle",
                            " (",
                            "unless",
                            " you",
                            " have",
                            " to",
                            " stand",
                            " in",
                            " line",
                            " behind",
                            " someone",
                            " who",
                            "'s",
                            " buying",
                            " dozens",
                            " of",
                            " lottery",
                            " tickets",
                            ")",
                            " but",
                            " Jaguar",
                            " and",
                            " Shell",
                            " have",
                            " teamed",
                            " up",
                            " to",
                            " allow",
                            " drivers",
                            " to",
                            " make",
                            " ...",
                            "\n",
                            "\n",
                            "T",
                            "ough",
                            " odds",
                            "\n",
                            "\n",
                            "The",
                            " Rover",
                            " name",
                            " was",
                            " somewhat",
                            " tarn",
                            "ished",
                            " with",
                            " American",
                            " buyers",
                            ".",
                            " In",
                            " 1973",
                            ",",
                            " British",
                            " Ley",
                            "land",
                            ",",
                            " then",
                            " owner",
                            " of",
                            " Land",
                            " Rover",
                            ",",
                            " suddenly",
                            " pulled",
                            " the",
                            " brand",
                            " out",
                            " of",
                            " the",
                            " U",
                            ".",
                            "S",
                            ".",
                            " market",
                            ",",
                            " leaving",
                            " many",
                            " of",
                            " its",
                            " dealers",
                            " with",
                            " nothing",
                            " to",
                            " sell",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "1881",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 23.408,
                        "maxValueTokenIndex": 66,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            11.598,
                            23.408,
                            3.317,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T22:30:49.150Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 9.363,
                        "binMax": 14.045,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "79777",
            "description": " references to academic debates or discussions related to education and learning outcomes",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.47333760480098763,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "79777",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:09:25.866Z",
                "maxActApprox": 46.046,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    79777,
                    51084,
                    53814,
                    40754,
                    59252,
                    5026,
                    83595,
                    32144,
                    49770,
                    17453,
                    70977,
                    71278,
                    75023,
                    24270,
                    33228,
                    51197,
                    74403,
                    64967,
                    26628,
                    51055,
                    97149,
                    65469,
                    10630,
                    83348,
                    46351
                ],
                "topkCosSimValues": [
                    1,
                    0.5965,
                    0.586,
                    0.5614,
                    0.5049,
                    0.5007,
                    0.487,
                    0.4869,
                    0.4615,
                    0.4569,
                    0.4536,
                    0.4485,
                    0.442,
                    0.4391,
                    0.4363,
                    0.4356,
                    0.4295,
                    0.4293,
                    0.4201,
                    0.4139,
                    0.3964,
                    0.3958,
                    0.3839,
                    0.3827,
                    0.3718
                ],
                "neuron_alignment_indices": [
                    302,
                    71,
                    132
                ],
                "neuron_alignment_values": [
                    0.143,
                    0.126,
                    0.106
                ],
                "neuron_alignment_l1": [
                    0.007,
                    0.006,
                    0.005
                ],
                "correlated_neurons_indices": [
                    302,
                    52,
                    280
                ],
                "correlated_neurons_pearson": [
                    0.021,
                    0.02,
                    0.019
                ],
                "correlated_neurons_l1": [
                    0.023,
                    0.02,
                    0.02
                ],
                "correlated_features_indices": [
                    79798,
                    79851,
                    79823
                ],
                "correlated_features_pearson": [
                    0,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.001,
                    0,
                    0
                ],
                "neg_str": [
                    " unwanted",
                    " SERV",
                    "istries",
                    " listener",
                    "iences",
                    " ende",
                    "odo",
                    "vier",
                    "\u00e3\u0125\u0128",
                    "oe"
                ],
                "neg_values": [
                    -0.586,
                    -0.581,
                    -0.574,
                    -0.567,
                    -0.566,
                    -0.563,
                    -0.559,
                    -0.541,
                    -0.539,
                    -0.538
                ],
                "pos_str": [
                    " ,",
                    "*.",
                    " onwards",
                    " .",
                    "theless",
                    "externalActionCode",
                    "\u00e2\u0128",
                    " Conversely",
                    " Similarly",
                    "figure"
                ],
                "pos_values": [
                    0.861,
                    0.807,
                    0.766,
                    0.708,
                    0.705,
                    0.685,
                    0.684,
                    0.653,
                    0.64,
                    0.634
                ],
                "frac_nonzero": 0.00031,
                "freq_hist_data_bar_heights": [
                    203,
                    138,
                    101,
                    66,
                    66,
                    50,
                    33,
                    34,
                    29,
                    23,
                    17,
                    23,
                    17,
                    13,
                    14,
                    9,
                    9,
                    6,
                    10,
                    6,
                    6,
                    8,
                    4,
                    4,
                    4,
                    5,
                    9,
                    4,
                    4,
                    4,
                    3,
                    3,
                    7,
                    3,
                    2,
                    4,
                    0,
                    1,
                    2,
                    3,
                    5,
                    2,
                    1,
                    2,
                    1,
                    4,
                    3,
                    1,
                    1,
                    3
                ],
                "freq_hist_data_bar_values": [
                    0.469,
                    1.39,
                    2.311,
                    3.232,
                    4.152,
                    5.073,
                    5.994,
                    6.915,
                    7.835,
                    8.756,
                    9.677,
                    10.598,
                    11.518,
                    12.439,
                    13.36,
                    14.281,
                    15.201,
                    16.122,
                    17.043,
                    17.964,
                    18.884,
                    19.805,
                    20.726,
                    21.647,
                    22.567,
                    23.488,
                    24.409,
                    25.33,
                    26.25,
                    27.171,
                    28.092,
                    29.013,
                    29.933,
                    30.854,
                    31.775,
                    32.696,
                    33.616,
                    34.537,
                    35.458,
                    36.379,
                    37.299,
                    38.22,
                    39.141,
                    40.062,
                    40.982,
                    41.903,
                    42.824,
                    43.745,
                    44.665,
                    45.586
                ],
                "logits_hist_data_bar_heights": [
                    7,
                    4,
                    7,
                    20,
                    27,
                    58,
                    99,
                    163,
                    246,
                    401,
                    585,
                    921,
                    1234,
                    1600,
                    2173,
                    2701,
                    3182,
                    3571,
                    3870,
                    3879,
                    3863,
                    3838,
                    3419,
                    3046,
                    2614,
                    2138,
                    1725,
                    1324,
                    989,
                    783,
                    559,
                    400,
                    263,
                    169,
                    117,
                    87,
                    49,
                    43,
                    29,
                    19,
                    11,
                    14,
                    3,
                    2,
                    2,
                    0,
                    1,
                    0,
                    1,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.571,
                    -0.542,
                    -0.513,
                    -0.485,
                    -0.456,
                    -0.427,
                    -0.398,
                    -0.369,
                    -0.34,
                    -0.311,
                    -0.282,
                    -0.253,
                    -0.224,
                    -0.195,
                    -0.166,
                    -0.137,
                    -0.108,
                    -0.079,
                    -0.051,
                    -0.022,
                    0.007,
                    0.036,
                    0.065,
                    0.094,
                    0.123,
                    0.152,
                    0.181,
                    0.21,
                    0.239,
                    0.268,
                    0.297,
                    0.326,
                    0.354,
                    0.383,
                    0.412,
                    0.441,
                    0.47,
                    0.499,
                    0.528,
                    0.557,
                    0.586,
                    0.615,
                    0.644,
                    0.673,
                    0.702,
                    0.731,
                    0.759,
                    0.788,
                    0.817,
                    0.846
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " references to academic debates or discussions related to education and learning outcomes",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygiht03ztjf10exdxnr7g8w",
                        "tokens": [
                            " triggered",
                            " inhibition",
                            " used",
                            " stop",
                            " tasks",
                            " and",
                            " Go",
                            "/",
                            "No",
                            "Go",
                            " tasks",
                            " in",
                            " which",
                            " prep",
                            "otent",
                            " actions",
                            " had",
                            " to",
                            " be",
                            " inhibited",
                            " in",
                            " response",
                            " to",
                            " a",
                            " stimulus",
                            ".",
                            " These",
                            " external",
                            " inhibition",
                            " processes",
                            " have",
                            " been",
                            " associated",
                            " with",
                            " activation",
                            " in",
                            " the",
                            " lateral",
                            " prefrontal",
                            " cortex",
                            ",",
                            " most",
                            " prominently",
                            " the",
                            " right",
                            " inferior",
                            " frontal",
                            " g",
                            "yrus",
                            " [",
                            "22",
                            "]",
                            "\u2013",
                            "[",
                            "24",
                            "].",
                            " In",
                            " line",
                            " with",
                            " this",
                            " distinction",
                            " functional",
                            " neuro",
                            "im",
                            "aging",
                            " studies",
                            " on",
                            " emotion",
                            " regulation",
                            " have",
                            " predominantly",
                            " reported",
                            " the",
                            " involvement",
                            " of",
                            " lateral",
                            " but",
                            " also",
                            " of",
                            " medial",
                            " prefrontal",
                            " cortex",
                            " when",
                            " participants",
                            " were",
                            " instructed",
                            " to",
                            " use",
                            " strategies",
                            " to",
                            " reduce",
                            " negative",
                            " emotional",
                            " experiences",
                            " [",
                            "25",
                            "]",
                            "\u2013",
                            "[",
                            "28",
                            "].",
                            " The",
                            " involvement",
                            " of",
                            " lateral",
                            " prefrontal",
                            " cortex",
                            " might",
                            " be",
                            " explained",
                            " by",
                            " the",
                            " fact",
                            " that",
                            " participants",
                            " were",
                            " prompted",
                            " to",
                            " suppress",
                            " emotions",
                            " externally",
                            ".",
                            " Based",
                            " on",
                            " the",
                            " neural",
                            " diss"
                        ],
                        "dataIndex": null,
                        "index": "79777",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.046,
                        "maxValueTokenIndex": 51,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.046,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.217,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:09:28.030Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 46.046,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiht03ztjk10exz1aokdwy",
                        "tokens": [
                            " triggered",
                            " inhibition",
                            " used",
                            " stop",
                            " tasks",
                            " and",
                            " Go",
                            "/",
                            "No",
                            "Go",
                            " tasks",
                            " in",
                            " which",
                            " prep",
                            "otent",
                            " actions",
                            " had",
                            " to",
                            " be",
                            " inhibited",
                            " in",
                            " response",
                            " to",
                            " a",
                            " stimulus",
                            ".",
                            " These",
                            " external",
                            " inhibition",
                            " processes",
                            " have",
                            " been",
                            " associated",
                            " with",
                            " activation",
                            " in",
                            " the",
                            " lateral",
                            " prefrontal",
                            " cortex",
                            ",",
                            " most",
                            " prominently",
                            " the",
                            " right",
                            " inferior",
                            " frontal",
                            " g",
                            "yrus",
                            " [",
                            "22",
                            "]",
                            "\u2013",
                            "[",
                            "24",
                            "].",
                            " In",
                            " line",
                            " with",
                            " this",
                            " distinction",
                            " functional",
                            " neuro",
                            "im",
                            "aging",
                            " studies",
                            " on",
                            " emotion",
                            " regulation",
                            " have",
                            " predominantly",
                            " reported",
                            " the",
                            " involvement",
                            " of",
                            " lateral",
                            " but",
                            " also",
                            " of",
                            " medial",
                            " prefrontal",
                            " cortex",
                            " when",
                            " participants",
                            " were",
                            " instructed",
                            " to",
                            " use",
                            " strategies",
                            " to",
                            " reduce",
                            " negative",
                            " emotional",
                            " experiences",
                            " [",
                            "25",
                            "]",
                            "\u2013",
                            "[",
                            "28",
                            "].",
                            " The",
                            " involvement",
                            " of",
                            " lateral",
                            " prefrontal",
                            " cortex",
                            " might",
                            " be",
                            " explained",
                            " by",
                            " the",
                            " fact",
                            " that",
                            " participants",
                            " were",
                            " prompted",
                            " to",
                            " suppress",
                            " emotions",
                            " externally",
                            ".",
                            " Based",
                            " on",
                            " the",
                            " neural",
                            " diss"
                        ],
                        "dataIndex": null,
                        "index": "79777",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.046,
                        "maxValueTokenIndex": 51,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.046,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.217,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:09:28.030Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 46.046,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygiht05ztk110ex6dtqcdke",
                        "tokens": [
                            " triggered",
                            " inhibition",
                            " used",
                            " stop",
                            " tasks",
                            " and",
                            " Go",
                            "/",
                            "No",
                            "Go",
                            " tasks",
                            " in",
                            " which",
                            " prep",
                            "otent",
                            " actions",
                            " had",
                            " to",
                            " be",
                            " inhibited",
                            " in",
                            " response",
                            " to",
                            " a",
                            " stimulus",
                            ".",
                            " These",
                            " external",
                            " inhibition",
                            " processes",
                            " have",
                            " been",
                            " associated",
                            " with",
                            " activation",
                            " in",
                            " the",
                            " lateral",
                            " prefrontal",
                            " cortex",
                            ",",
                            " most",
                            " prominently",
                            " the",
                            " right",
                            " inferior",
                            " frontal",
                            " g",
                            "yrus",
                            " [",
                            "22",
                            "]",
                            "\u2013",
                            "[",
                            "24",
                            "].",
                            " In",
                            " line",
                            " with",
                            " this",
                            " distinction",
                            " functional",
                            " neuro",
                            "im",
                            "aging",
                            " studies",
                            " on",
                            " emotion",
                            " regulation",
                            " have",
                            " predominantly",
                            " reported",
                            " the",
                            " involvement",
                            " of",
                            " lateral",
                            " but",
                            " also",
                            " of",
                            " medial",
                            " prefrontal",
                            " cortex",
                            " when",
                            " participants",
                            " were",
                            " instructed",
                            " to",
                            " use",
                            " strategies",
                            " to",
                            " reduce",
                            " negative",
                            " emotional",
                            " experiences",
                            " [",
                            "25",
                            "]",
                            "\u2013",
                            "[",
                            "28",
                            "].",
                            " The",
                            " involvement",
                            " of",
                            " lateral",
                            " prefrontal",
                            " cortex",
                            " might",
                            " be",
                            " explained",
                            " by",
                            " the",
                            " fact",
                            " that",
                            " participants",
                            " were",
                            " prompted",
                            " to",
                            " suppress",
                            " emotions",
                            " externally",
                            ".",
                            " Based",
                            " on",
                            " the",
                            " neural",
                            " diss"
                        ],
                        "dataIndex": null,
                        "index": "79777",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 46.046,
                        "maxValueTokenIndex": 51,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            46.046,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.217,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:09:28.030Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 36.837,
                        "binMax": 46.046,
                        "binContains": 1e-05,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "77000",
            "description": " experiences of learning and the acquisition of knowledge",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4729618712044885,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "77000",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-11T00:06:19.048Z",
                "maxActApprox": 44.612,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    77000,
                    44064,
                    32386,
                    13254,
                    62592,
                    32890,
                    1477,
                    34767,
                    54696,
                    96937,
                    15406,
                    71639,
                    31191,
                    11338,
                    67784,
                    38528,
                    50957,
                    62879,
                    65225,
                    3406,
                    68625,
                    23047,
                    69869,
                    27303,
                    17480
                ],
                "topkCosSimValues": [
                    1,
                    0.7421,
                    0.7363,
                    0.7182,
                    0.5699,
                    0.5634,
                    0.5619,
                    0.5074,
                    0.4857,
                    0.4841,
                    0.481,
                    0.4775,
                    0.4766,
                    0.4654,
                    0.4636,
                    0.4626,
                    0.4526,
                    0.4481,
                    0.4469,
                    0.4442,
                    0.4424,
                    0.4418,
                    0.4399,
                    0.4261,
                    0.4252
                ],
                "neuron_alignment_indices": [
                    679,
                    271,
                    288
                ],
                "neuron_alignment_values": [
                    0.128,
                    0.104,
                    0.101
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    271,
                    748,
                    62
                ],
                "correlated_neurons_pearson": [
                    0.028,
                    0.021,
                    0.021
                ],
                "correlated_neurons_l1": [
                    0.027,
                    0.018,
                    0.02
                ],
                "correlated_features_indices": [
                    76960,
                    77023,
                    76974
                ],
                "correlated_features_pearson": [
                    0.004,
                    0,
                    0
                ],
                "correlated_features_l1": [
                    0.004,
                    0.001,
                    0.001
                ],
                "neg_str": [
                    "etrical",
                    "ataka",
                    "oided",
                    "abwe",
                    "etric",
                    "idity",
                    "nic",
                    "oscope",
                    "ipping",
                    "adjusted"
                ],
                "neg_values": [
                    -0.716,
                    -0.69,
                    -0.673,
                    -0.655,
                    -0.641,
                    -0.634,
                    -0.633,
                    -0.63,
                    -0.628,
                    -0.628
                ],
                "pos_str": [
                    " firsthand",
                    " Curve",
                    " lessons",
                    "llor",
                    " about",
                    " how",
                    " Lauder",
                    " srfAttach",
                    " Teach",
                    ">("
                ],
                "pos_values": [
                    0.963,
                    0.784,
                    0.718,
                    0.707,
                    0.697,
                    0.693,
                    0.662,
                    0.655,
                    0.654,
                    0.647
                ],
                "frac_nonzero": 0.00021,
                "freq_hist_data_bar_heights": [
                    80,
                    50,
                    53,
                    34,
                    24,
                    22,
                    18,
                    18,
                    8,
                    13,
                    21,
                    6,
                    16,
                    10,
                    8,
                    6,
                    15,
                    7,
                    9,
                    6,
                    9,
                    16,
                    6,
                    6,
                    7,
                    14,
                    9,
                    8,
                    9,
                    11,
                    9,
                    7,
                    7,
                    6,
                    6,
                    11,
                    10,
                    11,
                    9,
                    10,
                    4,
                    7,
                    8,
                    4,
                    5,
                    5,
                    3,
                    3,
                    1,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.451,
                    1.343,
                    2.235,
                    3.127,
                    4.02,
                    4.912,
                    5.804,
                    6.696,
                    7.588,
                    8.48,
                    9.372,
                    10.265,
                    11.157,
                    12.049,
                    12.941,
                    13.833,
                    14.725,
                    15.618,
                    16.51,
                    17.402,
                    18.294,
                    19.186,
                    20.078,
                    20.97,
                    21.863,
                    22.755,
                    23.647,
                    24.539,
                    25.431,
                    26.323,
                    27.216,
                    28.108,
                    29,
                    29.892,
                    30.784,
                    31.676,
                    32.568,
                    33.461,
                    34.353,
                    35.245,
                    36.137,
                    37.029,
                    37.921,
                    38.814,
                    39.706,
                    40.598,
                    41.49,
                    42.382,
                    43.274,
                    44.166
                ],
                "logits_hist_data_bar_heights": [
                    2,
                    2,
                    8,
                    12,
                    18,
                    22,
                    48,
                    78,
                    124,
                    203,
                    276,
                    449,
                    661,
                    968,
                    1352,
                    1825,
                    2383,
                    3042,
                    3571,
                    4020,
                    4324,
                    4540,
                    4497,
                    3966,
                    3531,
                    2923,
                    2187,
                    1702,
                    1200,
                    834,
                    561,
                    343,
                    237,
                    137,
                    85,
                    36,
                    35,
                    22,
                    13,
                    7,
                    6,
                    2,
                    3,
                    0,
                    1,
                    0,
                    0,
                    0,
                    0,
                    1
                ],
                "logits_hist_data_bar_values": [
                    -0.699,
                    -0.666,
                    -0.632,
                    -0.599,
                    -0.565,
                    -0.531,
                    -0.498,
                    -0.464,
                    -0.431,
                    -0.397,
                    -0.363,
                    -0.33,
                    -0.296,
                    -0.263,
                    -0.229,
                    -0.196,
                    -0.162,
                    -0.128,
                    -0.095,
                    -0.061,
                    -0.028,
                    0.006,
                    0.04,
                    0.073,
                    0.107,
                    0.14,
                    0.174,
                    0.208,
                    0.241,
                    0.275,
                    0.308,
                    0.342,
                    0.375,
                    0.409,
                    0.443,
                    0.476,
                    0.51,
                    0.543,
                    0.577,
                    0.611,
                    0.644,
                    0.678,
                    0.711,
                    0.745,
                    0.778,
                    0.812,
                    0.846,
                    0.879,
                    0.913,
                    0.946
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " experiences of learning and the acquisition of knowledge",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": " instances of the word \"learned\" and its variations",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clygidwanxpp910ex3aoh0epu",
                        "tokens": [
                            " the",
                            " lengthy",
                            " legal",
                            " process",
                            " wore",
                            " on",
                            ",",
                            " the",
                            " options",
                            " for",
                            " his",
                            " freshman",
                            " year",
                            " of",
                            " college",
                            " were",
                            " limited",
                            " by",
                            " proximity",
                            " so",
                            " he",
                            " could",
                            " comply",
                            " with",
                            " subpoen",
                            "as",
                            " for",
                            " his",
                            " testimony",
                            ".",
                            "\u00e2\u0122",
                            "\u013f",
                            "\n",
                            "\n",
                            "Sh",
                            "asta",
                            " Bel",
                            "ty",
                            " says",
                            " her",
                            " son",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " senior",
                            " year",
                            " was",
                            " completely",
                            " tainted",
                            ".",
                            "\n",
                            "\n",
                            "\u00e2\u0122",
                            "\u013e",
                            "People",
                            " look",
                            " at",
                            " this",
                            " as",
                            ",",
                            " \u00e2\u0122",
                            "\u013a",
                            "I",
                            " don",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " know",
                            " why",
                            " he",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " complaining",
                            ",",
                            "\u00e2\u0122",
                            "\u013b",
                            " you",
                            " know",
                            "?",
                            " They",
                            " haven",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " been",
                            " in",
                            " our",
                            " shoes",
                            ".",
                            " \u00e2\u0122\u00a6",
                            " They",
                            " know",
                            " nothing",
                            " about",
                            " it",
                            ",",
                            "\u00e2\u0122",
                            "\u013f",
                            " she",
                            " said",
                            ".",
                            "\n",
                            "\n",
                            "Mrs",
                            ".",
                            " Bel",
                            "ty",
                            " told",
                            " KT",
                            "UL",
                            "-",
                            "TV",
                            " she",
                            " learned",
                            " of",
                            " the",
                            " sexual",
                            " relationship",
                            " with",
                            " a",
                            " phone",
                            " call",
                            " to",
                            " her",
                            " son",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 44.612,
                        "maxValueTokenIndex": 114,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            44.612,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygidwanxppa10exr8gs5d2p",
                        "tokens": [
                            " way",
                            ".",
                            " There",
                            " were",
                            " several",
                            " times",
                            " when",
                            " his",
                            " car",
                            " was",
                            " searched",
                            " from",
                            " bumper",
                            " to",
                            " bumper",
                            " yet",
                            " the",
                            " guards",
                            " did",
                            " not",
                            " seem",
                            " to",
                            " notice",
                            " the",
                            " B",
                            "ibles",
                            " in",
                            " plain",
                            " view",
                            " on",
                            " the",
                            " seat",
                            " beside",
                            " Brother",
                            " Andrew",
                            ".",
                            " At",
                            " one",
                            " time",
                            " he",
                            " was",
                            " talking",
                            " with",
                            " a",
                            " Russian",
                            " guard",
                            " and",
                            " commented",
                            " that",
                            " the",
                            " Russians",
                            " seemed",
                            " to",
                            " know",
                            " all",
                            " about",
                            " him",
                            ".",
                            " The",
                            " guard",
                            " told",
                            " him",
                            " that",
                            " God",
                            "'s",
                            " Sm",
                            "ugg",
                            "ler",
                            " was",
                            " required",
                            " reading",
                            " for",
                            " the",
                            " Russian",
                            " police",
                            ".",
                            " I",
                            " learned",
                            " so",
                            " much",
                            " listening",
                            " to",
                            " this",
                            " book",
                            " and",
                            " one",
                            " of",
                            " the",
                            " things",
                            " that",
                            " really",
                            " stuck",
                            " in",
                            " my",
                            " mind",
                            " was",
                            " the",
                            " fact",
                            " that",
                            " in",
                            " Bulgaria",
                            " there",
                            " are",
                            " churches",
                            " that",
                            " do",
                            " not",
                            " have",
                            " even",
                            " one",
                            " Bible",
                            ".",
                            " At",
                            " least",
                            " this",
                            " was",
                            " true",
                            " when",
                            " the",
                            " book",
                            " was",
                            " written",
                            " in",
                            " the",
                            " s",
                            "ixties",
                            "."
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 43.687,
                        "maxValueTokenIndex": 77,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            43.687,
                            0.09,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clygidwanxppb10ex6718jvxc",
                        "tokens": [
                            " why",
                            " the",
                            " Pepsi",
                            " was",
                            " in",
                            " such",
                            " poor",
                            " taste",
                            ".",
                            "\n",
                            "\n",
                            "If",
                            " only",
                            " Daddy",
                            " would",
                            " have",
                            " known",
                            " about",
                            " the",
                            " power",
                            " of",
                            " #",
                            "P",
                            "ep",
                            "si",
                            ".",
                            " pic",
                            ".",
                            "twitter",
                            ".",
                            "com",
                            "/",
                            "FA",
                            "6",
                            "J",
                            "Pr",
                            "Y",
                            "72",
                            "V",
                            " \u2014",
                            " Be",
                            " A",
                            " King",
                            " (@",
                            "Bern",
                            "ice",
                            "King",
                            ")",
                            " April",
                            " 5",
                            ",",
                            " 2017",
                            "\n",
                            "\n",
                            "We",
                            " also",
                            " learned",
                            " that",
                            " some",
                            " people",
                            " still",
                            " believe",
                            " that",
                            " Sony",
                            " is",
                            " advertising",
                            " the",
                            " PlayStation",
                            " Portable",
                            " in",
                            " 2017",
                            " ...",
                            " but",
                            " above",
                            " that",
                            ",",
                            " we",
                            " have",
                            " a",
                            " few",
                            " more",
                            " examples",
                            " of",
                            " how",
                            " advertising",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " explicit",
                            " goal",
                            " is",
                            " to",
                            " sell",
                            " products",
                            ",",
                            " while",
                            " also",
                            " having",
                            " the",
                            " implicit",
                            " goal",
                            " of",
                            " making",
                            " sure",
                            " the",
                            " current",
                            " socially",
                            " dominant",
                            " group",
                            " remains",
                            " in",
                            " power",
                            " and",
                            " the",
                            " status",
                            " quo",
                            " is",
                            " maintained",
                            ".",
                            "\n",
                            "\n",
                            "Sony",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " racist",
                            " ad"
                        ],
                        "dataIndex": null,
                        "index": "77000",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 42.58,
                        "maxValueTokenIndex": 56,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            42.58,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-11T00:06:25.688Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 44.613,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        },
        {
            "modelId": "gpt2-small",
            "layer": "8-res_fs98304-jb",
            "index": "36819",
            "description": "references to various types of educational or institutional frameworks",
            "explanationModelName": "gpt-4o-mini",
            "typeName": "oai_token-act-pair",
            "cosine_similarity": 0.4720591339994542,
            "neuron": {
                "modelId": "gpt2-small",
                "layer": "8-res_fs98304-jb",
                "index": "36819",
                "sourceSetName": "res_fs98304-jb",
                "creatorId": null,
                "createdAt": "2024-07-10T23:17:20.863Z",
                "maxActApprox": 9.08,
                "hasVector": false,
                "vector": [],
                "vectorLabel": null,
                "vectorDefaultSteerStrength": 10,
                "hookName": null,
                "topkCosSimIndices": [
                    36819,
                    27504,
                    29349,
                    73305,
                    90627,
                    5153,
                    94870,
                    20575,
                    81240,
                    92629,
                    30939,
                    20532,
                    94271,
                    54877,
                    87745,
                    74536,
                    64760,
                    95329,
                    3582,
                    10769,
                    87992,
                    65711,
                    7099,
                    8563,
                    57646
                ],
                "topkCosSimValues": [
                    1,
                    0.4184,
                    0.3677,
                    0.3662,
                    0.3658,
                    0.3554,
                    0.3549,
                    0.3522,
                    0.3516,
                    0.3503,
                    0.3487,
                    0.3459,
                    0.3441,
                    0.3425,
                    0.338,
                    0.3341,
                    0.3293,
                    0.3287,
                    0.328,
                    0.3227,
                    0.3218,
                    0.3181,
                    0.3178,
                    0.3158,
                    0.3147
                ],
                "neuron_alignment_indices": [
                    294,
                    71,
                    679
                ],
                "neuron_alignment_values": [
                    0.116,
                    0.103,
                    0.096
                ],
                "neuron_alignment_l1": [
                    0.006,
                    0.005,
                    0.005
                ],
                "correlated_neurons_indices": [
                    288,
                    575,
                    146
                ],
                "correlated_neurons_pearson": [
                    0.03,
                    0.027,
                    0.024
                ],
                "correlated_neurons_l1": [
                    0.039,
                    0.033,
                    0.023
                ],
                "correlated_features_indices": [
                    36828,
                    36783,
                    36835
                ],
                "correlated_features_pearson": [
                    0.015,
                    0.006,
                    0.006
                ],
                "correlated_features_l1": [
                    0.015,
                    0.007,
                    0.007
                ],
                "neg_str": [
                    "erb",
                    "bound",
                    " earthqu",
                    "locked",
                    "bread",
                    "mel",
                    "cigarettes",
                    "col",
                    "cpu",
                    "biology"
                ],
                "neg_values": [
                    -0.594,
                    -0.594,
                    -0.574,
                    -0.571,
                    -0.568,
                    -0.56,
                    -0.559,
                    -0.548,
                    -0.517,
                    -0.514
                ],
                "pos_str": [
                    "ary",
                    " alike",
                    "ulhu",
                    "\u00e8\u0122\u0127",
                    "ierre",
                    "jriwal",
                    "aries",
                    "alam",
                    "unia",
                    " Preview"
                ],
                "pos_values": [
                    0.717,
                    0.705,
                    0.612,
                    0.592,
                    0.571,
                    0.564,
                    0.546,
                    0.546,
                    0.545,
                    0.544
                ],
                "frac_nonzero": 0.00111,
                "freq_hist_data_bar_heights": [
                    424,
                    402,
                    354,
                    319,
                    247,
                    224,
                    254,
                    182,
                    148,
                    133,
                    123,
                    109,
                    85,
                    85,
                    63,
                    54,
                    55,
                    31,
                    34,
                    29,
                    16,
                    22,
                    19,
                    18,
                    18,
                    10,
                    8,
                    4,
                    5,
                    1,
                    2,
                    5,
                    2,
                    2,
                    1,
                    1,
                    2,
                    2,
                    0,
                    1,
                    0,
                    0,
                    1,
                    0,
                    0,
                    0,
                    2,
                    0,
                    0,
                    1
                ],
                "freq_hist_data_bar_values": [
                    0.092,
                    0.273,
                    0.455,
                    0.636,
                    0.818,
                    1,
                    1.181,
                    1.363,
                    1.544,
                    1.726,
                    1.908,
                    2.089,
                    2.271,
                    2.452,
                    2.634,
                    2.816,
                    2.997,
                    3.179,
                    3.36,
                    3.542,
                    3.724,
                    3.905,
                    4.087,
                    4.268,
                    4.45,
                    4.631,
                    4.813,
                    4.995,
                    5.176,
                    5.358,
                    5.539,
                    5.721,
                    5.903,
                    6.084,
                    6.266,
                    6.447,
                    6.629,
                    6.811,
                    6.992,
                    7.174,
                    7.355,
                    7.537,
                    7.719,
                    7.9,
                    8.082,
                    8.263,
                    8.445,
                    8.626,
                    8.808,
                    8.99
                ],
                "logits_hist_data_bar_heights": [
                    5,
                    3,
                    1,
                    9,
                    17,
                    35,
                    46,
                    78,
                    131,
                    209,
                    338,
                    482,
                    606,
                    878,
                    1124,
                    1542,
                    1986,
                    2247,
                    2744,
                    3075,
                    3356,
                    3624,
                    3809,
                    3752,
                    3609,
                    3174,
                    2919,
                    2526,
                    1959,
                    1664,
                    1237,
                    934,
                    657,
                    495,
                    329,
                    225,
                    154,
                    111,
                    67,
                    50,
                    19,
                    12,
                    5,
                    8,
                    2,
                    2,
                    0,
                    0,
                    0,
                    2
                ],
                "logits_hist_data_bar_values": [
                    -0.581,
                    -0.555,
                    -0.528,
                    -0.502,
                    -0.476,
                    -0.45,
                    -0.424,
                    -0.397,
                    -0.371,
                    -0.345,
                    -0.319,
                    -0.292,
                    -0.266,
                    -0.24,
                    -0.214,
                    -0.188,
                    -0.161,
                    -0.135,
                    -0.109,
                    -0.083,
                    -0.056,
                    -0.03,
                    -0.004,
                    0.022,
                    0.048,
                    0.075,
                    0.101,
                    0.127,
                    0.153,
                    0.18,
                    0.206,
                    0.232,
                    0.258,
                    0.285,
                    0.311,
                    0.337,
                    0.363,
                    0.389,
                    0.416,
                    0.442,
                    0.468,
                    0.494,
                    0.521,
                    0.547,
                    0.573,
                    0.599,
                    0.625,
                    0.652,
                    0.678,
                    0.704
                ],
                "decoder_weights_dist": [],
                "umap_cluster": null,
                "umap_log_feature_sparsity": null,
                "umap_x": null,
                "umap_y": null,
                "explanations": [
                    {
                        "description": " terms related to academic and scientific contexts",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "references to various types of educational or institutional frameworks",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    },
                    {
                        "description": "terms related to academic disciplines and research proposals",
                        "explanationModelName": "gpt-4o-mini",
                        "typeName": "oai_token-act-pair"
                    }
                ],
                "activations": [
                    {
                        "id": "clyggmz6s374110ex62pnweml",
                        "tokens": [
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " leave",
                            " loose",
                            " ends",
                            ".",
                            "\n",
                            "\n",
                            "Cut",
                            ",",
                            " cut",
                            ",",
                            " cut",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " reason",
                            ",",
                            " I",
                            " think",
                            ",",
                            " that",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " important",
                            " to",
                            " begin",
                            " with",
                            " the",
                            " NS",
                            "FD",
                            "DR",
                            "IG",
                            " is",
                            " that",
                            " it",
                            " is",
                            " easier",
                            " (",
                            "for",
                            " me",
                            ")",
                            " to",
                            " trim",
                            " and",
                            " cut",
                            " material",
                            " than",
                            " it",
                            " is",
                            " to",
                            " add",
                            ".",
                            " It",
                            " is",
                            " true",
                            " that",
                            " some",
                            " agencies",
                            " are",
                            " asking",
                            " different",
                            " kinds",
                            " of",
                            " questions",
                            ".",
                            " The",
                            " Social",
                            " Science",
                            " Research",
                            " Council",
                            ",",
                            " for",
                            " example",
                            ",",
                            " wants",
                            " Mellon",
                            " International",
                            " Diss",
                            "ertation",
                            " Research",
                            " Fellowship",
                            " proposals",
                            " to",
                            " draw",
                            " heavily",
                            " on",
                            " inter",
                            "dis",
                            "cipl",
                            "in",
                            "arity",
                            ",",
                            " so",
                            " I",
                            " wrote",
                            " about",
                            " feminist",
                            " geography",
                            ",",
                            " urban",
                            " studies",
                            ",",
                            " global",
                            " health",
                            ",",
                            " and",
                            " the",
                            " sociology",
                            " of",
                            " space",
                            ".",
                            " The",
                            " Wen",
                            "ner",
                            "-",
                            "G",
                            "ren",
                            " Diss",
                            "ertation",
                            " Field",
                            "work",
                            " Grant"
                        ],
                        "dataIndex": null,
                        "index": "36819",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.08,
                        "maxValueTokenIndex": 123,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.058,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.08,
                            0,
                            0.262,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:30.108Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.08,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggmz6u374n10ex9zbu39mf",
                        "tokens": [
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " leave",
                            " loose",
                            " ends",
                            ".",
                            "\n",
                            "\n",
                            "Cut",
                            ",",
                            " cut",
                            ",",
                            " cut",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " reason",
                            ",",
                            " I",
                            " think",
                            ",",
                            " that",
                            " it",
                            "\u00e2\u0122",
                            "\u013b",
                            "s",
                            " important",
                            " to",
                            " begin",
                            " with",
                            " the",
                            " NS",
                            "FD",
                            "DR",
                            "IG",
                            " is",
                            " that",
                            " it",
                            " is",
                            " easier",
                            " (",
                            "for",
                            " me",
                            ")",
                            " to",
                            " trim",
                            " and",
                            " cut",
                            " material",
                            " than",
                            " it",
                            " is",
                            " to",
                            " add",
                            ".",
                            " It",
                            " is",
                            " true",
                            " that",
                            " some",
                            " agencies",
                            " are",
                            " asking",
                            " different",
                            " kinds",
                            " of",
                            " questions",
                            ".",
                            " The",
                            " Social",
                            " Science",
                            " Research",
                            " Council",
                            ",",
                            " for",
                            " example",
                            ",",
                            " wants",
                            " Mellon",
                            " International",
                            " Diss",
                            "ertation",
                            " Research",
                            " Fellowship",
                            " proposals",
                            " to",
                            " draw",
                            " heavily",
                            " on",
                            " inter",
                            "dis",
                            "cipl",
                            "in",
                            "arity",
                            ",",
                            " so",
                            " I",
                            " wrote",
                            " about",
                            " feminist",
                            " geography",
                            ",",
                            " urban",
                            " studies",
                            ",",
                            " global",
                            " health",
                            ",",
                            " and",
                            " the",
                            " sociology",
                            " of",
                            " space",
                            ".",
                            " The",
                            " Wen",
                            "ner",
                            "-",
                            "G",
                            "ren",
                            " Diss",
                            "ertation",
                            " Field",
                            "work",
                            " Grant"
                        ],
                        "dataIndex": null,
                        "index": "36819",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 9.08,
                        "maxValueTokenIndex": 123,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            5.058,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            9.08,
                            0,
                            0.262,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:30.108Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": 7.264,
                        "binMax": 9.08,
                        "binContains": 0,
                        "qualifyingTokenIndex": null
                    },
                    {
                        "id": "clyggmz6s374210excv7avn35",
                        "tokens": [
                            " differ",
                            " in",
                            " a",
                            " default",
                            " value",
                            " are",
                            " a",
                            " redef",
                            "inition",
                            ",",
                            " not",
                            " an",
                            " overload",
                            ".)",
                            " But",
                            " because",
                            " a",
                            " parameter",
                            " pack",
                            " can",
                            " be",
                            " empty",
                            " (",
                            "and",
                            " will",
                            " be",
                            " in",
                            " this",
                            " use",
                            " case",
                            "),",
                            " the",
                            " two",
                            " definitions",
                            " are",
                            " really",
                            " the",
                            " same",
                            " in",
                            " practice",
                            ".",
                            " It",
                            " doesn",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " matter",
                            " which",
                            " definition",
                            " gets",
                            " the",
                            " parameter",
                            " pack",
                            " because",
                            ",",
                            " as",
                            " we",
                            " just",
                            " discussed",
                            ",",
                            " it",
                            " will",
                            " be",
                            " empty",
                            ".",
                            "\n",
                            "\n",
                            "The",
                            " reason",
                            " that",
                            " the",
                            " compiler",
                            " rejects",
                            " a",
                            " redef",
                            "inition",
                            " is",
                            " because",
                            " it",
                            " won",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            " know",
                            " which",
                            " function",
                            " to",
                            " call",
                            ",",
                            " the",
                            " original",
                            " or",
                            " the",
                            " redef",
                            "inition",
                            ".",
                            " By",
                            " using",
                            " the",
                            " empty",
                            " parameter",
                            " pack",
                            " trick",
                            " to",
                            " fool",
                            " the",
                            " compiler",
                            " into",
                            " thinking",
                            " that",
                            " these",
                            " are",
                            " two",
                            " different",
                            " definitions",
                            " when",
                            " in",
                            " practice",
                            " they",
                            " really",
                            " aren",
                            "\u00e2\u0122",
                            "\u013b",
                            "t",
                            ",",
                            " aren",
                            "\u00e2\u0122"
                        ],
                        "dataIndex": null,
                        "index": "36819",
                        "layer": "8-res_fs98304-jb",
                        "modelId": "gpt2-small",
                        "dataSource": null,
                        "maxValue": 8.443,
                        "maxValueTokenIndex": 94,
                        "minValue": 0,
                        "values": [
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            1.366,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            2.212,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            8.443,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        "dfaValues": [],
                        "dfaTargetIndex": null,
                        "dfaMaxValue": null,
                        "creatorId": "cljj57d3c000076ei38vwnv35",
                        "createdAt": "2024-07-10T23:17:30.108Z",
                        "lossValues": [],
                        "logitContributions": null,
                        "binMin": -1,
                        "binMax": 9.08,
                        "binContains": -1,
                        "qualifyingTokenIndex": null
                    }
                ]
            }
        }
    ],
    "resultsCount": 20,
    "hasMore": true,
    "nextOffset": 20
}